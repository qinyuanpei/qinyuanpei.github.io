[{"title":"ASP.NET Core gRPC 健康检查的探索与实现","date":"2021-06-01T11:37:36.000Z","path":"posts/1657075397/","text":"各位朋友，大家好，欢迎大家关注我的博客。在上一篇 博客 中，博主和大家分享了gRPC的拦截器在日志记录方面的简单应用，今天我们继续来探索gRPC在构建微服务架构方面的可能性。其实，从博主个人的理解而言，不管我们的微服务架构是采用RPC方式还是采用RESTful方式，我们最终要面对的问题本质上都是一样的，博主这里将其归纳为：服务划分、服务编写 和 服务治理。首先，服务划分决定了每一个服务的上下文边界以及服务颗粒度大小，如果按照领域驱动设计(DDD)的思想来描述微服务，我认为它更接近于限界上下文(BoundedContext)的概念。其次，服务编写决定了每一个服务的具体实现方式，譬如是采用无状态的RESTful风格的API，还是采用强类型的、基于代理的RPC风格的API。最后，服务治理是微服务架构中永远避不开的话题，服务注册、服务发现、健康检查、日志监控等等一切的话题，其实都是在围绕着服务治理而展开，尤其是当我们编写了一个又一个的服务以后，此时该如何管理这些浩如“星”海的服务呢？所以，在今天这篇博客中，博主想和大家一起探索下gRPC的健康检查，希望能给大家带来一点启发。 健康检查-服务注册-服务发现示意图 关于“健康检查”，大家都知道的一点是，它起到一种“防微杜渐”的作用。不知道大家还记不记得，语文课本里的经典故事《扁鹊见蔡桓公》，扁鹊一直在告知蔡桓公其病情如何，而蔡桓公讳疾忌医，直至病入骨髓、不治而亡。其实，对应到我们的领域知识，后端依赖的各种服务譬如数据库、消息队列、Redis、API等等，都需要这样一个“扁鹊”来实时地“望闻问切”，当发现问题的时候及时地采取相应措施，不要像“蔡桓公”一样病入骨髓，等到整个系统都瘫痪了，这时候火急火燎地去“救火”，难免会和蔡桓公一样，发出“悔之晚矣”的喟叹。当我们决定使用gRPC来构建微服务架构的时候，我们如何确保这些服务一直是可用的呢？所以，提供一种针对gRPC服务的健康检查方案就会显得非常迫切。这里，博主主要为大家介绍两种实现方式，它们分别是：基于IHostedService的实现方式 以及 基于Consul的实现方式。 基于 IHostedService 的实现方式第一种方式，主要是利用IHostedService可以在程序后台执行的特点，搭配Timer就可以实现定时轮询。在 gRPC 的 官方规范 中，提供了一份Protocol Buffers的声明文件，它规定了一个健康检查服务必须实现Check()和Watch()两个方法。既然是官方定义好的规范，建议大家不要修改这份声明文件，我们直接沿用即可： 123456789101112131415161718192021syntax = \"proto3\";package grpc.health.v1;message HealthCheckRequest &#123; string service = 1;&#125;message HealthCheckResponse &#123; enum ServingStatus &#123; UNKNOWN = 0; SERVING = 1; NOT_SERVING = 2; &#125; ServingStatus status = 1;&#125;service Health &#123; rpc Check(HealthCheckRequest) returns (HealthCheckResponse); rpc Watch(HealthCheckRequest) returns (stream HealthCheckResponse);&#125; 接下来，我们需要实现对应的HealthCheckService: 12345678910111213141516171819202122232425public class HealthCheckService : Health.HealthBase&#123; public override Task&lt;HealthCheckResponse&gt; Check( HealthCheckRequest request, ServerCallContext context ) &#123; // TODO: 在这里添加更多的细节 return Task.FromResult(new HealthCheckResponse() &#123; Status = HealthCheckResponse.Types.ServingStatus.Serving &#125;); &#125; public override async Task Watch( HealthCheckRequest request, IServerStreamWriter&lt;HealthCheckResponse&gt; responseStream, ServerCallContext context ) &#123; // TODO: 在这里添加更多的细节 await responseStream.WriteAsync(new HealthCheckResponse()&#123; Status = HealthCheckResponse.Types.ServingStatus.Serving &#125;); &#125;&#125; 接下来，我们需要实现HostedHealthCheckService，它实现了IHostedService接口，并在其中调用HealthCheckService: 12345678910111213141516171819202122232425262728293031public class HostedHealthCheckService : IHostedService&#123; private Timer _timer = null; private readonly ILogger&lt;HostedHealthCheckService&gt; _logger; public HostedHealthCheckService(ILogger&lt;HostedHealthCheckService&gt; logger) &#123; _logger = logger; &#125; public Task StartAsync(CancellationToken cancellationToken) &#123; _logger.LogInformation($\"&#123;nameof(HostedHealthCheckService)&#125; start running....\"); _timer = new Timer(DoCheck, null, TimeSpan.Zero, TimeSpan.FromSeconds(5)); return Task.CompletedTask; &#125; public Task StopAsync(CancellationToken cancellationToken) &#123; _logger.LogInformation($\"&#123;nameof(HostedHealthCheckService)&#125; stop running....\"); _timer?.Change(Timeout.Infinite, 0); return Task.CompletedTask; &#125; private void DoCheck(object state) &#123; using var channel = GrpcChannel.ForAddress(\"https://localhost:5001\"); ; var client = new Health.HealthClient(channel); client.Check(new HealthCheckRequest() &#123; Service = \"https://localhost:5001\" &#125;); &#125;&#125; 接下来，是大家非常熟悉的依赖注入环节： 123456789101112131415// ConfigureServicespublic void ConfigureServices(IServiceCollection services)&#123; services.AddGrpc(options =&gt; options.Interceptors.Add&lt;GrpcServerLoggingInterceptor&gt;()); services.AddHostedService&lt;HostedHealthCheckService&gt;();&#125;// Configurepublic void Configure(IApplicationBuilder app, IWebHostEnvironment env)&#123; app.UseEndpoints(endpoints =&gt; &#123; endpoints.MapGrpcService&lt;HealthCheckService&gt;(); &#125;);&#125; 如果大家对上一篇博客中的拦截器还有印象，对于下面的结果应该会感到非常亲切： 基于 IHostedService 的 gRPC 健康检查 除此以外，我们还可以直接安装第三方库：Grpc.HealthCheck。此时，我们需要继承HealthServiceImpl类并重写其中的Check()和Watch()方法: 123456789101112131415161718192021222324252627public class HealthCheckService : HealthServiceImpl&#123; public override Task&lt;HealthCheckResponse&gt; Check( HealthCheckRequest request, ServerCallContext context ) &#123; // TODO: 在这里添加更多的细节 return Task.FromResult(new HealthCheckResponse() &#123; Status = HealthCheckResponse.Types.ServingStatus.Serving &#125;); &#125; public override async Task Watch( HealthCheckRequest request, IServerStreamWriter&lt;HealthCheckResponse&gt; responseStream, ServerCallContext context ) &#123; // TODO: 在这里添加更多的细节 await responseStream.WriteAsync(new HealthCheckResponse() &#123; Status = HealthCheckResponse.Types.ServingStatus.Serving &#125;); &#125;&#125; 接下来，我们只需要在HostedHealthCheckService调用它即可，这个非常简单。 故，无需博主多言，相信屏幕前的你都能写得出来，如果写不出来，参考博主给出得实现即可(逃！ 基于 Consul 的实现方式Consul 是一个由 HashiCorp 提供的产品，它提供了服务注册、服务发现、健康检查、键值存储等等的特性。这里，我们通过集成它的SDK来实现gRPC服务的服务注册、服务发现、健康检查，从某种程度上来讲，它无形中帮助我们实现了客户端的负载均衡，因为我们可以将每一个服务的终结点都注册到Consul中，而Consul的健康检查则可以定时移除那些不可用的服务。所以，客户端获得的终结点实际上都是可用的终结点。 首先，我们需要安装第三方库：Consul。接下来，我们可需要通过Docker安装一下Consul: 12docker pull consuldocker run --name consul -d -p 8500:8500 consul 默认情况下，Consul的端口号为：8500，我们可以直接访问：http://localhost:8500： Consul 界面效果展示 接下来，为了让Startup类看起来清爽一点，首先，我们先来写一点扩展方法： 123456789101112131415// 为指定的gRPC服务添加健康检查public static void AddGrpcHealthCheck&lt;TService&gt;(this IServiceCollection services)&#123; var configuration = services.BuildServiceProvider().GetService&lt;IConfiguration&gt;(); // 注册ConsulClient services.AddSingleton&lt;IConsulClient, ConsulClient&gt;(_ =&gt; new ConsulClient(consulConfig =&gt; &#123; var baseUrl = configuration.GetValue&lt;string&gt;(\"Consul:BaseUrl\"); consulConfig.Address = new Uri(baseUrl); &#125;)); // 注册gRPC服务 RegisterConsul&lt;TService&gt;(services).Wait();&#125; 其中，RegisterConsul()方法负责告诉Consul，某个服务对应的IP和端口号分别是多少，采用什么样的方式进行健康检查。 不过，由于Consul默认不支持gRPC的健康检查，所以，我们使用了更为常见的基于TCP方式的健康检查。你可以认为，只要服务器连接畅通，gRPC服务就是健康的。 1234567891011121314151617181920212223242526272829303132333435// 注册指定服务到Consulprivate static async Task RegisterConsul&lt;TService&gt;(IServiceCollection services)&#123; var serverHost = GetLocalIP(); var serverPort = services.BuildServiceProvider().GetService&lt;IConfiguration&gt;().GetValue&lt;int&gt;(\"gRPC:Port\"); await RegisterConsul&lt;TService&gt;(services, serverHost, serverPort);&#125;// 注册指定服务到Consulprivate static async Task RegisterConsul&lt;TService&gt;( IServiceCollection services, string serverHost, int serverPort)&#123; var client = services.BuildServiceProvider().GetService&lt;IConsulClient&gt;(); var registerID = $\"&#123;typeof(TService).Name&#125;-&#123;serverHost&#125;:&#123;serverPort&#125;\"; await client.Agent.ServiceDeregister(registerID); var result = await client.Agent.ServiceRegister(new AgentServiceRegistration() &#123; ID = registerID, Name = typeof(TService).Name, Address = serverHost, Port = serverPort, Check = new AgentServiceCheck &#123; TCP = $\"&#123;serverHost&#125;:&#123;serverPort&#125;\", Status = HealthStatus.Passing, DeregisterCriticalServiceAfter = TimeSpan.FromSeconds(10), Interval = TimeSpan.FromSeconds(10), Timeout = TimeSpan.FromSeconds(5) &#125;, Tags = new string[] &#123; \"gRpc\" &#125; &#125;) ;&#125; 对于Consul中的健康检查，更常用的是基于HTTP的健康检查，简单来说，就是我们提供一个接口，供Consul来调用，我们可以去设置请求的头(Header)、消息体(Body)、方法(Method)等等。所以，对于这里的实现，你还可以替换为更一般的实现，即提供一个API接口，然后在这个接口中调用gRPC的客户端。除此以外，如果你擅长写脚本，Consul同样支持脚本级别的健康检查。 在这里，博主水平扩展(复制)了两套服务，它们分别被部署在5001和6001两个端口上，通过Consul能达到什么效果呢？我们一起来看一下： 1234567891011121314151617// ConfigureServicespublic void ConfigureServices(IServiceCollection services)&#123; services.AddGrpc(options =&gt; options.Interceptors.Add&lt;GrpcServerLoggingInterceptor&gt;()); services.AddGrpcHealthCheck&lt;GreeterService&gt;(); services.AddGrpcHealthCheck&lt;CalculatorService&gt;();&#125;// Configurepublic void Configure(IApplicationBuilder app, IWebHostEnvironment env)&#123; app.UseEndpoints(endpoints =&gt; &#123; endpoints.MapGrpcService&lt;GreeterService&gt;(); endpoints.MapGrpcService&lt;CalculatorService&gt;(); &#125;);&#125; OK，此时，我们注意到Consul中有两个服务注册进去，它们分别是：GreeterService 和 CalculatorService： gRPC 服务成功注册到 Consul 中 以其中一个CalculatorService为例，我们可以注意到，它的确注册了5001和6001两个实例： CalculatorService 的两个实例 至此，我们就完成了基于Consul的健康检查，在这里，图中的绿色标记表示服务可用。 关于 gRPC 的引申话题其实，写到这里的时候，这篇博客就该接近尾声啦，因为对于 gRPC 健康检查的探索基本都已找到答案，可我还是想聊一聊关于 gRPC 的引申话题。理由特别简单，就是在我看来，接下来要讲的这点内容，完全撑不起一篇博客的篇幅，索性就在这篇博客里顺带一提。我打算分享两个话题，其一，是 gRPC 客户端的负载均衡；其二，是 gRPC 接口的测试工具。 gRPC 客户端的负载均衡截止到目前为止，结合Consul我们已经实现了服务注册和服务发现两个功能。通过调研我们可以发现，针对服务器端的gRPC的负载均衡，目前主要有Nginx和Envoy两种方案，这两种相方案对要更复杂一点，博主目前所在的公司，在gRPC的负载均衡上感觉是个空白，这算是博主想要研究gRPC的一个主要原因。而在这里，由于Consul里注册了所有gRPC服务的终结点信息，所以，我们更容易想到的，其实是客户端的负载均衡，具体怎么实现呢？我们一起看一下： 12345678910111213// 从Consul中获取服务终结点信息var consulClient = serviceProvider.GetService&lt;IConsulClient&gt;();var serviceName = typeof(TGrpcClient).Name.Replace(\"Client\", \"Service\");var services = await consulClient.Health.Service(serviceName, string.Empty, true);var serviceUrls = services.Response.Select(s =&gt; $\"&#123;s.Service.Address&#125;:&#123;s.Service.Port&#125;\").ToList();if (serviceUrls == null || !serviceUrls.Any()) throw new Exception($\"Please make sure service &#123;serviceName&#125; is registered in consul\");// 构造Channel和Clientvar serviceUrl = serviceUrls[new Random().Next(0, serviceUrls.Count - 1)];var channel = GrpcChannel.ForAddress($\"https://&#123;serviceUrl&#125;\");var client = new var client = new Calculator.CalculatorClient(channel);await client.CalcAsync(new CalculatorRequest() &#123; Num1 = 10, Op = \"+\", Num2 = 12 &#125;); 可以看出，基本思路就是从Consul里拿到对应服务的终结点信息，然后构造出GrpcChannel，再通过GrpcChannel构造出Client即可。 不过，博主觉得这个过程有一点繁琐，我们有没有办法让这些细节隐藏起来呢？于是，我们有了下面的改进方案： 1234567891011121314151617181920public static async Task&lt;TGrpcClient&gt; GetGrpcClientAsync&lt;TGrpcClient&gt;( this IServiceProvider serviceProvider)&#123; var consulClient = serviceProvider.GetService&lt;IConsulClient&gt;(); var serviceName = typeof(TGrpcClient).Name.Replace(\"Client\", \"Service\"); var services = await consulClient.Health.Service(serviceName, string.Empty, true); var serviceUrls = services.Response.Select(s =&gt; $\"&#123;s.Service.Address&#125;:&#123;s.Service.Port&#125;\").ToList(); if (serviceUrls == null || !serviceUrls.Any()) throw new Exception($\"Please make sure service &#123;serviceName&#125; is registered in consul\"); var serviceUrl = serviceUrls[new Random().Next(0, serviceUrls.Count - 1)]; var channel = GrpcChannel.ForAddress($\"https://&#123;serviceUrl&#125;\"); var constructorInfo = typeof(TGrpcClient).GetConstructor(new Type[] &#123; typeof(GrpcChannel) &#125;); if (constructorInfo == null) throw new Exception($\"Please make sure &#123;typeof(TGrpcClient).Name&#125; is a gRpc client\"); var clientInstance = (TGrpcClient)constructorInfo.Invoke(new object[] &#123; channel &#125;); return clientInstance;&#125; 现在，有没有觉得简单一点？完美！ 12var client = await serviceProvider.GetGrpcClientAsync&lt;CalculatorClient&gt;();await client.CalcAsync(new CalculatorRequest() &#123; Num1 = 1, Num2 = 2, Op = \"+\" &#125;); gRPC 接口的测试工具我猜，大多数看到这个标题会一脸鄙夷，心里大概会想，就测试工具这种东西值得特地写出来吗？诚然，以前写API接口的时候，大家都是用 Postman 或者 Apifox 这样的工具来进行测试的，可是突然有一天你要调试一个gRPC的接口，你总不能每次都调用客户端啊，所以，这里要给大家推荐两个gRPC接口的测试工具，它们分别是: grpcurl 和 grpcui，它们都出自同一个人 FullStory 之手，基于Go语言开发，简单介绍下使用方法： 123456// grpcurlbrew install grpcurl// grpcuigo get github.com/fullstorydev/grpcui/...go install github.com/fullstorydev/grpcui/cmd/grpcui 虽然这个说明简单而直白，可我还是没能装好，我不得不祭出Docker这个神器，果然它不会令我失望： 1docker run -e GRPCUI_SERVER=localhost:5001 -p 8080:8080 wongnai/grpcui 这里有两个重要的参数，其中，8080是grpcui的服务地址，可以按个人喜好进行修改，GRPCUI_SERVER是gRPC服务地址，该工具运行效果如下： gRPCUI 接口测试工具 对于使用者来说，我们只需要选择服务(service)、方法(rpc)、然后填入参数即可，个人感觉非常方便。 本文小结本文探索并实现了gRPC服务健康检查，主要提供了两种思路：基于IHostedService + Timer的轮询的方案 以及 基于Consul的集服务注册、服务发现、健康检查于一身的方案。特别地，对于后者而言，我们可以顺理成章地联想到客户端的负载均衡，其原理是：Consul中注册了所有gRPC服务的终结点信息，通过IConsulClient可以拿到所有可用的终结点信息，只要以此为基础来构建GrpcChannel即可。根据这个原理，我们引申出了gRPC客户端负载均衡的相关话题，这里我们采用的是随机选择一个终结点信息的做法，事实上，按照一般负载均衡的理论，我们还可以采取轮询、加权、Hash等等的算法，大家可以按照自己的业务场景来选择合适的方法。最后，我们简单介绍了下gRPC接口测试方面的内容，它可以帮助我们更高效地编写、验证gRPC接口。好了，以上就是这篇博客的全部内容啦，欢迎大家在评论区留言、参与讨论，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"gRPC","slug":"gRPC","permalink":"https://qinyuanpei.github.io/tags/gRPC/"},{"name":"微服务","slug":"微服务","permalink":"https://qinyuanpei.github.io/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"健康检查","slug":"健康检查","permalink":"https://qinyuanpei.github.io/tags/%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5/"},{"name":"Consul","slug":"Consul","permalink":"https://qinyuanpei.github.io/tags/Consul/"}]},{"title":"ASP.NET Core gRPC 拦截器的使用技巧分享","date":"2021-05-26T09:03:35.000Z","path":"posts/1679688265/","text":"gRPC是微软在.NET Core 及其后续版本中主推的 RPC 框架，它使用 Google 的 Protocol Buffers 作为序列化协议，使用 HTTP/2 作为通信协议，具有跨语言、高性能、双向流式调用等优点。考虑到，接下来要参与的是，一个以gRPC为核心而构建的微服务项目。因此，博主准备调研一下gRPC的相关内容，而首当其冲的，则是从 .NET Core 3.1 开始就有的拦截器，它类似于ASP.NET Core中的过滤器和中间件，体现了一种面向切面编程(AOP)的思想，非常适合在RPC服务调用的时候做某种统一处理，譬如参数校验、身份验证、日志记录等等。在今天这篇博客中，博主主要和大家分享的是，利用 .NET Core gRPC 中的拦截器实现日志记录的简单技巧，希望能给大家带来一点启发。 开源、多语言、高性能的 gRPC 关于 Interceptor 类Interceptor类是 gRPC 服务拦截器的基类，它本身是一个抽象类，其中定义了下面的虚方法： 123456789public virtual AsyncClientStreamingCall&lt;TRequest, TResponse&gt; AsyncClientStreamingCall&lt;TRequest, TResponse&gt;();public virtual AsyncDuplexStreamingCall&lt;TRequest, TResponse&gt; AsyncDuplexStreamingCall&lt;TRequest, TResponse&gt;();public virtual AsyncUnaryCall&lt;TResponse&gt; AsyncUnaryCall&lt;TRequest, TResponse&gt;();public virtual TResponse BlockingUnaryCall&lt;TRequest, TResponse&gt;();public virtual Task&lt;TResponse&gt; ClientStreamingServerHandler&lt;TRequest, TResponse&gt;();public virtual AsyncServerStreamingCall&lt;TResponse&gt; AsyncServerStreamingCall&lt;TRequest, TResponse&gt;();public virtual Task DuplexStreamingServerHandler&lt;TRequest, TResponse&gt;();public virtual Task ServerStreamingServerHandler&lt;TRequest, TResponse&gt;();public virtual Task&lt;TResponse&gt; UnaryServerHandler&lt;TRequest, TResponse&gt;(); 整体而言，如果从通信方式上来划分，可以分为：流式调用 和 普通调用；而如果从使用方来划分，则可以分为：客户端 和 服务端。进一步讲的话，针对流式调用，它还分为：”单向流“ 和 “双向流“。关于这些细节上的差异，大家可以通过 gRPC 的 官方文档 来了解，这里我们给出的是每一种方法对应的用途： 方法名 描述 AsyncClientStreamingCall 拦截异步客户端流式调用 AsyncDuplexStreamingCall 拦截双向流式调用 AsyncUnaryCall 拦截异步普通调用 BlockingUnaryCall 拦截阻塞普通调用 AsyncServerStreamingCall 拦截异步服务端流式调用 ClientStreamingServerHandler 拦截客户端流式调用的服务端处理程序 DuplexStreamingServerHandler 拦截双向流式调用的服务端处理程序 ServerStreamingServerHandler 拦截服务端流式调用的服务端处理程序 UnaryServerHandler 拦截普通调用的服务端处理程序 实现一个拦截器好了，下面我们一起实现一个拦截器。这里，我们使用的是微软官方的例子： 12345678910111213141516public class GreeterService : Greeter.GreeterBase&#123; private readonly ILogger&lt;GreeterService&gt; _logger; public GreeterService(ILogger&lt;GreeterService&gt; logger) &#123; _logger = logger; &#125; public override Task&lt;HelloReply&gt; SayHello(HelloRequest request, ServerCallContext context) &#123; return Task.FromResult(new HelloReply &#123; Message = \"Hello \" + request.Name &#125;); &#125;&#125; 服务器端实现服务器端的普通调用拦截，我们需要重写的方法是UnaryServerHandler: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public class GRPCServerLoggingInterceptor : Interceptor&#123; private readonly ILogger&lt;GRPCServerLoggingInterceptor&gt; _logger; public GRPCServerLoggingInterceptor(ILogger&lt;GRPCServerLoggingInterceptor&gt; logger) &#123; _logger = logger; &#125; // 重写 UnaryServerHandler() 方法 public override Task&lt;TResponse&gt; UnaryServerHandler&lt;TRequest, TResponse&gt;( TRequest request, ServerCallContext context, UnaryServerMethod&lt;TRequest, TResponse&gt; continuation ) &#123; var builder = new StringBuilder(); // Call gRPC begin builder.AppendLine($\"Call gRPC &#123;context.Host&#125;/&#123;context.Method&#125; begin.\"); // Logging Request builder.AppendLine(LogRequest(request)); // Logging Response var reply = continuation(request, context); var response = reply.Result; var exception = reply.Exception; builder.AppendLine(LogResponse(response, exception)); // Call gRPC finish builder.AppendLine($\"Call gRPC &#123;context.Host&#125;/&#123;context.Method&#125; finish.\"); _logger.LogInformation(builder.ToString()); return reply; &#125; // 记录gRPC请求 private string LogRequest&lt;TRequest&gt;(TRequest request) &#123; var payload = string.Empty; if (request is IMessage) payload = JsonConvert.SerializeObject( (request as IMessage) .Descriptor.Fields.InDeclarationOrder() .ToDictionary(x =&gt; x.Name, x =&gt; x.Accessor.GetValue(request as IMessage)) ); return $\"Send request of &#123;typeof(TRequest)&#125;:&#123;payload&#125;\"; &#125; // 记录gRPC响应 private string LogResponse&lt;TResponse&gt;(TResponse response, AggregateException exception) &#123; var payload = string.Empty; if (exception == null) &#123; if (response is IMessage) payload = JsonConvert.SerializeObject( (response as IMessage) .Descriptor.Fields.InDeclarationOrder() .ToDictionary(x =&gt; x.Name, x =&gt; x.Accessor.GetValue(response as IMessage)) ); return $\"Receive response of &#123;typeof(TResponse)&#125;:&#123;payload&#125;\"; &#125; else &#123; var errorMsgs = string.Join(\";\", exception.InnerExceptions.Select(x =&gt; x.Message)); return $\"Receive response of &#123;typeof(TResponse)&#125; throws exceptions: &#123;errorMsgs&#125;\"; &#125; &#125;&#125; 对于gRPC而言，每一个由.proto声明文件生成的类，都带有一个叫做Descriptor的属性，我们可以利用这个属性获得gRPC请求和响应的详细信息。所以，在LogRequest()和LogResponse()两个方法中，我们均使用了这一思路来记录gRPC的报文信息，因为传输层的gRPC使用了二进制作为数据载体，这可以说是一种用可读性换取高效率的做法，不过幸运的是，我们在这里实现了这个小目标。 接下来，为了让这个拦截器真正生效，我们还需要修改一下Startup类中注册gRPC这部分的代码： 1services.AddGrpc(options =&gt; options.Interceptors.Add&lt;GRPCServerLoggingInterceptor&gt;()); 此时，我们可以得到下面的结果： gRPC服务器端拦截器效果展示 客户端实现客户端的普通调用拦截，我们需要重写的方法是AsyncUnaryCall()，依样画葫芦即可： 123456789101112131415161718192021222324252627282930public class GRPCClientLoggingInterceptor : Interceptor&#123; // 重写 AsyncUnaryCall() 方法 public override AsyncUnaryCall&lt;TResponse&gt; AsyncUnaryCall&lt;TRequest, TResponse&gt;( TRequest request, ClientInterceptorContext&lt;TRequest, TResponse&gt; context, AsyncUnaryCallContinuation&lt;TRequest, TResponse&gt; continuation ) &#123; var builder = new StringBuilder(); // Call gRPC begin builder.AppendLine($\"Call gRPC &#123;context.Host&#125;/&#123;context.Method&#125; begin.\"); // Logging Request builder.AppendLine(LogRequest(request)); // Logging Response var reply = continuation(request, context); var response = reply.ResponseAsync.Result; var exception = reply.ResponseAsync.Exception; builder.AppendLine(LogResponse(response, exception)); // Call gRPC finish builder.AppendLine($\"Call gRPC &#123;context.Host&#125;/&#123;context.Method&#125; finish.\"); Console.WriteLine(builder.ToString()); return reply; &#125;&#125; 类似地，为了让拦截器在客户端生效，我们需要这样： 123456789using Grpc.Core.Interceptors;var channel = GrpcChannel.ForAddress(\"https://localhost:5001\");// 简化写法channel.Intercept(new GRPCClientLoggingInterceptor());// 完整写法var invoker = channel.CreateCallInvoker().Intercept(new GRPCClientLoggingInterceptor());var client = new Greeter.GreeterClient(invoker);await client.SayHelloAsync(new HelloRequest() &#123; Name = \"长安书小妆\" &#125;); 此时，我们可以得到下面的结果： gRPC客户端拦截器效果展示 客户端感觉不太好的一点就是，这个Interceptor传入的必须是一个实例，考虑到拦截器内部可能会依赖类似ILogger等等的组件，建议还是通过IoC容器来取得一个拦截器的实例，然后再传入Intercept()方法中。博主所在的项目中，则是非常“土豪”地使用了PostSharp，直接走动态编织的方案，果然，“这次第，怎一个羡字了得”。当然，gRPC的客户端，其实提供了日志相关的支持，不过，我个人感觉这个有一点无力： 123456789var loggerFactory = LoggerFactory.Create(logging =&gt;&#123; logging.AddConsole(); logging.SetMinimumLevel(LogLevel.Debug);&#125;);var channel = GrpcChannel.ForAddress( \"https://localhost:5001\", new GrpcChannelOptions &#123; LoggerFactory = loggerFactory &#125;); 本文小结本文主要分享了gRPC拦截器的使用技巧，gRPC支持一元调用(UnaryCall)、流式调用(StreamingCall)、阻塞调用(BlockingCall)，因为区分客户端和服务器端，所以，实际上会有各种各样的组合方式。gRPC的拦截器实际上就是选择对应的场景去重写相应的方法，其中，拦截器的基类为Interceptor类，这里我们都是以普通的一元调用为例的，大家可以结合各自的业务场景，去做进一步的调整和优化。这里，我们使用IMessage类的Descriptor属性来“反射”报文中定义的字段，这样就实现了针对gRPC服务请求/响应的日志记录功能。关于gRPC中日志和诊断的更进一步的话题，大家可以参考微软的 官方文档 。好了，以上就是这篇博客的全部内容啦，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"gRPC","slug":"gRPC","permalink":"https://qinyuanpei.github.io/tags/gRPC/"},{"name":".NET","slug":"NET","permalink":"https://qinyuanpei.github.io/tags/NET/"},{"name":"AOP","slug":"AOP","permalink":"https://qinyuanpei.github.io/tags/AOP/"},{"name":"日志","slug":"日志","permalink":"https://qinyuanpei.github.io/tags/%E6%97%A5%E5%BF%97/"}]},{"title":"SnowNLP 使用自定义语料进行模型训练","date":"2021-05-19T21:22:41.000Z","path":"posts/1772340994/","text":"SnowNLP 是一个功能强大的中文文本处理库，它囊括了中文分词、词性标注、情感分析、文本分类、关键字/摘要提取、TF/IDF、文本相似度等诸多功能，像隐马尔科夫模型、朴素贝叶斯、TextRank等算法均在这个库中有对应的应用。如果大家仔细观察过博主的博客，就会发现博主使用了摘要提取这一功能来增强博客的SEO，即通过自然语言处理(NLP)技术，提取每一篇文章中的摘要信息。因为 SnowNLP 本身使用的语料是电商网站评论，所以，当我们面对不同的使用场景时，它自带的这个模型难免会出现“水土不服”。因此，如果我们希望得到更接近实际的结果，最好的方案是使用自定义语料进行模型训练。值得庆幸的是，这一切在 SnowNLP 中实施起来非常简单，并不需要我们去钻研那些高深莫测的算法。至此，就引出了今天这篇博客的主题，即 SnowNLP 使用自定义语料进行模型训练。 不知道大家是否还有印象，博主曾经在 《通过Python分析2020年全年微博热搜数据》 这篇文章中提到过 SnowNLP 的模型训练。当时，博主采集了整个 2020 年的微博热搜话题，因为要体现整个一年里的情感变化，博主特意找了两份微博语料，并以此为基础训练出了一个模型文件。 2020全年微博热搜情感变化趋势 那么，具体是怎么样做的呢？我们一起来看一下： 123from snownlp import sentimentsentiment.train('./train/neg60000.txt', './train/pos60000.txt')sentiment.save('weibo.marshal') 千万不要怀疑你的眼睛，因为它真的只有短短的三行代码。简单来说，我们只需要准备一个“积极”的语料文件，一个“消极”的语料文件，它就可以训练出一个模型文件。特别注意的是，如果是在Python 3.X的版本下，最终生成的模型文件的扩展名将会是.3，下图是博主这里训练出的模型文件： SnowNLP 使用自定义语料进行模型训练 好了，一旦训练出这个模型文件，我们就可以考虑替换掉 SnowNLP 的默认模型文件，我们可以在以下位置：\\Lib\\site-packages\\snownlp\\sentiment 找到下列文件。为了安全起见，我们首先将原来的模型文件重命名，然后再放入我们自己的模型文件。 SnowNLP 使用自定义模型替换默认模型 此时，我们就可以利用训练好的模型，分析某一条微博的情感倾向。这里我选取了几条我的微博，看看这个情感倾向预测的结果如何： 12345678910111213from snownlp import SnowNLPs = SnowNLP(u'我爱你，并不期待回声')s.sentiments # 0.8760737296091975s = SnowNLP(u'想找一个人，一起做老爷爷、老奶奶才做的事情，比如，替我拔一拔头上的白头发……[二哈] ​​')s.sentiments # 0.001629297651780881s = SnowNLP(u'如果两个人都不爱了，一别两宽，各生欢喜，其实是挺好的结局；可如果还有一个人爱着，对那个人来说，爱又是什么呢？')s.sentiments # 0.809651945221708s = SnowNLP(u'为了发张自拍，特意出来跑步，还有谁？[doge] ​​​')s.sentiments # 0.4041057894917053 有人说，双子座是一个白天自愈、晚上孤独的星座，我确信这是真的，因为从我出生的那一刻起，那种宏大宇宙中的孤独感就一直笼罩着我，用一句话来形容，大概就是“热闹是人家的，我什么都没有”，因为内心世界里的两个灵魂，从来没有一刻闲歇地在纠缠和撕裂。我一直都想了解一件事情，如果这些基于概率或者是公式的算法，都可以琢磨出人类某个时刻的心境，我们期望别人能懂自己是不是太过矫情，我们是真的了解自己吗？ OK，说完微博话题这个场景，我们再来说说电影评论这个场景。回想今年过年的时候，一部《你好，李焕英》，成为贺岁档电影中的一匹黑马，而相比之下，《唐人街探案3》则有点“滑铁卢”的感觉。为了搞清楚某一部电影真实的评价情况，此时，我们可以考虑使用 SnowNLP ，对影评的情感趋向进行打分。同样地，这里我们找了一部分影评语料，为 SnowNLP 训练一个单独的模型。接下来，我们不妨从豆瓣上抓取一定数量的影评，来验证下我们这里训练好的模型，这里以《唐人街探案3》为例： 从豆瓣上抓取到的电影评论 可以发现，这些影评的情感趋向介于0到0.1这个区间的数量最多，占到160以上，这意味着约有30%的观众认为这部电影是个不折不扣的烂片。 唐人街探案3豆瓣影评情感分布 目前，《唐人街探案3》 在豆瓣上的评分只有5.5分，其中，2星和3星的评价占到70%以上。由于豆瓣接口的限制，我们大概只能抓到500条左右的影评信息，可即使如此，可以看出大家对这部电影的情绪多少有一点不满。博主当时看这个电影，最大的感受是里面充斥着太多强行搞笑的东西，例如开篇机场那一场打砸抢的戏份，我完全不明白它存在的意义是什么，虽然日本演员们的表演可圈可点，可在这样一个推理和叙事都非常脆弱的故事里，大概就剩下翻来覆去重复使用的搞笑伎俩啦，你敢说医院这场戏和第一部阿香家那场戏没有相似的地方吗？更不用说，医院这场戏大家都在评论里无限吐槽啦！ 豆瓣电影-唐人街探案3 其实，对于情感，我一直不知道该怎么来讲，可能是程序员的这份理性，让我在维系亲密关系或者说的情感的时候，有时候会生出一种近乎漠然的、置身事外的错觉，换句话说，也许是那种被人称为“天性凉薄”的东西。前任同我讲，我最爱的人其实是我自己，并不是她。因为站在她的角度上来讲，她并没有感受到我给予她的爱。我该怎么回答这个问题呢？在一切看似理性的数学计算背后，人类这些极为在乎的情感到底又是什么形式？也许有一天，两个人的感情说变淡就突然变淡，不管我们曾经说过什么样的话，在那一刻都会变得苍白无力，逐年攀升的离婚率触目惊心，可我们每个人都像扑向火焰的飞蛾，在这爱与欲望无法随心所欲的世界里，被欲望裹挟着不断向前。人会变的绝情、冷漠，我们自以为那是成长，可那不过是心变硬了，可这是我们当初期待的长大吗？ 欢迎来到无法随心所欲的爱与欲望的世界 今天，听到袁隆平爷爷去世的消息，除了不断地提醒我们这代人已然老去这个事实以外，也许最大的体会应该是，我们在这个世界上追求的名利、身份和爱，最终都会无可避免地走向消亡，就如同我们身上这具躯壳一样，而真正能流传下去、泽被后世地，永远都是思想、是文化、是技术、是精神。佛家云：人死身灭，大概我们都不得不去接受这个残酷的事实，所以，请放下那些爱而不得、求而不得的执念吧，你一辈子不管遇见多少人，在某一个时候也许就会荡然无存，爱会消失、身会毁灭，这一切都是宇宙间的自然法则，与其去纠结那些“薛定谔态”的事物，不如多为这个世界做一点有意义的事情，正如尼采的那句名言，“对待生命你不妨大胆冒险一点, 因为无论如何你都要失去它”，我也许并不真正懂得人类的情感，因为它在理性面前毫无意义，世间万物毫无例外地走向那个坍塌的奇点，这难道不是一种荒凉的美感吗？ 人的心情难道不是一个黑洞 嘘，如果你读到这里，意外发现这是一篇水字数的博客，而这或许说明了一件事情，我的确是一个会懈怠、会疲倦的活生生的人。关于 SnowNLP 使用自定义语料进行模型训练的话题，这次我们就先写到这里，做数据挖掘的时候，有的人在乎的是最终的结果，而有的人享受的是整个过程，人类的情感或许是相似的，所以，学着去接受这个多样性有点多到奇葩的世界，学着去和平凡而普通的自己和解吧，欢迎大家在评论区交换想法或者观点，谢谢大家！","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://qinyuanpei.github.io/tags/NLP/"},{"name":"训练","slug":"训练","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%AD%E7%BB%83/"},{"name":"模型","slug":"模型","permalink":"https://qinyuanpei.github.io/tags/%E6%A8%A1%E5%9E%8B/"},{"name":"情感","slug":"情感","permalink":"https://qinyuanpei.github.io/tags/%E6%83%85%E6%84%9F/"}]},{"title":"假如时间有温度","date":"2021-05-03T14:00:41.000Z","path":"posts/2136925853/","text":"我一直在想，世事无常，该是一种什么样的感觉。直到我读到夏目先生的《我是猫》，先生在书中不无感慨地写道，“世事变迁就像猫的眼珠一样变幻莫测”。可此时此刻，我会不由得觉得，世事无常，更像是时间突然间有了温度，“春观夜樱，夏望繁星，秋赏满月，冬会初雪”，拥有这般温度的时间毫无疑问是浪漫的，可世事无常所带来的时间的温度，更像是某种意义上的极致，譬如从地球两极瞬移到赤道，或者是一场大爆炸后突兀着的宁静。也许，四季还是那个四季，无非是我一厢情愿的自以为是，时间真的有温度吗？ 这次终于可以乘坐高铁回家，可当列车以每小时250公里的速度呼啸而过时，我已来不及仔细留意车窗外的风景。我隐隐约约地觉得，外面的山丘变得平缓，时不时穿过漆黑悠长的隧道，平原上点缀着麦田和葡萄架，等到列车横跨着黄河驶过的时候，我终于确信我回到了故乡。而我不得不说，人生的境遇里实在有太多的似曾相识，正如此刻窗外的风，兀自呼啸着撼动着那棵我自小便认识的树。回家后收到的第一个消息是，家族中一位叔叔的儿子，在工作时不慎从高处摔落下来，送到医院以后终于还是没能抢救过来，听长辈们讲，彼时他们正在参加某个人的婚礼，一时间百感交集。 可以说，这是我这么多年来，第一次以一个成年人的身份去面对一个人的离开。因为逝者与我为同一辈人，所以于情于理我都要去吊唁一番。于是，快三十岁的人，第一次有了买花圈、写挽联的经历，甚至我在去见这位叔叔的时候，在脑海中浮现了多次的“还请您节哀顺变”，终于还是没能说出口来。或许是因为事出突然，有太多的身后事需要料理，留给悲伤的时间并不多。在逝者面前焚香、叩拜、鞠躬，虽然有长辈从旁指点，可整套动作还是显得有点僵硬。我终于还是想起来，这个只有27岁的年轻人，在我某次回家探亲的时候，自顾自走上前来，面带微笑的自我介绍道，“我是某某某，你不认得我了吗？” 有时候想想，我喜欢怀旧，喜欢念念不忘，或许就是因为我怕，怕生命中每一次告别都是永诀。同样可以认为是第一次的，也许是公墓，是陵园，这种从前只有在电视上见到过的东西。于是，在夕阳的映照下，半边天空被染成金黄色，而在这一片荒凉中，一座六角形的塔静静地矗立着。站在一个高坡上一眼望去，满眼都是密密麻麻的墓碑。我在想，有一天人们会不会建成更加极致的地下宫殿，就如同城市中越来越多的高楼大厦一样，唯一的不同，或许是那具比单人床还要小一点的棺木，或者是和小酒坛差不多大的骨灰盒。独自站在旷野中，风吹着塔角的铃铛不时发出响声，我敲击不锈钢柱子时，它竟然发出了沉钟一般的轰鸣，难道人真的有灵魂吗？ 对于死亡，从小到大，我着实经历了不少，小学时爷爷去世，中学时有位同学被歹人杀害，大学时有位同学患白血病不治而亡，工作以后有一位同事因意外而溺水身亡……有时候想想，虽然我的人生，可能并不如别人那般精彩绝伦，可比起失去生命的他们，我能见到更多的人，见到更多的事情，这实在是幸运中的幸运。可或许是因为故事的视角发生了改变，所以，此刻比往常有了更多不由分说的感慨，就好像从前的我，虽然一样是某个事件的亲历者，但那时的我，还不大懂得死亡的意义，都说是人死灯灭，可只有你自己知道，一旦别人彻底地忘记了你，忘记了你在这世上的故事，你就大概的确真的死了罢！我们终其一生，不论记忆以文字还是影像的形式存在，所求者不过是记住别人和被别人记住，人生如朝露也好，如雪泥鸿爪也罢，也许，珍惜此时此刻，方能无惧参商永隔的痛苦吧…… 很多年前，作为长孙的我，举着高过我头顶的引魂幡走在前面，风裹挟着引魂幡的纸穗呼呼作响，那时，我还不知道再也见不到一个人，将会是多么难过的一件事情。后来，我偶尔会回想起，夏天做完农活回来，坐在凉席上吃西瓜的情形，就是在那个时候，爷爷开始埋怨头上有白头发，而我则被拉去帮爷爷找白头发。再后来，我偶尔会想有个人帮我找白头发，可明明我还没到三十岁啊，直到我看到三叔后脑勺开始变白，我终于惊觉，这是二十年前的事情了。有时候想想，我人生中最美好的那几年，同这二十年的长度相比，何尝不是沧海一粟呢？人生时常如此，你觉得几十年特别漫长，可二十年你还不是就这样“弹指一挥间”，而人生又特别短暂，短暂到我们怕这次见了就再见不着彼此。这样想来，拉黑或者删除一个人，成本简直低廉到无法想象，因为失去得太容易，大家就不会有这种看似突兀的想法。浮生倥偬，失散在风里的是沙，而失散在水里的是萍，失散的人们，会有引魂幡前来招魂，然后各自相认吗？ 所以，时间有温度吗？我想，该是有的，因为我们会在时间的长河里放下一盏浮灯，它承载着我们记忆深处最温暖的回忆。可也许这只是我们的一厢情愿，时间自顾自地往前走，从来不在乎人的记忆到底如何，就如同窗外呼啸而过的风，它并不懂得人类内心深处的那些情感，所以，更多的时候，我以为，时间是没有温度的，是冰冷的，是荒凉的，就像我在陵园里看到的夕阳一般冰冷，即使它被晚霞映得金黄。有时候，我会期待时间走得稍微慢一点，出于我的自私，我希望我此刻爱着的、曾经爱过的人们，都能老去地稍微慢一点，因为我怕再见不到那个人，因为我怕时间凝固成冰，因为我怕我终有一天要忘记，因为我怕我永远都赶不上时间，这或许是我想在此时此刻赋予时间的温度，如同人的正常体温37度，或许，它是如此的平静甚至是普通，可是啊，活着真的很好啊。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://qinyuanpei.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"时间","slug":"时间","permalink":"https://qinyuanpei.github.io/tags/%E6%97%B6%E9%97%B4/"},{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"},{"name":"生死","slug":"生死","permalink":"https://qinyuanpei.github.io/tags/%E7%94%9F%E6%AD%BB/"}]},{"title":"使用 HttpMessageHandler 实现 HttpClient 请求管道自定义","date":"2021-04-28T20:25:47.000Z","path":"posts/2070070822/","text":"最近，博主偶然间在 博客园 看到一篇文章：ASP.NET Core 扩展库之 Http 请求模拟，它里面介绍了一种利用 HttpMessageHandler 来实现 Http 请求模拟的方案。在日常工作中，我们总是不可避免地要和第三方的服务或者接口打交道，尤其是当我们需要面对“联调”这样一件事情的时候。通常，我们可以通过类似 YAPI 这样的工具来对尚在开发中的接口进行模拟。可是，因为这种方式会让我们的测试代码依赖于一个外部工具，所以，从严格意义上讲，它其实应该属于“集成测试”的范畴。在接触前端开发的过程中，对于其中的 Mock.js 印象深刻。故而，当看到 .NET 中有类似实现的时候，好奇心驱使我对其中的核心，即 HttpMessageHandler 产生了浓厚的兴趣。平时，我们更多的是使用 Moq 这样的库来模拟某一个对象的行为，而对一个 Http 请求进行模拟，可以说是开天辟地头一遭。带着这些问题出发，就有了今天这篇博客，通过 HttpMessageHandler 实现 HttpClient 请求管道的自定义。 什么是 HttpMessageHandler？相信大家读过我提到的文章以后，都能找到这里面最核心的一个点：HttpMessageHandler。于是，我们今天要面对的第一个问题就是，什么是 HttpMessageHandler？此时，我们需要一张历久弥新的示意图，来自 微软官方。这里，我们重点关注的是 DelegatingHandler，它继承自 HttpMessageHandler。通过这张图，我们能够获得哪些信息呢？ 我认为，主要有以下几点：第一，HttpMessageHandler 处于整个 Http 请求管道的第一梯队，每一个路由匹配的请求都会从这里“进入”和“离开”；第二，HttpMessageHandler 可以是全局配置或者针对某个特定的路由，只要这个路由被匹配到就会执行；第三，HttpMessageHandler 可以直接构造 Http 响应并且返回，跳过剩余的管道流程。不知道大家看到这里会想到什么？坦白讲，我联想到了.NET Core 中的中间件，而唯一不同的地方或许是，中间件是 ASP.NET Core 里的概念，这里则是 ASP.NET Web API 里的概念。尤其是第三点，它对于我们的意义非常重大，因为它，我们才可以做到对一个 Http 请求进行模拟。 HttpMessageHandler 与 ASP.NET Web API 而事实上，在 ASP.NET Web API 的设计中，它是由一组 HttpMessageHandler 经过“首尾相连”而成，这种管道式的设计使得框架本身具有很高的扩展性。虽然，作为一个服务端框架，ASP.NET Web API 最主要的作用是就是“处理请求、响应回复”，可具体采用的处理策略会因具体场景的不同而不同。所以，管道式设计的本质，就是让某一个 Handler 只负责某个单一的消息处理功能，在根据具体场景的不同，选择需要的 Handler 并将其串联成一个完整的消息处理通道。而在这里，这个负责单一的消息处理功能的 Handler 其实就是 HttpMessageHandler，因为它不单单可以对请求消息(HttpRequestMessage)进行处理，同时还可以对响应消息(HttpResponseMessage)进行处理。此时，我们就不难理解 HttpMessageHandler 的定义： 1234567891011121314public abstract class HttpMessageHandler : IDisposable&#123; protected HttpMessageHandler(); public void Dispose(); protected virtual void Dispose(bool disposing); protected internal virtual HttpResponseMessage Send( HttpRequestMessage request, CancellationToken cancellationToken ); protected internal abstract Task&lt;HttpResponseMessage&gt; SendAsync( HttpRequestMessage request, CancellationToken cancellationToken );&#125; 也许，你会忍不住问这样一个问题：DelegatingHandler 和 HttpMessageHandler 的区别是什么？ 其实，只要你稍微仔细一点，你就会发现，两者最大的区别是 DelegatingHandler 里新增一个叫做 InnerHandler 的成员，它本身就是一个 HttpMessageHandler。所以，聪明的你又联想到什么呢？我想，或许是一个叫做 RequestDelegate 的委托，还记得我们写中间件是一直都少不了的 Next 吗？不得不说，这里越来越有中间件的味道了。你可以立马想到的一件事情是，除了最后一个 Handler 是 HttpMessageHandler 以外，剩下的前面的所有的 Handler 都是 DelegatingHandler。为什么这样说呢？因为前面的 n-1 个 Handler 都需要串联下一个 Handler，只有第 n 个 Handler可以允许短路，所以，大概就相当于 Use() 和 Run() 的区别？ 12345678910111213141516public abstract class DelegatingHandler : HttpMessageHandler&#123; protected DelegatingHandler(); protected DelegatingHandler(HttpMessageHandler innerHandler); // InnerHandler是实现管道式设计的关键 public HttpMessageHandler? InnerHandler &#123; get; set; &#125; protected override void Dispose(bool disposing); protected internal override HttpResponseMessage Send( HttpRequestMessage request, CancellationToken cancellationToken ); protected internal override Task&lt;HttpResponseMessage&gt; SendAsync( HttpRequestMessage request, CancellationToken cancellationToken );&#125; 所以，此时此刻，你能否为 HttpMessageHandler 下一个清晰的定义呢？我想，或许可以这样理解，一种可以对 请求消息(HttpRequestMessage) 和 响应消息(HttpResponseMessage) 进行处理，同时多个 HttpMessageHandler 可以组成一个完整的消息处理通道的中间件。屏幕前的你又是如何理解的呢？欢迎大家在评论区留言，留下你对于 HttpMessageHandler 的想法或者认识。 实现自定义请求管道好了，搞清楚 HttpMessageHandler 是什么以后，我们就可以考虑自定义请求管道的实现啦！让我们从一个最简单的示例开始，假设我们这里定义了两个自定义的 Handler，它们分别是： HandlerA 和 HandlerB，我们应该如何将其应用到具体的 HttpClient上呢？ 1234567891011121314151617181920212223242526272829// Handler Apublic class HandlerA : DelegatingHandler&#123; private readonly ILogger&lt;HandlerA&gt; _logger; public HandlerA(ILogger&lt;HandlerA&gt; logger) &#123; _logger = logger; &#125; protected override Task&lt;HttpResponseMessage&gt; SendAsync( HttpRequestMessage request, CancellationToken cancellationToken ) &#123; _logger.LogInformation(\"This is Handler A\"); return base.SendAsync(request, cancellationToken); &#125;&#125;// Handler Bpublic class HandlerB : DelegatingHandler&#123; private readonly ILogger&lt;HandlerB&gt; _logger; public HandlerB(ILogger&lt;HandlerB&gt; logger) &#123; _logger = logger; &#125; protected override Task&lt;HttpResponseMessage&gt; SendAsync( HttpRequestMessage request, CancellationToken cancellationToken ) &#123; _logger.LogInformation(\"This is Handler B\"); return base.SendAsync(request, cancellationToken); &#125;&#125; 这里，我们考虑两种场景，依赖注入 和 非依赖注入。对于依赖注入的场景，我们只需要调用AddHttpMessageHandler()方法按顺序注册即可，不需要处理InnerHandler，这里遵循先注册后使用的原则；对于非依赖注入的场景，需要处理InnerHandler，并在构造HttpClient的时候作为参数传入。 12345678910111213// 依赖注入var services = new ServiceCollection();services.AddTransient&lt;HandlerA&gt;();services.AddTransient&lt;HandlerB&gt;();services.AddHttpClient(\"MyClient\", options =&gt; &#123; options.BaseAddress = new Uri(\"https://blog.yuanpei.me/\");&#125;) .AddHttpMessageHandler&lt;HandlerA&gt;() .AddHttpMessageHandler&lt;HandlerB&gt;();// 非依赖注入var handler = new HandlerA() &#123; InnerHandler = new HandlerB() &#125;;var client = new HttpClient(handler) 此时，我们就可以得到下面的结果，可以注意到的是，两个Handler的执行顺序与注册顺序一致： Handler执行顺序与注册顺序 好了，热身环节到此结束！下面，我们来开始实战，这里展示的是 HttpMessageHandler 在日志记录、请求重试 和 接口模拟等方面的应用。 日志记录对于 Http 请求的日志，我们希望记录请求的Url、Http动词、请求时长等信息，而这一点，在一个大量接入第三方接口的系统或者是以 Http 驱动的微服务架构中，常常是不可或缺的一环，对于我们排查故障、监控服务非常有用。 12345678910111213141516171819202122232425protected override async Task&lt;HttpResponseMessage&gt; SendAsync(HttpRequestMessage request, CancellationToken cancellationToken)&#123; var correlationId = GetCorrelationId(request); using (_logger.BeginScope($\"correlationId=&#123;correlationId&#125;\")) &#123; var sw = Stopwatch.StartNew(); _logger.LogInformation($\"Start Processing HTTP Request &#123;request.Method&#125; &#123;request.RequestUri&#125; [Correlation: &#123;correlationId&#125;]\"); var response = base.Send(request, cancellationToken); _logger.LogInformation($\"End Processing HTTP Request in &#123;sw.ElapsedMilliseconds&#125;ms &#123;response.StatusCode&#125;, [Correlation: &#123;correlationId&#125;]\"); return response; &#125;&#125;// GetCorrelationIdprivate string GetCorrelationId(HttpRequestMessage request)&#123; if (request.Headers.TryGetValues(\"X-Correlation-ID\", out var values)) return values.First(); var correlationId = Guid.NewGuid().ToString(); request.Headers.Add(\"X-Correlation-ID\", correlationId); return correlationId;&#125; 此时，我们可以得到下面的结果： HttpMessageHandler 实现日志记录 请求重试我们知道，一个系统中接入的外部因素越多，则整个系统的稳定性越低。而国内的产品通常都喜欢”大而全”的”万物互联”，所以，最实际的问题，其实就是调用一个第三方的接口，如何保证其可靠性。所以，考虑请求的故障恢复就显得非常有意义，为此，我们可以引入Polly，在实现SendAsync()方法的时候，通过Polly中的超时、重试等机制对其做一层包装： 123456789101112131415161718192021222324252627public class RetryableHttpMessageHandler : DelegatingHandler&#123; private readonly ILogger&lt;RetryableHttpMessageHandler&gt; _logger; private readonly IAsyncPolicy&lt;HttpResponseMessage&gt; _retryPolicy; public RetryableHttpMessageHandler( ILogger&lt;RetryableHttpMessageHandler&gt; logger ) &#123; _logger = logger; _retryPolicy = Policy&lt;HttpResponseMessage&gt; .Handle&lt;HttpRequestException&gt;() .Or&lt;TimeoutException&gt;() .OrResult(x =&gt; (int)x.StatusCode &gt;= 400) .RetryAsync(3, (ret, index) =&gt; &#123; _logger.LogInformation($\"调用接口异常：&#123;ret.Exception?.Message&#125;，状态码：&#123;ret.Result.StatusCode&#125;, 正在进行第&#123;index&#125;次重试\"); &#125;); &#125; protected override Task&lt;HttpResponseMessage&gt; SendAsync( HttpRequestMessage request, CancellationToken cancellationToken ) &#123; return _retryPolicy.ExecuteAsync(() =&gt; base.SendAsync(request, cancellationToken)); &#125;&#125; 同样地，我们这里通过HttpClient来请求指定的接口。因为，下面的接口实际上是不存在的。所以，理论上它会返回404这个状态码。而我们的重试策略是，在发生HttpRequestException或者TimeoutException异常以及 Http 响应的状态码大于 400 时，自动触发 3 次重试。 12var client = _clientFactory.CreateClient(\"ApiMock\");var response = await client.GetAsync(\"/api/fail\"); 此时，我们可以得到下面的结果： HttpMessageHandler 实现请求重试 可以发现，不多不少刚好是 3 次。除了重试以外，Polly还支持类似超时、断路器等等不同的策略，甚至可以将它们组合起来使用，这些都属于Polly的内容，不作为本文的重点内容来讲解，感兴趣的朋友可以查阅这篇文章：.NET 开源项目 Polly 介绍。需要说明的是，微软官方提供的 Microsoft.Extensions.Http.Polly，它在IHttpClientBuilder上添加了一个名为AddPolicyHandler()的扩展方法，这里的例子可以被简化为下面这样，它和我们这里举的例子是完全一致的： 123456789101112131415// 定义重试策略var retryPolicy = Policy&lt;HttpResponseMessage&gt; .Handle&lt;HttpRequestException&gt;() .Or&lt;TimeoutException&gt;() .OrResult(x =&gt; (int)x.StatusCode &gt;= 400) .RetryAsync(3, (ret, index) =&gt; &#123; Console.WriteLine($\"调用接口异常：&#123;ret.Exception?.Message&#125;，状态码：&#123;ret.Result.StatusCode&#125;, 正在进行第&#123;index&#125;次重试\"); &#125;);// 注册HttpClient并指定重试策略services.AddHttpClient(\"ApiMock\", options =&gt; &#123; options.BaseAddress = new Uri(\"https://blog.yuanpei.me\");&#125;) .AddPolicyHandler(retryPolicy); 接口模拟在集成第三方接口时，在双方确定好接口以后，接口消费方会有一段时间的“黒写”时期。因为在接口提供方的接口没有正式提供前，接口消费方始终只能通过“模拟”的方式来进行测试。考虑到单元测试对 YAPI 存在耦合，所以，接口模拟同样是一件意义非凡的事情。这里的思路是利用 HttpMessageHandler 的“短路”功能，即构造一个 HttpResponseMessage 并返回。 首先，我们定义一个MockItem类型，它含有两个委托类型的属性RouteSelector和Executor。其中，前者用来匹配路由，而后者则用来处理接口返回值。 12345public class MockItem&#123; public Func&lt;HttpRequestMessage, bool&gt; RouteSelector &#123; get; set; &#125; public Func&lt;HttpRequestMessage, HttpResponseMessage, Task&gt; Executor &#123; get; set; &#125;&#125; 接下来，我们需要定义相应的Handler，这里是ApiMockHttpMessageHandler： 1234567891011121314151617181920212223242526272829public class ApiMockHttpMessageHandler: DelegatingHandler&#123; private readonly ILogger&lt;ApiMockHttpMessageHandler&gt; _logger; private readonly IEnumerable&lt;MockItem&gt; _routes; public ApiMockHttpMessageHandler( ILogger&lt;ApiMockHttpMessageHandler&gt; logger, IEnumerable&lt;MockItem&gt; routes) &#123; _logger = logger; _routes = routes; &#125; protected override async Task&lt;HttpResponseMessage&gt; SendAsync( HttpRequestMessage request, CancellationToken cancellationToken ) &#123; // 匹配路由并调用其Executor属性 var route = _routes.FirstOrDefault(x =&gt; x.RouteSelector?.Invoke(request)); if (route != null) &#123; var response = new HttpResponseMessage(); await route.Executor?.Invoke(request, response); return response; &#125; return base.Send(request, cancellationToken); &#125;&#125; 我们的思路是，对于所有注入到Ioc容器中的MockItem，检查其路由是否匹配，如果路由匹配，则通过其指定的Executor对HttpResponseMessage进行加工并返回。为了更加方便地在Ioc容器中进行注入，我们为IServiceCollection编写了相应的扩展方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public static IServiceCollection AddMock&lt;TReturn&gt;( this IServiceCollection services, string url, HttpMethod method, TReturn @return)&#123; var mockItem = new MockItem(); mockItem.Executor = BuildExecutor&lt;TReturn&gt;(@return); mockItem.RouteSelector = BuildRouteSelector(url, method); return services.AddTransient&lt;MockItem&gt;(sp =&gt; mockItem);&#125; public static IServiceCollection AddMock&lt;TReturn&gt;( this IServiceCollection services, Func&lt;HttpRequestMessage, bool&gt; routeSelector, Func&lt;HttpRequestMessage, HttpResponseMessage, Task&gt; executor)&#123; var mockItem = new MockItem(); mockItem.Executor = executor; mockItem.RouteSelector = routeSelector; return services.AddTransient&lt;MockItem&gt;(sp =&gt; mockItem);&#125;private static Func&lt;HttpRequestMessage, bool&gt; BuildRouteSelector( string url, HttpMethod method)&#123; Func&lt;HttpRequestMessage, bool&gt; selector = request =&gt; &#123; if (url == \"*\") return true; return url.ToLower() == res.RequestUri.AbsolutePath.ToLower() &amp;&amp; method == res.Method; &#125;; return selector;&#125;private static Func&lt;HttpRequestMessage, HttpResponseMessage, Task&gt; BuildExecutor&lt;TReturn&gt;(TReturn @return)&#123; Func&lt;HttpRequestMessage, HttpResponseMessage, Task&gt; executor = (request, response) =&gt; &#123; response.StatusCode = System.Net.HttpStatusCode.OK; if (@return is HttpStatusCode) response.StatusCode = (HttpStatusCode)Enum.Parse( typeof(HttpStatusCode), @return.ToString() ); else if (@return is Exception) throw @return as Exception; else if (@return is string) response.Content = new StringContent(@return as string); else response.Content = new StringContent(@return == null ? \"\" : JsonConvert.SerializeObject(@return) ); return Task.CompletedTask; &#125;; return executor;&#125; 此时，我们就可以在单元测试中对接口进行模拟，这样就实现了真正意义上的单元测试： 123456789101112131415161718192021var services = new ServiceCollection();// 添加 HttpClient并注册ApiMockHttpMessageHandlerservices.AddHttpClient(\"ApiMock\", options =&gt; &#123; options.BaseAddress = new Uri(\"https://blog.yuanpei.me\");&#125;) .AddHttpMessageHandler&lt;ApiMockHttpMessageHandler&gt;();// 添加3个模拟接口services.AddMock(\"/api/status\", HttpMethod.Get, HttpStatusCode.OK);services.AddMock(\"/api/query\", HttpMethod.Post, new Exception(\"帅哥你谁啊\"));services.AddMock(\"/api/order\", HttpMethod.Get, new &#123; OrderId = \"OR09874\", CreatedBy = \"张三\"&#125;);var serviceProvider = services.BuildServiceProvider();var httpClientFactory = serviceProvider.GetRequiredService&lt;IHttpClientFactory&gt;();var httpClient = httpClientFactory.CreateClient(\"ApiMock\");// 调用/api/order接口var response = await httpClient.GetAsync(\"/api/order\"); 下图是模拟接口返回的结果，与我们期望的完全一致： HttpMessageHandler 实现接口模拟 本文小结古人云：他山之石，可以攻玉。原本被接口模拟(Mock)所吸引的博主，意外地收获了 HttpMessageHandler 这个令人兴奋的知识点。博主认为，它是一种可以对 请求消息(HttpRequestMessage) 和 响应消息(HttpResponseMessage) 进行处理，同时多个 HttpMessageHandler 可以组成一个完整的消息处理通道的中间件。在此基础上，我们实现了诸如日志记录、请求重试、接口模拟等等的扩展性功能。除此以外，它还可以应用到 Http认证头处理 、客户端负载均衡等方面。 其实，从 ASP.NET、OWIN、Nancy、ASP.NET Core 这样一路走过来，你会发现，管道的概念一直都存在，无非是以不同的形式存在着，譬如 ASP.NET Core 里的中间件，其实是替代了曾经的 HttpHandler 和 HttpModule，就像时间一直都在那里，不快不慢，觉得物是人非、喜新厌旧的多半还是我们。对我而言，写到这里，最大的感慨或许是，曾经试图实现的类似 Servlet 的 Http Server ，现在想起来还是太年轻、太朴实了，可年轻或者朴实，难道不好吗？好了，以上就是这篇博客的全部内容了，如果你觉得这篇博客对你有所帮助或者启发，希望你可以毫不吝啬地给个一键三连。如果你对这篇博客里的内容有意见或者建议，欢迎你评论区留下你的足迹和声音，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"扩展","slug":"扩展","permalink":"https://qinyuanpei.github.io/tags/%E6%89%A9%E5%B1%95/"},{"name":"HttpClient","slug":"HttpClient","permalink":"https://qinyuanpei.github.io/tags/HttpClient/"},{"name":"Mock","slug":"Mock","permalink":"https://qinyuanpei.github.io/tags/Mock/"},{"name":"管道","slug":"管道","permalink":"https://qinyuanpei.github.io/tags/%E7%AE%A1%E9%81%93/"}]},{"title":"ABP vNext 的实体与服务扩展技巧分享","date":"2021-04-18T20:42:47.000Z","path":"posts/3619320289/","text":"使用 ABP vNext 有一个月左右啦，这中间最大的一个收获是：ABP vNext 的开发效率真的是非常好，只要你愿意取遵循它模块化、DDD 的设计思想。因为官方默认实现了身份、审计、权限、定时任务等等的模块，所以，ABP vNext 是一个开箱即用的解决方案。通过脚手架创建的项目，基本具备了一个专业项目该有的“五脏六腑”，而这可以让我们专注于业务原型的探索。例如，博主是尝试结合 Ant Design Vue 来做一个通用的后台管理系统。话虽如此，我们在使用 ABP vNext 的过程中，还是希望可以针对性地对 ABP vNext 进行扩展，毕竟 ABP vNext 无法 100% 满足我们的使用要求。所以，在今天这篇博客中，我们就来说说 ABP vNext 中的扩展技巧，这里主要是指实体扩展和服务扩展这两个方面。我们经常在讲“开闭原则”，可扪心自问，我们每次修改代码的时候，是否真正做到了“对扩展开放，对修改关闭”呢？ 所以，在面对扩展这个话题时，我们不妨来一起看看 ABP vNext 中是如何实践“开闭原则”。 扩展实体首先，我们要说的是扩展实体，什么是实体呢？这其实是领域驱动设计(DDD)中的概念，相信对于实体、聚合根和值对象，大家早就耳熟能详了。在 ABP vNext 中，实体对应的类型为Entity，聚合根对应的类型为AggregateRoot。所以，你可以片面地认为，只要继承自Entity基类的类都是实体。通常，实体都会有一个唯一的标识(Id)，所以，订单、商品或者是用户，都属于实体的范畴。不过，按照业务边界上的不同，它们会在核心域、支撑域和通用域三者间频繁切换。而对于大多数系统而言，用户都将是一个通用的域。在 ABP vNext 中，其用户信息由AbpUsers表承载，它在架构上定义了IUser接口，借助于EF Core的表映射支持，我们所使用的AppUser本质上是映射到了AbpUsers表中。针对实体的扩展，在面向数据库编程的业务系统中，一个最典型的问题就是，我怎么样可以给AppUser添加字段。所以，下面我们以AppUser为例，来展示如何对实体进行扩展。 DDD 中的实体、聚合根与值对象 实际上，ABP vNext 中提供了2种方式，来解决实体扩展的问题，它们分别是：Extra Properties 和 基于 EF Core 的表映射。在 官方文档 中，我们会得到更加详细的信息，这里简单介绍一下就好： Extra Properties对于第1种方式，它要求我们必须实现IHasExtraProperties接口，这样我们就可以使用GetProperty()和SetProperty()两个方法，其原理是，将这些扩展字段以JSON格式存储在ExtraProperties这个字段上。如果使用MongoDB这样的非关系型数据库，则这些扩展字段可以单独存储。参考示例如下： 12345678// 设置扩展字段var user = await _identityUserRepository.GetAsync(userId);user.SetProperty(\"Title\", \"起风了，唯有努力生存\");await _identityUserRepository.UpdateAsync(user);// 读取扩展字段var user = await _identityUserRepository.GetAsync(userId);return user.GetProperty&lt;string&gt;(\"Title\"); 可以想象得到，这种方式使用起来没有心智方面的困扰，主要问题是，这些扩展字段不利于关系型数据库的查询。其次，完全以字符串形式存在的键值对，难免存在数据类型的安全性问题。博主的上家公司，在面对这个问题时，采用的方案就是往数据库里加备用字段，从起初的5个，变成后来的10个，最后甚至变成20个，先不说这没完没了的加字段，代码中一直避不开的，其实是各种字符串的Parse/Convert，所以，大家可以自己去体会这其中的痛苦。 基于 EF Core 的表映射对于第2种方式，主要指 EF Core 里的“表拆分”或者“表共享”，譬如，当我们希望单独创建一个实体SysUser来替代默认的AppUser时，这就是表拆分，因为同一张表中的数据，实际上是被AppUser和SysUser共享啦，或者，你可以将其理解为，EF Core配置两个不同的实体时，它们的ToTable()方法都指向了同一张表。这里唯一不同的是，ABP vNext 中提供了一部分方法用来处理问题，因为牵扯到数据库，所以，还是需要“迁移”。下面，我们以给AppUser扩展两个自定义字段为例： 首先，我们给AppUser类增加两个新属性，Avatar 和 Profile: 12345678public class AppUser : FullAuditedAggregateRoot&lt;Guid&gt;, IUser&#123; // ... public virtual string Profile &#123; get; private set; &#125; public virtual string Avatar &#123; get; private set; &#125; // ... 接下来，按照 EF Core 的“套路”，我们需要配置下这两个新加的字段： 12345678910111213141516171819builder.Entity&lt;AppUser&gt;(b =&gt;&#123; // AbpUsers // Sharing the same table \"AbpUsers\" with the IdentityUser b.ToTable(AbpIdentityDbProperties.DbTablePrefix + \"Users\"); b.ConfigureByConvention(); b.ConfigureAbpUser(); // Profile b.Property(x =&gt; x.Profile) .HasMaxLength(AppUserConsts.MaxProfileLength) .HasColumnName(\"Profile\"); // Avatar b.Property(x =&gt; x.Avatar) .HasMaxLength(AppUserConsts.MaxAvatarLength) .HasColumnName(\"Avatar\");&#125;); 接下来，通过MapEfCoreProperty()方法，将新字段映射到IdentityUser实体，你可以理解为，AppUser和IdentityUser同时映射到了AbpUsers这张表： 12345678910111213// AvatarObjectExtensionManager.Instance.MapEfCoreProperty&lt;IdentityUser, string&gt;( nameof(AppUser.Avatar), (entityBuilder, propertyBuilder) =&gt; &#123; propertyBuilder.HasMaxLength(AppUserConsts.MaxAvatarLength);&#125;);// ProfileObjectExtensionManager.Instance.MapEfCoreProperty&lt;IdentityUser, string&gt;( nameof(AppUser.Profile), (entityBuilder, propertyBuilder) =&gt; &#123; propertyBuilder.HasMaxLength(AppUserConsts.MaxProfileLength);&#125;); 既然，连数据库实体都做了扩展，那么，数据传输对象(DTO)有什么理由拒绝呢？ 123456789101112131415161718192021222324ObjectExtensionManager.Instance .AddOrUpdateProperty&lt;string&gt;( new[] &#123; typeof(IdentityUserDto), typeof(IdentityUserCreateDto), typeof(IdentityUserUpdateDto), typeof(ProfileDto), typeof(UpdateProfileDto), &#125;, \"Avatar\" ) .AddOrUpdateProperty&lt;string&gt;( new[] &#123; typeof(IdentityUserDto), typeof(IdentityUserCreateDto), typeof(IdentityUserUpdateDto), typeof(ProfileDto), typeof(UpdateProfileDto) &#125;, \"Profile\" );&#125;); 经过这一系列的“套路”，此时，我们会发现，新的字段已经生效： ABP vNext 实体扩展效果展示 扩展服务在 ABP vNext 中，我们还可以对服务进行扩展，得益于依赖注入的深入人心，我们可以非常容易地实现或者替换某一个接口，这里则指 ABP vNext 中的应用服务(ApplicationService)，例如，CrudAppService类可以帮助我们快速实现枯燥的增删改查，而我们唯一要做的，则是定义好实体的主键(Primary Key)、定义好实体的数据传输对象(DTO)。当我们发现 ABP vNext 中内置的模块或者服务，无法满足我们的使用要求时，我们就可以考虑对原有服务进行替换，或者是注入新的应用服务来扩展原有服务，这就是服务的扩展。在 ABP vNext 中，我们可以使用下面两种方法来对一个服务进行替换： 123456789101112// 通过[Dependency]和[ExposeServices]实现服务替换[Dependency(ReplaceServices = true)][ExposeServices(typeof(IIdentityUserAppService))]public class YourIdentityUserAppService : IIdentityUserAppService, ITransientDependency&#123; //...&#125;// 通过ReplaceService实现服务替换context.Services.Replace( ServiceDescriptor.Transient&lt;IIdentityUserAppService, YourIdentityUserAppService&gt;()); 这里，博主准备的一个示例是，默认的用户查询接口，其返回信息中只有用户相关的字段，我们希望在其中增加角色、组织单元等关联信息，此时。我们可以考虑实现下面的应用服务： 123456public interface IUserManageAppService&#123; Task&lt;PagedResultDto&lt;UserDetailQueryDto&gt;&gt; GetUsersWithDetails( GetIdentityUsersInput input );&#125; 首先，我们定义了IUserManageAppService接口，它含有一个分页查询的方法GetUsersWithDetails()。接下来，我们来考虑如何实现这个接口。需要说明的是，在 ABP vNext 中，仓储模式的支持由通用仓储接口IRepository&lt;TEntity, TKey&gt;提供，ABP vNext 会在AddDefaultRepositories()方法中为每一个聚合根注入对应的仓储。同样地，你可以按照个人喜好为指定的实体注入对应的仓储。由于ABP vNext 同时支持 EF Core、Dapper 和 MongoDB，所以，我们还可以使用EfCoreRepository、DapperRepository 以及 MongoDbRepository，它们都是IRepository的具体实现类。在下面的例子中，我们使用的是EfCoreRepository这个类。 事实上，这里注入的EfCoreIdentityUserRepository、EfCoreIdentityRoleRepository 以及 EfCoreOrganizationUnitRepository，都是EfCoreRepository的子类，这使得我们可以复用 ABP vNext 中关于身份标识的一切基础设施，来实现不同于官方的业务逻辑，而这就是我们所说的服务的扩展。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081[Authorize(IdentityPermissions.Users.Default)]public class UserManageAppService : ApplicationService, IUserManageAppService&#123; private readonly IdentityUserManager _userManager; private readonly IOptions&lt;IdentityOptions&gt; _identityOptions; private readonly EfCoreIdentityUserRepository _userRepository; private readonly EfCoreIdentityRoleRepository _roleRepository; private readonly EfCoreOrganizationUnitRepository _orgRepository; public UserManageAppService( IdentityUserManager userManager, EfCoreIdentityRoleRepository roleRepository, EfCoreIdentityUserRepository userRepository, EfCoreOrganizationUnitRepository orgRepository, IOptions&lt;IdentityOptions&gt; identityOptions ) &#123; _userManager = userManager; _orgRepository = orgRepository; _userRepository = userRepository; _roleRepository = roleRepository; _identityOptions = identityOptions; &#125; [Authorize(IdentityPermissions.Users.Default)] public async Task&lt;PagedResultDto&lt;UserDetailQueryDto&gt;&gt; GetUsersWithDetails( GetIdentityUsersInput input ) &#123; //Users var total = await _userRepository.GetCountAsync(input.Filter); var users = await _userRepository.GetListAsync( input.Sorting, input.MaxResultCount, input.SkipCount, input.Filter, includeDetails: true ); //Roles var roleIds = users .SelectMany(x =&gt; x.Roles) .Select(x =&gt; x.RoleId) .Distinct() .ToList(); var roles = await _roleRepository .WhereIf(roleIds.Any(), x =&gt; roleIds.Contains(x.Id)) .ToListAsync(); //OrganizationUnits var orgIds = users .SelectMany(x =&gt; x.OrganizationUnits) .Select(x =&gt; x.OrganizationUnitId) .Distinct() .ToList(); var orgs = await _orgRepository .WhereIf(orgIds.Any(), x =&gt; orgIds.Contains(x.Id)) .ToListAsync(); var items = ObjectMapper.Map&lt;List&lt;Volo.Abp.Identity.IdentityUser&gt;, List&lt;UserDetailQueryDto&gt;&gt;(users); foreach (var item in items) &#123; foreach (var role in item.Roles) &#123; var roleInfo = roles.FirstOrDefault(x =&gt; x.Id == role.RoleId); if (roleInfo != null) ObjectMapper.Map(roleInfo, role); &#125; foreach (var org in item.OrganizationUnits) &#123; var orgInfo = orgs.FirstOrDefault(x =&gt; x.Id == org.OrganizationUnitId); if (orgInfo != null) ObjectMapper.Map(orgInfo, org); &#125; &#125; return new PagedResultDto&lt;UserDetailQueryDto&gt;(total, items); &#125;&#125; 这里做一点补充说明，应用服务，即ApplicationService类，它集成了诸如ObjectMapper、LoggerFactory、GuidGenerator、国际化、AsyncExecuter等等的特性，继承该类可以让我们更加得心应手地编写代码。曾经，博主写过一篇关于“动态API”的博客，它可以为我们免去从 Service 到 Controller 的这一层封装，当时正是受到了ABP 框架的启发。当博主再次在 ABP vNext 中看到这个功能时，不免会感慨逝者如斯，而事实上，这个功能真的好用，真香！下面是经过改造以后的用户列表。考虑到，在上一篇博客里，博主已经同大家分享过分页查询方面的实现技巧，这里就不再展开讲啦！ 对“用户服务”进行扩展 本文小结我们时常说，”对修改关闭，对扩展开放“，”单一职责“，可惜这些原则最多就出现在面试环节。当你接触了真实的代码，你会发现”修改“永远比”扩展“多，博主曾经就见到过，一个简单的方法因为频繁地”打补丁“，最后变得面目全非。其实，有时候并不是维护代码的人，不愿意去”扩展“，而是写出可”扩展“的代码会更困难一点，尤其是当所有人都不愿意去思考，一味地追求短平快，这无疑只会加速代码的腐烂。在这一点上，ABP vNext 提供了一种优秀的范例，这篇文章主要分享了 ABP vNext 中实体和服务的扩展技巧，实体扩展解决了如何为数据库表添加扩展字段的问题，服务扩展解决了如何为默认服务扩展功能的问题，尤其是后者，依赖注入在其中扮演着无比重要的角色。果然，这世上的事情，只有你真正在乎的时候，你才会愿意去承认，那些你曾经轻视过的东西，也许，它们是对的吧！好了，以上就是这篇博客的全部内容，欢迎大家在评论区留言，喜欢的话请记得点赞、收藏、一键三连。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"ABP","slug":"ABP","permalink":"https://qinyuanpei.github.io/tags/ABP/"},{"name":"扩展","slug":"扩展","permalink":"https://qinyuanpei.github.io/tags/%E6%89%A9%E5%B1%95/"},{"name":"实体","slug":"实体","permalink":"https://qinyuanpei.github.io/tags/%E5%AE%9E%E4%BD%93/"},{"name":"服务","slug":"服务","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%8D%E5%8A%A1/"}]},{"title":"ABP vNext 对接 Ant Design Vue 实现分页查询","date":"2021-04-07T21:07:47.000Z","path":"posts/3670340170/","text":"在 上一篇 博客中，博主和大家分享了如何在 EF Core 中实现多租户架构。在这一过程中，博主主要参考了 ABP vNext 这个框架。从上个月开始，我个人发起了一个项目，基于 ABP vNext 和 Ant Design Vue 来实现一个通用的后台管理系统，希望以此来推进 DDD 和 Vue 的学习，努力打通前端与后端的“任督二脉”。因此，接下来的这段时间内，我写作的主题将会围绕 ABP vNext 和 Ant Design Vue。而在今天的这篇博客中，我们来说说 ABP vNext 对接 Ant Design Vue 实现分页查询的问题，希望能让大家在面对类似问题时有所帮助。我不打算写一个系列教程，更多的是从我个人的关注点出发，如果大家有更多想要交流的话题，欢迎大家通过评论或者邮件来留言，谢谢大家！ ABP vNext中的分页查询OK，当大家接触过 ABP vNext 以后，就会了解到这样一件事情，即，ABP vNext 中默认提供的分页查询接口，在大多数情况下，通常都会是下面这样的风格。这里以角色查询的接口为例，它对应的请求地址是：/api/identity/roles?SkipCount=0&amp;MaxResultCount=10。此时，我们可以注意到，返回的数据结构中含有totalCount和items两个属性。其中，totalCount表示记录的总数目，items表示当前页对应的记录。 1234567891011121314151617181920212223&#123; \"totalCount\": 2, \"items\": [ &#123; \"name\": \"Admin\", \"isDefault\": false, \"isStatic\": true, \"isPublic\": true, \"concurrencyStamp\": \"cb53f2d7-159e-452d-9d9c-021629b500e0\", \"id\": \"39fb19e8-fb34-dfbd-3c70-181f604fd5ff\", \"extraProperties\": &#123;&#125; &#125;, &#123; \"name\": \"Manager\", \"isDefault\": false, \"isStatic\": false, \"isPublic\": false, \"concurrencyStamp\": \"145ec550-7fe7-4c80-85e3-f317a168e6b6\", \"id\": \"39fb6216-2803-20c6-7211-76f8fe38b90e\", \"extraProperties\": &#123;&#125; &#125; ]&#125; 事实上，ABP vNext 中自带的分页查询，主要是通过SkipCount和MaxResultCount两个参数来实现。假设MaxResultCount，即分页大小为m，则第n页对应的SkipCount应该为(n-1) * m。如果大家对于LINQ非常熟悉的话，应该可以自然而然地联想到Skip()和Take()两个方法，这是一个非常自然的联想，因为 ABP vNext 就是这样实现分页查询的。这里以博主的“数据字典”分页查询接口为例： 12345678910111213141516171819202122public async Task&lt;PagedResultDto&lt;DataDictionaryQueryDto&gt;&gt; GetCategories( GetDataDictionaryRequestInput input)&#123; var totalCount = (await _dataDictRepository.GetQueryableAsync()) .WhereIf(!string.IsNullOrEmpty(input.Name), x =&gt; x.Name.Contains(input.Name) || x.Name == input.Name) .WhereIf(!string.IsNullOrEmpty(input.Description), x =&gt; x.Description.Contains(input.Description) || x.Description == input.Description) .Count(); var items = (await _dataDictRepository.GetQueryableAsync()) .WhereIf(!string.IsNullOrEmpty(input.Name), x =&gt; x.Name.Contains(input.Name) || x.Name == input.Name) .WhereIf(!string.IsNullOrEmpty(input.Description), x =&gt; x.Description.Contains(input.Description) || x.Description == input.Description) .Skip(input.SkipCount) .Take(input.MaxResultCount) .ToList(); return new PagedResultDto&lt;DataDictionaryQueryDto&gt;() &#123; TotalCount = totalCount, Items = ObjectMapper.Map&lt;List&lt;DataDictionary&gt;, List&lt;DataDictionaryQueryDto&gt;&gt;(items) &#125;;&#125; 可以注意到，在 ABP vNext 中我们只需要构造好TotalCount和Items这两个属性即可。 STable组件中的分页查询接下来，在 Ant Design Vue 的 Pro 版本中，我们使用STable组件来展示列表类的数据，关于这个组件的使用方法，大家可以参考 官方文档。按照最小化可行产品(MVP)的理念，一个最简单的STable组件的使用，如下面所示： 1234567891011&lt;template&gt; &lt;s-table ref=\"table\" size=\"default\" :rowKey=\"(record) =&gt; record.data.id\" :columns=\"columns\" :data=\"loadData\" :rowSelection=\"&#123; selectedRowKeys: selectedRowKeys, onChange: onSelectChange &#125;\" &gt; &lt;/s-table&gt;&lt;/template&gt; 对于这个组件而言，其中最重要的地方当属data属性，它接受一个函数，该函数的返回值为Promise对象，并且有一个参数： 123456789101112131415161718192021222324252627&lt;script&gt; import STable from '@/components' export default &#123; components: &#123; STable &#125;, data() &#123; return &#123; // 表格列名 columns: [], // 查询条件 queryParam: &#123; &#125;, // 加载数据方法，必须为 Promise 对象 loadData: parameter =&gt; &#123; return getRoles(Object.assign(&#123;&#125;, this.queryParam, parameter)) .then(res =&gt; &#123; return res.result &#125;) &#125;, // ... selectedRowKeys: [], selectedRows: [] &#125; &#125; &#125;&lt;/script&gt; 也许，你会好奇这个parameter到底是个什么东西？可如果我们将其打印出来，就会发现它其实是分页查询相关的参数：Object { pageNo: 1, pageSize: 10 }，而更进一步，如果深入到这个组件的源代码中，我们会注意到组件内部有一个loadData()方法： 12345678910111213141516171819loadData (pagination, filters, sorter) &#123; this.localLoading = true const parameter = Object.assign(&#123; pageNo: (pagination &amp;&amp; pagination.current) || this.showPagination &amp;&amp; this.localPagination.current || this.pageNum, pageSize: (pagination &amp;&amp; pagination.pageSize) || this.showPagination &amp;&amp; this.localPagination.pageSize || this.pageSize &#125;, (sorter &amp;&amp; sorter.field &amp;&amp; &#123; sortField: sorter.field &#125;) || &#123;&#125;, (sorter &amp;&amp; sorter.order &amp;&amp; &#123; sortOrder: sorter.order &#125;) || &#123;&#125;, &#123; ...filters &#125; ) const result = this.data(parameter) // 对接自己的通用数据接口需要修改下方代码中的 r.pageNo, r.totalCount, r.data 可以注意到，在STable组件内部，它会将分页、排序和过滤三种不同类型的参数，通过Object.assign()方法聚合到一个对象上，这个对象实际上就是我们刚刚打印出来的parameter。为什么这样说呢？因为它接下来就要调用data属性指向的方法啦！还记得这个data是什么吗？不错，它是一个函数，既然是一个函数，当然可以直接调用。到这里，我们可以获得第一个信息，即，ABP vNext 中的表格组件STable，本身封装了分页查询相关的参数，只要将这些参数传递给后端就可以实现分页查询。 实现参数转换层既然，这个参数和 ABP vNext 需要的参数不同，为了不修改已有的接口，我们考虑在这中间加一层转换。为此，我们定义下面的函数： 123456789101112131415161718192021222324252627282930313233// 默认列表查询条件const baseListQuery = &#123; page: 1, limit: 20&#125;// 查询条件转化export function transformAbpListQuery (query) &#123; query.filter = query.filter === '' ? undefined : query.filter if (window.isNaN(query.pageSize)) &#123; query.pageSize = baseListQuery.limit &#125; if (window.isNaN(query.pageNo)) &#123; query.pageNo = baseListQuery.page &#125; const abpListQuery = &#123; maxResultCount: query.pageSize, skipCount: (query.pageNo - 1) * query.pageSize, sorting: '', filter: '', ...query &#125; if (typeof (query.sortField) !== 'undefined' &amp;&amp; query.sortField !== null) &#123; abpListQuery.sorting = query.sortOrder === 'ascend' ? query.sortField : `$&#123;query.sortField&#125; Desc` &#125; return abpListQuery&#125; 代码非常简单，通过transformAbpListQuery函数，我们就实现了从STable到ABP vNext的参数转换。需要说明的是，这里的排序使用到了 System.Linq.Dynamic.Core 这个库，它可以实现IQueryable级别的、基于字符串的动态表达式构建功能，使用方法如下： 123var resultSingle = queryable.OrderBy&lt;User&gt;(\"NumberProperty\");var resultSingleDescending = queryable.OrderBy&lt;User&gt;(\"NumberProperty DESC\");var resultMultiple = queryable.OrderBy&lt;User&gt;(\"NumberProperty, StringProperty\"); 所以，当它为降序排序时，我们在排序字段的后面添加DESC即可。关于filter参数，我准备做一套通用性更强的方案，所以，这里就暂时留空啦！接下来，如果大家足够细心的话，会发现STable组件对返回值同样有一定的要求，它要求返回值中至少含有pageNo、totalCount, data三个属性，而这，是我们获得的第二个信息： 123456789101112131415161718// 对接自己的通用数据接口需要修改下方代码中的 r.pageNo, r.totalCount, r.data// eslint-disable-next-lineif ((typeof result === 'object' || typeof result === 'function') &amp;&amp; typeof result.then === 'function') &#123; result.then(r =&gt; &#123; this.localPagination = this.showPagination &amp;&amp; Object.assign(&#123;&#125;, this.localPagination, &#123; current: r.pageNo, // 返回结果中的当前分页数 total: r.totalCount, // 返回结果中的总记录数 showSizeChanger: this.showSizeChanger, pageSize: (pagination &amp;&amp; pagination.pageSize) || this.localPagination.pageSize &#125;) || false this.localDataSource = r.data // 返回结果中的数组数据 this.localLoading = false &#125;)&#125; 依样画葫芦，我们继续编写转换层的代码，返回值格式参考了 Ant Design Vue 中Mock接口的返回值格式： 12345678910111213141516171819202122232425262728293031323334// 查询结果转化export function transformAbpQueryResult (data, message, code = 0, headers = &#123;&#125;) &#123; const responseBody = &#123; &#125; responseBody.result = data if (message !== undefined &amp;&amp; message !== null) &#123; responseBody.message = message &#125; if (code !== undefined &amp;&amp; code !== 0) &#123; responseBody.code = code responseBody._status = code &#125; if (headers !== null &amp;&amp; typeof headers === 'object' &amp;&amp; Object.keys(headers).length &gt; 0) &#123; responseBody._headers = headers &#125; responseBody.timestamp = new Date().getTime() return responseBody&#125;// 分页查询结果转化export function buildPagingQueryResult (queryParam, data) &#123; for (const item of data.items) &#123; // Ant Design Vue 中要求每行数据中必须存在字段：key item.key = item.id &#125; const pagedResult = &#123; pageSize: queryParam.pageSize, pageNo: queryParam.pageNo, totalCount: data.totalCount, totalPage: data.totalCount / queryParam.pageSize, data: data.items &#125; return transformAbpQueryResult(pagedResult)&#125; 对于分页结果而言，我们会将分页大小、当前页数、总页数、总记录数及其对应的数据，统一封装到一个对象中，然后再将其传递给返回值中的result属性。 最终对接效果好了，写了这么多，我们到底实现了一个什么效果呢？对于一开始的角色查询接口，我们可以这样封装到前端的服务层： 12345678910export function getRoles (query) &#123; const queryParam = transformAbpListQuery(query) return axios(&#123; url: AppConsts.resourceService.baseUrl + '/api/identity/roles', method: 'get', params: queryParam &#125;).then(data =&gt; &#123; return buildPagingQueryResult(queryParam, data) &#125;)&#125; 接下来，我们只需要实现loadData()方法即可： 12345678import &#123; getRoles, updateRole, createRole, deleteRole &#125; from '@/api/recipe/abp.role'loadData: parameter =&gt; &#123; return getRoles(Object.assign(&#123;&#125;, parameter, this.queryParam)) .then(res =&gt; &#123; return res.result &#125;) &#125;, 此时，我们可以注意到，ABP vNext 与 Ant Design Vue 完美地集成在一起，并且参数的转换完全符合我们的预期。这样做的好处显而易见，我们只需要遵循 ABP vNext 的规范进行开发即可，考虑到 ABP vNext 可以直接将ApplicationService暴露为 API 接口，这意味着我们写完了接口，就可以立即开始前后端的联调工作，这无疑可以加快我们的研发效率！ ABP vNext 与 Ant Design Vue 完成整合 好了，以上就是这篇博客的全部内容啦！这篇博客要实现的功能其实并不复杂，唯一的难点是，需要在前端和后端两个技术栈上频繁地切换上下文，这可能就是全栈开发者面临的最大挑战，因为技术世界浩如烟海，而一个人的精力终究有限，古人云：朝闻道，夕死可矣，人生百年，吾道不孤，还是请你继续努力哦！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"ABP","slug":"ABP","permalink":"https://qinyuanpei.github.io/tags/ABP/"},{"name":"Vue","slug":"Vue","permalink":"https://qinyuanpei.github.io/tags/Vue/"},{"name":"分页","slug":"分页","permalink":"https://qinyuanpei.github.io/tags/%E5%88%86%E9%A1%B5/"},{"name":"前端","slug":"前端","permalink":"https://qinyuanpei.github.io/tags/%E5%89%8D%E7%AB%AF/"}]},{"title":"浅议 EF Core 分库分表及多租户架构的实现","date":"2021-03-27T17:47:47.000Z","path":"posts/2151871792/","text":"各位朋友，大家好，我是 Payne，欢迎大家关注我的博客，我的博客地址是：https://blog.yuanpei.me。最近这段时间，我一直在学习 ABP vNext 框架，在整个学习过程中，我基本就是在“文档”和“源码”间来回横跳。我个人推荐大家，多去阅读一点优秀的代码，因为阅读 ABP vNext 的源代码简直就是一种享受，它可以暂时让你摆脱如泥沼一般的业务代码。言归正传，ABP vNext 是一个支持多租户架构的框架，在了解了其多租户的实现原理以后，从中收获一点微不足道的小技巧。正好前几天，刚刚同一位朋友讨论完分库、分表这类话题。因此，在今天这篇博客中，我想和大家一起探讨下 EF Core 关于分库、分表以及多租户架构的实现。此中曲折，可以说是初窥门径，或许我无法提供给你一个开箱即用的方案，至少它可以带给你一点启发。有读者朋友建议我，不要总是写这种“高深”、“复杂”的话题，适当地迎合读者写点不需要动脑子的东西。对此，我想说，我有我个人技术上的追求，希望大家理解！ 分库首先，我们一起来探讨分库这个话题。从字面含义上了解，分库就是指应用程序拥有多个数据库，而这些数据库则拥有相同的表结构。你可能会问，为什么我们需要分库、分表？答案自然是性能，性能，还是TM的性能。我相信，大家都曾经或多或少地听到过垂直拆分、水平拆分这样的术语，下图展示了如何在数据库这一层级上进行拆分： 数据库的垂直拆分与水平拆分 其实，我们可以从索引存储、B+树高度、QPS 和 连接数 这四个不同的角度来审视这个话题。相关观点认为，当单表数据量达到一定量级(阿里巴巴Java开发手册中为500W)时，由于内存无法存储其索引，此时SQL查询会产生磁盘IO；行记录的大小决定了B+树的每个叶子节点能存储多少记录，所以，行记录的大小会影响B+树的高度；单个MySQL物理机实例写QPS峰值大概为1万，一旦业务量达到某个量级，这个瓶颈会逐步凸显出来；单个MySQL实例最大连接数有限，更多的访问量意味着需要更多的连接数。 在谈论分库、分表的时候，我们忍不住会去想譬如“自动分表”和“路由”这样的问题，这些子库、子表，到底是提前在数据库里分好呢，还是在运行时期间自动去拆分呢，以及我对库/表进行拆分以后，我应该怎么样找到某条数据对应的库/表。我承认，这些问题并不简单，但当我们对问题进行简化以后，分库本质上就是动态地切换数据库，对不对？无非是拆分后的数据库可能会是类似db_0、db_1等等这样的序列。 对 Chinook 进行水平拆分 对于数据库的自动拆分，博主尝试过的一种方案是：首先，通过Add-Migration生成迁移。然后，通过循环修改连接字符串的方式，调用Context.Database.Migrate()方法为一个数据库迁移表结构和种子数据。当然，有些朋友不认同在生产环境使用迁移的做法，认为对数据库的操作权限还是应该交给 DBA 来管理，这当然无可厚非。我表达的一直都是一种思路，我不想一个工作六年的人，对技术的态度永远都停留在“能跑”、“能抄”这种水平。 一旦想清楚这一层，实现起来还是非常简单的。我们在配置中准备多个数据库来模拟分库的场景，实际应用中到底是用范围、Hash 还是 配置，大家结合自己的场景来决定就好。其实，这个思路还可以用来做读写分离，无非是这个库更特殊一点，它是个从库。好了，我们一起来看下面的代码： 123456789// 这里随机连接到某一个数据库// 实际应该按照某种方式获得数据库库名后缀var shardings = _options.Value.MultiTenants;var sharding = shardings[new Random().Next(0, shardings.Count)];_chinookContext.Database.GetDbConnection().ConnectionString = sharding.ConnectionString;Console.WriteLine(\"--------分库场景--------\");Console.WriteLine(_chinookContext.Database.GetDbConnection().ConnectionString);Console.WriteLine(_chinookContext.Album.ToQueryString());Console.WriteLine(_chinookContext.Artist.ToQueryString()); 事实上，如果选择性地忽略 “路由” 和 “自动分表” 这两个特性，我们已经在 EF 层面上局部的实现了 “分库” 功能： 分库场景 分表好了，聊完分库，我们再来聊聊分表。分表就是指同一个数据库里拥有多张结构(Schema)相同的表。一个典型的例子是，Excel里的多张Sheet，只要它们拥有相同的结构(Schema)，就可以视为同一类型的数据，虽然它们拥有不同的表名。和分库类似，分表的着眼点是避免产生“大表”，从而达到提高查询性能的目的。而对应到 EF(EntityFramework) 的场景中，分表本质上就是在解决 EF 动态适配表名的问题。同样的，下面两张图展示了如何在表这个层级进行拆分： 表的垂直拆分 表的水平拆分 图片援引自：雨点的名字 - 分库分表(1) — 理论 譬如，我们以年为单位，产生了Album_2020和Album_2021两张表。那么，在已经定义好了实体Album的情况下，有没有办法可以让实体Album动态地去适配这两张表呢？或许，熟悉 EF 的你，此刻正在心里暗笑道，这有何难，只要在对应实体的OnModelCreating()方法中，修改ToTable()方法的参数就好了啊。可如果你亲自试一试，就会知道这是你的一厢情愿啦！ 针对 Album 和 Artist 按年份进行拆分 事实上，EF 针对实体和表的映射关系做了缓存，这意味着，一旦在OnModelCreating()方法中确定映射关系，这组映射关系将被缓存下来。在 EF 中，这组映射关系的缓存行为，由IModelCacheKeyFactory接口来决定，它提供了一个Create()方法，如果该方法的返回值与上一次相同，则不会调用OnModelCreating()方法。所以，我们的思路就是，让这个Create()方法返回不同的对象。为此，我们考虑实现IModelCacheKeyFactory接口，并用这个自定义实现来替换微软的默认实现。我们一起来看下面的代码： 123456789public class DynamicModelCacheKeyFactory : IModelCacheKeyFactory&#123; public object Create(DbContext context) &#123; return context is ShardingContext shardingContext ? (context.GetType(), shardingContext.ShardingSuffix) : (object)context.GetType(); &#125;&#125; 为了配合DynamicModelCacheKeyFactory的使用，我们还需要定义用于分表的ShardingContext，它继承自DbContext，我们为其扩展了ShardingSuffix属性，并通过注入的IShardingPolicyProvider接口来获取一个分表后缀。比如，我们有Order表，经过拆分后获得Order_01、Order_02这样的子表，所以，这个分表后缀其实就是01、02。没错，我们还是要去修改ToTable()方法中的表名，不同的是，这里的表名是动态的。注意到，Create()方法返回的是一个元组，所以，不同的ShardingSuffix会产生不同的映射关系。 123456789101112131415161718192021222324252627282930313233343536373839404142public class ShardingContext : DbContext&#123; public DbSet&lt;Artist&gt; Artist &#123; get; set; &#125; public DbSet&lt;Album&gt; Album &#123; get; set; &#125; private readonly IShardingPolicyProvider _shardingPolicyProvider; public string ShardingSuffix &#123; get; private set; &#125; public ShardingContext( DbContextOptions&lt;ShardingContext&gt; options, IShardingPolicyProvider shardingPolicyProvider ) : base(options) &#123; _shardingPolicyProvider = shardingPolicyProvider; ShardingSuffix = _shardingPolicyProvider.GetShardingSuffix(); &#125; protected override void OnModelCreating(ModelBuilder modelBuilder) &#123; base.OnModelCreating(modelBuilder); // Album // 动态映射表名，譬如：Album_2021 modelBuilder.Entity&lt;Album&gt;().ToTable($\"Album_&#123;ShardingSuffix&#125;\"); modelBuilder.Entity&lt;Album&gt;().HasKey(x =&gt; x.AlbumId); modelBuilder.Entity&lt;Album&gt;() .Property(x =&gt; x.AlbumId).HasColumnName(\"AlbumId\"); modelBuilder.Entity&lt;Album&gt;() .Property(x =&gt; x.Title).HasColumnName(\"Title\"); modelBuilder.Entity&lt;Album&gt;() .Property(x =&gt; x.ArtistId).HasColumnName(\"ArtistId\"); // Artist // 动态映射表名，譬如：Artist_2021 modelBuilder.Entity&lt;Artist&gt;().ToTable($\"Artist_&#123;ShardingSuffix&#125;\"); modelBuilder.Entity&lt;Artist&gt;().HasKey(x =&gt; x.ArtistId); modelBuilder.Entity&lt;Artist&gt;() .Property(x =&gt; x.ArtistId).HasColumnName(\"ArtistId\"); modelBuilder.Entity&lt;Artist&gt;() .Property(x =&gt; x.Name).HasColumnName(\"Name\"); &#125;&#125; 关于分库、分表以后，怎么去匹配对应的库或者表，这类问题我们称之为路由问题。常见的策略主要有，范围、Hash 和 配置： 范围最直观的就是按照时间来拆分，比如按年、按月、按天等等，主要的问题是分布不均匀；其次，可以按照Id的范围来划分，比如0到10万、10万到20万依次划分到不同的表里，主要的问题是热点数据带来的性能问题。 Hash主要指哈希取模。例如，可以针对用户Id做如下处理：HASH(userId) % N，其中，N表示当前拆分表的数目。可以预见的问题是，当N变化的时候，会产生数据迁移的需求，所以，这种方式并不利于扩容， 配置，顾名思义，就是用一张表来存储数据和子表间的映射关系，每次先按照数据的主键找到子表，然后再从子表中查询所需要的数据。好处是扩容灵活，而缺点同样明显，查询配置表，带来了额外的性能损耗。 在这里，我们是使用年份来作为分表后缀的。为了方便演示，在实现ShardingByYearPolicy类时，我们直接使用了当前时间，这意味着我们会将Album实体映射到Album_2021这张表，以此类推。在实际使用中，更推荐大家使用 雪花算法 生成Id，因为这样，我们就可以通过Id反推出具体的时间范围，进而决定要映射到哪一个库、哪一张表。关于子表的生成，博主这里是通过迁移来实现的，考虑到EF自动创建数据库/表，都需要先创建迁移，所以，这并不是一个开箱即用的方案。 1234567class ShardingByYearPolicy : IShardingPolicyProvider&#123; public string GetShardingSuffix() &#123; return $\"&#123;DateTime.Now.ToString(\"yyyy\")&#125;\"; &#125;&#125; 好了，现在我们可以编写简单的代码，来验证我们的这些想法是都正确，即使是最简单的控制台程序，我还是喜欢用依赖注入： 123456789// 注入ShardingContextservices.AddDbContext&lt;ShardingContext&gt;(options =&gt; &#123; options.UseSqlite(config.GetValue&lt;string&gt;(\"Database:Default\")); //替换默认实现 options.ReplaceService&lt;IModelCacheKeyFactory, DynamicModelCacheKeyFactory&gt;(); &#125;);// 注入IShardingPolicyProviderservices.AddTransient&lt;IShardingPolicyProvider, ShardingByYearPolicy&gt;(); 接下来，我们可以通过ShardingContext来匹配Album_2021表： 123456// 这里应该连接到Album_2021表// 实际应该按照某种方式获得表名后缀Console.WriteLine(\"--------分表场景--------\");Console.WriteLine(_shardingContext.Database.GetDbConnection().ConnectionString);Console.WriteLine(_shardingContext.Album.ToQueryString());Console.WriteLine(_shardingContext.Artist.ToQueryString()); 此时，我们会得到下面的结果： EF Core 分表效果演示 至此，如果选择性地忽略 “路由” 和 “自动分表” 这两个特性，我们已经在 EF 层面上局部的实现了 “分表” 功能。怎么样，是不是还行？ 多租户架构最后，我们来聊聊多租户架构这个话题。可能有朋友觉得多租户架构和分库、分表没什么关系，不好意思啊，这是个非常合理的联想，因为还真就有关系，甚至我们还能继续发散到读写分离。你想想看，多租户架构中，如果一个租户一个数据库，这是不是就是分库的场景。而在分库的场景中，如果一个是主库，一个是从库，这是不是就是读写分离的场景。在学习数学的过程中，学会转化问题是一种重要的思维，即让一个不熟悉的问题变成一个熟悉的问题，在今天这篇博客中，从分库发散到多租户、读写分离，正是这一思路的体现，通常情况下，多租户架构有多数据库和单数据库两种实现方式。 多数据库多数据库，指每一个租户一个数据库。这种实现方式的好处是，租户间的数据天然隔离，数据库的访问压力天然隔离。可由于所有租户都共享一套应用程序，随着数据库越来越多，维护的成本亦越来越高。参考分库的实现，我们可以非常容易地实现租户数据库的切换。这里，我们的思路是，调用方在 HTTP 请求中加入自定义的首部字段X-TenantId，DbContext通过该字段来匹配对应的链接字符串，这样就可以实现多数据库的多租户架构： 123456789101112131415161718public class TenantInfoProvider : ITenantInfoProvider&#123; private const string X_TENANT_ID = \"X-TenantId\"; private readonly IHttpContextAccessor _httpContextAccessor; public TenantInfoProvider(IHttpContextAccessor httpContextAccessor) &#123; _httpContextAccessor = httpContextAccessor; &#125; public string GetTenantId() &#123; var httpContext = _httpContextAccessor.HttpContext; if (httpContext != null &amp;&amp; httpContext.Request.Headers.ContainsKey(X_TENANT_ID)) return httpContext.Request.Headers[X_TENANT_ID].FirstOrDefault(); return null; &#125;&#125; 接下来，假设我们AppSettings.json文件维护各个租户的连接字符串信息。通常，在实际场景中，我们会将这些信息存储在数据库中： 123456789101112131415&#123; \"Database\": &#123; \"Default\": \"Data Source=Chinook.db\", \"MultiTenants\": [ &#123; \"tenantId\": \"01\", \"ConnectionString\": \"Data Source=Chinook01.db\" &#125;, &#123; \"tenantId\": \"02\", \"ConnectionString\": \"Data Source=Chinook02.db\" &#125; ] &#125;&#125; 此时，我们可以通过下面的代码片段来实现租户切换： 1234567891011var tenantId = _tenantInfoProvider.GetTenantId();var database = _options.Value.MultiTenants.FirstOrDefault(x =&gt; x.TenantId == tenantId);if (database == null) throw new Exception($\"Invalid tenantId \\\"&#123;tenantId&#125;\\\"\");_chinookContext.Database.GetDbConnection().ConnectionString = database.ConnectionString;Console.WriteLine(\"--------多租户 + 多数据库--------\");Console.WriteLine($\"TenantId:&#123;tenantId&#125;\");Console.WriteLine(_chinookContext.Database.GetDbConnection().ConnectionString);Console.WriteLine(_chinookContext.Album.ToQueryString());Console.WriteLine(_chinookContext.Artist.ToQueryString()); 可以注意到，一切如我们所预料的一样，程序自动切换到01这个租户： 多租户 + 多数据库 单数据库单数据库，指所有租户都在一个数据库里，使用相同的表结构(Schema)，并通过TenantId字段进行区分。ABP vNext 中的多租户架构就是这种模式，而我之前的公司，则是单数据库 + 多数据库的混合模式。这种实现方式的好处是数据库非常精简，而缺点同样很明显，一旦某个租户出现问题，非常容易波及所有租户，因为所有租户都在一个数据库里，数据库的压力实际上是大家一起分担的，租户间相互影响的可能性非常大。 同样地，我们依然需要用到X-TenantId这个请求头，由于所有租户都在一个数据库上，我们不会再试图去修改链接字符串。EF Core 中针对实体提供了HasQueryFilter()扩展方法，该访问允许我们传入一个 Lambda 表达式。此时，我们所有的请求都会自动带上类似Album.TenantId = &#39;xxxx&#39;这样的条件，这样我们就实现了单数据库的多租户架构。 1234567891011121314151617181920212223242526272829public class MulitiTenancyContext : DbContext&#123; public DbSet&lt;Artist&gt; Artist &#123; get; set; &#125; public DbSet&lt;Album&gt; Album &#123; get; set; &#125; private readonly ITenantInfoProvider _tenantInfoProvider; public MulitiTenancyContext( DbContextOptions&lt;MulitiTenancyContext&gt; options, ITenantInfoProvider tenantInfoProvider ) : base(options) &#123; _tenantInfoProvider = tenantInfoProvider; &#125; protected override void OnModelCreating(ModelBuilder modelBuilder) &#123; base.OnModelCreating(modelBuilder); modelBuilder.ApplyConfiguration(new ArtistMap()); modelBuilder.ApplyConfiguration(new AlbumMap()); // 利用 HasQueryFilter 进行租户间数据隔离 var tenantId = _tenantInfoProvider.GetTenantId(); if (!string.IsNullOrEmpty(tenantId)) &#123; modelBuilder.Entity&lt;Album&gt;().HasQueryFilter(x =&gt; x.TenantId == tenantId); modelBuilder.Entity&lt;Artist&gt;().HasQueryFilter(x =&gt; x.TenantId == tenantId); &#125; &#125;&#125; 为了在实体上应用这个过滤条件，参照 ABP vNext 中的实现，我们定义了IMulitiTenancy接口，所有实体均需要实现TenantId字段。为了简化设计，我们直接使用字符串类型来定义租户Id，而在 ABP vNext 中很多主键都被定义为 Guid，我们掌握核心原理即可，不用过分强求和 ABP vNext 的一致。 1234567891011121314// IMulitiTenancypublic interface IMulitiTenancy&#123; public string TenantId &#123; get; set; &#125;&#125;// Albumpublic class Album : IMulitiTenancy&#123; public int AlbumId &#123; get; set; &#125; public string Title &#123; get; set; &#125; public int ArtistId &#123; get; set; &#125; public string TenantId &#123; get; set; &#125;&#125; 此时，我们可以编写简单的测试代码，来验证我们的想法是否正确。同样地，我还是使用了依赖注入： 1234567// 这里应该查询01租户内的Albumvar tenantId = _tenantInfoProvider.GetTenantId();Console.WriteLine(\"--------多租户 + 单数据库--------\");Console.WriteLine($\"TenantId:&#123;tenantId&#125;\");Console.WriteLine(_mulitiTenancyContext.Database.GetDbConnection().ConnectionString);Console.WriteLine(_mulitiTenancyContext.Album.ToQueryString());Console.WriteLine(_mulitiTenancyContext.Artist.ToQueryString()); 可以注意到，打印出的 SQL 语句中自动带出了过滤条件： 多租户 + 多数据库 本文小结这篇博客主要探讨了 EF 在分库、分表及多租户架构上实施的可能性。分库、分表的目的是为了提高数据库的查询性能，在这个过程中，我们可以考虑范围、Hash和配置三种路由策略，它们各自有自己的优缺点，需要使用者结合业务场景去衡量。虽然分库、分表在面对百万级别以上的数据时，不失为一种提高性能的方案，可世间万物都是双刃剑，它同样带来了一系列新的问题，譬如跨库写带来的分布式事务问题，跨库读带来的Join、Count()、排序、分页等问题，数据迁移问题等等，而如果希望通过Hash(Id)来进行拆分，还需要解决全局Id唯一的问题。所以说，这是一个没有标准答案的问题，需要使用者自己去进行取舍。多租户架构、读写分离均可以看作是特殊的分库场景，EF Core 中新增的HasQueryFilter()方法则帮助我们解决了单数据库的多租户架构问题。好了，以上就是这篇博客的全部内容啦，如果大家对文中的观点有建议或者意见，欢迎大家在评论区留言，谢谢！ 附本文源代码：https://github.com/Regularly-Archive/2021/tree/master/EF.Sharding","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"EF","slug":"EF","permalink":"https://qinyuanpei.github.io/tags/EF/"},{"name":"架构","slug":"架构","permalink":"https://qinyuanpei.github.io/tags/%E6%9E%B6%E6%9E%84/"},{"name":"多租户","slug":"多租户","permalink":"https://qinyuanpei.github.io/tags/%E5%A4%9A%E7%A7%9F%E6%88%B7/"}]},{"title":"源代码探案系列之 .NET Core 跨域中间件 CORS","date":"2021-03-16T21:25:47.000Z","path":"posts/1276287490/","text":"本文是 #源代码探案系列# 第三篇，今天这篇博客，我们来一起解读下 ASP.NET Core 中的 CORS 中间件，熟悉这个中间件的的小伙伴们，想必都已经猜出本文的主题：跨域。这确实是一个老生常谈的话题，可我并不认为，大家愿意去深入探究这个问题，因为博主曾经发现，每当工作中遇到跨域问题的时候，更多的是直接重写跨域相关的 HTTP 头。博主曾经写过一篇关于跨域的博客：《聊聊前端跨域的爱恨情仇》，当时是完全以前端的视角来看待跨域。所以，在今天这篇博客里，博主想带领大家从一种新的视角来看待跨域，也许，可以从中发现不一样的东西。 核心流程关于 ASP.NET Core 中的 CORS，大家都知道的是，可以通过UseCors()方法在整个 HTTP 请求管道中启用跨域中间件，或者是通过AddCors()方法来定义跨域策略，亦或者通过[EnableCors]来显式地指定跨域策略，更多的细节大家可以参考微软的官方文档，而在这里，我想聊一点大家可能不知道的东西，譬如：服务器端如何处理来自浏览器端的跨域请求？而这一切在 ASP.NET Core 中又如何实现？带着这些问题来解读 CORS 中间件的源代码，我们能更快的找到我们想得到的答案。一图胜千言，请允许博主使用这张流程图来“开宗明义”，我们这就开始今天的“探案”： 一张图览尽 CORS 中间件 核心部件对于整个 CORS 中间件而言，核心部件主要有：CorsPolicy、CorsService 以及 CorsMiddleware。 CorsPolicy整个 CORS 中间件中，首当其冲的是ICorsPolicy。这个接口的作用是定义跨域的策略，我们知道CORS中引入了Access-Control系列的 HTTP 头，所以，CorsPolicy 本质上是在定义允许哪些 HTTP 头、HTTP 方法、源(Origin) 可以访问受限的资源，以及当跨域请求是一个复杂请求的时候，预检请求的超时时间、是否支持凭据等等： 123456789101112public class CorsPolicy&#123; public bool AllowAnyHeader &#123; get; &#125; public bool AllowAnyMethod &#123; get; &#125; public bool AllowAnyOrigin &#123; get; &#125; public Func&lt;string, bool&gt; IsOriginAllowed &#123; get; private set; &#125; public IList&lt;string&gt; ExposedHeaders &#123; get; &#125; = new List&lt;string&gt;(); public IList&lt;string&gt; Headers &#123; get; &#125; = new List&lt;string&gt;(); public IList&lt;string&gt; Methods &#123; get; &#125; = new List&lt;string&gt;(); public IList&lt;string&gt; Origins &#123; get; &#125; = new List&lt;string&gt;(); public TimeSpan? PreflightMaxAge &#123; get; set; &#125; public bool SupportsCredentials &#123; get; set; &#125; 在整个中间件的设计中，与CorsPolicy接口产生直接联系的，是CorsPolicyBuilder和ICorsPolicyProvider。相信大家从命名上就可以了解到，前者是一个基于建造者模式的、针对 CorsPolicy进行“加工”的工具类，可以快速地对 跨域策略中允许的 HTTP 方法、HTTP 头、源(Origin)等信息进行修改。关于这一点，我们可以从CorsPolicyBuilder提供的方法签名中得到印证，而最终CorsPolicyBuilder通过Build()方法来返回一个“加工”好的CorsPolicy。 12345678910111213141516public class CorsPolicyBuilder &#123; CorsPolicyBuilder WithOrigins(params string[] origins); CorsPolicyBuilder WithHeaders(params string[] headers); CorsPolicyBuilder WithExposedHeaders(params string[] exposedHeaders); CorsPolicyBuilder WithMethods(params string[] methods); CorsPolicyBuilder AllowCredentials(); CorsPolicyBuilder DisallowCredentials(); CorsPolicyBuilder AllowAnyOrigin(); CorsPolicyBuilder AllowAnyMethod(); CorsPolicyBuilder AllowAnyHeader(); CorsPolicyBuilder SetPreflightMaxAge(TimeSpan preflightMaxAge); CorsPolicyBuilder SetIsOriginAllowed(Func&lt;string, bool&gt; isOriginAllowed); CorsPolicyBuilder SetIsOriginAllowedToAllowWildcardSubdomains(); CorsPolicy Build();&#125; 除了通过CorsPolicyBuilder来生成跨域策略，我们还可以通过ICorsPolicyProvider来生成跨域策略。如果你经常使用ASP.NET Core中的配置系统和依赖注入，对于这种“套路”应该不会感到陌生。这里，微软提供了一个默认实现：DefaultCorsPolicyProvider。DefaultCorsPolicyProvider本身依赖CorsOptions，允许使用者传入一个CorsPolicy的实例 或者是一个委托，来自定义跨域策略的“加工”细节，并在其内部维护一个字典，来实现具名的跨域策略。如果使用者不为当前跨域策略指定名称，则会使用默认的跨域策略名称。在大多数场景下，我们并不会直接使用CorsPolicyBuilder，而是在Startup类中通过委托来定义跨域策略，两者可以说是不同层次上的跨域策略的“提供者”。 123456789101112131415161718192021// DefaultCorsPolicyProvider的GetPolicyAsync()public Task&lt;CorsPolicy?&gt; GetPolicyAsync(HttpContext context, string? policyName)&#123; if (context == null)&#123; throw new ArgumentNullException(nameof(context)); &#125; policyName ??= _options.DefaultPolicyName; if (_options.PolicyMap.TryGetValue(policyName, out var result)) &#123; return result.policyTask!; &#125; return NullResult;&#125;// CorsOptionspublic void AddDefaultPolicy(CorsPolicy policy);public void AddDefaultPolicy(Action&lt;CorsPolicyBuilder&gt; configurePolicy);public void AddPolicy(string name, CorsPolicy policy);public void AddPolicy(string name, Action&lt;CorsPolicyBuilder&gt; configurePolicy);public CorsPolicy? GetPolicy(string name); CorsServiceOK，说完了跨域策略的“定义”，现在我们来看看跨域策略是如何被中间件“执行”的，这部分代码被定义在CoreService类的EvaluatePolicy()方法中。可以注意到，如果受限资源允许任意源(Origin)访问，则服务器端会认为这是一个不安全的跨域策略。 接下来，从HttpContext中提取客户端的源(Origin)，请求方法(HttpMethod)。此时，服务器端可以根据请求方法和 HTTP 头 判断当前请求是都为预检请求。按照CORS规范，当请求方法为OPTION且请求头中含有Access-Control-Request-Method时，即表示这是一个预检请求。 至此，我们有了两种选择，预检请求会交给EvaluatePreflightRequest()方法去处理，非预检请求会交给EvaluateRequest()方法去处理。除了HttpContext和CorsPolicy这两个参数以外，它们都会接受第三个参数CorsResult，它里面封装了我们一开始判断出来的关于源和预检请求的信息。继续细看，我们会发现这两个方法，都调用了PopulateResult()方法，继续顺着这条线索下去，我们就会发现，这个方法的主要作用是，结合跨域策略设定的各种参数，进一步对上一步生成的CorsResult进行“加工”。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869public CorsResult EvaluatePolicy(HttpContext context, CorsPolicy policy)&#123; // ... if (policy.AllowAnyOrigin &amp;&amp; policy.SupportsCredentials) &#123; throw new ArgumentException(Resources.InsecureConfiguration, nameof(policy)); &#125; var requestHeaders = context.Request.Headers; var origin = requestHeaders[CorsConstants.Origin]; var isOptionsRequest = HttpMethods.IsOptions(context.Request.Method); var isPreflightRequest = isOptionsRequest &amp;&amp; requestHeaders.ContainsKey(CorsConstants.AccessControlRequestMethod); var corsResult = new CorsResult &#123; IsPreflightRequest = isPreflightRequest, IsOriginAllowed = IsOriginAllowed(policy, origin), &#125;; if (isPreflightRequest) &#123; //预检请求 EvaluatePreflightRequest(context, policy, corsResult); &#125; else &#123; //非预检请求 EvaluateRequest(context, policy, corsResult); &#125; return corsResult;&#125;private static void PopulateResult(HttpContext context, CorsPolicy policy, CorsResult result)&#123; var headers = context.Request.Headers; if (policy.AllowAnyOrigin) &#123; result.AllowedOrigin = CorsConstants.AnyOrigin; result.VaryByOrigin = policy.SupportsCredentials; &#125; else &#123; var origin = headers[CorsConstants.Origin]; result.AllowedOrigin = origin; result.VaryByOrigin = policy.Origins.Count &gt; 1 || !policy.IsDefaultIsOriginAllowed; &#125; // 支持凭据 result.SupportsCredentials = policy.SupportsCredentials; // 预检请求超时时间 result.PreflightMaxAge = policy.PreflightMaxAge; // https://fetch.spec.whatwg.org/#http-new-header-syntax AddHeaderValues(result.AllowedExposedHeaders, policy.ExposedHeaders); // 允许的HTTP方法 var allowedMethods = policy.AllowAnyMethod ? new[] &#123; result.IsPreflightRequest ? (string)headers[CorsConstants.AccessControlRequestMethod] : context.Request.Method &#125; : policy.Methods; AddHeaderValues(result.AllowedMethods, allowedMethods); // 允许的HTTP头 var allowedHeaders = policy.AllowAnyHeader ? headers.GetCommaSeparatedValues(CorsConstants.AccessControlRequestHeaders) : policy.Headers; AddHeaderValues(result.AllowedHeaders, allowedHeaders);&#125; 那么，这些参数最终的走向是哪里呢？我们注意到CorsService里有一个叫做ApplyResult()的方法，观察方法签名可以发现，它负责把跨域检测的结果应用到 HTTP 响应上，相信大家都能想到，这里会设置各种Access-Control系列的头，比如Access-Control-Allow-Origin、Access-Control-Allow-Methods、Access-Control-Allow-Headers、Access-Control-Max-Age…等等。事实上，在CorsMiddleware中间件中，原本就是先调用EvaluateResult()方法，再调用ApplyResult()方法。当然，实际的代码中，还需要考虑[DisableCors]和[EnableCors]两个特性的影响，会多出一点判断的代码。关于跨域的代码层面的东西，我们就先讲到这里，在下一部分，我们会专门讲CORS里的简单请求和复杂请求。 1234567891011121314151617181920212223242526272829303132333435public Task Invoke(HttpContext context, ICorsPolicyProvider corsPolicyProvider)&#123; // ... if (!context.Request.Headers.ContainsKey(CorsConstants.Origin)) &#123; return _next(context); &#125; // [DisableCors] var corsMetadata = endpoint?.Metadata.GetMetadata&lt;ICorsMetadata&gt;(); if (corsMetadata is IDisableCorsAttribute) &#123; var isOptionsRequest = HttpMethods.IsOptions(context.Request.Method); var isCorsPreflightRequest = isOptionsRequest &amp;&amp; context.Request.Headers.ContainsKey(CorsConstants.AccessControlRequestMethod); if (isCorsPreflightRequest) &#123; // If this is a preflight request, and we disallow CORS, complete the request context.Response.StatusCode = StatusCodes.Status204NoContent; return Task.CompletedTask; &#125; return _next(context); &#125; // ... // [EnableCors] else if (corsMetadata is IEnableCorsAttribute enableCorsAttribute &amp;&amp; enableCorsAttribute.PolicyName != null) &#123; // ... // Evaluate &amp;&amp; Apply return EvaluateAndApplyPolicy(context, corsPolicy); async Task InvokeCoreAwaited(HttpContext context, Task&lt;CorsPolicy?&gt; policyTask) &#123; var corsPolicy = await policyTask; await EvaluateAndApplyPolicy(context, corsPolicy); &#125; &#125;&#125; 再论CORS好了，行文至此。既然这篇博客的主题是“跨域”，那么，我们不妨多说一点。我们知道，“跨域”产生的背景是，浏览器作为一个公共环境，它本身是不被信任的，所以，为了杜绝非当前域的资源，例如Cookie、API等等被“窃取”，浏览器便增加了“跨域”这一限制。而为了顺应“前后端分离”、“微服务”等等的开发思想，“跨域”这个问题开始频繁地出现在人们的视野中，从最初的JSONP，到如今成为事实标准的CORS，甚至从Vue里的代理服务器、Nginx里的反向代理，我们总是能窥出一点“跨域”的影子，“跨域”可谓是无处不在。 那么，什么是 CORS 呢？ CORS ，即跨域资源共享，是一种利用 HTTP 头部来指示服务器端对除自身以外的源(域、协议、端口)是否可以访问指定的资源。你可能会联想到OAuth2、JWT等等关于认证授权的词汇，请注意，“跨域”始终发生在浏览器端，相对于浏览器，一般意义上的客户端都被视为可信任的。除此之外，CORS提供了一种被称之为“预检”的机制，它可以用来检测服务器端支持的 HTTP 请求头、HTTP 动词，在预检中，浏览器发送的头中标示有 HTTP 方法和真实请求中会用到的头。 为什么会发生跨域？ 如上图所示，浏览器端，特别是XMLHttpRequest 、Fetch API 、Web字体 和 Canvas等始终遵循同源策略，domain-a.com和domain-b.com被视为两个不同域，因此，当domain-a.com试图访问domain-b.com下的资源时，就会被浏览器所限制，这就是我们所说的“跨域”。可能，这并不是一个特别好的例子，因为 HTML 中某些元素天生就被设计为允许跨域，例如：image、iframe、link、script等等。而如果我们通过“协商”来告诉domain-b，domain-a希望访问它下面的资源，这其实就是我们所说的 CORS 啦！这个“协商”过程呢，主要有两种，即 简单请求 和 复杂请求。 简单请求我们将不触发 CORS 预检 的请求称为简单请求，通常情况下，简单请求满足下列条件： 使用下列方法之一：GET、HEAD 和 POST 除了被用户代理自动设置的首部字段(例如：Connection、User-Agent) 和 在 Fetch 规范中定义为 禁用首部名称 的其他首部，允许人为设置的字段为 Fetch 规范定义的 对 CORS 安全的首部字段集合。该集合为：Accept、Accept-Language、Content-Language、Content-Type、DPR、Downlink、Save-Data、Viewport-Width、Width Content-Type 的值仅限于下列三者之一：text/plain、multipart/form-data、application/x-www-form-urlencoded 请求中的任意 XMLHttpRequestUpload 对象均没有注册任何事件监听器；XMLHttpRequestUpload 对象可以使用 XMLHttpRequest.upload 属性访问。 请求中没有使用 ReadableStream 对象。 对于 简单请求 ，由于它的 HTTP 动词是确定的，故其跨域主要体现在服务器端返回的 HTTP 响应中，可能出现的响应头有：Access-Control-Allow-Origin、Access-Control-Allow-Headers等。所以，如果客户端请求的Origin被包含在服务器端返回的Access-Control-Allow-Origin中，则表示跨域被允许，反之则不被允许。所以，现在大家应该能想明白，为啥那些年里大家稀里糊涂地，把Access-Control-Allow-Origin和Access-Control-Allow-Headers设置为*就万事大吉了吧，而对照着中间件的代码，理解这层含义会更容易一点！ 复杂请求与简单请求不同，复杂请求 要求必须首先使用 OPTIONS 方法发起一个预检请求到服务器，以获知服务器是否允许该实际请求。”预检请求“的使用，可以避免跨域请求对服务器的用户数据产生未预期的影响。 预检请求 当浏览器检测到，从JavaScript中发起的请求需要被预检。此时，可以注意到，预检请求中同时携带了下面两个首部字段： 12Access-Control-Request-Method: POSTAccess-Control-Request-Headers：X-PINGOTHER, Content-Type 服务器在接受预检请求后，会返回以下响应头： 1234Access-Control-Allow-Origin: http://foo.exampleAccess-Control-Allow-Methods: POST, GET, OPTIONSAccess-Control-Allow-Headers: X-PINGOTHER, Content-TypeAccess-Control-Max-Age: 86400 其中： 首部字段Access-Control-Allow-Methods表明服务器允许客户端使用 POST、GET 和 OPTIONS 方法发起请求。 首部字段Access-Control-Allow-Headers表明服务器允许请求中携带字段 X-PINGOTHER 与 Content-Type。 首部字段Access-Control-Max-Age表明该响应的有效时间为 86400 秒，即 24 小时。在有效时间内，浏览器无须为同一请求再次发起预检请求。 下面整理了 CORS 中常见的 Access-Control 系列头部字段： 123456789Access-Control-Allow-OriginAccess-Control-Expose-HeadersAccess-Control-Max-AgeAccess-Control-Allow-CredentialsAccess-Control-Allow-MethodsAccess-Control-Allow-HeadersOriginAccess-Control-Request-MethodAccess-Control-Request-Headers 本文小结本文分别从 源代码 和 规范 两个角度探讨了 “跨域” 这个话题，两者可以说是相辅相成的存在，CORS 中间件实现了 CORS 规范，而通过 CORS 规范帮助我们理解了中间件。“跨域”产生的背景是，浏览器作为一个公共环境，它本身是不被信任的，所以，为了杜绝非当前域的资源，例如Cookie、API等等被“窃取”，浏览器便增加了 “跨域” 这一限制。最初我们通过 JSONP 这种方案来解决跨域问题，而后来我们有了CORS 这种事实上的标准，其原理上利用 Origin 及 Access-Control系列的头来标识服务器端可以允许哪些源、以什么样的 HTTP 动词 / 头来访问资源，按照 CORS 规范，浏览器端发起的请求被分为： 简单请求 和 复杂请求 两种，两者最大的区别是，复杂请求 必须首先通过 OPTIONS 方法发起一个预检请求到服务器，以获知服务器是否允许该实际请求。好了，以上就是这篇博客的全部内容啦，欢迎大家在博客评论中参与讨论，再次谢谢大家，晚安！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"源码","slug":"源码","permalink":"https://qinyuanpei.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"中间件","slug":"中间件","permalink":"https://qinyuanpei.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"跨域","slug":"跨域","permalink":"https://qinyuanpei.github.io/tags/%E8%B7%A8%E5%9F%9F/"},{"name":"CORS","slug":"CORS","permalink":"https://qinyuanpei.github.io/tags/CORS/"}]},{"title":"源代码探案系列之 .NET Core 限流中间件 AspNetCoreRateLimit","date":"2021-03-10T21:52:47.000Z","path":"posts/2396015802/","text":"在上一篇文章中，博主带领大家一起深入了解 ConcurrencyLimiter 这个中间件，正当我得意洋洋地向 Catcher Wong 大佬吹嘘这一点小收获时，大佬一脸嫌弃地说，一个单机版的方案有什么好得意的啊。大佬言下之意，显然是指，这个中间件在分布式环境中毫无用武之地。其实，你只需要稍微想一下，就能想明白这个问题。毕竟，它只是通过SeamphoreSlim控制线程数量而已，一旦放到分布式环境中，这个并发控制就被大大地削弱。所以，在今天这篇文章中，博主会带领大家一起“探案” ASP.NET Core 中的限流中间件 AspNetCoreRateLimite，希望大家可以从中感悟到不一样的东西。对我而言，这可能是人到中年的焦虑感所催生出来的一种源动力，同时亦是为了不让那些订阅专栏的同学失望。 关于“限流”这个话题，我个人以为，它可以引申出非常多的东西，譬如“熔断”和“限流”，其实可以看作是同一类问题的“一体两面”。最早接触熔断，是源于 Spring Cloud 中的 Hystrix，它其实是指当服务不可用的时候，客户端应该采取什么样的措施去应对，实际使用中我们可能会考虑重试、超时、降级等策略。相应地，当服务端在面对来自客户端的异常流量时，就产生了“限流”这个概念，“限流”可以是线程隔离(线程数 + 队列大小限制)，可以是信号量隔离(设置最大并发请求数目)，可以是限制QPS。这里，我们讨论的主要是第三种，而实现限流的常见算法主要有计数器算法、漏桶算法和令牌桶算法。这里，AspNetCoreRateLimit 这个中间件，则主要使用了计数器算法**，并配合 IMemoryCache 和 IDistributedCache 分别实现了基于内存和基于分布式缓存的持久化逻辑。 源代码解读首先，使用者通过配置定义了一个或者多个规则，这些规则决定了每个客户端在访问特定终结点时，一段时间内可以访问的最大次数。 RateLimitMiddleware 通过注入的IRateLimitProcessor 来匹配规则，然后依次判断每个规则是否达到了限流条件。一旦达到限流条件，中间件会改变 HTTP 响应的状态码、响应头、返回值，告知使用者已达到最大调用次数。而针对每一种 IRateLimitProcessor ，主要通过ProcessRequestAsync() 方法来实现计数，如果上一次的请求对应的时间戳 + 规则中时间间隔 &gt;= 当前时间，则说明请求没有过期，此时，就需要给这个计数增加1。好了，现在我们来针对 AspNetCoreRateLimit 中的核心部件逐个进行解读。 RateLimitProcessorRateLimitProcessor，是一个抽象类，实现了IRateLimitProcessor接口，公开的方法有 3 个：ProcessRequestAsync()、IsWhitelisted() 和 GetRateLimitHeaders()。在此基础上，派生出ClientRateLimitProcessor和IpRateLimitProcessor两个子类。两者最大的不同在于，其所依赖的Store不同，前者为IClientPolicyStore，后者IIpPolicyStore，它们都实现了同一个接口IRateLimitStore： 123456789public interface IRateLimitStore&lt;T&gt;&#123; Task&lt;bool&gt; ExistsAsync(string id, CancellationToken cancellationToken = default); Task&lt;T&gt; GetAsync(string id, CancellationToken cancellationToken = default); Task RemoveAsync(string id, CancellationToken cancellationToken = default); Task SetAsync(string id, T entry, TimeSpan? expirationTime = null, CancellationToken cancellationToken = default );&#125; 可以注意到，这些都是典型的基于键-值的存储，所以，不管是基于内存的IMemeryCache，还是基于分布式缓存的IDistributedCache，都可以做到无缝切换。不同的Processor，本质上是它们生成缓存键的方式不同，例如，IpRateLimitProcessor是用一个前缀来表示一组IP，而ClientRateLimitProcessor则是用通过客户端前缀和客户端Id来作为区分： 12345678910111213141516171819202122232425262728293031323334353637// src/AspNetCoreRateLimit/Core/IpRateLimitProcessor.cspublic async Task&lt;IEnumerable&lt;RateLimitRule&gt;&gt; GetMatchingRulesAsync( ClientRequestIdentity identity, CancellationToken cancellationToken = default)&#123; var policies = await _policyStore.GetAsync( $\"&#123;_options.IpPolicyPrefix&#125;\", cancellationToken ); var rules = new List&lt;RateLimitRule&gt;(); if (policies?.IpRules?.Any() == true) &#123; // search for rules with IP intervals containing client IP var matchPolicies = policies.IpRules .Where(r =&gt; IpParser.ContainsIp(r.Ip, identity.ClientIp)); foreach (var item in matchPolicies) &#123; rules.AddRange(item.Rules); &#125; &#125; return GetMatchingRules(identity, rules);&#125;// src/AspNetCoreRateLimit/Core/ClientRateLimitProcessor.cspublic async Task&lt;IEnumerable&lt;RateLimitRule&gt;&gt; GetMatchingRulesAsync( ClientRequestIdentity identity, CancellationToken cancellationToken = default)&#123; var policy = await _policyStore.GetAsync( $\"&#123;_options.ClientPolicyPrefix&#125;_&#123;identity.ClientId&#125;\", cancellationToken ); return GetMatchingRules(identity, policy?.Rules);&#125; 对于RateLimitProcessor而言，其实现思路是，通过CounterKeyBuilder及其子类来生成计数器标识(CounterId)，然后再通过AsyncKeyLock来实现计数，最终通过IRateLimitCounterStore来实现存储： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public virtual async Task&lt;RateLimitCounter&gt; ProcessRequestAsync( ClientRequestIdentity requestIdentity, RateLimitRule rule, CancellationToken cancellationToken = default)&#123; var counter = new RateLimitCounter &#123; Timestamp = DateTime.UtcNow, Count = 1 &#125;; // 生成CounterId var counterId = BuildCounterKey(requestIdentity, rule); // 基于AsyncLock的计数器 // serial reads and writes on same key using (await AsyncLock.WriterLockAsync(counterId).ConfigureAwait(false)) &#123; var entry = await _counterStore.GetAsync(counterId, cancellationToken); if (entry.HasValue) &#123; // entry has not expired if (entry.Value.Timestamp + rule.PeriodTimespan.Value &gt;= DateTime.UtcNow) &#123; // increment request count var totalCount = entry.Value.Count + _config.RateIncrementer?.Invoke() ?? 1; // deep copy counter = new RateLimitCounter &#123; Timestamp = entry.Value.Timestamp, Count = totalCount &#125;; &#125; &#125; // 计数器存储 // stores: id (string) - timestamp (datetime) - total_requests (long) await _counterStore.SetAsync( counterId, counter, rule.PeriodTimespan.Value, cancellationToken ); &#125; return counter;&#125; AsyncKeyLock在分析RateLimitProcessor类的时候，我们提到了AsyncKeyLock。对于AsyncKeyLock的实现，我个人认为这是整个中间件的精华，因为这里出现了，和SeamphoreSlim一样经典的东西，这里用到了自旋锁SpinLock。我个人理解，SpinLock 约等于 Interlocked + 内核级别的while。这部分代码本身并不复杂，难就难在这样一个精妙的想法上面。其中，AsyncKeyLockDoorman 这个类的实现，应该是参考了微软的一篇博客—— Building Async Coordination Primitives, Part 7: AsyncReaderWriterLock，因为ReaderLockAsync()、WriterLockAsync()、ReaderRelease() 和 WriterRelease() 这 4 个关键方法完全一样。结合限流这个场景来看，它是典型的“多写”场景，因为如果是相同的请求，那么就会产生相同的计数器标识(CounterId)，所以，这个AsyncLockDoorman这个类所定义的上下文边界，其实是“一读多写”的问题，所以，我们可以注意到，它里面定义了一个“写”操作的队列_waitingWriters，一个“读操作”的_waitingReader： 123456789101112public AsyncKeyLockDoorman(Action&lt;AsyncKeyLockDoorman&gt; reset)&#123; // 多个写入者 _waitingWriters = new Queue&lt;TaskCompletionSource&lt;Releaser&gt;&gt;(); // 单个读取者 _waitingReader = new TaskCompletionSource&lt;Releaser&gt;(); _status = 0; _readerReleaser = Task.FromResult(new Releaser(this, false)); _writerReleaser = Task.FromResult(new Releaser(this, true)); _reset = reset;&#125; 对于“写”操作而言，当一个新的写入者希望进来的时候，如果此时锁没有被别人占用，那么这个新的写入者会获得这个锁，状态值m_status会被修改为-1。反之，如果此时这个锁已经被别人占用了，那么这个新的写入者将会进入等待队列。 1234567891011121314151617public Task&lt;Releaser&gt; WriterLockAsync()&#123; lock (_waitingWriters) &#123; if (_status == 0) &#123; _status = -1; return _writerReleaser; &#125; else &#123; var waiter = new TaskCompletionSource&lt;Releaser&gt;(); _waitingWriters.Enqueue(waiter); return waiter.Task; &#125; &#125;&#125; 对于“读”操作而言，我们来思考这样一个问题，什么时候“读”操作会被允许呢？答案是这一时刻没有写入者正在“写”或者“等”，因为如果不这样的话，就会发生我们平常所说的“脏读”，所以，这种情况下，就必须强迫“读取者”去等待写入者“空闲”下来。此时，不难理解ReadLockAsync()的实现： 12345678910111213141516public Task&lt;Releaser&gt; ReaderLockAsync()&#123; lock (_waitingWriters) &#123; if (_status &gt;= 0 &amp;&amp; _waitingWriters.Count == 0) &#123; ++_status; return _readerReleaser; &#125; else &#123; ++_readersWaiting; return _waitingReader.Task.ContinueWith(t =&gt; t.Result); &#125; &#125;&#125; 现在，让我们把视线拉回到AsyncKeyLock，它负责维护一组AsyncKeyLockDoorman，其内部部通过一个字典来维护CounterId和AsyncKeyLockDoorman间的关系。与此同时，为了减少创建·AsyncKeyLockDoorman·带来的性能损耗，它使用一个栈来存储AsyncKeyLockDoorman。每次获取AsyncKeyLockDoorman的过程，本质上就是为指定的Key分配AsyncKeyLockDoorman的过程，同时会更新其引用数RefCount。相应地，释放AsyncKeyLockDoorman的过程，本质上就是减少其引用数RefCount，从字典中移除指定Key，“归还”对象池的过程： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354// GetDoorman()private static AsyncKeyLockDoorman GetDoorman(string key)&#123; AsyncKeyLockDoorman doorman; bool lockTaken = false; try &#123; _spinLock.Enter(ref lockTaken); if (!Keys.TryGetValue(key, out doorman)) &#123; doorman = (Pool.Count &gt; 0) ? Pool.Pop() : new AsyncKeyLockDoorman(ReleaseDoorman); doorman.Key = key; Keys.Add(key, doorman); &#125; doorman.RefCount++; &#125; finally &#123; if (lockTaken) &#123; _spinLock.Exit(); &#125; &#125; return doorman;&#125;// ReleaseDoorman()private static void ReleaseDoorman(AsyncKeyLockDoorman doorman)&#123; bool lockTaken = false; try &#123; _spinLock.Enter(ref lockTaken); if (--doorman.RefCount == 0) &#123; Keys.Remove(doorman.Key); if (Pool.Count &lt; MaxPoolSize) &#123; doorman.Key = null; Pool.Push(doorman); &#125; &#125; &#125; finally &#123; if (lockTaken) &#123; _spinLock.Exit(); &#125; &#125;&#125; RateLimitMiddlewareOK，到这里，我们再回过头去看源代码解读这里的内容，大概就可以串起来整合中间件的调用链路，Middleware-&gt;RateLimteProcessor-&gt;AsyncKeyLock-&gt;AsyncKeyLockDoorman，坦白来讲，我一直没能想明白为什么要用SpinLock？难道仅仅是为了减少等待时间、提高性能吗？经过精简，我们发现，整个中间件的Invoke()方法，大致要经历下面几个阶段： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172public async Task Invoke(HttpContext context)&#123; // 检查限流是否启用 if (_options == null) &#123; await _next.Invoke(context); return; &#125; // 获取用户身份 var identity = await ResolveIdentityAsync(context); // 检查白名单 if (_processor.IsWhitelisted(identity)) &#123; await _next.Invoke(context); return; &#125; //获取限流规则 var rulesDict = new Dictionary&lt;RateLimitRule, RateLimitCounter&gt;(); var rules = await _processor.GetMatchingRulesAsync( identity, context.RequestAborted ); foreach (var rule in rules) &#123; // 获取计数器数目 var rateLimitCounter = await _processor.ProcessRequestAsync( identity, rule, context.RequestAborted ); if (rule.Limit &gt; 0) &#123; // 请求未过期 if (rateLimitCounter.Timestamp + rule.PeriodTimespan.Value &lt; DateTime.UtcNow) &#123; continue; &#125; // 请求过期 if (rateLimitCounter.Count &gt; rule.Limit) &#123; // 各种记日志，告诉调用者多长时间后再重试 var retryAfter = rateLimitCounter.Timestamp.RetryAfterFrom(rule); // ... // 中止请求 await ReturnQuotaExceededResponse(context, rule, retryAfter); return; &#125; &#125; else &#123; // Limit &lt;= 0, 相当于直接不允许放行，中止请求 await ReturnQuotaExceededResponse( context, rule, int.MaxValue.ToString(System.Globalization.CultureInfo.InvariantCulture) ); &#125; // ... &#125; // 设置X-Rate-Limit头 // ... await _next.Invoke(context);&#125; 本文小结作为 并发限制 这一篇的“姊妹篇”，这一篇的难度相对上一篇堪称“高山仰止”，主要的难点是 SpinLock 、“一读多写”的异步读写锁 AsyncKeyLock 以及 AsyncKeyLockDoorman 。如果大家感兴趣的话，可以去搜索一下 AsyncKeyLock 这个关键字，大家就会发现在好多开源项目 中都能找到类似的代码片段，莫非这是某种神奇的算法吗？阅读源代码，其实是一个无法“立竿见影”的学习方法，有时候我们要通过叙述或者表达来输出我们对待一件事物的看法。这是因为，我们自以为是的“学会”和真正的“学会”，这两者间可能千差万别，就像我最近在用 ABP vNext 搭建一个小项目，阅读文档的时候，眼睛觉得它“学会”了，而实际需要需要扩展或者替换 ABP 的实体/服务的时候。我的手会告诉我，它真的“不会”。做一个知难行易的“调包”侠也许会非常容易，可正因为如此，你要凸显自我就会非常困难。世上的事情，“夫夷以近，则游者众；险以远，则至者少。而世之奇伟、瑰怪，非常之观，常在于险远，而人之所罕至焉，故非有志者不能至也”，哪怕就是增长一下见识呢，你说对吧……","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"源码","slug":"源码","permalink":"https://qinyuanpei.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"中间件","slug":"中间件","permalink":"https://qinyuanpei.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"},{"name":"限流","slug":"限流","permalink":"https://qinyuanpei.github.io/tags/%E9%99%90%E6%B5%81/"}]},{"title":"源代码探案系列之 .NET Core 并发限制中间件 ConcurrencyLimiter","date":"2021-03-04T20:13:47.000Z","path":"posts/18417412/","text":"打算开一个新的专栏——源代码探案系列，目的是通过源代码来探索更广阔的技术世界。因为我越来越意识到，我可能缺乏一个结构化的知识体系，虽然处在一个碎片化的时代，从外界接收了大量的信息，可这些碎片化的信息，到底能不能转化为自身可用的知识，其实是需要去认真思考一番。尤其是当我注意到，许多人工作多年，在经历过从“生手”到“熟练工”这种蜕变以后，居然还是会害怕原理性内容的考察。我承认，程序员这个职业更像是一个“手艺人”，可我更想说一句古人的话——君子不器。什么是器呢？“形而上者谓之道，形而下者谓之器”，用一句更直白的话来说，就是“不能知其然而不知其所以然”，这是我一个非CS科班出身的程序员，想去写这样一个专栏的初衷，因为在我看来，“器”是永远学不完的，而“道”虽然听起来虚无缥缈，实则“朝闻道，夕死可矣”。 作为这个专栏的第一篇博客，我打算从 ASP.NET Core 中的 ConcurrencyLimiter 这个中间件开始。并发是一个爱恨交织的话题，我们喜欢高并发，因为这是程序员跻身高手行列的好机会；我们厌恶并发，因为它引入了多线程、锁、信号量这些复杂的东西。相信大家都曾被并发困扰过，古人云：他山之石，可以攻玉，还有什么比阅读源代码更朴实无华的“学习”呢？你找大牛，大牛可能忙着开会、做PPT；你找同事，同事里可能十个有八个都不知道啊。这个中间件的核心是 IQueuePolicy ，其位于以下位置，它定义了两个核心的方法：TryEnterAsync() 和 OnExit()： 12345public interface IQueuePolicy&#123; ValueTask&lt;bool&gt; TryEnterAsync(); void OnExit();&#125; 在其默认实现QueuePolicy中，TryEnterAsync()方法，决定着一个请求是会被拒绝还是接受。具体是怎么做呢？它定义了一个最大的并发请求数目，如果实际数超过了最大的并发请求数目，那么请求将会被拒绝。反之，请求将被接受。再仔细看，我们就会发现，它内部使用了SeamphoreSlim和Interlocked，所以，聪明的小伙伴们应该立马会联想到，这两种锁各自的作用是什么。 其中，Seamphore 是一个 Windows 内核中的一个同步信号量，适用于在多个有限的线程资源中共享内存资源，它就像一个栅栏，本身具有一定的容量，当线程数量达到这个容量后，新的线程就无法再通过，直到某个线程执行完成。SeamphoreSlim是Seamphore优化后的版本，在性能上表现更好一点，更推荐大家使用SeamphoreSlim。 而 Interlocked 的则是我们熟悉的原子操作，它可以在多个线程中，对共享的内存资源进行原子加或者原子减操作。在这里，Interlocked主要用来控制并发请求数的加和减。如果当前的并发请求数小于最大的并发请求数，表示还可以允许新的请求进来，此时，TryEnterAsync()方法会返回true。如果此时的并发请求数大于最大的并发请求数，则需要对当前请求数进行减操作，此时，TryEnterAsync()方法会返回false。 一旦搞清楚这一点，结合中间件的代码，我们可以非常容易地想明白,这个并发控制的实现思路。下面是QueuePolicy中TryEnterAsync()和OnExit()两个方法的实现，分别代表了“加锁”和“解锁”两个不同的阶段。某种程度上，Seamphore更像一个水闸，每次可以通过的“流量”是固定的，超出的部分会被直接“拒绝”： 1234567891011121314151617181920212223242526272829//“加锁”public ValueTask&lt;bool&gt; TryEnterAsync()&#123; // a return value of 'false' indicates that the request is rejected // a return value of 'true' indicates that the request may proceed // _serverSemaphore.Release is *not* called in this method, // it is called externally when requests leave the server int totalRequests = Interlocked.Increment(ref _totalRequests); //当前请求次数 &gt; 最大请求次数，返回false表示拒绝 if (totalRequests &gt; _maxTotalRequest) &#123; Interlocked.Decrement(ref _totalRequests); return new ValueTask&lt;bool&gt;(false); &#125; Task task = _serverSemaphore.WaitAsync(); if (task.IsCompletedSuccessfully) &#123; return new ValueTask&lt;bool&gt;(true); &#125; return SemaphoreAwaited(task);&#125;//“解锁”public void OnExit()&#123; _serverSemaphore.Release(); Interlocked.Decrement(ref _totalRequests);&#125; 揭秘 StackPolicy除了QueuePolicy这种实现以外，官方还提供了StackPolicy的实现。从名称上，我们就能大致区分出它们的不同，因为我相信大家都能拎得清“队列”和“栈”。在实现StackPolicy的过程中，首先会判断是否还有访问请求次数_freeServerSpots，直接返回true，确保中间件可以继续执行。如果_queueLength和我们设置的队列最大容量相同，此时，表示队列已满，需要先取消之前的请求，并保留后来的请求。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263public ValueTask&lt;bool&gt; TryEnterAsync()&#123; lock (_bufferLock) &#123; if (_freeServerSpots &gt; 0) &#123; _freeServerSpots--; return new ValueTask&lt;bool&gt;(true); &#125; // 队列已满，则取消之前的请求，即_head if (_queueLength == _maxQueueCapacity) &#123; _hasReachedCapacity = true; _buffer[_head].Complete(false); _queueLength--; &#125; var tcs = _cachedResettableTCS ?? = new ResettableBooleanCompletionSource(this); _cachedResettableTCS = null; if (_hasReachedCapacity || _queueLength &lt; _buffer.Count) &#123; _buffer[_head] = tcs; &#125; else &#123; _buffer.Add(tcs); &#125; _queueLength++; // increment _head for next time // 如果_head = 最大队列容量，则_head需要移动至首位 _head++; if (_head == _maxQueueCapacity) &#123; _head = 0; &#125; return tcs.GetValueTask(); &#125;&#125;public void OnExit()&#123; lock (_bufferLock) &#123; if (_queueLength == 0) &#123; _freeServerSpots++; f (_freeServerSpots &gt; _maxConcurrentRequests) &#123; _freeServerSpots--; throw new InvalidOperationException(\"OnExit must only be called once per successful call to TryEnterAsync\"); &#125; return; &#125; // step backwards and launch a new task if (_head == 0) &#123; _head = _maxQueueCapacity - 1; &#125; else &#123; _head--; &#125; _buffer[_head].Complete(true); _queueLength--; &#125;&#125; 所以，现在，你可以感受到这两种策略的差异了，QueuePolicy是一个水闸，“多”出来的流量会被直接拒绝掉。StackPolicy是一个垂直的管道，每次都是先取消底部的请求，再让新的请求从顶部进来。此时，如果我们再回过头来看 ConcurrencyLimiterMiddleware 这个中间件的实现，就会有种恍然大悟的感觉。 揭秘 Middleware1234567891011121314151617181920212223242526272829303132333435public async Task Invoke(HttpContext context)&#123; // Make sure we only ever call GetResult once on the TryEnterAsync ValueTask b/c it resets. // 以下代码片段，其实都是调用IQueuePolicy.TryEnterAsync() var waitInQueueTask = _queuePolicy.TryEnterAsync(); bool result; if (waitInQueueTask.IsCompleted) &#123; ConcurrencyLimiterEventSource.Log.QueueSkipped(); result = waitInQueueTask.Result; &#125; else &#123; using (ConcurrencyLimiterEventSource.Log.QueueTimer()) &#123; result = await waitInQueueTask; &#125; &#125; // 当result为true，表示请求被接收，此时，让中间件继续执行 // 切记：调用_queuePolicy.OnExit()来释放锁 if (result) &#123; try &#123; await _next(context); &#125; finally &#123; _queuePolicy.OnExit(); &#125; &#125; else &#123; //这里就是请求被拒绝的情况，修改状态码以及输出错误信息 ConcurrencyLimiterEventSource.Log.RequestRejected(); ConcurrencyLimiterLog.RequestRejectedQueueFull(_logger); context.Response.StatusCode = StatusCodes.Status503ServiceUnavailable; await _onRejected(context); &#125;&#125; 至此，我们就理清了整个中间件的运作机制，ConcurrencyLimiterMiddleware 中注入了IQueuePolicy这个接口，当一个新的请求进来，中间件会调用IQueuePolicy接口的TryEnterAsync()方法，该方法决定了一个请求是会被接受还是拒绝。当请求被接受的时候，中间件会调用_next(context)让请求继续往下走；当请求被拒绝的时候，中间件会修改 HTTP 状态码(503) 和 返回值，保证调用者可以收到错误信息。这就是这个中间件全部的秘密。而如果要在项目中使用这个中间件，同样是非常简单的： 123456789101112// 中间件基本法，先注册后使用// ConfigureServices()// 或者 services.AddQueuePolicy()services.AddStackPolicy(options =&gt;&#123; options.MaxConcurrentRequests = 2; options.RequestQueueLimit = 25;&#125;)// Configure()app.UseConcurrencyLimiter(); 本文小结这篇博客，主要揭秘了 ASP.NET Core 中的 ConcurrencyLimiter 中间件，这个中间件的主要功能是控制 ASP.NET Core 中的请求并发。作为这个中间件的核心，微软为 IQueuePolicy 接口提供了 QueuePolicy 和 StackPolicy 两种不同的策略实现。其中，QueuePolicy是一个水闸，“多”出来的流量会被直接拒绝掉。StackPolicy是一个垂直的管道，每次都是先取消底部的请求，再让新的请求从顶部进来。对于我们而言，这个中间件最值得学习的地方，其实是SeamphoreSlim和Interlocked，我们经常提到“锁”，其实，“锁”不单单是指 .NET 中Monitor的语法糖，即lock关键字，在同步信号量以及线程同步的相关话题中，我们还会接触到譬如 Mutex(互斥锁)、ReaderWriterLockSlim、Interlocked(原子操作)、SpinLock(自旋锁) 以及 SeamphoreSlim 等等不同的“锁”。除此之外，还有譬如AutoResetEvent、ManualResetEvent 和 ManualResetEventSlim 等等的同步信号量。如果有读者朋友对此感兴趣，可以到 MSDN 上去搜索相关的关键字，能让博主本人和大家从中有所收获，这是我坚持写下去的理由。好了，以上就是这篇博客的全部内容啦，欢迎大家在评论区留言、讨论。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"源码","slug":"源码","permalink":"https://qinyuanpei.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"并发","slug":"并发","permalink":"https://qinyuanpei.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"中间件","slug":"中间件","permalink":"https://qinyuanpei.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/"}]},{"title":"通过 EmbededFileProvider 实现 Blazor 的静态文件访问","date":"2021-02-23T05:37:47.000Z","path":"posts/3789745079/","text":"重构我的 独立博客 ，是博主今年的计划之一，这个基于 Hexo 的静态博客，最早搭建于2014年，可以说是比女朋友更亲密的存在，陪伴着博主走过了毕业、求职以及此刻的而立之年。其间虽然尝试过像 Jekyll 和 Hugo 这样的静态博客生成器，可是考虑到模板、插件等周边生态，这个想法一直被搁置下来。直到最近，突然涌现出通过 Blazor 重写博客的想法，尤其是它对于 WebAssembly 的支持，而类似 Vue 和 React的组件化开发模式，在开发体验上有着同样不错的表现。所以，今天这篇博客就来聊聊在重写博客过程中的一点收获，即如何让 Blazor 访问本地的静态文件。 从内嵌资源说起首先，我们要引入一个概念，即：内嵌资源。我们平时接触的更多的是本地文件系统，或者是 FTP 、对象存储这类运行在远程服务器上的文件系统，这些都是非内嵌资源，所以，内嵌资源主要是指那些没有目录层级的文件资源，因为它会在编译的时候“嵌入”到动态链接库(DLL)中。一个典型的例子是Swagger，它在.NET Core平台下的实现是Swashbuckle.AspNetCore，它允许使用自定义的HTML页面。这里可以注意到，它使用到了GetManifestResourceStream()方法： 123456app.UseSwaggerUI(c =&gt;&#123; // requires file to be added as an embedded resource c.IndexStream = () =&gt; GetType().Assembly .GetManifestResourceStream(\"CustomUIIndex.Swagger.index.html\"); &#125;); 其实，这里使用的就是一个内嵌资源。关于内嵌资源，我们有两种方式来定义它： 在 Visual Studio 中选中指定文件，在其属性窗口中选择生成操作为嵌入的资源： 如何定义一个文件资源为内嵌资源 在项目文件(.csproj)中修改对应ItemGroup节点，参考示例如下： 123456789&lt;Project Sdk=\"Microsoft.NET.Sdk.Web\"&gt;&lt;!-- ... --&gt; &lt;ItemGroup&gt; &lt;EmbeddedResource Include=\"_config.yml\"&gt; &lt;CopyToOutputDirectory&gt;Always&lt;/CopyToOutputDirectory&gt; &lt;/EmbeddedResource&gt; &lt;/ItemGroup&gt;&lt;!-- ... --&gt;&lt;/Project&gt; 这样，我们就完成了内嵌资源的定义。而定义内嵌资源，本质上还是为了在运行时期间去读取和使用，那么，自然而然地，我们不禁要问，该怎么读取这些内嵌资源呢？在Assembly类中，微软为我们提供了下列接口来处理内嵌资源： 1234public virtual ManifestResourceInfo GetManifestResourceInfo(string resourceName);public virtual string[] GetManifestResourceNames();public virtual Stream GetManifestResourceStream(Type type, string name);public virtual Stream GetManifestResourceStream(string name); 其中，GetManifestResourceNames()方法用来返回所有内嵌资源的名称，GetManifestResourceInfo()方法用来返回指定内嵌资源的描述信息，GetManifestResourceStream()方法用来返回指定内嵌资源的文件流。为了方便大家理解，这里我们准备了一个简单的示例： 1234567var assembly = Assembly.GetExecutingAssembly();var resources = assembly.GetManifestResourceNames();resources.ToList().ForEach(x =&gt; Console.WriteLine(x));//ConsoleApp.A.B.示例文档.txt//ConsoleApp.A._config.ymlvar fileInfo = assembly.GetManifestResourceInfo(resources[0]);var fileStream = assembly.GetManifestResourceStream(resources[0]); 此时，我们会发现，内嵌资源都是使用类似A.B.C.D这样的形式来表示资源路径的，因为内嵌资源本身是没有目录层级的。现在，如果我们再回过头去看Swagger的示例，就不难理解为什么会有CustomUIIndex.Swagger.index.html这样一个奇怪的值，因为它对应着实际的物理文件路径，如下图所示，示例代码中输出的资源路径和实际的物理路径存在着对应关系： 项目中的物理路径与内嵌资源路径对照 EmbededFileProviderOK，那么在了解了内嵌资源以后，接下来，我们需要关注的是EmbededFileProvider。需要说明的是，在ASP.NET Core中，微软是通过IFileProvider这个接口来解决文件读取问题的，典型的使用场景有静态文件中间件、Rozar模板引擎以及WWWRoot目录定位等等，通常情况下，我们使用PhysicalFileProvider更多一点，它和EmbededFileProvider一样，都实现了IFileProvider接口，所以，ASP.NET Core可以从不同的来源访问文件信息。 显然，EmbededFileProvider正是为了内嵌资源而生，它在内部使用到了Assembly类中和内嵌资源相关的接口.所以，除了上面的方式，我们还可以通过下面的方式来访问内嵌资源，需要注意的是，使用EmbededFileProvider需要引用Microsoft.Extensions.FileProviders.Embedded，大家可以比较一下这两种方式地差异： 123456var assembly = Assembly.GetExecutingAssembly();var provider = new EmbeddedFileProvider(assembly);//注意，这里写\".\"或者\"\"都可以var resouces = provider.GetDirectoryContents(\".\").ToList();var fileInfo = provider.GetFileInfo(resouces[0]);var fileStream = fileInfo.CreateReadStream(); 除此以外，IFileProvider还有一个最重要的功能，即Watch()方法，它可以监听文件的变化，并返回一个IChangeToken。有没有一种似曾相识燕归来的感觉？没错，博主曾经在 基于选项模式实现.NET Core的配置热更新 这篇文章中介绍过它，它是实现配置热更新的关键。事实上，FileConfigurationSource这个类中有一个Provider属性，而它对应的类型恰好是IFileProvider，这难道是巧合吗？不，仔细顺着这条线，我们大概就能明白微软的良苦用心，我们的配置文件自然是来自文件系统，而考虑到内嵌资源的存在，我们面对的文件系统其实是一个广义的文件系统，它可以是物理文件、内嵌文件、Glob、对象存储(OSS)等等 Blazor的奇妙缘分好了，千呼万唤始出来，现在终于要讨论 Blazor 这个话题啦！众所周知，静态博客生成器里主要存在着两种配置，即站点配置和主题配置，Hexo 里甚至还支持从特定文件夹里加载自定义的数据。所以，对于静态博客而言，它需要有从外部加载数据这个特性。我们知道，Blazor 分为服务器和客户端两个版本，两者的区别主要在于 Rozar 模板由谁来渲染，前者相当于服务端渲染(SSR) + SignalR，而后者则是基于 WebAssembly，它可以直接在浏览器中加载。显然，后者更接近我们静态博客生成器的想法。由于 Hexo 使用 Yaml 作为配置语言，所以，为了读取原来 Hexo 博客的配置，参考 实现自己的.NET Core配置Provider之Yaml 这篇博客实现了一个YamlConfigurationProvider。 在使用的过程中，遇到的问题是，它无法识别配置文件的路径。原因很简单，经过编译的 Blazor 会被打包为 WebAssembly ，而 WebAssembly 在前端加载以后，原来的目录层级早已荡然无存。此时，基于物理文件的 PhysicalFileProvider 将无法工作。解决方案其实大家都能想到，换一种IFileProvider的实现就好了啊！至此，奇妙的缘分产生了： 12345678910111213141516171819class YamlConfigurationProvider : FileConfigurationProvider&#123; private readonly FileConfigurationSource _source; public YamlConfigurationProvider(FileConfigurationSource source) : base(source) &#123; _source = source; &#125; public override void Load() &#123; var path = _source.Path; var provider = _source.FileProvider; using (var stream = provider.GetFileInfo(path).CreateReadStream()) &#123; //核心问题就是这个Stream的来源发生了变化 var parser = new YamlConfigurationFileParser(); Data = parser.Parse(stream); &#125; &#125; 其实，官方文档中提到过，Blazor 的配置文件默认从 WWWRoot 下的appsettings.json加载，所以，对于像JSON这类静态文件，可以注入HttpClient，以API的方式进行访问。例如，官方文档中推荐的加载配置文件的方式为： 123456789101112var httpClient = new HttpClient()&#123; BaseAddress = new Uri(builder.HostEnvironment.BaseAddress)&#125;;builder.Services.AddScoped(sp =&gt; httpClient);//前方有语法糖，高甜:)using var response = await http.GetAsync(\"cars.json\");using var stream = await response.Content.ReadAsStreamAsync();builder.Configuration.AddJsonStream(stream); 而经过我们这样改造以后，我们还可以这样加载配置： 123456builder.Configuration.AddYamlFile( provider:new EmbeddedFileProvider(Assembly.GetExecutingAssembly()), path: \"_config.yml\", optional:false, reloadOnChange:true); 一旦这些配置注入到 IoC 容器里，我们就可以纵享无所不在的依赖注入，这里以某个组件为例： 1234567891011@using Microsoft.Extensions.Configuration@inject IConfiguration Configuration&lt;div class=\"mdui-container-fluid\"&gt; &lt;div class=\"mdui-row DreamCat-content-header\"&gt; &lt;div class=\"mdui-container fade-scale in\"&gt; &lt;h1 class=\"title\"&gt;@Configuration[\"title\"]&lt;/h1&gt; &lt;h5 class=\"subtitle\"&gt;@Configuration[\"subtitle\"]&lt;/h5&gt; &lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 同样地，对于组件内的数据，在大多数场景下，我们可以这样来处理，还是因为有无所不在的依赖注入： 123456789101112131415161718192021222324@page \"/\"@layout MainLayout@inject HttpClient httpClient@using BlazorBlog.Core.Domain.Blog;@using BlazorBlog.Web.Shared.Partials;@if (posts != null &amp;&amp; posts.Any())&#123; foreach (var post in posts) &#123; //这是一个自定义组件 &lt;PostItem Model=post&gt;&lt;/PostItem&gt; &#125;&#125;@code&#123; private List&lt;Post&gt; posts &#123; get; set; &#125; protected override async Task OnInitializedAsync() &#123; posts = await httpClient.GetFromJsonAsync&lt;List&lt;Post&gt;&gt;(\"content.json\"); await base.OnInitializedAsync(); &#125;&#125; 这里可以给大家展示下尚在开发中的静态博客： 基于 Balzor 的静态博客 理论上任何文件都可以这样做，主要是考虑到配置这种信息，用依赖注入会更好一点，这样每一个组件都可以使用这些配置，而如果是以 API 的形式集成，以目前 Blazor 打包以后加载的效果来看，页面会有比较大的“空白期”。我更加疑惑的是，如果 Blazor 打包后的体积过大，那么浏览器自带的存储空间是否够用呢？一句话总结的话， Blazor 是一个写起来非常舒服的框架，可未来是否会像当年的 Sliverlight 一样，这还要看大家对 WebAssembly 的接受程度，可谓是“路漫漫其修远兮”啊…… 本文小结这篇博客，是博主由一个个“闪念”而串联起来的脑洞，作为一个实验性质的尝试，希望通过 Blazor 的客户端模式(WebAssembly) 实现一个静态博客，而在这个过程中，需要解决 Balzor 读取本地文件的问题，由此，我们引入了这篇博客的主题之一，即：EmbededFileProvider。顺着这条线索，我们梳理了内嵌的文件资源、IFileProvider接口、FileConfigurationProvider、FileConfigurationSource等等一系列看起来毫无关联的概念。事实上，“冥冥之中自有天意”，这一切怎么会毫无关联呢？我们最终从文件系统看到了配置系统，聊到了 Blazor 中的配置问题，这里我们熟悉的依赖注入、配置系统都得以延续下来。其实，单单就解决这个问题而言，完全不值得专门写一篇博客，可从一个点辐射到整个面的这种感悟，在人生的成长中更显得弥足珍贵，希望我们每一个人都能多多跳脱出自己的视角，去努力的看一看这个丰富多彩的世界，在多样性与多元化中去寻找整体上的统一，这是作为技术人员的我，一生都想去探索的哲学。好了，以上就是这篇博客的全部内容啦，欢迎大家在评论中留下你的想法或者建议，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"Blazor","slug":"Blazor","permalink":"https://qinyuanpei.github.io/tags/Blazor/"},{"name":"文件","slug":"文件","permalink":"https://qinyuanpei.github.io/tags/%E6%96%87%E4%BB%B6/"},{"name":"WebAssembly","slug":"WebAssembly","permalink":"https://qinyuanpei.github.io/tags/WebAssembly/"}]},{"title":"低代码，想说爱你不容易","date":"2021-02-15T12:37:47.000Z","path":"posts/2637069146/","text":"一直想写篇文章，聊一聊“低代码”这个话题。一方面，“低代码”这个概念确实非常火，其热度丝毫不亚于曾经的“中台”。有人说，2021年是属于“云原生”的时代，看起来我们每一年都在被技术的“娱乐圈”抛弃，明明连 Kubernetes 都还没有入门呢？人们已然在欢呼雀跃般地声称要抛弃 Docker 。这个世界有时就是如此地魔幻，明明我们生活在一个拥有大量基础设施的时代，我们不必再像前辈们“刀耕火种”一般地去开发软件，可我们的生存空间为什么就越来越狭窄了呢？拼多多事件过去没有多久，腾讯的阳光普照奖再次让“打工魂”觉醒，也许果真像大鱼海棠里设定的一样，人的记忆只有7秒。而另一方面，我想结合我最近开发“工作流”的感受，来吐槽下这个看起来美好的“低代码”。也许，对企业而言，引入“低代码”的确能减少研发成本，可博主并不认为，它会降低业务本身的复杂性，如果所有声称“低代码”或者“无代码”的项目，最终依然需要研发人员来作为收场。对此，我想说，对不起，这不是我想要的“低代码”。 低代码发展现状或许，一个人成熟的标志就是，在面对一个未知的事物的时候，决不会不由分说地一通吐槽，就像一个人在职场上，你不能永远都只是学会抱怨，相对于抱怨，人们更希望听到的是解决方案。所以，一个人的成长，本质上就是不断学会为自己、为别人找解决方案的过程，前者是为了认识自我，而后者是为了交换资源。所以，在听我吐槽“低代码”前，不妨先一起来看看低代码的发展现状。 低代码产品发展现状 国外趋势有人认为，“低代码”的兴起源于钉钉的低代码应用 易搭 的落地。诚然，巨头企业的每一个动向都引领着整个行业的风潮，可低代码这个概念最早要追溯到1980年。彼时，IBM 的快速应用程序开发工具(RAD)被冠以新的名字——低代码，这是低代码这个概念首次面向大众，此后的40年里，国外诞生了诸如 Outsystem 、Mendix 、 Zoho Creator 等等的产品，整体发展相对缓慢。直到2015年以后，AWS、Google、Microsoft 和 Oracle 等巨头开始入局低代码领域。2018年，西门子更是宣布以 6 亿欧元收购低代码应用开发领域的领导者 Mendix 、快速应用开发的低代码平台 Outsystem 获得 3.6 亿美金的投资，低代码平台市场开始火爆起来，我们所熟悉的 Power Platform，其实就是微软的低代码开发平台，低代码领域通常都需要大量的积累和研发，需要有10到20年左右的技术沉淀。 国内风云国内的低代码领域，相比国外发展起步较晚，可依然涌现出像牛刀、APICloud、iVX、搭搭云、氚云、简道云、云表、宜搭云等等产品。从整体上而言，这类这类产品基本上都提供了可视化搭建环境，都声称无需编码即可完成业务系统的搭建。其实，从一名程序员的初心出发，我们所做的一切努力都是为了以后不写代码。经常有人问，怎么样可以做到零缺陷、零 Bug ，其实不写代码就好啦！我们并不担心低代码让我们失业，相反地，如果低代码可以消化掉 30% 的垃圾项目，那么，我们将会有更多的时间去做些有意义的事情，而不是在一个“劣币驱逐良币”的市场里，靠着 996 来争个你死我活。而从低代码的商业价值角度来看，Salesforce、Appian、Joget 这三家公司均已上市，Mendix 和 Outsystem 更是估值 10 亿美元以上的独角兽公司，这正是巨头们入局低代码的原因所在。 低代码领域，目前关注的重点主要集中在：表单生成和处理、工作流生成和管理、办公协作、人力资源、客户关系、ERP 等企业应用上，就如同 SAP 、金蝶、 SCM 等企业软件一样，每一个软件都曾声称能帮助企业解决某一类问题，低代码领域同样遵循“二八原则”，即 80% 的场景，通过定义的方法论、方式、工具集能够实现；而剩下的 20% 的场景或许实现不了，需要使用者通过扩展的方式来自行解决。譬如，针对大多数企业都存在的 CRUD 的需求，通过在线的 Excel 表格来实现基于表的业务驱动。例如 SeaTable 就是这类主打协同工作的产品；针对大多数企业都存在的审批类的需求，则可以通过可视化的工作流设计系统来完成。例如 葡萄城 的 SpreadJS 和 活字格 ，同样可以视为低代码平台，甚至早期的 .NET 开发者被人“黑”只会拖控件，这难道不是广义上的低代码吗？ 低代码产品形态搞清楚整个低代码的发展现状以后，那么，整个低代码领域主要的产品形态有哪些呢？了解其主要的产品形态，对于我们形成低代码的直观印象非常有帮助。在我看来，主要分为四类： 表单生成类：以 宜搭云 和 JNPF 为代表，主张通过可视化的设计器来完成页面布局、编排、设计，即所谓的“所见即所得”，类似的还有 iVX。 工作流生成类：以 Mendix 和 Outsystems 为代表，提供组件式的服务，通过编排工作流来实现特定的业务，即通过流程图的方式来实现业务逻辑部分，不同的节点代表不同的功能，不同的线条代表不同的分支。 协同工作类：以 SeaTable 为代表，基于表的业务驱动开发平台，可以以不同的维度管理数据、对数据可视化、共享协作等等，同时具备自动化规则、脚本运行等能力。 服务聚合类：以 APICloud 为代表，基于API聚合的组件市场工具，通过流程管理工具，可以管理整个应用的开发周期，从产品、设计开始，到研发测试和运营。 所以，整体而言，低代码产品的核心是表单引擎 和 流程引擎(BPM)，外围支撑是BI引擎、*协同工作、服务聚合等等，目前，市面上主流的低代码产品，表单引擎和流程引擎(BPM)基本是标配，所以，严格地说起来，上面的分类并不严谨，因为基本上都是混合式的产品形态。下面是部分低代码产品的截图： 某“低代码”二维码应用 某“低代码”人力资源管理系统 某“低代码”可视化搭建系统 低代码研发痛点相信大家都知道了，接下来的内容是本文真正的重点。为什么要这样说呢？这主要和博主自身的工作有关系，简单来说，公司需要一个想象中的可视化设计器，业务人员只需要通过拖拽就可以完成业务逻辑的编排，而开发人员则需要负责对外输出组件供业务人员使用。这听起来特别像我们刚刚讨论的第二种产品形态对不对？听起来非常美好对不对？我承认这个想法真的符合潮流、非常的“低代码”。所以，我们前期采用了微软的 Windows Workflow Foundation 框架，使用以后的效果大概是下面这个样子： Windows Workflow Foundation 设计器 多人协作不便那么，我们在这个过程中到底遇到了哪些问题呢？首先，这种可视化编辑的场景，遇到的第一个问题就是多人协作，如果你使用过腾讯文档、钉钉文档这类在线文档类产品，你应该能领悟到我说的这个点。微软的这个框架是采用XMAL这种格式来储存数据的，虽然理论上可以通过 Git 实现多人协作，实际维护起来表示非常地麻烦，所以，我们最终由单人去维护这些工作流。那么，更广义上的低代码又该如何解决这个问题呢？流程图这种东西，就是一种看起来非常清晰，改起来非常麻烦的东西，就像一条锁链一样，你要不停地断开和接上。 孱弱的表达能力其次，是流程图这种表现方式的“表达”问题，就像你如果需要在SQL里表示循环要用到游标一样，这类工作流都无法表达程序三个结构中的循环，更不用说表达力孱弱的表达式啦，所以，这就造成一个非常尴尬的问题，你在流程图里写不了太复杂的表达式，一旦业务人员写不出来，就需要开发人员去写辅助性质的代码，类似正则、字符串插值、字符串处理、格式化等等的函数或者API非常缺乏。当然，我最无法忍受的，就是组件与组件间传值的方式，你除了返回JSON和写表再没有其它方式，更何况这个JSON返回给某个组件了，人家还未必能直接解析直接使用呢？因为编辑器无法绑定这种复杂的数据结构。 混乱的变量和参数接下来，我最想吐槽的是，关于全局变量和参数的问题，在流程图中你经常需要各个分支的标志位(Flag)或者是临时变量，然后你就看到了那种“变量满天飞”的混乱局面，简直像极了你刚开始写的代码，你需要顺着每个线条，逐个点开每个组件的属性面板，查看它都使用了哪些参数或者变量，至此，你终于明白了它的数据是如何流动的。从前，乡愁是成千上万行的代码；现在，乡愁是剪不断理还乱的“蜘蛛网”。多年前，我对虚幻引擎(Unreal)的蓝图功能有多么憧憬；多年后，我对这种基于流程引擎的低代码就有多排斥。尤其是，当我需要复用某一段逻辑的时候，我只能小心翼翼地选中节点和线条，然后再拷贝过去。 动态计算/事件顺序/黑盒子最后，我参考了一位被 Power Apps 所折磨的朋友的意见，除了上面提到的这些问题， 属性面板或者公式无法使用动态计算的值，类似Vue 里面的计算属性，从实际使用的体验来看，这类以流程引擎和表单引擎为主要卖点的低代码工具，其实都会存在这样的问题，而面对这种问题，一般只能通过trick的手段来解决。同样地，Power Apps 事件顺序的不确定问题，因为低代码实际上是框架提供了某种机制，可以帮你完成某个事情，所以，低代码内部对于使用者来说，完全就是一个黑盒子，譬如 Power Apps 在无网络的环境下使用会卡顿，调试起来非常不便等等。 本文小结坦白来讲，这篇博客实在没什么“技术含量”，无非是按照一个月前的计划在整理内容。我对“低代码”持一种中立的态度，作为程序员，我是希望有这样的技术来简化流程，可以让研发人员从枯燥的“增删改查”中解放出来，留出时间去做更多有意义、有价值的事情。当我了解了低代码和零代码的差异以后，我突然明白，我需要的其实是零代码，因为我希望那帮业务人员能自己搞定，这样就不用再来烦我，可经历这段时间的“低代码”，我清醒地认识到，这个想法根本不现实。一来业务人员并不像他们想象的那样，除了不会写代码以外无所不能；二来业务的复杂性满足守恒定律，它永远不会消失，只会从一种形式变成另一种形式。也许，低代码真的能帮企业省不少钱；也许，企业最喜欢做的事情，就是花点小钱招人外包做这种事情。但我依然想告诫开发者们，不要去追逐这些看起来美好的东西，对企业来说，它今天使用 A 技术，明天使用 B 技术，完全无关紧要。可对于个人而言，这个选择显得非常重要。看一看曾经的 SAP 咨询顾问就知道了，如果有一天 SAP 都倒闭了，你掌握着这些只有在 SAP 上能发挥作用的技术有什么用呢？对技术人员来说，学习通用型的知识和技能，永远比把鸡蛋放在一个篮子里要更保险。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E7%A8%8B/"},{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"},{"name":"低代码","slug":"低代码","permalink":"https://qinyuanpei.github.io/tags/%E4%BD%8E%E4%BB%A3%E7%A0%81/"},{"name":"行业","slug":"行业","permalink":"https://qinyuanpei.github.io/tags/%E8%A1%8C%E4%B8%9A/"}]},{"title":"记一次失败的 ThoughtWorks 面试经历","date":"2021-02-09T20:37:47.000Z","path":"posts/2837181325/","text":"年前朋友问我，要不要试试 ThoughtWorks 澳洲线的岗位。对于这家号称“世界上面试最难”的公司，多少还是有一点畏惧，直到朋友安慰我说，它们这次有中级的岗位，还是可以试一试的，梦想还是要有的，万一实现了呢？自此，我凑齐了西安. NET圈子里的四大“天花板”公司的面试：葡萄城、活跃网络、奥博杰天、ThoughtWorks ，而对于我来说，亦有幸见识到世界上最难的面试，虽然后来事实证明，这个世界上没有太多的逆袭，可我还是想分享一下我的这次面试经历，因为它让我知道，在过去的两年里，我在哪些方面取得进步，在哪些方面存在不足。当我写下这篇博客的时候，我即将在今年夏天迎来我的29岁，果然我还是希望自己能再努力一点，因为不想让平行世界里的某个人失望。 面试流程关于ThoughtWorks 的社招流程，大体上由HomeWork、Pair Programming 和 Face-to-face Interviews 3个部分组成，其中，HomeWork，即家庭作业，原则上给3天时间来完成，不过据说可以向 HR 申请更多的时间来完成。Pair Programming 和 Face-to-face Interviews 通常是安排到同一天来进行的，前者时间为1.5小时，即传说中的结对编程，面试时会有一左一右两名面试官看着你现场写代码。后者时间为1小时，即传说中的技术文化面试，考察技术的深度、广度以及对 Thought Works 敏捷文化的认同感。 HomeWork2月18日，下班以后接到HR小姐姐的电话，在明确了我投简历的意向以后，我收到了HR小姐姐的邮件，基本上就是一个家庭作业，三选一提交，需要在三天内完成。我选择了Conference Track Management 这道题目，因为白天要上班，所以，我为此而连续肝了三个晚上。 坦白说，不同的阶段对这道题目的理解是不同的，在做家庭作业的阶段，你以为这道题考察的是职责分离和设计模式；而等到结对编程的阶段，你终于意识到，这其实是个背包问题。当然，这并不是说我会错了意，考虑到面试官有上帝视角，他们更容易看清楚问题的全貌。或许，面试官想最想看到的，恰恰就是你从冰山一角到目窥全牛这一瞬间的反应。 当我接到HR小姐姐的通知，这份作业Review通过时，我内心是非常激动的，因为这意味着我获得了去ThoughtWorks面试的“入场券”。可当我事后再以上帝视角去看待这个题目，我内心又变得非常难过，因为无论怎么看这份作业，都会觉得它设计得并不好，尤其是当它引入弹性时间这个因素以后，我一直深陷于如何从Part 1 到 Part 2，是不是按 Part 2 重新设计会更好一点？此时此刻，终于能理解面试官反馈的，关于扩展性方面的问题。 作业反馈01 作业反馈02 作业反馈03 关于这部分，我个人建议多多关注： 编程风格：编码规范、项目结构、代码坏味道等。 语言特性：澳洲线岗位需要熟悉 .NET Core，所以，我使用 .NET Core 完成整个项目的编写。 设计模式：选择合适的设计模式，遵循 SOLID 原则。 TDD：一定要有单元测试代码，这一点TW最为看中。如果写的好，一定是加分项。建议遵循AAA原则来编写用例。 程序满足要求：程序一定满足题目要求，可执行，运行结果满足题意，这是最基本的要求。 Pair Programming提交作业后，等了一周多的时间，1月29日，HR 小姐姐终于联系我了，正如我上文所述，当时听到这个消息非常激动，因为终于有机会去 ThoughtWorks 这家世界上面试最难的公司去看看，ThoughtWorks 西安办公室位于环普产业园，这个地方相信大家都非常熟悉啦！当时算上周末，我给了自己 5 天时间去准备面试，因为我觉得面对 ThoughtWorks 的面试还是要重视一点，虽然后来好多问题都没有被问到。 结对编程是基本上就是，两个面试官一左一右地坐在你旁边，采用聊天和探讨的方式一起写代码，刚开始本来是用电视投屏“直播”的方式，后来因为 HDMI 接口接触不良的缘故，两位面试官干脆就直接看我电脑屏幕啦！在这个环节，个人感觉解释编码思路花时间太多，重构完有一个用例没有通过。最重要的是，家庭作业阶段的设计不利于现场新需求的开展，所以，这些因素综合起来，导致我结对变成这个部分表现得不好，希望大家引以为戒啊。 整个结对编程时长为一个半小时(1.5h)，在这段时间，你需要讲解编码思路、完成代码重构和完成现场作业，时间上还是非常紧凑的，回想起那天下午的两个半小时，有种像参加高考的感觉：你以为时间会很长，结果发现时间完全不够用。看起来轻松的氛围下，其实在不经意间考察你的沟通能力、工程能力和学习能力，ThoughtWorks 的面试，往往就是这样的朴实无华且“有趣”…… 对于这部分，我个人建议多多关注： 工程能力：语言特性、调试能力、设计能力等。像TW非常重视快捷键的使用，频繁使用鼠标会拉低印象分。 沟通能力：善于倾听和表达、以及理解需求的能力，需要你在面试官的引导下完成需求确认，这个阶段一样可以展示你技术的深/广度，但建议最好长话短说。 学习能力：要求你对TDD、敏捷开发等有一定的好奇心，面试官教给你的新东西/思路，能否举一反三、学以致用，我是在重构的过程中得到了面试官的指导，对此我表示感谢。 适应能力：能否以开放的态度接受面试官的重构意见，当意见不一致时，能否有理有据地、自信地表达你的观点，我遇到的问题是，面试官认为我混淆了职责分离和组件依赖。 Face-to-face Interviews结对编程环节结束以后，正当我还在关注那个失败用例的时候，两位新的面试官就走了进来，就这样，我迎来了那天下午的“技术文化面试”，考虑到天气的原因，我那天穿了一件鬼灭之刃的卫衣就去参加面试了，可那个小房间的闷热还是让人焦躁不安，一杯放凉的白开水，完全不足以缓解那种闷热的感觉。ThoughtWorks 的办公室和大多数外包公司的办公室没有什么区别，不同的是，它的办公室摆满了各种 O’Reilly 的动物书，至少在氛围上确实像它对外所展示的那样重视技术。 在这个环节，我遇到了很多的开放型问题，譬如你经历过的、印象最深刻的项目是什么，你在项目中遇到问题以后都是怎么样去解决的，你所在项目的人员配置、研发流程是什么样的……等等，虽然一开始还是经典的“自我介绍”，可我感觉我在回答这些开放型问题的时候，缺乏一种系统性思考或者某种方法论，它和回答技术问题不同，有时候我们需要层层展开、关注细节，可是在这样的问题上，它需要的是简洁而准确的答案。面试期间，面试官不止一次提示我听清楚她的问题，难道真的是我的沟通能力出了问题吗？ 坦白来讲，这次我准备的很多面试题都没有被问到，我以为至少会问一下.NET Core、微服务 和 DDD 这些东西的。我同样不太明白的，是关于项目经历方面的，为什么面试官会认为，工作中主要负责的内容就是由我一个人单打独斗来的呢？我承认我这几年，性格上收敛了许多，没有了攻击性和对抗性，变成了一个非常随和的人，可我本质上并不是一个喜欢兜售或者推销的人，我并不觉得无法口若悬河是缺乏自信的表现。后来，面试官就考察了一下我的口语，本来就是口干舌燥，说到为什么选择 ThoughtWorks 的时候，大脑有一点卡壳，一边在组织中文，一边在想怎么翻译成英文，还有什么比结结巴巴地说完一段英语更让人难过的呢？ 对于这个部分，我个人建议多多关注： 系统思考：结合工作经验，不断去提炼类似架构方向、敏捷开发、项目管理方面的内容，不要永远局限在一个点上看待问题，不管是表达还是编程，都采用系统性、结构化的思路来梳理，要做到清晰、准确、完整。 自信：ThoughtWorks 是一家咨询服务公司，所以，很多研发都是顶着咨询师的头衔，个人觉得还是自信一点，会就是会，正常交流，不会的话，就虚心接受，表现出后期愿意去学习的状态。 协作能力：能否影响和带动团队中的人一起学习、成长，ThoughtWorks 盛行学习和分享的文化，你一定听说过它们的技术雷达、洞见。 沟通能力：这体现在你能否和客户正常地沟通、能否和团队成员达成有效的协作，虽然程序员都不大喜欢说话，但你至少应该能传达出正确的声音、能理解来自别人的观点。 动机：对 ThoughtWorks 的意愿性/认同度，为什么会考虑 ThoughtWorks 等这些问题。 面试心得其实，当天面试一结束，我就知道这次面试大概率是凉了。回去的路上，我和老大哥说了我面试的过程，老大哥说，“让我冷静，要对自己有信心”。果然，第二天下午，收到HR小姐姐的回复，说面试没有通过，看了下面试官反馈的意见，主要是在结对编程过程中重构做得不好，对重构的意义不太明确；其次是面试官觉得我在沟通方面还不够大胆，希望我可以在发展他人方面做出改变。 听到这话，怎么突然就有种传销的感觉呢？说到影响别人，从12年开始写博客至今，我自认为我的博客还是帮助到了很多人，可能面试官一直觉得我在单打独斗吧，都2021年了，早就不是求伯君、雷军这些前辈们单打独斗写软件的时代啦，所以，果然还是我的表达出现了问题吗？我的朋友们经常批评说我沉迷于技术无法自拔，可我同样见过30多岁怕别人问原理的“中年”程序员，原本这个行业因为门槛低而越来越内卷，而这个圈子里的人又不以技术为重，有太多单纯为了钱而进入这个行业的人。可当整个行业都越来越“体力”劳动的时候，有很多浮躁的人跑来你面前说，技术并不重要类似的话，这个世界到底怎么了呢？ 我想说什么呢？我认为技术因素和非技术因素都很重要，其实写作一直是我练习表达的一种方式。也许，在那些能言善辩的人眼中，我们这些“闷葫芦”都是些内向的、不太会沟通的人吧！这次面试结束以后，我打算找点系统性思考方面的书来看看，继续背单词增加词汇量，利用空闲时间来练习口语。我从来不认为，一个技术人员努力钻研技术有什么不对，因为这是一个技术人员的基本功。沟通能力能做到妙语生花是一种艺术，而我，追求的目标非常简单，即有条理的、清晰的、结构化的表达，我不追求所谓“高情商”的话术，人类时常因为这些模棱两可的字眼而相互误会，因为信息失真，因为信息冗余。当然，此刻我的首要目标是，完成那个家庭作业的重构，因为它写得实在是太糟糕啦！","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://qinyuanpei.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"求职","slug":"求职","permalink":"https://qinyuanpei.github.io/tags/%E6%B1%82%E8%81%8C/"},{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"},{"name":"ThoughtWorks","slug":"ThoughtWorks","permalink":"https://qinyuanpei.github.io/tags/ThoughtWorks/"}]},{"title":"从 C# 1.0 到 C# 9.0，历代 C# 语言特性一览","date":"2021-02-01T22:36:47.000Z","path":"posts/3918433482/","text":"C# 版本历史记录 从 C# 1.0 到 C# 9.0，历代 C# 语言特性一览 说明：因为Markdown下维护这样复杂的表格有一点麻烦，故，这里以图片形式展示出来，如后续内容有更新，请点击 这里 访问原始笔记链接。为知笔记 的表格渲染在移动端表现不佳，为了获得更好的阅读体验，请在电脑端访问查看。 C# 版本特性说明现在是 2021 年，相信 C# 7.0 以前的版本大家都应该没有什么问题，因为像博主这样的 90 后“中年”男人，接触的都是这个版本的 C#。所以，在这里我们主要讲解大家C# 7.0、8.0 以及 9.0 的语法特性。考虑到文章篇幅有限，这里选取的都是博主个人比较喜欢的语法特性，如果这里没有你喜欢的特性，请参考文章末尾的参考链接。如果这里的特性你都不喜欢，请你马上关掉这个网页，愿这个世界：Love &amp; Peace。可能你会感觉到我说话变得小心翼翼起来，因为这个世界上有种叫做“杠精”的生物，当它从我的只言片语里读出那些挫败感的时候，终于有了嘲笑我们这批步入30岁行列的90后的底气，没错，我在最近的博客评论中被读者“嘲讽”了，让暴风雨来得更猛烈一些吧！ C# 7.0在 C# 7.0 中，我个人比较喜欢的特性主要有以下几个：元组和弃元、更多的 expression-bodied 成员、out 变量、异步 Main 方法、模式匹配 和 引发表达式。 元组和弃元这个概念乍听起来可能会有一点陌生，其实，按我的理解，这就是增强的元组语法，终于可以摆脱Item1、Item2……啦： 1234567891011 //示例1(string Alpha, string Beta) namedLetters = (\"a\", \"b\");Console.WriteLine($\"&#123;namedLetters.Alpha&#125;, &#123;namedLetters.Beta&#125;\"); //示例2var alphabetStart = (Alpha: \"a\", Beta: \"b\");Console.WriteLine($\"&#123;alphabetStart.Alpha&#125;, &#123;alphabetStart.Beta&#125;\");//示例3int count = 5;string label = \"Colors used in the map\";var pair = (count, label);Console.WriteLine(pair); 有一段时间，前端同事总和我吹嘘 ES6 里面的解构多么多么好用！对此，我想说，C# 一样可以解构，假设我们现在有下面的一个方法： 1234567static (string, double, double) GetLocation() &#123; var city = \"西安市\"; var lat = 33.42d; var lon = 107.40d; return (city, lon, lat);&#125; 这就是简化后的元组的用法，如果是以前，我们还需要返回一个Tuple&lt;string, double, double&gt;。此时，如果我们需要解析城市名称及其经纬度，可以这样做： 123//示例4(string city, double lon, double lat) = GetLocation();Console.WriteLine($\"&#123;city&#125;,(&#123;lon&#125;,&#123;lat&#125;)\"); OK，那么什么又是弃元呢？继续以上面的代码为例，如果我不关心经纬度，只需要城市名称又该怎么办呢？人家的方法返回的是一个3元的结果，而我们只需要其中的1元，此时，就有了所谓弃元的概念： 12(string city, _, _) = GetLocation();Console.WriteLine($\"&#123;city&#125;\"); 在 C# 中可以使用下划线_来表示要舍弃的元，是为弃元，怎么样？你学会了吗？ 更多的 expression-bodied 成员这部分同样是经过强化的 Lambda 表达式，之前我们可以在成员函数和 只读属性上使用 Lambda 表达式，而现在，我们可以将其运用在构造函数、终结器以及 get和set访问器： 1234567891011121314// Expression-bodied constructorpublic ExpressionMembersExample(string label) =&gt; this.Label = label;// Expression-bodied finalizer~ExpressionMembersExample() =&gt; Console.Error.WriteLine(\"Finalized!\");private string label;// Expression-bodied get / set accessors.public string Label&#123; get =&gt; label; set =&gt; this.label = value ?? \"Default label\";&#125; out变量个人认为，这是一个非常不错的改进，终于不用再单独声明out变量啦： 1234if (int.TryParse(input, out int result)) Console.WriteLine(result);else Console.WriteLine(\"Could not parse input\"); 异步 Main 方法顾名思义，Main 方法现在可以支持 async 关键字啦： 123456static async Task&lt;int&gt; Main()&#123; // This could also be replaced with the body // DoAsyncWork, including its await expressions: return await DoAsyncWork();&#125; 在没有返回值的情况下，可以考虑返回Task: 1234static async Task Main()&#123; await SomeAsyncMethod();&#125; 模式匹配主要是针对 is 和 switch 语句提供了增强的语法。在这里，对于前者来说，我们可以将判断和赋值两个步骤合二为一： 12345678910111213public static double ComputeAreaModernIs(object shape)&#123; if (shape is Square s) return s.Side * s.Side; else if (shape is Circle c) return c.Radius * c.Radius * Math.PI; else if (shape is Rectangle r) return r.Height * r.Length; // elided throw new ArgumentException( message: \"shape is not a recognized shape\", paramName: nameof(shape));&#125; 而对于后者来说，主要打破了传统 switch 语句的常量模式： 123456789101112131415161718public static double ComputeArea_Version3(object shape)&#123; switch (shape) &#123; case Square s when s.Side == 0: case Circle c when c.Radius == 0: return 0; case Square s: return s.Side * s.Side; case Circle c: return c.Radius * c.Radius * Math.PI; default: throw new ArgumentException( message: \"shape is not a recognized shape\", paramName: nameof(shape)); &#125;&#125; 引发表达式这个主要是针对 throw 关键字的增强，当我看到微软的文档的时候，我突然意识到，这个语法其实我用了很久啦！ 123456789101112131415//场景A：条件运算符string arg = args.Length &gt;= 1 ? args[0] : throw new ArgumentException(\"You must supply an argument\");//场景B：Null合并运算符public string Name&#123; get =&gt; name; set =&gt; name = value ?? throw new ArgumentNullException( paramName: nameof(value), message: \"Name cannot be null\");&#125;//场景C：Lambda表达式DateTime ToDateTime(IFormatProvider provider) =&gt; throw new InvalidCastException(\"Conversion to a DateTime is not supported.\"); 以上，就是 C# 7.0 中我个人比较喜欢的语法特性。需要了解所有 C# 7.0 语法特性的小伙伴们，则可以参考这里：C# 7.0 - C# 7.3 中的新增功能。 C# 8.0在 C# 8.0 中，我个人比较喜欢的特性主要有以下几个：默认接口方法、异步流、索引和范围。 默认接口方法关于这个，我觉得有点多此一举，如果一定要有一个默认行为，那你用继承来实现不就好啦，接口本来就是用来实现的啊摔！ 123456789101112131415public class ChineseSayHello : ISayHello&#123; public string Who &#123; get; set; &#125;&#125;public interface ISayHello&#123; private const string DefaultPersopn = \"Anumouse\"; string Who &#123; get; set; &#125; void SayHello() &#123; Who = DefaultPersopn; Console.WriteLine($\"Hello, &#123;Who&#125;\"); &#125; &#125; 在上面这个例子里，ChineseSayHello没有实现SayHello()方法不影响编译，因为ISayHello有默认实现，可正因为如此，SayHello()方法属于ISayHello，不属于ChineseSayHello： 123456//正确，可以编译var sayHello = new ChineseSayHello() as ISayHello;sayHello.SayHello();//错误，无法编译 var sayHello = new ChineseSayHello();sayHello.SayHello(); 异步流该特性可以看作是IEnumerable&lt;T&gt;的一个延伸，即IAsyncEnumerable&lt;T&gt;，主要有下面三个属性： 它是用 async 修饰符声明的。 它将返回 IAsyncEnumerable。 该方法包含用于在异步流中返回连续元素的 yield return 语句。 下面是一个来自微软官方的基本示例： 1234567891011121314//生成异步流public static async System.Collections.Generic.IAsyncEnumerable&lt;int&gt; GenerateSequence()&#123; for (int i = 0; i &lt; 20; i++) &#123; await Task.Delay(100); yield return i; &#125;&#125;//枚举异步流await foreach (var number in GenerateSequence())&#123; Console.WriteLine(number);&#125; 和异步流相关的一个概念是：异步可释放，即 System.IAsyncDisposable，这个可以参考：实现 DisposeAsync 方法。 索引和范围关于这个，我们换一种说法，可能大家就能接受啦！是什么呢？答案是：切片。切片语法博主经常在 Python 中使用，想不到有生之年居然可以在 C# 里用到这个语法。不过，这个语法糖怎么看都不甜啊，因为没那味儿！ 12345678910111213141516171819202122232425var words = new string[]&#123; // index from start index from end \"The\", // 0 ^9 \"quick\", // 1 ^8 \"brown\", // 2 ^7 \"fox\", // 3 ^6 \"jumped\", // 4 ^5 \"over\", // 5 ^4 \"the\", // 6 ^3 \"lazy\", // 7 ^2 \"dog\" // 8 ^1&#125;; //取最后一个元素Console.WriteLine($\"The last word is &#123;words[^1]&#125;\");//获取第一个元素到第三个元素var quickBrownFox = words[1..4];//获取倒数第一个元素到倒数第二个元素var lazyDog = words[^2..^0];//获取全部元素var all = words[..];//获取开始到第三个元素var firstPhrase = words[..4];//获取结束到倒数第二个元素var lastPhrase = words[6..]; 看起来这些东西在 Python 里都有啊，到底是哪里除了问题呢？我觉得更多的是符号上的不同吧， ^ 这个符号除了表示指数的意思以外，还有按位进行异或运算的意思，所以，这个语法糖加进来以后就会显得相当混乱，而 .. 这个符号显然没有 : 写起来方便啊，所以，虽然 C# 从 C# 8.0 开始有了切片语法，可这不是我想要的切片语法啊！ 以上，就是 C# 8.0 中我个人比较喜欢的语法特性。需要了解所有 C# 8.0 语法特性的小伙伴们，则可以参考这里：C# 8.0 中的新增功能。 C# 9.0在 C# 9.0 中，我个人比较喜欢的特性主要有以下几个：Record、顶级语句、模式匹配增强。 Recordrecord 是 C# 9.0 中提供的一个新的关键字，地位上等同于 class 和 struct，中文翻译为：记录类型。这是一种引用类型，它提供合成方法来提供值语义，从而实现相等性。 默认情况下，记录是不可变的。简而言之，record 是不可变的引用类型。你可能会说，我们为什么要搞这么一个类型出来呢？难道 class 不香吗？ 我觉得如果要回答这个问题，可以借鉴 DDD 中的实体 和 值对象这两个概念。实体 通常都有一个唯一的标识并且在整个生命周期中具有连续性，这一类角色通过 class 来实现一直都工作得很好。例如，每一个 User 都会有一个唯一的UserId ，我们使用 UserId 来判断其相等性。而 值对象 则是指那些没有唯一的标识、不可变的、通过属性来判断相等性。例如，我们有一个地址 Address，它由省、市、区、县和详细地址组成，那么，问题来了，如果两个 Address 的省、市、区、县和详细地址都相同，这两个 Address 是不是同一个地址呢？常识告诉我们：不会，因为它们是不同的实例。 这就是 record 出现的原因，对于上面的这个问题，我们可以来解决： 1234567891011record Address&#123; public string Province &#123; get; set; &#125; public string City &#123; get; set; &#125; public string District &#123; get; set; &#125; public string County &#123; get; set; &#125;&#125;var addr1 = new Address() &#123; Province = \"陕西省\", City = \"西安市\", District = \"雁塔区\" &#125;;var addr2 = new Address() &#123; Province = \"陕西省\", City = \"西安市\", District = \"雁塔区\" &#125;;Console.WriteLine($\"addr1 == addr2：&#123;addr1 == addr2&#125;\"); 想想以前我们是怎么做的呢？是不是要写类似下面这样的代码： 123if (addr1.Province == addr2.Province &amp;&amp; addr1.City == addr2.City) &#123; //属性太多啦，我就不一个一个地比较啦，懂得都懂&#125; 所以，这就是 record 存在的意义。除此之外呢，这个关键字更多的是语法层面上的，实际上从编译出来的 IL 来看，它本质上依然是一个类，并且它是不可变的。定义记录类型时，编译器会合成其他几种方法： 基于值的相等性比较方法 替代 GetHashCode() 复制和克隆成员 PrintMembers 和 ToString() 那么，你可能还会有疑问，假如我定义了两个不同的记录类型，它们都拥有相同的属性成员，如果按值相等来判断的话，岂不是这两个不同的记录类型变成相同的了？这么重要的问题，微软怎么可能没有想到呢？编译器会合成一个 EqualityContract 属性，该属性返回与记录类型匹配的 Type 对象。在这里，微软再一次发挥了元组的威力，对于上面定义的地址，我们可以继续使用解构语法： 1(province, city, district, county) = addr1; 当然，我相信哪怕到2090年，这个世界上依然会有“杠精”：你说这玩意儿不能变？我就想变怎么办？答案是使用with语法： 1234567891011public record Person&#123; public string LastName &#123; get; &#125; public string FirstName &#123; get; &#125; public Person(string first, string last) =&gt; (FirstName, LastName) = (first, last);&#125;var person = new Person(\"Bill\", \"Wagner\");Person brother = person with &#123; FirstName = \"Paul\" &#125;; // 修改FirstName的副本Person clone = person with &#123; &#125;; // 空集副本 好了，关于记录类型就先为大家介绍到这里，更详细的说明可以参考这里：使用记录类型。 顶级语句顶级语句，这个又是一个听起来非常模糊的概念对不对？ 大家可以看一下这篇文章：26 种不同的编程语言的 “Hello World” 程序。怎么样，在众多解释型的语言中，C#、Java 甚至 C++ 的 “Hello World” 是不是都看起来有一点臃肿？ 好了，现在可以梦想成真啦！ 123using System;Console.WriteLine(\"Hello World!\"); 如果觉得这样还显得臃肿，可以省略 using 部分： 1System.Console.WriteLine(\"Hello World!\"); 当然啦，一个项目里显然只能有一个文件可以使用顶级语句，你可以理解为这些代码运行在一个看不见的Main()方法中，而Main()方法显然只能有一个，相比下来，Python 就自由多啦，不过if __name__ == &#39;__main__&#39;的老梗就不再这里展开啦！ 模式匹配增强感觉微软在模式匹配的道路上越走越远啊，说好的语法糖呢？这简直是毒药，7.0 里面眼花缭乱的switch都还没学会呢！ 12345678910public static bool IsLetter(this char c) =&gt; c is &gt;= 'a' and &lt;= 'z' or &gt;= 'A' and &lt;= 'Z';public static bool IsLetterOrSeparator(this char c) =&gt; c is (&gt;= 'a' and &lt;= 'z') or (&gt;= 'A' and &lt;= 'Z') or '.' or ',';if (e is not null)&#123; // ...&#125; 以上，就是 C# 9.0 中我个人比较喜欢的语法特性。需要了解所有 C# 9.0 语法特性的小伙伴们，则可以参考这里：C# 9.0 中的新增功能。 参考链接 C# 发展历史 C# 7.0 - C# 7.3 中的新增功能 C# 8.0 中的新增功能 C# 9.0 中的新增功能 C# 版本与 .NET 版本对应关系以及各版本的特性 C# 语言历史版本特性（C# 1.0到C# 8.0汇总）","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"总结","slug":"总结","permalink":"https://qinyuanpei.github.io/tags/%E6%80%BB%E7%BB%93/"},{"name":".NET","slug":"NET","permalink":"https://qinyuanpei.github.io/tags/NET/"},{"name":"CSharp","slug":"CSharp","permalink":"https://qinyuanpei.github.io/tags/CSharp/"},{"name":"语言","slug":"语言","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%AD%E8%A8%80/"}]},{"title":"通过Python分析2020年全年微博热搜数据","date":"2021-01-24T22:36:47.000Z","path":"posts/2758545080/","text":"几天前， Catcher Wong 大佬告诉我，他终于写完了2020年的年终总结。在看完大佬的年终总结以后，我有一种“前浪被后浪拍死在沙滩上”的感觉，正如当学生时都看“别人家的孩子”，工作以后看的都是“别人的年终总结”。我们的生活，其实就是由“别人”和“我们”交织在一起，而更多的时候，是成为“大多数”的“我们”，去关注成为“少数”的“别人”。我想说的是，世间万物互为装饰，就像卞之琳在《断章》里写道，“明月装饰了你的窗子，你装饰了别人的梦”。即便一个人在历史长河中，尤如一叶飘泊不定的孤舟在波涛中摇荡，可每一朵浪花都曾以自己的方式美丽过，所以，看“别人”的生活，联想“我们”的生活，这便是我同2020告别的一种方式，为此，博主决定抓取2020年全年366天的微博热搜，通过可视化的方式来串联起2020年的回忆。 热搜抓取首先，我们来考虑微博热搜的数据来源。 微博 官方提供了一个热搜排行榜的页面：https://s.weibo.com/top/summary，可惜这个网站只支持查看当天的热搜，显然这无法满足我们的需求。在搜索引擎的帮助下，找到了两个网站，它们分别是：微博时光机 和 热搜神器。经过一番权衡，决定选择页面结构更简单一点的 微博时光机 。 通过抓包，可以快速获得两个关键的接口，它们分别是 获取timeId接口 和 获取历史热搜接口。 Firefox抓包示意图 简单来说，我们指定一个日期，第一个接口会返回timeId。接下来，通过这个timeId调用第二个接口就可以获得热搜数据。仔细观察的话，第一个接口传递的data参数像是一个BASE64加密后的结果，尝试解密后发现我的猜想是对的，加密前的内容如下： 1[\"getclosesttime\",[\"2021-01-20T23:08:02\"]] 这意味着我们只需要改变这里的日期就可以啦，因此，我们的思路无非就是从2020年1月1日开始，依次请求热搜接口获取数据，直到2020年12月31日。这里想顺便吐槽下这个网站的接口设计，居然清一色地全部用数组来返回结果，难道是为了省掉这几个字段来节省流量吗？ 接口返回值说明-1 接口返回值说明-2 吐槽归吐槽，这里我们可以非常容易地写出对应的代码，由于日期和timeId的对应关系是固定的，为了减少后续的请求数量，我们使用MongoDB来对数据进行持久化。同样地，抓取热搜采用了类似的方式，因为历史热搜同样是确定的数据，这里只给出关键的代码，并不代表你可以无脑地复制、粘贴： 123456789101112131415161718192021222324252627282930313233# 获取指定日期对应的timeIddef get_timeId(date, cookie): cacheKey = date.strftime('%Y-%m-%d') records = list(store.find(TABLE_TIME_ID, &#123;'date': cacheKey&#125;)) if len(records) &gt; 0: return records[0]['timeId'] else: data = \"[\\\"getclosesttime\\\",[\\\"&#123;d&#125;\\\"]]\".format(d=cacheKey) data = base64.b64encode(data.encode('utf-8')) url = 'https://www.weibotop.cn/apis/androidrouter/?versioncode=1&amp;=&amp;data=' + str(data, 'utf-8') data = request(url, cookie) timeId = json.loads(data)[0] store.insert(TABLE_TIME_ID, [&#123;'date': cacheKey, 'timeId': timeId &#125;]) return timeId# 获取指定timeId对应的热搜def get_weibo_trending(timeId, cookie): records = list(store.find(TABLE_TRENDING, &#123;'timeId': timeId&#125;)) if len(records) &gt; 0: return records else: url = 'https://www.eecso.com/test/weibo/apis/currentitems.php?timeid=' + timeId data = request(url, cookie) data = json.loads(data) trendings = list(map(lambda x:&#123;'title':x[0], 'createdDate':x[1], 'updatedDate':x[2], 'rank':int(x[3])&#125;, data)) for trending in trendings: trending['timeId'] = timeId trending['href'] = 'https://s.weibo.com/weibo?q=' + trending['title'] trending['createdDate'] = datetime.datetime.strptime(trending['createdDate'], '%Y-%m-%d %H:%M:%S') trending['updatedDate'] = datetime.datetime.strptime(trending['updatedDate'], '%Y-%m-%d %H:%M:%S') store.insert(TABLE_TRENDING, trendings) return trendings 至此，我们就完成了微博热搜数据的抓取工作！ 热搜分析好了，在采集到这些热搜数据以后，我们就可以着手准备热搜数据的分析工作啦！其实，目前这份热搜数据挺简陋的，它只有热搜话题、上榜时间、更新时间以及话题热度这样四个关键字段。而作为辅助，我们增加了热搜话题的链接，如果后续需要更详尽的信息，可能需要从这里来寻找突破口。在今天这篇博客里，我们主要从下面四个维度来分析和挖掘2020年全年的微博热搜： 全年热搜热度分析首先，我们要分析的是全年热搜的热度。何谓热度呢？我个人认为，可以从话题的使用频率和话题的持续时间两个方面来考虑，即，一个话题转发或者参与的人越多，话题持续的时间越长，则认为该话题越“热”。例如罗翔老师说2020年进入了“全民网课”的时代，因为“网课”是一个热门话题，而当时的背景则是因为疫情原因无法上学(班)，一时间远程会议/办公/教育变得炙手可热。所以，分析全年的热搜热度，可以让我们去关注每个月都发生了什么事情，而这样，我们就有了和这个世界建立联系的思绪，想想当时的你在做什么，心里又作何感想，这会是一件非常有趣的事情： 2020全年微博热搜热度变化趋势 首先，我们看到的是：2020全年微博热搜热度变化趋势。通过这张图，我们可以注意到：在3月份左右国内疫情得到控制以后，大家都渐渐地回归到日常的工作和生活中，相应地，人们在社交媒体上的关注是逐渐下降的，直到7月份以后逐渐开始出现回升。我个人认为可能与下面这件事情有关，第一，是腾讯公司因为一份虚假合同而起诉老干妈的事件；第二、因为疫情而姗姗来迟的高考推迟到了7月7日和7月8日这两天；第三、张一山、宋妍霏、阚清子、宋茜等一众明星频频登上热搜榜。对于前两个因素，可以覆盖整个7月份的大多数时间段；对于第三个因素，更多的是从微博这样一个泛娱乐化的平台的属性去考虑，还有什么比吃明星的瓜更开心的事情吗？再往后，我们都知道，迎来了美国大选，不管这场大选闹出了多少风波，此时此刻，终于尘埃落定。 2020全年微博热搜数量变化趋势 接下来，我们看到的是：2020全年微博热搜数量变化趋势。通过这张图，我们可以注意到：热搜数量的变化趋势整体上是吻合热搜热度的变化趋势的，两者的“低谷”都出现在7月份，不同的是热搜数量的变化要更为“缓和”一点，这可能和新浪微博的热搜榜单有一定的关系，不知道是不是因为微博的推荐算法，决定了每个月“吃瓜”的次数是差不多的，可如果没有算法来约束这一切，完全由用户及其粉丝自行主导，这会不会演变成现实版的美国大选呢？我特别心疼那位新浪微博的研发小哥@丁振凯，人生中三次遭遇热搜引发的“宕机”：结婚时撞上鹿晗公布恋情，海外度假时撞上双宋官宣、老婆待产撞上华晨宇承认和张碧晨未婚生有一女，简直永远都在扩容的路上，被誉为“史上最惨新浪程序员”一点都不冤枉啊…… 全年热搜情感分析李诞在2020年年底策划了一期反跨年晚会，从头到尾都是脱口秀这种“语言类”节目，在这期节目里，有人以毛不易的“歌词”调侃了2020年大家的心境变化，从“像我这样优秀的人”到“消愁”，有时候打脸就是这么的猝不及防。坦白来说，我有段时间过得特别“丧”，“丧”到要靠《当幸福来敲门》来打鸡血。那么，整个2020年“活”在热搜里的人们的心态变化又是怎么样的呢？所以，接下来我们通过 SnowNLP 对2020年全年的热搜话题的情感倾向进行分析，到底大家是过得“积极”还是“消极”呢，让我们一起拭目以待，为了达到更好的效果，博主提前对 SnowNLP 进行了训练，因为 SnowNLP 自带的语料库主要是电商评论，与我们此刻的场景多少有一点差异。 2020全年微博热搜情感变化趋势 果然，2020年真的是“丧”到家啦，366天里平均置信概率在0.5以上的堪称寥寥啊。我有时候会想，我们常常希望在感情中有足够的安全感，希望对方可以“懂”我。诚然，我可以从一个人的朋友圈、微博去分析对方的情感变化，可身为人类的我们，并不是冷冰冰的计算机器。多年后，当我懊恼于曾经没有进行及时的沟通的时候，我静静地坐在电脑面前，你说这些字里行间没有透露出足够充足地信息，可我们依然有办法去反映过去一年里的喜怒哀乐。世事无常，每天都开开心心地面对，固然是心向往之，而生命中更朴实无华地大多数时刻，其实就是此刻如白开水一般索然无味，如果理性的思维最终还是要输给感性的直觉，我希望我可以两者兼有之，今年可能要在外地一个人度过春节啦，希望我的心情可以超过0.5呢…… 全年热搜词云分析其实，在做这个分析的时候，我一直在想，也许“新冠”或者“疫情”这样的字眼会成为2020年的共同记忆吧！至少对博主这样即将步入中年的90后而言，这场疫情留下的深刻记忆丝毫不亚于08年的汶川地震。可转念间又安慰自己道，相比国外愈演愈烈的疫情，我们在三月份左右的时候就基本得到了控制，如果说互联网是没有记忆的，人们对这一切应该会遗忘地非常快，就像这热搜榜上的话题，简直是“你方唱罢我登场”。可惜，互联网的确是有记忆的，即使过去了整整一年，这一切还是通过数据被挖掘出来。这里，我们通过结巴分词对热搜话题进行分词，再通过这些关键词来绘制词云。对于这个结果，突然就变得感性起来，可能这就是所谓的“冥冥之中自有天意”吧，甚至对于2021年来说，疫情目前依然是人们关注的热搜话题： 2020年全年微博热搜关键词词云 全年热搜人物分析曾经在知乎上读到过这样一句话，“人们宁愿去关心一个蹩脚电影演员的吃喝拉撒和鸡毛蒜皮，而不愿了解一个普通人波涛汹涌的内心世界”，这句话如果放到2020年的语境中，或许就是，人们在危难的时候会突然关心“国士无双”，而在安稳的时候则会更关注“娱乐八卦”，考虑到新浪微博是借鉴新浪博客的“名人效应”而起家，所以，我更关心在过去一年里有哪些人都登上过热搜。说实话，我挺怀念某位七十多岁高龄的老人，他和我奶奶差不多同龄，在这个“丧”如此普遍的年代，他带给了我们多少欢乐啊，虽然我预感到会有许多明星靠着“否认”、“道歉”、“心疼”、“回应”、“声明”等等字眼而登上热搜，可我还是想知道答案啊…… 2020全年微博热搜上榜人物分析.png 果然，“说曹操曹操到”，2020年以压倒性优势多次登上微博热搜的，居然真的是前美国总统特朗普。虽然说这位美国前总统喜欢孜孜不倦地发推特，史称“推特治国”，可在一个某明星代孕风波快速令“拼夕夕”事件烟消云散的社交平台上，这位老人能频频进入我们的视野，大概就能说明过去一年里国际形势的风起云涌。我们嘲笑他为“懂王”，甚至“亲切”地称之为“川建国”同志。有一段时间里，好像每一个人都觉得自己比这位老人更会做总统；同样地，好像每一个人都觉得自己比张小龙更懂得微信。我无意讨论政治相关的东西，可我依然感谢这位老人在疫情期间带给我们的欢乐，因为我并不觉得，他像媒体眼中的那样滑稽而愚蠢，一个能在商人、明星和总统多重身份中切换自如的人，无论如何会都有他的过人之处，疫情这件事情，换一个人来当这个总统未必会做得比他好。回过头来看，他在2020年都做了哪些事情呢？ 2020年特朗普的微博热搜 本文小结其实，在规划这篇博客的时候，我一直在想，该以一种什么样的心态去回顾2020，因为当我看着“别人”的年终总结的时候，总有一种难以言说的失落感。一方面，时间在不经意间匆匆逝去，身边的一切都在刻意地想你强调着“物是人非”。而另一方面，你需要去面对诸如买房、结婚这种所谓“某某年龄应该去做的事情”。当我看到身边的同事，整天坐在一起讨论的无外乎是房子、车子、股票等一切所谓“投资”的事情的时候，我时而会觉得他们有一点枯燥，就是那种我们曾经都不愿意成为的“中年人”。等翻过年，我即将迎来我的29岁，可令人心动的Offer里的“背水辉”一样的被嫌弃的年纪，而距离IT行业所谓的“35岁”门槛还剩下年时间。 虽然给自己订了几个目标，可有时候难免会感到懈怠，尤其是当你意识到你再无法抓住某一样东西的时候，或许，你唯一的能做的事情，就是让自己永远不要忘记吧！写数据挖掘相关的内容，不管是在数据的抓取还是分析阶段，都需要投入大量的精力去试验，结合实际去调整写作的方向，在这篇博客中甚至还花了大量时间去训练 SnowNLP。“悟已往之不谏，知来者之可追”，2021年flag我在心里记下来，我不想写出来，因为我怕到时候脸会疼，如果大家觉得这篇博客对你有帮助，欢迎点赞和收藏，如果可以一键三连，那就更好啦！2020，再见！","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"可视化","slug":"可视化","permalink":"https://qinyuanpei.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"},{"name":"微博","slug":"微博","permalink":"https://qinyuanpei.github.io/tags/%E5%BE%AE%E5%8D%9A/"},{"name":"热搜","slug":"热搜","permalink":"https://qinyuanpei.github.io/tags/%E7%83%AD%E6%90%9C/"}]},{"title":"基于 Python 和 Selenium 实现 CSDN 一键三连自动化","date":"2021-01-19T22:35:47.000Z","path":"posts/3148958651/","text":"最近一段时间，博主感觉到了某种危机感，或者说是每一个不再年轻的人都会面对的问题，即，怎么面对来自更年轻的“后浪”们的压力，自打国内IT行业有了35岁这个不成文的“门槛”以后，年轻的“后浪”们仿佛有了更多将“前浪”们拍死在岸上的勇气，我辈忍不住要叹一声后生可畏啊！我认识的 Catcher Wong 正是这样一位大佬，此君虽然比我小三岁，可在技术的广/深度以及经验的丰富程度上，足以令我这个”老人”汗颜，单单 EasyCaching 这一项，就令人望尘莫及啦！我看着他的时候，一如当年 Wesley 大哥看着我的时候，可能这就是某种轮回，姑且执浊酒一杯，致我们终将老去的青春。 不正经的Kimol君关注Kimol君，最早源于他在我博客里留言，作为礼尚往来，我回访了他的博客，然后发现此人人如其名，非常的”不正经”，他的博客访问量出奇地高，在CSDN里写博客多年，深知现在不比从前有运营梦鸽和大白两位小姐姐帮忙推荐到首页，普通的内容很少有机会拥有这样的曝光机会，而像 郭霖 这种从 10 年前后开始写移动开发系列博客的“大神”或者是以图形学为主要写作方向的 诗人“浅墨” ，在通篇都是干货的情况下，长期保持着不错的人气。 这萌萌哒求赞的表情我是做不来的 起初，我以为此君的流量来自于标题党，譬如《学会这招，小姐姐看你的眼神将不一样》 和 《震惊！小伙竟然用Python找出了马大师视频中的名场面》这几篇，非常像UC编辑部和微信公众号的风格。我是一个擅长学习的人，主动去借鉴了他博客中的优点，比如尝试使用轻松、幽默的文风，在文章开头放入目录，适当“蹭”热点等等，我甚至专门致敬了一篇博客： 《厉害了！打工人用Python分析西安市职位信息》。而整个1月份，我就只有一篇博客流量高一点，就这还不是特别正经的”技术”博客，而此君的流量则是一个又一个的1w+ ，可我实在想不通，一个不到100行的Python脚本，真就值得花那么多的流量，真就值得上百条的评论吗？这里放张图大家感受一下： 不知道该说什么好 仔细研究了他博客里评论的风格，发现有大量类似“夸夸群”风格的评论，就是那种读起来确实像对方读过了你的文章，可实际一想就觉得这是那种“放之四海而皆准”的话。我最近知道了一位大佬的博客，我惊奇地发现，此君居然在上面留过言，我顺着大佬的博客继续找，发现一个非常有意思的事情，此君曾经给我留言过的内容，居然出现在了别人的博客底下，而从这篇博客的评论里继续找，你会发现好像有一个团队专门在做这种事情，互相点赞、互相评论，甚至这些留言都是来自一篇博客都没有的”新人”，至此，基本可以断定，此君“不讲武德”，用作弊的方式在刷流量！当然，他自己都承认了： 作弊实锤 年轻人不讲”武德”OK，既然现在的年轻人都把心思用到这种事情上，作为一个老年人，必须要让他知道什么叫“耗子尾汁”，我们技术做一点正经事儿不行吗？其实，博客园的博客质量相比 CSDN 是要高出许多的，而正因为如此，CSDN 在全力转在线教育/课程以后，博客这个板块就再无往日的“生气”，如果每个人都像他一样，天天跑别人底下刷评论，发一点不痛不痒的话，甚至是推广某个小圈子里的QQ群，那真正优质的内容又如何能被大家看到呢？博主曾经加过这样的QQ群，你以为是交流技术的群吗？其实是为了推广某个Python 课程，博主本想交流一下“半泽直树”，然后就被群管理员给删除了！此君大概是抓取Python 板块排名靠前的博客，通过程序来刷存在感。 对此，我想说，这玩意儿用 Selenium + Python 简直和闹着玩一样，毕竟在了解网页结构以后，直接上 jQuery 操作 DOM 即可，甚至连抓包都不需要，不信你看： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105import requestsfrom bs4 import BeautifulSoupimport fake_useragentimport os, json, time, randomfrom selenium import webdriverfrom selenium.webdriver.support.ui import Selectfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECclass Proxy: def __init__(self, profile): os.environ['TEMPDIR'] = os.path.join(os.path.abspath('.'), 'profile') firefoxProfile = webdriver.FirefoxProfile(profile) fireFoxOptions = webdriver.FirefoxOptions() self.driver = webdriver.Firefox( firefox_options=fireFoxOptions, firefox_profile=firefoxProfile ) # 批量点赞 def vote(self, urls): ''' 对指定的一组博客地址批量进行点赞 ''' for url in urls: self.driver.get(url) time.sleep(3) flag = self.driver.execute_script(\"return $('#is-like-span').text().trim()\") == \"已赞\" if not flag: self.driver.execute_script(\"$('#is-like-span').click()\") time.sleep(1) # 批量收藏 def collect(self, urls): ''' 对指定的一组博客地址批量进行收藏 ''' for url in urls: self.driver.get(url) time.sleep(3) flag = self.driver.execute_script(\"return $('#is-collection').text()\") == \"已收藏\" if not flag: self.driver.execute_script(\"$('#is-collection').click()\") self.driver.execute_script(\"$('.csdn-collection-submit').click()\") time.sleep(1) # 批量关注 def follow(self, urls): ''' 对指定的一组博客地址批量进行关注 ''' for url in urls: self.driver.get(url) time.sleep(3) flag = '已关注' in self.driver.execute_script( \"return $($('.toolbox-list').children()[6]).find('a').text().trim()\" ) if not flag: self.driver.execute_script(\"$($('.toolbox-list').children()[6]).find('a').click()\") time.sleep(1) # 批量一键三连 def iloveyuou(self, urls): ''' 对指定的一组博客地址批量进行三连 ''' for url in urls: self.driver.get(url) time.sleep(3) self.driver.execute_script(\"$($('.toolbox-list').children()[7]).find('p').click()\") time.sleep(1) # 批量留言 def comment(self, urls, texts): ''' 对指定的一组博客地址批量进行评论 ''' for url in urls: self.driver.get(url) time.sleep(3) text = random.choice(texts) self.driver.execute_script(f\"$('#comment_content').text('&#123;text&#125;')\") self.driver.execute_script(f\"$('.btn-comment').click()\") # CSDN对评论间隔有要求，那就再睡一会儿 time.sleep(5) # 热门文章 def hotRank(self, channel): ''' 抓取某个话题下的热门文章 ''' url = f'https://blog.csdn.net/phoenix/web/blog/hotRank?page=0&amp;pageSize=25&amp;child_channel=&#123;channel&#125;' headers = &#123; 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:84.0) Gecko/20100101 Firefox/84.0', 'Cookie':'uuid_tt_dd=10_220300310-1611402514139-727015; dc_session_id=10_1611402514139.129755; dc_sid=37a633fe075b2698beeae6fb9c306fb4' &#125; response = requests.get(url, headers=headers) response.raise_for_status() data = json.loads(response.text) if (data['code'] == 200 and data['message'] == 'success'): return list(map(lambda x:x['articleDetailUrl'], data['data'])) else: return [] 我们都知道，在通常情况下，Selenium 每次运行时都会打开一个浏览器， 可这个浏览器呢，相对于我们平时使用的浏览器来说是“独立”的，因为细心的朋友一定会发现，虽然我们在 Chrome 或者 Firefox 中早已登录过了某个网站，可此时此刻，当 Selenium 启动浏览器窗口的时候，我们发现这个网站依然是需要登录的。为什么要讨论这个问题呢？因为如果我们希望对 CSDN 实现“一键三连”，登录这一步是必不可少的步骤。那么，有没有一种办法，可以让 Selenium 共享我们本地浏览器中的 Cookie 信息呢？因为只要有了Cookie，我们就可以专注于实现“一键三连”这部分。相信大家都看过上面的代码啦，答案当然是有的，我们为其指定一个配置文件的路径即可： 1234567891011121314# 设置 Firefox 配置文件# 默认路径：C:\\\\Users\\\\&lt;User&gt;\\\\AppData\\\\Roaming\\\\Mozilla\\\\Firefox\\\\Profiles\\\\XXXX.default# 参考链接：https://support.mozilla.org/zh-CN/kb/用户配置文件profile_dir = 'C:\\\\Users\\\\YuanPei\\\\AppData\\\\Roaming\\\\Mozilla\\\\Firefox\\\\Profiles\\\\xypbnthd.default-release'firefoxProfile = webdriver.FirefoxProfile(profile_dir) fireFoxOptions = webdriver.FirefoxOptions()webdriver.Firefox(firefox_options=fireFoxOptions, firefox_profile=firefoxProfile)# 设置 Chrome 配置文件# 默认路径：C:\\\\Users\\\\&lt;User&gt;\\\\AppData\\Local\\Google\\Chrome\\User Dataprofile_dir = 'C:\\\\Users\\\\YuanPei\\\\AppData\\Local\\Google\\Chrome\\User Data'chromeOptions = webdriver.ChromeOptions() chromeOptions.add_argument('user-data-dir=' + os.path.abspath(profile_dir)) webdriver.Chrome(chrome_options=chromeOptions) 这样，Selenium 启动的就不再是一个“裸”的浏览器，我们平时使用的各种配置、插件等等都会被原封不动地加载到 Selenium 中，这其中同样了我们的 Cookie，所以，当大家看到我的代码的时候，会发现这里没有做任何登录相关的事情，这其实是在用“时间”换取技术实现的“简单”，因为要额外加载大量的信息，所以，Selenium 启动的时候会变得缓慢起来，经过博主自己测试，Firefox 启动大概需要1分钟左右，熬过这1分钟接下来就是坦途啦！ 其实，除此以外，关于登录这个问题，我们还有一种方案是对Cookie进行持久化。简而言之，就是利用 Selenium 的get_cookies() 和 add_cookie() 这一组API，第一次打开某个网站的时候，首先人为地或者模拟登录，此时可以获得Cookie并对其进行序列化，而访问那些需要登陆的资源时，则可以对Cookie进行反序列化并将其加载到 Selenium 环境中，基本的代码示例如下： 12345678910# 保存Cokie到本地文件cookies = driver.get_cookies()with open(\"cookies.txt\", \"w\") as fp: json.dump(cookies, fp)# 从本地文件加载Cookiewith open(\"cookies.txt\", \"r\") as fp: cookies = json.load(fp) for cookie in cookies: driver.add_cookie(cookie) 下面来做一个简单的演示， CSDN 有一个类似微博热搜的 博客榜单。这里，我们会从中筛选前 5 的博客链接来进行“一键三连”操作。与此同时，博主选取了一部分这些年轻人们喜欢用的评论，就在刚刚，我在这篇博客 《第十二届蓝桥杯模拟赛Python组（第一期）》 下面再次发现 Kimol君 的身影，年轻人你不讲武德啊！我就想起了《开讲啦》里面惹恼易中天教授的那位学生，一个人的文章写得好，大家愿意去读去看，这自然是好事，可正因为梦鸽和大白这些小姐姐们都不在了，这个社区的内容质量完全由点赞、评论、收藏数这些因素在左右着，作为一名博客作者，我更希望别人能真的在读完我的文章后，或者能找出我考虑不周的地方，或者可以就某一个问题深入讨论一番，我发现社区里都喜欢动辄加别人QQ或者微信，可如果这种毫无意义地灌水的评论，这一切又有什么意义呢？ 12345678910111213141516171819# 如果你经常收到这些评论，千万不要“飘”# 你觉得这些话都是真心的吗？comments = [ '代码之路任重道远，愿跟博主努力习之。', '学起来，头秃的那种~', '写的太好了，很实用', '好文！希望博主以后多多分享哈！', '哇，好棒啊，崇拜的小眼神，欢迎回赞，回评哦~~~', '收藏从未停止，学习从未开始。', '大佬，看了您的文章，内心的仰慕之情油然而生，赶紧给大佬点个赞！', '太赞了！666666']proxy = Proxy('C:\\\\Users\\\\YuanPei\\\\AppData\\\\Roaming\\\\Mozilla\\\\Firefox\\\\Profiles\\\\xypbnthd.default-release')# 热搜前5名的文章urls = proxy.hotRank('python')[:5]# 批量留言，刷存在感proxy.comment(urls, comments)# 一键三连proxy.iloveyuou(urls) 当然啦，像我这里提供的关于点赞(vote)、收藏(collect)、关注(follow)等等方法，同样是可以使用的，这里就不再一一例举啦！本身都是基于 jQuery 来操作DOM，理解上应该没有太大难度，虽然我不大喜欢用 jQuery 写业务代码，可对于爬虫这种事情，自然是越简单越好，因为我不想再去学一门操作 DOM 的语言：XPath， 而关于 Selenium 驱动的安装、配置等细节，可以参考博主的这篇文章： 作为技术宅的我，是这样追鬼滅の刃的 博主最近新开了一个付费专栏：Python数据挖掘系列，主要介绍关于爬虫、PyECharts、结巴分词、Pandas、Matplotlib、SnowNLP、OpenCV等数据挖掘相关内容，如果大家喜欢或者感兴趣，欢迎订阅。好了，以上就是这篇博客的全部内容啦，欢迎大家在评论区，就你对于这篇博客的想法或者意见进行讨论，再次谢谢大家！如果 Kimol君 恰好读至此处，最好能一键三连，我权当作为你打广告的广告费啦，哈哈！","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://qinyuanpei.github.io/tags/%E7%88%AC%E8%99%AB/"},{"name":"自动化","slug":"自动化","permalink":"https://qinyuanpei.github.io/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"},{"name":"Selenium","slug":"Selenium","permalink":"https://qinyuanpei.github.io/tags/Selenium/"}]},{"title":"使用多线程为你的Python爬虫提速的N种姿势，你会几种？","date":"2021-01-14T20:35:47.000Z","path":"posts/3247093203/","text":"最近博主在优化一个爬虫程序，它是博主在2017年左右刚接触 Python 时写下的一个程序。时过境迁，当 Python 2.X 终于寿终正寝成为过去，当博主终于一只脚迈进30岁的大门，一切都来得猝不及防，像一阵龙卷风裹挟着回忆呼啸而去。和大多数学习 Python 的人一样，博主学习 Python 是从写爬虫开始的，而这个爬虫程序刚好是那种抓取“宅男女神”的程序，下载图片无疑是整个流程里最关键的环节，所以，整个优化的核心，无外乎提升程序的稳定性、提高抓取速度。所以，接下来，我会带大家走近 Python 中的多线程编程，涉及到的概念主要有线程(池)、进程(池)、异步I/O、协程、GIL等，而理解这些概念，对我们而言是非常重要的，因为它将会告诉你选择什么方案更好一点。想让你的爬虫更高效、更快吗？在这里就能找到你的答案。 楔子现在，假设我们有一组图片的地址(URL)，我们希望通过requests来实现图片的下载，为此我们定义了Spider类。在这个类中，我们提供了getImage()方法来完成下载这个动作。我们可以非常容易地写出一个“单线程”的版本，但这显然这不是我们今天这篇博客的目的。此时，我们来考虑一个问题，怎么样实现一个“多线程”的版本？ 123456789101112131415161718192021222324252627282930class Spider: def __init__(self, urls): self.session = requests.session() self.session.headers['User-Agent'] = fake_useragent.UserAgent().random self.session.headers[\"Referer\"] = \"https://www.nvshens.org\" self.urls = urls # 下载图片 def getImage(self, url, fileName, retries=5): try: print(f'&#123;threading.currentThread().name&#125; -&gt; &#123;url&#125;') response = self.session.get(url, allow_redirects=False, timeout=10, proxies=None ) response.raise_for_status() data = response.content imgFile = open(fileName, 'wb') imgFile.write(data) imgFile.close() return True except : while retries &gt; 0: retries -= 1 if self.getImage(url, fileName, retries): break else: continue 线程与线程池既然提到了线程，我们会非常自然地想到 Thread 和 ThreadPool ，而这几乎是所有编程语言里都有的通用型概念。可是，Python 中的多线程其实是一种“假”的多线程，这又从何说起呢？答案是全局解释器锁(GIL)，原来在设计 Python 解释器的时候，为了保证同时只有一个线程在运行，引入了这样一个锁，你可以类比游戏开发时主循环的概念来辅助理解。那为什么又说 Python 中的多线程是一种“假”的多线程呢？这是因为它没法发挥出多核的优势，每个线程在执行前都要先获得 GIL ，这就导致一个问题，即使你有多个核心，线程永远只能用到其中一个核，因为多线程在 Python 中只能交替执行。以一言蔽之， Python 中 I/O 密集型任务相比 CPU 密集型任务更能充分发挥多线程的好处。所以，像爬虫这种和网络打交道的事物，是非常适合使用多线程来提高效率的。在这里，我们我们要介绍的是 Thread 和 ThreadPool 以及 ThreadPoolExecutor。 Thread首先，我们需要了解的是，Python 中的 Thread ，实际上先后有thread和threading两种模块，它们的关系有一点像 .NET 里的Thread和Task，考虑到thread的使用频率非常低，这里我们更推荐大家使用threading，它提供了更高级的、完全的线程管理。例如，我们现在面临的这个“多线程”下载的问题，使用threading的话可以这样解决： 12345678910111213# 使用Thread下载def downloadByThread(self): threads = [] for index in range(0, len(self.urls)): thread = threading.Thread( target=self.getImage, args=(self.urls[index], f'&#123;str(index)&#125;.jpg',) ) threads.append(thread) for thread in threads: thread.setDaemon(True) thread.start() 可以注意到，当我们需要构造一个线程时，只需要指定target和args两个参数，其中，前者是指线程执行的方法，后者是指传递给线程所执行的方法的参数。当我们需要启动线程时，只需要调用线程的start()方法，而通过setDaemon()方法则可以设置一个线程为守护线程。关于守护线程，这里简单说明一下，一旦一个线程被设置为守护线程，那么，只要线程执行的方法中存在等待时间譬如time.sleep(1)，此时等待时间下面的代码都不会再执行。如果线程中执行的方法是一个耗时的操作，此时，我们还可以通过join()方法来阻塞主线程，以确保主线程再子线程执行完后再结束。除了这种函数式的使用方法以外，我们还可以通过继承Thread类并重写其run()方法的方式，对于这一点可以参考官方文档中的线程对象。 使用Thread下载 ThreadPool对于线程，我们都知道它是作为一种系统资源而存在的，所以，和这个世界上的大多数资源一样，无法供我们肆意地挥霍和浪费。在 .NET Core中对象池(Object Pool)的使用 这篇博客中，我曾经大家介绍过“对象池”这种设计，和这篇博客中所提到的原理一样，线程池相对于普通线程而言多了一种可复用的可能性，这意味着我们可以用有限的线程来下载可能无限多的图片资源。在 Python 中我们使用 threadpool 模块来实现线程池的功能，需要注意的是这是一个第三方的模块。下面，我们来一起看看具体的使用方法： 123456789101112131415# 使用ThreadPool下载def downloadByThreadPool(self, poolSize=3): count = len(self.urls) # 构造线程参数 args = [] for index in range(0, count): args.append((None, &#123;'url': self.urls[index], 'fileName': f'&#123;str(index)&#125;.jpg'&#125;)) # 线程池大小 if count &lt; poolSize: poolSize = count # 构造线程池 pool = threadpool.ThreadPool(poolSize) requests = threadpool.makeRequests(self.getImage, args) [pool.putRequest(req) for req in requests] pool.wait() 在这里，我们声明了一个指定大小的线程池，通过一个方法getImage()和一组参数args来构造“请求”，再将这些请求全部放进线程池里，此时，线程池会自动等待这些“请求”执行完毕。这里唯一比较难理解的，可能是如何构造参数args，尤其是当被执行的方法需要传递多个参数的时候。其实这里有两种传参的方式，第一种是按数组来解构，此时我们可以写[([&#39;&#39;,&#39;&#39;], None), ([&#39;&#39;,&#39;&#39;], None)]；而第二种则是按字典来解构，此时我们可以写[(None, {&#39;url&#39;:&#39;&#39;, &#39;fileName&#39;:&#39;&#39;}), (None, {&#39;url&#39;:&#39;&#39;, &#39;fileName&#39;:&#39;&#39;})。两者的区别主要在None的位置，不知道大家有没有发现规律。这里我们准备了张图片，而线程池最大线程是3个，理论上某个线程会被重复使用，实际结果又是如何呢？ 使用ThreadPool下载 ThreadPoolExecutor对于ThreadPoolExecutor，相信不用我多说什么，你就能知道它是做什么的吧，这就是博主反复提及的命名规范的问题。简而言之，Python 在 concurrent.futures中为我们提供了 ThreadPoolExecutor 和 ProcessPoolExecutor 两个高级接口，它们都继承自同一个抽象类Executor，它可以让我们在线程池或者进程池中异步地执行回调函数，属于官方提供的标准的“线程池”和“进程池”模块，下面，我们来一起看看具体的使用方法： 123456789101112131415161718# 使用ThreadPoolExecutor下载def downloadByThreadPoolExecutor(self, poolSize=3): count = len(self.urls) # 构造线程参数 args = [] for index in range(0, count): args.append(&#123;'url': self.urls[index], 'fileName': f'&#123;str(index)&#125;.jpg'&#125;) # 线程池大小 if count &lt; poolSize: poolSize = count # 构造线程池 pool = ThreadPoolExecutor(max_workers=poolSize) tasks = [] for arg in args: task = pool.submit(self.getImage(arg['url'], arg['fileName']), arg) tasks.append(task) wait(tasks, return_when=ALL_COMPLETED) # tasks = pool.map(lambda arg:self.getImage(arg['url'], arg['fileName']), args) 这里需要注意的是，submit()方法和map()方法的区别，前者相当于声明线程后并不立即执行，故而，需要wait()方法来等待所有任务执行结束；而后者则相当于声明线程并理解执行，故而，返回值实际是每一个任务执行的结果的集合，这里就隐隐有一点 .NET 中 Task 的味道啦！同样地，我们给了一个最大线程数：3，它能否得到和threadpool 类似的结果呢？我们拭目以待： 使用ThreadPoolExecutor下载 进程与进程池看到这里，可能有读者朋友会忍不住吐槽，博主你三十岁不到，怎么越来越糊涂了啊，你这博客标题明明写的是多线程，怎么写着写着就写到进程上来了呢？其实，这里是紧接着 GIL 这个话题来讲的。既然 Python 中的多线程更适合 I/O 密集型的任务，那么，是不是说 Python 不适合处理 CPU 密集型的任务呢？答案是否定的，我们这里将多进程理解为并行就会更容易想明白一点。我们都知道操作系统可以同时执行多个任务，而这每一个任务其实就是一个进程，而每个进程内又可以同时执行多个子任务，这每一个子任务其实就是一个线程。这样说，我们或许就能明白，这意味着，如果我们的确需要并行地去处理某些任务，进程(池)或许是个不错的选择。同样地，这里介绍的是，Process、ProcessPool 和 ProcessPoolExecutor。 Process关于进程，我个人感觉比线程要更好理解一点，因为不论是 Windows 下的任务管理器，亦或者是我们经常听到的“杀进程”，它都不算是一个特别陌生或者抽象的概念，而线程这种东西呢，大概是只有程序员会关注，同时爱之弥深、恨之弥切的一种事物。庆幸的是，在 Python 中线程与进程在代码的编写上是非常相似的，这里我们需要用到的是multiprocessing模块，下面，我们来一起看看 Python 中的进程的的使用方法，你会发现只需要改一下threading.Thread()这部分： 123456789101112# 使用Process下载def downloadByProcess(self): process = [] for index in range(0, len(self.urls)): proc = multiprocessing.Process( target=self.getImage, args=(self.urls[index], f'&#123;str(index)&#125;.jpg',) ) process.append(proc) for proc in process: proc.start() 此时，我们可以得到下面的结果，可以发现它都是在主线程上运行： 使用Process下载 ProcessPool既然有“线程池”，又怎么能少得了进程池呢？同样地，它位于multiprocessing模块中，通过apply()方法来执行某个任务，下面是一个基本的示例： 1234567891011121314# 使用multiprocessing.Pool()下载def downloadByProcessPool(self, poolSize=3): count = len(self.urls) # 构造线程参数 args = [] for index in range(0, count): args.append((self.urls[index], f'&#123;str(index)&#125;.jpg', )) # 线程池大小 if count &lt; poolSize: poolSize = count # 构造线程池 pool = multiprocessing.Pool(poolSize) for arg in args: pool.apply(self.getImage, arg) 有朋友难免会好奇“进程池”和“线程池”有什么不一样，我想，下面这张图会告诉你答案： 使用multiprocessing.Pool()下载 ProcessPoolExecutor和 ThreadPoolExecutor 类似，我们还可以使用 ProcessPoolExecutor 来实现“进程池”： 1234567891011121314# 使用ProcessPoolExecutor下载def downloadByProcessPoolExecutor(self, poolSize=3): count = len(self.urls) # 构造线程参数 args = [] for index in range(0, count): args.append(&#123;'url': self.urls[index], 'fileName': f'&#123;str(index)&#125;.jpg'&#125;) # 线程池大小 if count &lt; poolSize: poolSize = count # 构造线程池 pool = ProcessPoolExecutor(max_workers=poolSize) for arg in args: pool.submit(self.getImage(arg['url'], arg['fileName']), arg) 可以看到，“进程池”中的代码都是在主线程上执行的，这一点和multiprocessing.Pool()完全一致： 使用ProcessPoolExecutor下载 协程与异步I/O其实，如果单单从 I/O 密集型和 CPU 密集型两种场景而言，这篇博客到这里就差不多应该结束啦！不过呢，博主好奇 Scrapy 这个爬虫框架的实现原理，发现它是基于 Twisted 这样一个异步网络框架，考虑到目前为止，我们通过 requests 来下载图片都是采用同步的方式，除了任务调度上的优化以外，任务本身还存在一定的优化空间，所以，这里就顺带着一起整理出来，这里主要结合 asyncio 和 requests 来对 Python 中关于异步 I/O 、协程等的使用方法进行演示和说明。 asyncioasyncio 是用来编写 并发 代码的库，使用 async/await 语法，它是构建 I/O 密集型和高层级 结构化 网络代码的最佳选择。它提供了类似并发地执行协程、网络 I/O 和进程间通信(IPC)、事件循环等等的能力，例如，我们可以通过下面的代码来创建和使用协程: 1234567891011121314import asyncioasync def say_after(what, delay): await asyncio.sleep(delay) print(what)async def main(): await say_after('你好', 1) await say_after('Hello', 2)# 方式1# Python 3.7 + asyncio.rum(main())# Python 3.7 -asyncio.get_event_loop().run_until_complete(main()) 参考官方文档，我们还可以使create_task()方法来创建asyncio的并发任务： 123456789101112# 方式2async def main(): # Python 3.7 + task1 = asyncio.create_task(say_after('你好', 1)) task2 = asyncio.create_task(say_after('Hello', 2)) # Python 3.7 - task1 = asyncio.get_event_loop().(say_after('你好', 1)) task2 = asyncio.get_event_loop().(say_after('Hello', 2)) await task1 await task2asyncio.get_event_loop().run_until_complete(main()) 这是因为 Python 中的协程、任务 和 Future 都是可等待对象，故而，凡有 async 处皆可 await ，果然，主流编程语言的最终走向是如此的一致啊，回头想想 .NET 中 Thread 、 ThreadPool 、 Task 的进化历程，是不是有种“天下大势，分久必合”的感觉呢？ requests好了，当我们对异步 I/O、协程有了一个基本的了解以后，我们就可以考虑结合着 requests 来做一点小小的尝试，我们大多数时候写的 requests 相关的代码，基本上都是博主这里getImage()类似的画风，最多再加上流式传输(Stream) 和 iter_content。为了配合异步 I/O来使用，我们这里需要定义一个异步的方法getImageAsync()，一起来看下面的代码： 123456789101112131415161718192021222324async def getImageAsync(self, url, fileName, retries=5): try: print(f'&#123;threading.currentThread().name&#125; -&gt; &#123;url&#125;') headers = &#123; 'User-Agent': fake_useragent.UserAgent().random, 'Referer': \"https://www.nvshens.org\" &#125; future = asyncio.get_event_loop().run_in_executor( None, functools.partial(requests.get, url, headers=headers) ) response = await future data = response.content imgFile = open(fileName, 'wb') imgFile.write(data) imgFile.close() return True except: while retries &gt; 0: retries -= 1 if await self.getImageAsync(url, fileName, retries): break else: continue 接下来，我们还需要定义downloadAsync()方法，这里我们使用了create_task()方法： 123456async def downloadAsync(self): count = len(self.urls) for index in range(0, count): url = self.urls[index] fileName = f'&#123;str(index)&#125;.jpg' await asyncio.get_event_loop().create_task(self.getImageAsync(url, fileName)) 此时，我们可以在入口函数中这样调用： 1234spider = Spider(urls)loop = asyncio.get_event_loop()task = loop.create_task(spider.downloadAsync())loop.run_until_complete(task) 看看结果： 异步I/O + Requests 实现并行下载] 这里，针对本文中提到的各种方法，博主做了一个简单对比： 项目 时间 Thread 0:00:01.789790 ThreadPool 0:00:00.134065 ThreadPoolExecutor 0:00:06.510224 Process 0:00:00.100506 ProcessPool 0:00:11.046871 ProcessPoolExecutor 0:00:02.226153 AsyncIO 0:00:04.096083 本文小结本文从线程(池)、进程(池)和异步 I/O 三个方面探讨和尝试了多线程编程在 Python 爬虫领域的简单应用。其实，除了以上这些优化的思路以外，我们还可以借助队列(Queue)这类数据结构来改善现有方案的设计，大家可以注意到我给getImage()方法增加了错误重试的机制，这同样是为了增强爬虫程序的健壮性，而关于这个错误重试机制，考虑通过装饰器来进行改良则又是一个新的努力的方向，所以说，没有 deadline 才能让我们不断地自我改善，而有 deadline 只能让我们赶紧做完赶紧清净。好了，以上就是这篇博客的全部内容啦，最后要送给大家一个福利，本文中援引的爬虫程序已开源，地址是：https://github.com/qinyuanpei/zngirls，感兴趣的朋友可以自己去玩一玩，你懂的哦！","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://qinyuanpei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"技巧","slug":"技巧","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E5%B7%A7/"},{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"爬虫","slug":"爬虫","permalink":"https://qinyuanpei.github.io/tags/%E7%88%AC%E8%99%AB/"}]},{"title":"实现网页长截图的常见思路总结","date":"2021-01-09T20:37:47.000Z","path":"posts/3406626380/","text":"作为一个经常写博客的人，我有时会在微博上分享博客内容，可不知道从什么时候开始，国内互联网越来越丧失信仰，所有的厂商都在试图打造一个“只进不出”的信息孤岛，进而达到增强“用户黏度”的目的。以微博为例，微博中的外链永远都会被转化为短地址，并且无法通过微博内置的浏览器进行跳转。即使你通过手动复制链接的方式打开链接，你依然需要至少两个步骤方能见到“庐山真面目”。借鉴/抄袭这一陋习的还有简书，花时间做了一个第三方链接跳转提示页面，唯独不愿意在上面加一个a标签，你还是要手动复制黏贴。坦白说，我觉得国内互联网正在丧失着信仰，看起来电商、物流、外卖、打车、支付……此起彼伏逐渐渗透到我们生活的方方面面，成为名副其实的“互联网+”，可在信息泛滥的今天，我们越来越难找到真正有价值的信息……既然外链注定要被屏蔽掉，那我就勉为其难地顺应潮流发“长截图”咯，所以，接下来我会为大家分享实现网页“长截图”的常见思路，希望对有类似烦恼或者需求的小伙伴们有所帮助。 通过浏览器实现要实现网页长截图，显然是和网页打交道，而和网页打交道最多的是谁呢？自然是我们每天都要用的浏览器啦！值得庆幸的是，不管是 Chrome 还是 Firefox ，我们都可以通过它们来是实现这个想法。 Chrome对于 Chrome 来说，我们只需要“F12”打开开发者工具，并在其中找到“控制台”选项卡，在平时输入 JavaScript 脚本的地方(即 Console 选项卡)输入Ctrl + Shift + P命令，然后你会得到一个类似 VSCode 命令行体验的输入窗口，接下来，输入：Capture full size screenshot并回车。此时，我们就可以得到完整的页面截图。而如果你希望截取网页中的一部分，则可以在选中指定 DOM 元素后采用相同的方式输入命令：Capture node screenshot。此外，更常用的截取浏览器可见范围内的内容，可以使用：Capture screenshot。可能相对于一般可以进行拖拽截图的工具而言，这个方案显得有点笨拙且简陋，可它真的可以完美地实现我们的想法，而且不需要安装任何扩展或者插件。 使用 Chrome 的截图功能 Firefox对于 Firefox 而言，它本身自带截图功能，并且支持拖拽截图，对于我们这些需要长截图的人而言，唯一需要做的就是点击几下数据，确实要比敲命令行要简单一点、友好一点，我个人更喜欢用 Firefox 一点，因为 Chrome 正在从屠龙少年变成恶龙，为了让这个世界上不是只有 Chrome 一种浏览器内核，我决定支持一下 Firefox ，2020年因为疫情的原因， Mozila 裁员25%约250人，这家几乎靠着理想主义在维护 Gecko 内核的公司，之后可能再无法和 Google 的 Chrome 抗衡，而这个世界只有一种浏览器的时代我们都曾经经历过，它的名字叫做 IE6 ，不禁令人感慨，简直是开放 Web 的罗曼蒂克消亡史。 使用 Firefox 的截图功能 通过Selenium实现在我的认知中，有浏览器的地方就有爬虫，而有爬虫的地方就有 Selenium 。原本好端端的UI自动化测试框架，怎么就助纣为虐做起爬虫来了呢？其实，主要原因是它提供了一个可以和浏览器交互的环境，从某种意义上来讲，Selenium 、PhantomJS 以及 Playwright 都可以认为是类似的技术，这里我们以Selenium为例，而通过Selenium实现网页长截图则主要有两种方式：其一，是构造一个足够“大”的浏览器，然后调用save_screenshot()方法进行截图；其二，是通过“拖拽”滚动条来滚动截图，然后再通过PIL进行拼接，下面来看具体的代码实现： 123456789101112131415161718def save_screenshot(url, fp_pic): fireFoxOptions = webdriver.FirefoxOptions() fireFoxOptions.set_headless() driver = webdriver.Firefox(firefox_options=fireFoxOptions) driver.get(url) time.sleep(1) # 设置浏览器宽度和高度 width = driver.execute_script( \"return document.documentElement.scrollWidth\" ) height = driver.execute_script( \"return document.documentElement.scrollHeight\" ) driver.set_window_size(width, height) time.sleep(1) # 截图 driver.save_screenshot(fp_pic) driver.close() 这里我使用的是 Firefox 的驱动，喜欢 Chrome 的按个人喜好即可，这里我假设你已经掌握了 Python 和 Selenium，如果需要一点辅助知识，可以参考博主的这篇文章：作为技术宅的我，是这样追鬼滅の刃的 。这种方式的“长截图”实现起来非常简单，可是因为需要构造一个非常“大”的浏览器，所以，如果页面适配没有做好的话，可能会出现页面元素变形的问题，其次，这种方式生成的图片体积普遍比较大，所以，从总体上看主要就是这两个缺点。而“滚动截图”实现起来会稍微复杂一点，因为里面会涉及到一小部分计算： 123456789101112131415161718192021222324252627282930def save_screenshot2(url, fp_pic): fireFoxOptions = webdriver.FirefoxOptions() fireFoxOptions.set_headless() driver = webdriver.Firefox(firefox_options=fireFoxOptions) driver.fullscreen_window() # 全屏窗口 driver.get(url) window_height = driver.get_window_size()['height'] # 窗口高度 page_height = driver.execute_script( 'return document.documentElement.scrollHeight' ) # 页面高度 driver.save_screenshot('temp.png') if page_height &gt; window_height: n = page_height // window_height # 需要滚动的次数 base_mat = np.atleast_2d(Image.open('temp.png')) # 打开截图并转为二维矩阵 for i in range(n): driver.execute_script( f'document.documentElement.scrollTop=&#123;window_height * (i+1)&#125;;' ) time.sleep(.5) driver.save_screenshot(f'temp_&#123;i&#125;.png') # 保存截图 mat = np.atleast_2d(Image.open(f'temp_&#123;i&#125;.png')) # 打开截图并转为二维矩阵 base_mat = np.append(base_mat, mat, axis=0) # 拼接图片的二维矩阵 Image.fromarray(base_mat).save(fp_pic, format='PNG') os.remove(f'temp_&#123;i&#125;.png') os.remove('temp.png') driver.quit() 这个方案本身没有太大的问题，可如果你的网页是那种页面滚动时头部固定的设计，譬如类似博主的博客这样的风格，此时这种方案就会有一点问题，每次截取都会包含头部这部分，和我们最后想要实现的效果有一点出入，如果可以计算出头部的高度，截图或者拼接的时候把这个高度考虑进去，就可以彻底解决这个问题，可这样这个问题就从一个通用型问题变成一个局部型问题啦，果然，世上没有完美的解决方案呢…… 通过JavaScript实现有人可能要说，博主你好偏心，为什么 Python 都出来了，作为前端三剑客之一的 JavaScript 还没有出现？嗯，对此我想说——你不用说，我知道不就是“人生苦短，我用Python”吗？人家前端世界里有个叫做 html2canvas 的库，博主你可有耳闻？我笑了笑，我并没有看了看我的劳力士，因为我没有劳力士。好吧，既然这里提到了这个库，那就来说说这个库的实现思路吧，人家不是说了嘛？一切可以实现的东西，最终可以用 JavaScript 来实现，我们来看看具体的代码实现，这里，首先准备一个HTML文件： 1234567891011121314151617181920&lt;!DOCTYPE html&gt;&lt;head&gt; &lt;script src='./html2canvas.min.js'&gt;&lt;/script&gt; &lt;script src=\"https://cdn.jsdelivr.net/npm/vue/dist/vue.js\"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body style=\"overflow: hidden;\"&gt; &lt;div id=\"app\" style=\"height: 768px; overflow: hidden;\"&gt; 请输入URL: &lt;input type=\"text\" v-model=\"url\"&gt; &lt;button v-on:click=\"capture\"&gt;截取&lt;/button&gt; &lt;hr&gt; &lt;iframe id=\"view\" v-bind:src='url' width=\"100%\" height=\"100%\" frameborder=\"0\" ref=\"view\"&gt; &lt;/iframe&gt; &lt;/div&gt;&lt;/body&gt; 非常简单，输入一个地址，然后通过一个iframe进行预览，点击按钮进行截图。下面给出JavaScript代码： 12345678910111213141516171819202122232425262728&lt;script&gt; var vm = new Vue(&#123; el: '#app', data: &#123; url: 'https://regularly-archive.github.io/2020/Matrix/', &#125;, methods: &#123; capture: function() &#123; var self = this; var iframe = self.$refs.view.contentWindow; var iframeBody = iframe.document.getElementsByTagName('body')[0] html2canvas(iframeBody).then(canvas =&gt; &#123; document.body.appendChild(canvas); //canvas转图片 let canvasImg = canvas.toDataURL(\"image/png\"); //模拟下载 var a = document.createElement('a') a.href = canvasImg; a.download = self.url; let event = document.createEvent(\"MouseEvents\") event.initMouseEvent(\"click\", true, false, window, 0, 0, 0, 0, 0, false, false, false, false, 0, null) a.dispatchEvent(event) &#125;); &#125; &#125; &#125;);&lt;/script&gt; 效果如下，你可以点击 这里 访问在线演示DEMO： 使用html2canvas实现的长截图 这里使用iframe可能会引入跨域的问题，大家可以参考我的这篇文章：聊聊前端跨域的爱恨情仇 ，而 html2canvas 本身就提供了关于跨域问题的解决方案，大家可以参考这里：http://html2canvas.hertzen.com/configuration。 通过第三方工具实现我知道程序员都喜欢自己去折腾，如果是前无古人、后无来者的东西，我建议去折腾，因为梦想还是要有的，万一实现了呢？而我们这个圈子里同样有一句经典的话，叫做“不要重复制造轮子”，所以，博主这里找到了几个轮子供大家参考，不喜欢在冬天动手写代码的人，可以收藏下这几个工具，这个冬天实在是太冷了，冷到什么程度呢?大概听见笑话都不大愿意笑，用罗翔老师的话说这叫做搞笑未遂。 wkhtml2imagewkhtml系列，一个命令行工具，可以将本地HTML文件或者远程URL指向的网页转化为图片，该系列产品中还有wkhtml2pdf，顾名思义，网页转PDF，实际使用过程中基本没什么问题，输出的图片1:1还原网页，唯一的缺点是偶尔会丢失样式，尤其是页面中引入了第三方的JavaScript或者CSS的时候，整体上远程URL比本地HTML要稳定一点，推荐系数：4星。 长截图03.png PickFromPickFrom，一个在线的网页转图片的服务，填写URL然后点击按钮即可，提供免费预览一部分图片的功能，完整图片的查看、下载均需要支付一定费用，服务质量还可以，但不适合我们这种被迫“白嫖”的穷人家的孩子，土豪们随意，推荐系数：4星 PickFrom TiomgTiomg，接下来是博主要重点推荐，它和 PickFrom 提供着相同的服务，唯一不同的是，它是完全免费的，我现在主要用这个来工具来生成“长截图”，不错，我背叛了上面我写的那些代码，为什么要重复造轮子呢？有时候我想不明白，为什么国内公司都喜欢那种“大而全”的软件，恨不得要拥有竞争对手所有的特性，可明明大家都“卷”成这样了，为什么不试试差异化的路线呢？可能，是因为低端竞争太多吧！推荐系数：5星 Tiomg 冬天实在是没有动力去写有技术含量的东西啊！关于“长截图”这个话题，差不多是从一周前开始关注、做实验的，所以，请允许在下偶尔写这样一篇“水文”吧！关于“视频是不能P的系列”，因为 Dlib 安装起来实在讨厌，而 OpenCV 提供的 68 特征点算法目前只支持 C++ ，研究起来难免要花一点时间，好了，这篇博客暂时先写到这里吧，博主要先去冬眠啦，再见!","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"Selenium","slug":"Selenium","permalink":"https://qinyuanpei.github.io/tags/Selenium/"},{"name":"长截图","slug":"长截图","permalink":"https://qinyuanpei.github.io/tags/%E9%95%BF%E6%88%AA%E5%9B%BE/"},{"name":"工具","slug":"工具","permalink":"https://qinyuanpei.github.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"温故而知新，由ADO.NET与Dapper所联想到的","date":"2020-12-30T12:49:47.000Z","path":"posts/2621074915/","text":"这段时间在维护一个“遗产项目”，体验可以说是相当地难受，因为它的数据持久化层完全由ADO.NET纯手工打造，所以，你可以在项目中看到无所不在的DataTable，不论是读操作还是写操作。这个DataTable让我这个习惯了Entity Framework的人感到非常别扭，我并不排斥写手写SQL语句，我只是拥有某种自觉并且清醒地知道，自己写的SQL语句未必就比ORM生成的SQL语句要好。可至少应该是像Dapper这种程度的封装啊，因为关系型数据库天生就和面向对象编程存在隔离，所以，频繁地使用DataTable无疑意味着你要写很多的转换的代码，当我看到DbConnection、DbCommand、DbDataReader、DbDataAdapter这些熟悉的“底层”的时候，我意识到我可以结合着Dapper的实现，从中梳理出一点改善的思路，所以，这篇博客想聊一聊ADO.NET、Dapper和Dynamic这三者间交叉的部分，希望能给大家带来新的启发。 重温ADO.NET相信大家都知道，我这里提到的DbConnection、DbCommand、DbDataReader、DbDataAdapte以及DataTable、DataSet，实际上就是ADO.NET中核心的组成部分，譬如DbConnection负责管理数据库连接，DbCommand负责SQL语句的执行，DbDataReader和DbDataAdapter负责数据库结果集的读取。需要注意的是，这些类型都是抽象类，而各个数据库的具体实现，则是由对应的厂商来完成，即我们称之为“驱动”的部分，它们都遵循同一套接口规范，而DataTable和DataSet则是“装”数据库结果集的容器。关于ADO.NET的设计理念，可以从下图中得到更清晰的答案： ADO.NET架构 在这种理念的指引，使用ADO.NET访问数据库通常会是下面的画风。博主相信，大家在各种各样的DbHelper或者DbUtils中都见过类似的代码片段，在更复杂的场景中，我们会使用DbParameter来辅助DbCommand，而这就是所谓的SQL参数化查询。 1234567891011121314151617181920212223242526272829var fileName = Path.Combine(Directory.GetCurrentDirectory(), \"Chinook.db\");using (var connection = new SQLiteConnection($\"Data Source=&#123;fileName&#125;\"))&#123; if (connection.State != ConnectionState.Open) connection.Open(); using (var command = connection.CreateCommand()) &#123; command.CommandText = \"SELECT AlbumId, Title, ArtistId FROM [Album]\"; command.CommandType = CommandType.Text; //套路1：使用DbDataReader读取数据 using (var reader = command.ExecuteReader()) &#123; while (reader.Read()) &#123; //各种眼花缭乱的写法:) Console.WriteLine($\"AlbumId=&#123;reader.GetValue(0)&#125;\"); Console.WriteLine($\"Title=&#123;reader.GetFieldValue&lt;string&gt;(\"Title\")&#125;\"); Console.WriteLine($\"ArtistId=&#123;reader.GetInt32(\"ArtistId\")&#125;\"); &#125; &#125; //套路2：使用DbDataAdapter读取数据 using (var adapter = new SQLiteDataAdapter(command)) &#123; var dataTable = new DataTable(); adapter.Fill(dataTable); &#125; &#125;&#125; 这里经常会引发的讨论是，DbDataReader和DbDataAdapter的区别以及各自的使用场景是什么？简单来说，前者是按需读取/只读，数据库连接会一直保持；而后者是一次读取，数据全部加载到内存，数据库连接用完就会关掉。从资源释放的角度，听起来后者更友好一点，可显然结果集越大占用的内存就会越多。而如果从易用性上来考虑，后者可以直接填充数据到DataSet或者DataTable，前者则需要费一点周折，你看这段代码是不是有点秀操作的意思： 1234//各种眼花缭乱的写法:)Console.WriteLine($\"AlbumId=&#123;reader.GetValue(0)&#125;\");Console.WriteLine($\"Title=&#123;reader.GetFieldValue&lt;string&gt;(\"Title\")&#125;\");Console.WriteLine($\"ArtistId=&#123;reader.GetInt32(\"ArtistId\")&#125;\"); 在这个“遗产项目”中，DbDataReader和DbDataAdapter都有所涉猎，后者在结果集不大的情况下还是可以的，唯一的遗憾就是DataTable和LINQ的违和感实在太强烈了，虽然可以勉强使用AsEnumerable()拯救一下，而前者就有一点魔幻了，你能看到各种GetValue(1)、GetValue(2)这样的写法，这简直就是成心不想让后面维护的人好过，因为加字段的时候要小心翼翼地，确保字段顺序不会被修改。明明这个世界上有Dapper、SqlSugar、SmartSql这样优秀的ORM存在，为什么就要如此执著地写这种代码呢？是觉得MyBatis在XML里写SQL语句很时尚吗？ 所以，我开始尝试改进这些代码，我希望它可以像Dapper一样，提供Query&lt;T&gt;()和Execute()两个方法足矣！如果要把结果集映射到一个具体的类型上，大家都能想到使用反射，我更想实现的是Dapper里的DapperRow，它可以通过“·”或者字典的形式来访问字段，现在的问题来了，你能实现类似Dapper里DapperRow的效果吗？因为想偷懒的时候，dynamic不比DataRow更省事儿吗？那玩意儿光转换类型就要烦死人了，更不用说要映射到某个DTO啦！ 实现DynamicRow通过阅读Dapper的源代码，我们知道，Dapper中用DapperTable和DapperRow替换掉了DataTable和DataRow，可见这两个玩意儿有多不好用，果然，英雄所见略同啊，哈哈哈！其实，这背后的一切的功臣是IDynamicMetaObjectProvider，通过这个接口我们就能实现类似的功能，我们熟悉的ExpendoObject就是最好的例子： 1234567dynamic person = new ExpandoObject(); person.FirstName = \"Sherlock\"; person.LastName = \"Holmes\";//等价形式(person as IDctionary&lt;string, object&gt;)[\"FirstName\"] = \"Sherlock\";(person as IDctionary&lt;string, object&gt;)[\"LastName\"] = \"Holmes\"; 这里，我们用一种简单的方式，让DynamicRow继承者DynamicObject，下面一起来看具体的代码： 12345678910111213141516171819public class DynamicRow : DynamicObject&#123; private readonly IDataRecord _record; public DynamicRow(IDataRecord record) &#123; _record = record; &#125; public override bool TryGetMember(GetMemberBinder binder, out object result) &#123; var index = _record.GetOrdinal(binder.Name); result = index &gt; 0 ? _record[binder.Name] : null; return index &gt; 0; &#125; //支持像字典一样使用 public object this[string field] =&gt; _record.GetOrdinal(field) &gt; 0 ? _record[field] : null;&#125; 对于DynamicObject这个类型而言，里面最重要的两个方法其实是TryGetMember()和TrySetMember()，因为这决定了这个动态对象的读和写两个操作。因为我们这里不需要反向地去操作数据库，所以，我们只需要关注TryGetMember()即可，一旦实现这个方法，我们就可以使用类似foo.bar这种形式访问字段，而提供一个索引器，则是为了提供类似foo[&quot;bar&quot;]的访问方式，这一点同样是为了像Dapper看齐，无非是Dapper的DynamicRow本来就是一个字典！ 现在，我们来着手实现一个简化版的Dapper，给IDbConnection这个接口扩展出Query&lt;T&gt;()和Execute()两个方法，我们注意到Query&lt;T&gt;()需要用到DbDataReader或者DbDataAdapter其一，对于DbDataAdapter而言，它的实现完全由具体的子类决定，所以，对于IDbConnection接口而言，它完全不知道对应的子类是什么，此时，我们只能通过判断IDbConnection的类型来返回对应的DbDataAdapter。读过我之前博客的朋友，应该对Dapper里的数据库类型的字典有印象，不好意思，这里历史要再次上演啦！ 12345678910111213141516public static IEnumerable&lt;dynamic&gt; Query(this IDbConnection connection, string sql, object param = null, IDbTransaction trans = null)&#123; var reader = connection.CreateDataReader(sql); while (reader.Read()) yield return new DynamicRow(reader as IDataRecord);&#125;public static IEnumerable&lt;T&gt; Query&lt;T&gt;(this IDbConnection connection, string sql, object param = null, IDbTransaction trans = null) where T : class, new()&#123; var reader = connection.CreateDataReader(sql); while (reader.Read()) yield return (reader as IDataRecord).Cast&lt;T&gt;();&#125; 这里的CreateDataReader()和Cast()都是博主自定义的扩展方法： 12345678910111213141516171819202122232425private static IDataReader CreateDataReader(this IDbConnection connection, string sql)&#123; var command = connection.CreateCommand(); command.CommandText = sql; command.CommandType = CommandType.Text; return command.ExecuteReader();&#125;private static T Cast&lt;T&gt;(this IDataRecord record) where T:class, new()&#123; var instance = new T(); foreach(var property in typeof(T).GetProperties()) &#123; var index = record.GetOrdinal(property.Name); if (index &lt; 0) continue; var propertyType = property.PropertyType; if (propertyType.IsGenericType &amp;&amp; propertyType.GetGenericTypeDefinition() == typeof(Nullable&lt;&gt;)) propertyType = Nullable.GetUnderlyingType(propertyType); property.SetValue(instance, Convert.ChangeType(record[property.Name], propertyType)); &#125; return instance; &#125; 而Execute()方法则要简单的多，因为从IDbConnection到IDbCommand的这条线，可以直接通过CreateCommand()来实现： 12345678public static int Execute(this IDbConnection connection, string sql, object param = null, IDbTransaction trans = null)&#123; var command = connection.CreateCommand(); command.CommandText = sql; command.CommandType = CommandType.Text; return command.ExecuteNonQuery();&#125; 实现参数化查询大家可以注意到，我这里的参数param完全没有用上，这是因为IDbCommand的Paraneters属性显然是一个抽象类的集合。所以，从IDbConnection的角度来看这个问题的时候，它又不知道这个参数要如何来给了，而且像Dapper里的参数，涉及到集合类型会存在IN和NOT IN以及批量操作的问题，比普通的字符串替换还要稍微复杂一点。如果我们只考虑最简单的情况，它还是可以尝试一番的： 12345678910111213141516171819202122232425262728private static void SetDbParameter(this IDbCommand command, object param = null)&#123; if (param == null) return; if (param is IDictionary&lt;string, object&gt;) &#123; //使用字典作为参数 foreach (var arg in param as IDictionary&lt;string, object&gt;) &#123; var newParam = command.CreateParameter(); newParam.ParameterName = $\"@&#123;arg.Key&#125;\"; newParam.Value = arg.Value; command.Parameters.Add(newParam); &#125; &#125; else &#123; //使用匿名对象作为参数 foreach (var property in param.GetType().GetProperties()) &#123; var propVal = property.GetValue(param); if (propVal == null) continue; var newParam = command.CreateParameter(); newParam.ParameterName = $\"@&#123;property.Name&#125;\"; newParam.Value = propVal; command.Parameters.Add(newParam); &#125; &#125;&#125; 相应地，为了能在Query&lt;T&gt;()和Execute()两个方法中使用参数，我们需要修改相关的方法： 12345678910111213141516171819public static int Execute(this IDbConnection connection, string sql, object param = null, IDbTransaction trans = null)&#123; var command = connection.CreateCommand(); command.CommandText = sql; command.CommandType = CommandType.Text; command.SetDbParameter(param); return command.ExecuteNonQuery();&#125;private static IDataReader CreateDataReader(this IDbConnection connection, string sql, object param = null)&#123; var command = connection.CreateCommand(); command.CommandText = sql; command.CommandType = CommandType.Text; command.SetDbParameter(param); return command.ExecuteReader();&#125; 现在，唯一的问题就剩下DbType和@啦，前者在不同的数据库中可能对应不同的类型，后者则要面临Oracle这朵奇葩的兼容性问题，相关内容可以参考在这篇博客：Dapper.Contrib在Oracle环境下引发ORA-00928异常问题的解决。到这一步，我们基本上可以实现类似Dapper的效果。当然，我并不是为了重复制造轮子，只是像从Dapper这样一个结果反推出相关的技术细节，从而可以串联起整个ASO.NET甚至是Entity Framework的知识体系，工作中解决类似的问题非常简单，直接通过NuGet安装Dapper即可，可如果你想深入了解某一个事物，最好的方法就是亲自去探寻其中的原理。现在基础设施越来越完善了，可有时候我们再找不回编程的那种快乐，大概是我们内心深处放弃了什么….. 考虑到，从微软的角度，它鼓励我们为每一家数据库去实现数据库驱动，所以，它定义了很多的抽象类。而从ORM的角度来考虑，它要抹平不同数据库的差异，Dapper的做法是给IDbConnection写扩展方法，而针对每个数据库的“方言”，实际上不管什么ORM都要去做这部分“脏活儿”，以前是分给数据库厂商去做，现在是交给ORM设计者去做，我觉得ADO.NET里似乎缺少了一部分东西，它需要提供一个IDbAdapterProvider的接口，返回IDbAdapter接口，这样就可以不用关心它是被如何创建出来的。你看，同样是设计接口，可微软和ServiceStack俨然是两种不同的思路，这其中的差异，足可窥见一斑矣！实际上，Entity Framework就是在以ADO.NET为基础发展而来的，在这个过程中，还是由厂商来实现对应的Provider。此时此刻，你悟到了我所说的“温故而知新”了嘛？ 本文小结本文实则由针对DataSet/DataTable的吐槽而引出，在这个过程中，我们重新温习了ADO.NET中DbConnection、DbCommand、DbDataReader、DbDataAdapter这些关键的组成部分，而为了解决DataTable在使用上的种种不变，我们想到了借鉴Dapper中的DapperRow来实现“动态查询”，由此引出了.NET中实现dynamic最重要的一个接口：IDynamicMetaObjectProvide，这使得我们可以在查询数据库的时候返回一个dynamic的集合。而为了更接近Dapper一点，我们基于扩展方法的形式为IDbConnection编写了Query&lt;T&gt;()和Execute()方法，在数据库读写层面上彻底终结了DataSet/DataTable的生命。最后，我们实现了一个简化版本的参数化查询，同样是借鉴Dapper的思路。这说明一件什么事情呢？当你在一个看似合理、结局固定的现状中无法摆脱的时候，“平躺”虽然能让你获得一丝喘息的机会，但与此同时，你永远失去了跳出这个层级去看待事物的机会，就像我以前吐槽同事天天用StringBuider拼接字符串一样，一味地吐槽是没有什么用的，重要的是你会选择怎么做，所以，后来我向大家推荐了Linquid，2021年已经来了，希望你不只是增长了年龄和皱纹，晚安！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"技巧","slug":"技巧","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E5%B7%A7/"},{"name":"Dapper","slug":"Dapper","permalink":"https://qinyuanpei.github.io/tags/Dapper/"},{"name":"ADO.NET","slug":"ADO-NET","permalink":"https://qinyuanpei.github.io/tags/ADO-NET/"},{"name":"Dynamic","slug":"Dynamic","permalink":"https://qinyuanpei.github.io/tags/Dynamic/"}]},{"title":"视频是不能P的系列：OpenCV人脸检测","date":"2020-12-25T22:49:47.000Z","path":"posts/2997581895/","text":"恍惚间，2020年已接近尾声，回首过去这一年，无论是疫情、失业还是“996”，均以某种特殊的方式铭刻着这一年的记忆。也许，是这个冬天的西安雾霾更少一点。所以，有时透过中午的一抹冬阳，居然意外地觉得春天的脚步渐渐近了，甚至连圣诞节这种“洋节日”都感到亲切而且期待，我想，这大概是我丧了一段时间的缘故吧！可不管怎样，人们对未来的生活时常有一种“迷之自信”，果然生还还是要继续下去的呀！趁着最近的时间比较充裕，我决定开启一个信息的系列：视频是不能P的。这是互联网上流传的一个老梗了，正所谓“视频是不能P的，所以是真的”。其实，在如今这个亦真亦假的世界里，哪里还有什么东西是不能PS的呢？借助人工智能“改头换面”越来越轻而易举，而这背后关于隐私和伦理的一连串问题随之而来，你越来越难以确认屏幕对面的那个是不是真实的人类。所以，这个系列会以OpenCV作为起点，去探索那些好玩、有趣的视频/图像处理思路，通过技术来证明视频是可以被PS的。而作为这个系列的第一篇，我们将从一个最简单的地方开始，它就是人脸检测。 第一个入门示例学习OpenCV最好的方式，就是从官方的示例开始，我个人非常推荐的两个教程是 OpenCV: Cascade Classifier 和 Python OpenCV Tutorial，其次是 浅墨大神 的【OpenCV】入门教程，不同的是， 浅墨大神 的教程主要是使用C++，对于像博主这样的“不学无术”的人，这简直无异于从入门到放弃，所以，建议大家结合自己的实际情况，选择适合自己的“难度”。好了，思绪拉回我们这里，在OpenCV中实现人脸检测，主要分为以下三个步骤，即，首先，定义联级分类器CascadeClassifier并载入指定的模型文件；其次，对待检测目标进行灰度化和直方图均衡化处理；最后，对灰度图调用detectMultiScale()方法进行检测。下面是一个简化过的入门示例，使用世界上最省心的Python语言进行编写： 12345678910111213141516171819import cv2# 步骤1: 定义联级分类器CascadeClassifier并载入指定的模型文件faceCascade = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_alt2.xml')# 步骤2: 对待检测目标进行灰度化和直方图均衡化处理target = cv2.imread('target.jpg')target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)target_gray = cv2.equalizeHist(target_gray)# 步骤3: 人脸检测faces = faceCascade.detectMultiScale(target_gray)for (x,y,w,h) in faces: cv2.rectangle(target, (x, y), (x + w, y + h), (0, 255, 0), 2)# 步骤4: 展示结果cv2.imshow('Face Detection', target)cv2.waitKey(0)cv2.destroyAllWindows() 正常情况下，你会得到下面的结果，这里选取的素材是经典日剧《半泽直树》： OpenCV人脸检测效果展示 怎么样？是不是被OpenCV的强大给震惊到了？下面我们针对每个步骤做更详细的说明： 第1行引入OpenCV，需要我们安装OpenCV的Python版本。 第4行实例化级联分类器CascadeClassifier，关于这个级联分类器，它是OpenCV下做目标检测的模块，内置Haar、HOG和LBP三类特性算法，而所谓“级联”，则是指它通过多个强分类器串联实现最终分类的思路。在初始化级联分类器的时候，需要载入指定的模型文件，这些模型文件是官方提前训练好的，可以从Github上进行下载，不同的模型文件对应不同的功能，这里使用的haarcascade_frontalface_alt2.xml主要针对面部检测，而像haarcascade_eye_tree_eyeglasses.xml则可以对眼睛进行检测。除此之外，我们还通过训练获得自己的模型文件，当然，这一切都是后话啦！ 第7~9行，我们载入了一张图片素材，并对其进行了灰度化和直方图均衡化处理。这里需要关注的三个函数是：imread、cvtColor 和 equalizeHist，它们的作用分别是读取图片、转换颜色和直方图均衡化处理。其中，对人脸检测而言，灰度图是必要的条件，而直方图均衡化则是可选的一个过程。 第12~14行，通过 detectMultiScale 方法我们就可以对待检测目标进行检测，关于它的参数，常用的有scaleFactor、minNeighbors、minSize、maxSize，它可以对人脸检测做进一步的细节上控制，对于我们而言，我们更关心检测的结果，这里我们将检测到的人脸区域以矩形的方式绘制出来。 第17~19行，主要是为了方面大家观察结果，实际使用中可能会输出为文件或者实时渲染，这里需要关注的重点函数是：imshow，顾名思义，它可以让图片展示在窗口中，类似我们这个示例中的效果。 柴犬界的“网红”曾经，有“好事者”分析过微信和QQ的年度表情，表情包文化流行的背后，实际上表达方式多样化的一种体现，例如：“笑哭”这一符号，固然有哭笑不得的含义在里面，可又何尝不是二十多岁人生总是边哭边笑的真实写照呢？而“捂脸”这一符号在我看来更多的是一种无可奈何，甚至有一种自我嘲讽的意味在里面。至于“呲牙”，朴实无华的微笑背后，大抵是看惯了庭前花开花落，可以“不以物喜，不以己悲”地笑对人生吧！其实，在这许许多多地表情里，我最喜欢的是微博里的“Doge”，这个眉清目秀的“狗头”能表达出各种丰富的含义，相比之下，微信里的“Doge”就有一点拙劣的模仿的意味了，俗话说“狗头保命”，在一个互联网信仰缺失的时代，用这样一种表情作为人类的保护色，又是不是一种反讽呢？而大家都知道，这个“Doge”表情，实际上是源于一个叫做Homestar Runner的网上动画系列，其原型则来源于一只名为Kabosu的柴犬，由于它融合了萌宠和故意搞笑两大特点，因此在网络上迅速走红，并由此衍生出一系列二次创作。 微信年度表情 QQ年度表情 现在，让我们唤醒身体里的中二灵魂，通过OpenCV让这个柴犬界的网红出现在我们面前。这里的思路是，在检测到人脸后，在人脸区域绘制一个“狗头”表情，为此，我们需要定义一个copyTo()函数，它可以将一张小图(MaskImage)绘制到大图(SrcImage)的指定位置，我们一起来看它的具体实现： 12345678910111213141516171819202122def copyTo(srcImage, maskImage, x, y, w, h): # 按照区域大小对maskImage进行缩放 img_h, img_w, _ = maskImage.shape img_scale = h / img_h new_w = int(img_w * img_scale) new_h = int(img_h * img_scale) img_resize = cv2.resize(maskImage ,(new_w ,new_h)) # “粘贴”小图到大图的指定位置 if (srcImage.shape[2] != maskImage.shape[2]): y1, y2 = y, y + img_resize.shape[0] x1, x2 = x, x + img_resize.shape[1] alpha_s = img_resize[:, :, 3] / 255.0 alpha_l = 1.0 - alpha_s for c in range(0, 3): srcImage[y1:y2, x1:x2, c] = ( alpha_s * img_resize[:, :, c] + alpha_l * srcImage[y1:y2, x1:x2, c] ) else: srcImage[y:y + img_resize.shape[0], x:x + img_resize.shape[1]] = img_resize return srcImage 在这里，我们首先要关注这样一件事情，即OpenCV默认使用的是由R、G、B组成的三通道，可对于像PNG这种格式的图片，它会含有一个Alpha通道。这样，当我们尝试把一张含Alpha通道的小图，“粘贴”到只有R、G、B三个通道的大图上时，就会出现通道数对不上的问题，所以，这个函数实际上对这种情况做了特殊处理。其次，每一个OpenCV中的图片，即Mat，其shape属性是一个由三个元素组成的元组，依次为图片高度、图片宽度和图片通道数。“黏贴”的过程实际上是修改对应位置处的像素信息。好了，现在，我们来修改一下第一版的代码： 12345678910111213141516171819# 步骤1: 定义联级分类器CascadeClassifier并载入指定的模型文件faceCascade = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_alt2.xml')# cv2.IMREAD_UNCHANGED表示保留Alpha通道信息doge = cv2.imread('doge-4.png', cv2.IMREAD_UNCHANGED) # 步骤2: 对待检测目标进行灰度化和直方图均衡化处理target = cv2.imread('target.jpg')target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY)target_gray = cv2.equalizeHist(target_gray)# 步骤3: 人脸检测faces = faceCascade.detectMultiScale(target_gray)for (x,y,w,h) in faces: target = copyTo(target, doge, x, y, w, h) # 粘贴“狗头”表情至每一个面部区域# 步骤4: 展示结果cv2.imshow('Face Detection', target)cv2.waitKey(0)cv2.destroyAllWindows() 此时，我们就可以得到下面的结果： 全员Doge! 其实，我本人更喜欢这张，一张充满精神污染意味的图片： 来自神烦狗的精神污染 视频级PS入门OK，相信到这里为止，各位读者朋友，都已经顺着博主的思路实现了图片级别的“PS”，既然我们这个系列叫做视频是不能P的，那么大家要问了，视频到底能不能P呢？答案显然是可以，不然博主写这个系列就不是“人脸检测”而是“人肉打脸”啦！下面，我们来继续对今天的这个例子做一点升级。考虑在OpenCV中，VideoCapture可以通过摄像头捕捉视频画面，所以，我们只需要把这个“狗头”绘制到每一帧画面上，就可以实现视频级别的PS啦！ 1234567891011121314151617181920212223242526272829# 步骤1: 定义联级分类器CascadeClassifier并载入指定的模型文件faceCascade = cv2.CascadeClassifier('./haarcascades/haarcascade_frontalface_alt2.xml')doge = cv2.imread('doge-4.png', cv2.IMREAD_UNCHANGED)cap = cv2.VideoCapture(0) #笔记本自带摄像头while (True): ret, frame = cap.read() if (ret == False): break # 步骤2: 对待检测目标进行灰度化和直方图均衡化处理 # 读取视频中每一帧 target = frame target_gray = cv2.cvtColor(target, cv2.COLOR_BGR2GRAY) target_gray = cv2.equalizeHist(target_gray) # 步骤3: 人脸检测 faces = faceCascade.detectMultiScale(target_gray) for (x,y,w,h) in faces: target = copyTo(target, doge, x, y, w, h) # 步骤4: 展示结果 cv2.imshow('Face Detection', target) # 按Q退出 if cv2.waitKey(1) &amp; 0xFF == ord('q'): breakcap.release() cv2.destroyAllWindows() 一起来看看实现的效果吧！可能当你看完这篇博客的时候，你会觉得我写这玩意儿到底有什么用？不好意思，这玩意儿还真有用！它解决了像博主这样腼腆、不敢在公开场合抛头露面的人的困惑。暴走大事件里“王尼玛”一直戴着头罩，所以，很多人都好奇他本人到底长什么样子，如果当时能考虑这个思路的话，是不是可以不用一直戴着头罩。同样地，还有在浪客剑心真人版里饰演志志雄真实的藤原龙也，全身上下缠满绷带的造型其实对演员来说是非常不友好的，如果当时能考虑这个思路的话，是不是演员可以不用受那么大的罪。如果说这些都有些遥远的话，那么，至少在采访后期希望保护受访者隐私的场景下，这个思路是完全可行的，就像大家看到的它可以完全的遮挡住我的脸，而类似的打马赛克等等技术，本质上还是对图像进行处理，甚至美颜相机里的各种特效，底层都离不开OpenCV里的这些算法。怎么样？现在有没有觉得博主其实是一个非常有趣的人，哈哈! 视频级别的“PS” 本文小结这篇博客主要分享了OpenCV在人脸检测方面的简单应用，OpenCV中的CascadeClassifier整合Haar、HOG和LBP三类特性算法，通过预置的模型文件可以实现不同程度的目标检测功能，而在人脸检测的基础上，我们可以通过训练来实现简单的人脸识别，正如今年爆发的新冠疫情让人脸识别出现新的挑战一样，虽然人脸识别的场景正在变得越来越复杂，可作为一个世界上最流行的计算机视觉库，OpenCV中的各种模块、算法还是一如既往的经典。结合imread()、resize()、cvtColor()等等的方法，我们可以将“狗头”表情贴到图片或者视频中的人脸区域，而这个思路可以为人脸遮挡相关的场景做一点探索。 在一个流行美颜的时代，人们对于别人甚至自己的期望在无限拔高，像博主本人一直不怎么喜欢拍照，有时候我们埋怨别人没有把我们拍得好看一点，可那究竟是你眼中的自己还是别人眼中的自己呢？正如相亲的时候，人们总喜欢把最好的、美化过的一面展示给别人，因为只有这样才能让别人对你产生兴趣，可往往现实的落差会让这种来得快的兴趣消失得更快。所以，我想说，虽然在技术面前万物似乎皆可“PS”，可对于我们自己而言，你是否了解真正的自己呢？关于我博客的写作风格，我一直不确定是要用偏严谨还是偏活泼的方式来表达，因为眼看着被后浪们一点点超越，这实在是种难以言说的感觉，欢迎大家在评论区留下你对博客内容或者观点的想法，祝大家周末愉快，一个人一样要活得浪漫！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"OpenCV","slug":"OpenCV","permalink":"https://qinyuanpei.github.io/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"图像处理","slug":"图像处理","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"},{"name":"人脸检测","slug":"人脸检测","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/"}]},{"title":"作为技术宅的我，是这样追鬼滅の刃的","date":"2020-12-15T22:49:47.000Z","path":"posts/3602353334/","text":"有人说，“男人至死都是少年”，而这句听起来有一点中二的话，其实是出自一部同样有一点中二的动漫——银魂。我个人的理解是，知世故而不世故。也许，年轻时那些天马行空的想法，就像堂吉诃德大战风车一样荒诞，可依然愿意去怀着这样的梦想去生活。正如罗曼罗兰所言，“世上只有一种英雄主义，就是在认清生活真相之后依然热爱生活”。所以，继《浪客剑心》之后，我再次被一部叫做《鬼灭之刃》的动漫吸引，毕竟男人的快乐往往就是这么朴实无华且枯燥。一个快三十岁的人，如果还能被一部热血少年番吸引，大概可以说明，他身体里的中二少年连同中二少年魂还活着。最早的印象来自朋友圈里的一位二次元“少年”，他和自己儿子站一起，有种浑然天成的协调感，整个人是非常年轻的感觉。所以，大概，男人至死都是少年。 漫画的抓取 鬼滅の刃的漫画早已更完，令我不舍昼夜去追的，实际上是动画版的鬼滅の刃。虽然B站上提供中配版本，可一周更新两集的节奏，还是让我追得有一点焦灼(PS：我没有大会员呢)，甚至熬着夜提前“刷”了无限列车(PS：见文章末尾小程序码)。其实，鬼滅の刃前期并没有特别吸引人的地方，直到那田蜘蛛山那一话开始渐入佳境，鬼杀队和鬼两个阵营所构成的人物群像开始一点一点的展开。它的表达方式有点接近刺客信条，即反派都是在死亡一刹那间有了自我表达的机会，而玩家/观众都可以了解反派的过去。由于鬼是由人转变而来，所以，在热血和厮杀之外，同样有了一点关乎人性的思考。作为一名“自封”的技术宅，我必须要在追番的时候做点什么，从哪里开始好呢？既然漫画版早已更新完毕，我们要不先抓取漫画下来提前过过瘾？ OK，这里博主找了一个动漫网站，它上面有完整的鬼滅の刃漫画。我意识到从网上抓取漫画的行为是不对的，可这家网站提供的漫画明显是通过扫描获得的，因为正常的漫画都是通过购买杂志的方式获得的。所以，如果经济条件允许的情况下，还是希望大家可以支持正版，这里博主主要还是为了研究技术(逃，无意对这些资源做二次加工或者以任何方式盈利，所以，请大家不要向博主索取任何资源，我对自己的定位永远是一名软件工程师，谁让我无法成为尤小右这样的“美妆”博主呢？这一点希望大家可以理解哈！ 鬼滅の刃作品页面 鬼滅の刃章节页面 简单分析下动漫网站结构，可以发现，它主要有两种界面，即作品页面和章节页面。作品页面里面会显示所有的章节，而每个章节里会显示所有的图片。所以，我们的思路是，首先，通过作品页面获取所有章节的链接。其次，针对每一个章节，获取总页数后逐页下载图片即可。注意到这个网站有部分内容是通过JavaScript动态生成的，所以，requests针对这种情况会有点力不从心。幸好，我们还有Selenium这个神器可以使用，我们一起来看这部分内容如何实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798import requestsfrom bs4 import BeautifulSoupimport fake_useragentimport jsonimport urllibfrom selenium import webdriverfrom selenium.webdriver.support.ui import Selectfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECimport os, timeimport threadingimport threadpool class DemonSlayer: def __init__(self, baseUrl): self.baseUrl = baseUrl self.session = requests.session() self.headers = &#123; 'User-Agent': fake_useragent.UserAgent(verify_ssl=False).random &#125; # 使用无头浏览器 fireFoxOptions = webdriver.FirefoxOptions() fireFoxOptions.set_headless() self.driver = webdriver.Firefox(firefox_options=fireFoxOptions) # 获取所有章节信息 def getAllChapters(self, opusUrl): chapters = &#123;&#125; response = self.session.get(opusUrl, headers=self.headers) response.encoding = 'utf-8' response.raise_for_status() soup = BeautifulSoup(response.content) soup = soup.find(name='div', attrs=&#123;'class','cy_plist'&#125;) if (soup != None): for li in soup.ul.children: chapters[li.a.text] = self.baseUrl + li.a['href'] return chapters # 获取指定章节信息 def getChapter(self, url): page = 1 maxPage = self.getPageOfChapter(url) images = [] while page &lt;= maxPage: reqUrl = url + '?p=&#123;page&#125;'.format(page=page) self.driver.get(reqUrl) wait = WebDriverWait(self.driver, 10) # 等待漫画图片加载完成 wait.until(EC.presence_of_element_located((By.ID, \"qTcms_pic\"))) html = self.driver.page_source imgSrc = BeautifulSoup(html).find('img')['src'] # 从网页中提取的图片地址需要做一次解码 realSrc = urllib.parse.unquote(imgSrc.split('?')[1].split('&amp;')[0].split('=')[1]) images.append(realSrc) page += 1 return images # 获取指定章节页数 def getPageOfChapter(self, url): self.driver.get(url) wait = WebDriverWait(self.driver, 10) # 等待页数加载完成 wait.until(EC.presence_of_element_located((By.ID, \"k_pageSelect\"))) html = self.driver.page_source opts = list(BeautifulSoup(html).find('select').children) return int(opts[-1]['value']) # 下载漫画图片 def getImage(self, chapterPath, index, url): imagePath = os.path.join(chapterPath, str(index) + '.jpg') with open(imagePath, 'wb') as fp: response = self.session.get(url) response.raise_for_status() fp.write(response.content) # 公共入口 def run(self, url): chapters = self.getAllChapters(url) for chapter, url in chapters.items(): images = spider.getChapter(url) # 为每一个章节建立文件夹 chapterPath = './download/&#123;chapter&#125;/'.format(chapter=chapter) if (not os.path.exists(chapterPath)): os.mkdir(chapterPath) # 使用多线程下载图片 args = [] for index, url in enumerate(images): args.append((None,&#123;'chapterPath':chapterPath, 'url':url, 'index':index&#125;)) pool = threadpool.ThreadPool(max(10, len(images))) requests = threadpool.makeRequests(self.getImage, args) [pool.putRequest(req) for req in requests] pool.wait()if __name__ == '__main__': spider = DemonSlayer('http://www.7edm.com/') spider.run('http://www.7edm.com/rexue/guimiezhiren/') 在这里，需要注意的Firefox驱动，即GeckoDriver需要提前安装好。同时，确保Firefox主程序和驱动程序所在的目录均已配置到环境变量Path中。在有的资料中提到，GeckoDriver需要和Firefox主程序在同一个目录底下，不过经过博主的验证，需要放在Python主程序的根目录底下。这个驱动程序可以从这里下载：https://github.com/mozilla/geckodriver/releases/。当然，如果你更喜欢使用Chrome，只需要安装Chrome的驱动即可，完全遵从个人意愿即可。在运行这个脚本后，我们就可以获得完整的鬼滅の刃漫画： 鬼灭之刃204话 在Kindle上“追”番好了，到现在为止，我们实现了本文的第一个小目标，即漫画的抓取。那么，在抓取到漫画以后，我们可以做什么呢？可能会有读者朋友忍不住吐槽，“废话，漫画除了看还能干什么”。话虽如此，可这样一张张图片显然不能让我们方便地看漫画啊！早就听说在Kindle上可以看漫画，可一直没有真正尝试过，可能是因为我还不够中二吧！所以，接下来，我们来考虑将这些图片制作成电子书。Kindle本身支持像mobi、docx/doc、pdf等等这样的格式，这里我们选择一种最简单的方式，利用PyMuPDF这个库来生成PDF文件，一起来看具体的代码实现： 12345678910111213141516def createPdf(self, chapterPath): doc = fitz.open() pdfPath = './ebook/' + os.path.basename(chapterPath) + '.pdf' for image in sorted(os.listdir(chapterPath)): filePath = os.path.join(chapterPath, image) # 为每一张图片创建一个单独的PDF imgdoc = fitz.open(filePath) pdfbytes = imgdoc.convertToPDF() imgpdf = fitz.open(\"pdf\", pdfbytes) # 插入当前页 doc.insertPDF(imgpdf) # 将当前页插 # 保存PDF doc.save(pdfPath) 经常使用Kindle的朋友，一定对它的邮箱传书功能非常熟悉，这意味着我们此基础上，将生成的PDF文件直接推送到Kindle上，而在Python中发送邮件则是非常简单的，这一点我们不再赘述，那到底能不能实现我们这个想法呢？显然可以，我们一起来看看效果： 由PyMuPDF生成的“漫画书” 我们知道Kindle对PDF的支持是有点差的，主要体现在它不支持重排，在我们这个例子中，我们可以发现图片是横屏显示的，或许是因为我的Kindle屏幕太小，或许是因为我没有一个Pad，或许是因为图片尺寸无法适配，总之，它给人的体验是有点不舒服。博主注意到，Kindle官方提供了一个漫画书制作软件Kindle Comic Creator，它可以生成mobi格式的电子书。作为对比，我们来看一下它在Kindle上的显示效果： 由Kindle Comic Creator生成的“漫画书” 果然还是Kindle自家的格式更好一点，有同样需求的小伙伴们，不妨试一试这个软件！现在，我们终于可以在Kindle上“刷”漫画了，快乐肥宅水，安排！ 让漫画“动”起来一旦看过动画以后，再去看漫画，总觉得没那味儿，果然，“没声音再好的戏都出不来”，除了想念片头OP以外，更想念声优们绘声绘色的配音。有人说，博主你可以戴上耳机，放着片头OP，刷着漫画啊！哎，你可真是小机灵鬼！可作为一名技术宅，我们当然要追求手工耿的无用之美，不就是想看有声音有画面的视频吗？安排！所以，下面我们来通过这些图片生成视频，这里主要用到opencv-python和MoviePy两个库，前者可以通过OpenCV合成视频，而后者则可以对视频进行剪辑，例如加入片头、片尾、背景音乐等等。 1234567891011121314151617181920212223242526272829303132333435363738394041424344def createVideo(self, chapterPath): # OpenCV创建视频 videoFps = 40 videoSize = (655, 948) videoPath = './video/' + os.path.basename(chapterPath) + '.avi' videoWriter = cv2.VideoWriter(videoPath, cv2.VideoWriter_fourcc('I', '4', '2', '0'), videoFps, videoSize ) for image in sorted(os.listdir(chapterPath)): # 读取每张图片，并重复写40帧 image_path = chapterPath + '/' + image bg = cv2.imread('bg.jpg') max_h, max_w, _ = bg.shape img = cv2.imdecode(np.fromfile(image_path ,dtype=np.uint8),-1) img_h, img_w, _ = img.shape scale = max_h / img_h new_w = int(img_w * scale) new_h = int(img_h * scale) img = cv2.resize(img ,(new_w ,new_h)) offsetX = int((max_w - new_w) / 2) offsetY = int((max_h - new_h) / 2) bg[offsetY:offsetY + img.shape[0], offsetX:offsetX + img.shape[1]] = img for i in range(0, videoFps): videoWriter.write(bg) videoWriter.release() # 为当前视频加入片头/尾 videoClip = VideoFileClip(videoPath) titleClip = VideoFileClip('./title.mp4') finalClip = concatenate_videoclips([ titleClip.subclip(0, 12), videoClip, titleClip.subclip(70, 72), titleClip.subclip(85, 89), ]) # 为当前视频增加BGM audioClip = AudioFileClip('BGM.mp3').subclip(0, finalClip.duration) finalClip.audio = audioClip finalClip.write_videofile('output.avi', codec='libvpx') 在使用OpenCV合成视频这一步，和大多数第一次接触OpenCV的人一样，博主在这里遇到了很多的问题，例如，最典型的问题有：OpenCV合成的视频无法打开、OpenCV无法使用中文路径、OpenCV合成的视频长度较短等等。所以，在这里我简单做一下说明，首先，检查下视频画面的宽/高是否与图片的宽/高一致。其次，选择合适的编码器，在使用OpenCV保存视频的时候，需要综合考虑FOURCC和视频格式两个因素，前提是当前系统已经安装了对应的编码器，在Windows下推荐大家使用DIVX。最后，关于中文路径，大部分的解决方案都是引入NumPy，代码片段如下： 1234# 读取cv_img = cv2.imdecode(np.fromfile(file_path, dtype=np.uint8), -1)# 写入cv2.imencode('.jpg', cv_img)[1].tofile(file_path) 经过博客的验证，这个方案的确可以解决，不过同样有缺点，imdecode()方法读取的是RGB，而OpenCV需要的则是BGR，需要做一次转换，而转换则意味着会损失图片信息。所以，如果在意生成的视频质量的话，最好还是放在英文的路径下面。 (function(){var player = new DPlayer({\"container\":document.getElementById(\"dplayer0\"),\"theme\":\"#FADFA3\",\"loop\":true,\"video\":{\"url\":\"https://blog.yuanpei.me/assets/videos/output.mp4\"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})() 好了，现在来看看效果，当片头OP响起的时候，有没有觉得，那种熟悉感觉的又回来了(PS：此处可与飞驰人生梦幻联动)，虽然没有配音，还是有一点视频的样子的。我经常在B站看到那种，黑色背景 + 白色文字的视频，虽然没有特别复杂的转场动画，可搭配上小爱同学或者Siri同学的声音后，居然感觉还不错。知乎上同样提供了文章转视频的功能，所以，我在想这是不是可以作为一个思路，作为一个努力寻找流量方向的技术博客，我好累啊(逃…… 这个思路，其实还可以用来制作表情包，作为一部拥有大量“名场面”的动漫作品，它为博主带来了不少的“燃点”和“笑点”，下面例举一二供大家欣赏： 世界名画 安塞腰鼓 对于静态表情包，通常只需要用到PIL库就可以完成，下面是富冈义勇迫害时间(逃： 12345678image = Image.open('鬼灭之刃-09.jpg')width, height = image.sizetextFont = ImageFont.truetype('Deng.ttf', 18)imageDraw = ImageDraw.Draw(image)textPos = (width * 0.34, height * 0.8)text = '我感觉我没有被讨厌'imageDraw.text(textPos, text, fill='#fff', font=textFont, align='left')image.save('富岗义勇表情包.jpg','jpeg') 如此，我们就可以得到下面的名场面： 我感觉我没有被讨厌 冰柱表示不想和你说话 而对于动态表情包，我们可以考虑使用imageio和MoviePy，它们都可以从图片或者视频来生成GIF，一起来看下面的例子： 12345678910111213def createGif(self, framesPath, gifPath, duration=0.5): # 读取图片 frames = [] for image_name in sorted(os.listdir(framesPath)): image_path = os.path.join(framesPath, image_name) frames.append(imageio.imread(image_path)) # 保存GIF imageio.mimsave(gifPath, frames, 'GIF', duration=duration)# 读取一组图片并生成GIFhandler = ImageHandler()handler.createGif('./frames', '登峰造极.gif') 这里唯一需要注意的就是，imageio依赖于Pillow: 集中一点，登峰造极 如果使用MoviePy来生成GIF，则可以通过VideoFileClip或者ImageSequenceClip来分别从视频和图片创建GIF。同样，这里有一个简单的例子： 12345678910# 从一组图片并生成GIF和视频fps = 0.25sequence = ImageSequenceClip('./frames', fps)sequence.write_gif('登峰造极.gif')sequence.write_videofile('登峰造极.avi', codec='libvpx')# 从视频中截取指定片段生成GIFvideoClip = VideoFileClip('input.mp4')videoClip = videoClip.subclip(33, 45)videoClip.write_gif('霹雳一闪.gif') 在这里，我选取的是，我个人非常喜欢的角色——我妻善逸的名场面“霹雳一闪”： 霹雳一闪 至此，我们“绞尽脑汁”、“千方百计”、“搜肠刮肚”地想到了各种“刷”鬼滅の刃的方法，总算为这份中二信仰充了值，大家还有什么好的点子吗？欢迎大家在评论区留言、点赞、收藏、一键三连，我仿佛嗅到了Bilibili的味道(逃…… 本文小结坦白来讲，这篇博客的确有蹭热度的嫌疑，不过以鬼灭之刃在日本妇孺皆知的火热程度，足以令人们在这颇感失落的疫情背景下为之一振，甚至于连日本首相菅义伟在国会质询时，都引用了“全集中呼吸”这一经典台词。“纵有疾风起，人生不言弃”，热血少年漫告诉我们，在面对一个又一个的挫折的时候，不要沉溺于昨天的回忆，去勇敢地接受现实，直面惨淡的人生，这又何尝不是我们面对生活的态度呢？不管是旷日持久的疫情，还是似曾相识的失业，人生的道路上还有数不尽的“魑魅魍魉”呢！希望你活得像炭治郎一样乐观善良，像我妻善逸一样勇敢坚毅，像伊之助一样“猪”突猛进。如果这篇博客里所介绍的“追”动漫的方式，能让大家感到快乐和有趣的话，欢迎大家在评论区留言、点赞、收藏、一键三连。以上，这就是我，作为一个技术宅，在“追”动漫方面所做出的努力。少年，想加入鬼杀队吗？","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"鬼滅の刃","slug":"鬼滅の刃","permalink":"https://qinyuanpei.github.io/tags/%E9%AC%BC%E6%BB%85%E3%81%AE%E5%88%83/"},{"name":"Kindle","slug":"Kindle","permalink":"https://qinyuanpei.github.io/tags/Kindle/"},{"name":"动漫","slug":"动漫","permalink":"https://qinyuanpei.github.io/tags/%E5%8A%A8%E6%BC%AB/"},{"name":"OpenCV","slug":"OpenCV","permalink":"https://qinyuanpei.github.io/tags/OpenCV/"},{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"}]},{"title":"使用Python抽取《半泽直树》原著小说人物关系","date":"2020-12-08T22:49:47.000Z","path":"posts/1427872047/","text":"此时此刻，2020年的最后一个月，不管过去这一年给我们留下了怎样的记忆，时间终究自顾自地往前走，留给我们的怀念已时日无多。如果要说2020年的年度日剧，我想《半泽直树》实至名归，这部在时隔七年后上映的续集，豆瓣评分高达9.4分，一度超越2013年第一部的9.3分，是当之无愧的现象级电视剧，期间甚至因为疫情原因而推迟播出，这不能不感谢为此付出辛勤努力的演职人员们。身为一个“打工人”，主角半泽直树那种百折不挠、恩怨分明的性格，难免会引起你我这种“社畜”们的共鸣，即使做不到“以牙还牙，加倍奉还”，至少可以活得像一个活生生的人。电视剧或许大家都看过了，那么，电视剧相对于原著小说有哪些改动呢？今天，就让我们使用Python来抽取半泽直树原著小说中的人物关系吧！ 准备工作在开始今天的博客内容前，我们有一点准备工作要完成。考虑到小说人物关系抽取，属于自然语言处理(NLP)领域的内容，所以，除了准备好Python环境以外，我们需要提前准备相关的中文语料，在这里主要有：半泽直树原著小说、 半泽直树人名词典、半泽直树别名词典、中文分词停用词表。除此之外，我们需要安装结巴分词、PyECharts两个第三方库(注，可以通过pip直接安装)，以及用于展示人物关系的软件Gephi(注，这个软件依赖Java环境)。所以，你基本可以想到，我们会使用结巴分词对小说文本进行分词处理，而半泽直树人名列表则作为用户词典供结巴分词使用，经过一系列处理后，我们最终通过Gephi和PyECharts对结果进行可视化，通过分析人物间的关系，结合我们对电视剧剧情的掌握情况，我们就可以对本文所采用方法的效果进行评估，也许你认为两个人毫无联系，可最终他们以某种特殊的形式建立了联系，这就是我们要做这件事情的意义所在。本项目已托管在 Github上，供大家自由查阅。 原理说明这篇博客主要参考了 Python 基于共现提取《釜山行》人物关系 这个课程，该项目已在 Github 上开源，可以参考：https://github.com/Forec/text-cooccurrence。这篇文章中提到了一种称之为“共现网络”的方法，它本质上是一种基于统计的信息提取方法。其基本原理是，当我们在阅读书籍或者观看影视作品时，在同一时间段内同时出现的人物，通常都会存在某种联系。所以，如果我们将小说中的每个人物都看作一个节点，将人物间的关系都看作一条连线，最终我们将会得到一个图(指数据结构中的Graph)。因为Gephi和PyECharts以及NetworkX都提供了针对Graph的可视化功能，因此，我们可以使用这种方法，对《半泽直树》原著小说中的人物关系进行抽取。当然，这种方法本身会存在一点局限性，这些我们会放在总结思考这部分来进行说明，而我们之所以需要准备人名词典，主要还是为了排除单纯的分词产生的干扰词汇的影响；准备别名词典，则是考虑到同一个人物，在不同的语境下会有不同的称谓。 过程实现这里，我们定义一个RelationExtractor类来实现小说人物关系的抽取。其中，extract()方法用于抽取制定小说文本中的人物关系，exportGephi()方法用于输出Gephi格式的节点和边信息， exportECharts()方法则可以使用ECharts对人物关系进行渲染和输出： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131import os, sysimport jieba, codecs, mathimport jieba.posseg as psegfrom pyecharts import options as optsfrom pyecharts.charts import Graphclass RelationExtractor: def __init__(self, fpStopWords, fpNameDicts, fpAliasNames): # 人名词典 self.name_dicts = [line.strip().split(' ')[0] for line in open(fpNameDicts,'rt',encoding='utf-8').readlines()] # 停止词表 self.stop_words = [line.strip() for line in open(fpStopWords,'rt',encoding='utf-8').readlines()] # 别名词典 self.alias_names = dict([(line.split(',')[0].strip(), line.split(',')[1].strip()) for line in open(fpAliasNames,'rt',encoding='utf-8').readlines()]) # 加载词典 jieba.load_userdict(fpNameDicts) # 提取指定小说文本中的人物关系 def extract(self, fpText): # 人物关系 relationships = &#123;&#125; # 人名频次 name_frequency = &#123;&#125; # 每个段落中的人名 name_in_paragraph = [] # 读取小说文本，统计人名出现的频次，以及每个段落中出现的人名 with codecs.open(fpText, \"r\", \"utf8\") as f: for line in f.readlines(): poss = pseg.cut(line) name_in_paragraph.append([]) for w in poss: if w.flag != \"nr\" or len(w.word) &lt; 2: continue if (w.word in self.stop_words): continue if (not w.word in self.name_dicts and w.word != '半泽'): continue # 规范化人物姓名，例：半泽-&gt;半泽直树，大和田-&gt;大和田晓 word = w.word if (self.alias_names.get(word)): word = self.alias_names.get(word) name_in_paragraph[-1].append(word) if name_frequency.get(word) is None: name_frequency[word] = 0 relationships[word] = &#123;&#125; name_frequency[word] += 1 # 基于共现组织人物关系 for paragraph in name_in_paragraph: for name1 in paragraph: for name2 in paragraph: if name1 == name2: continue if relationships[name1].get(name2) is None: relationships[name1][name2] = 1 else: relationships[name1][name2] += 1 # 返回节点和边 return name_frequency, relationships # 输出Gephi格式的节点和边信息 def exportGephi(self, nodes, relationships): # 输出节点 with codecs.open(\"./output/node.txt\", \"w\", \"gbk\") as f: f.write(\"Id Label Weight\\r\\n\") for name, freq in nodes.items(): f.write(name + \" \" + name + \" \" + str(freq) + \"\\r\\n\") # 输出边 with codecs.open(\"./output/edge.txt\", \"w\", \"gbk\") as f: f.write(\"Source Target Weight\\r\\n\") for name, edges in relationships.items(): for v, w in edges.items(): if w &gt; 0: f.write(name + \" \" + v + \" \" + str(w) + \"\\r\\n\") # 使用ECharts对人物关系进行渲染 def exportECharts(self, nodes, relationships): # 总频次，用于数据的归一化 total = sum(list(map(lambda x:x[1], nodes.items()))) # 输出节点 nodes_data = [] for name, freq in nodes.items(): nodes_data.append(opts.GraphNode( name = name, symbol_size = round(freq / total * 100, 2), value = freq, )), # 输出边 links_data = [] for name, edges in relationships.items(): for v, w in edges.items(): if w &gt; 0: links_data.append(opts.GraphLink( source = v, target = w, value = w )) # 绘制Graph c = ( Graph() .add( \"\", nodes_data, links_data, gravity = 0.2, repulsion = 8000, is_draggable = True, symbol = 'circle', linestyle_opts = opts.LineStyleOpts( curve = 0.3, width = 0.5, opacity = 0.7 ), edge_label = opts.LabelOpts( is_show = False, position = \"middle\", formatter = \"&#123;b&#125;-&gt;&#123;c&#125;\" ), ) .set_global_opts( title_opts = opts.TitleOpts(title=\"半泽直树原著小说人物关系抽取\") ) .render(\"./docs/半泽直树原著小说人物关系抽取.html\") ) 你可以注意到，在input目录中，博主已经准备好了中文语料。因此，我们可以通过下面的代码来完成任务关系抽取： 1234567extractor = RelationExtractor('./input/停用词词典.txt', './input/人名词典.txt', './input/别名词典.txt')nodes, relationships = extractor.extract('./input/半泽直树.txt')extractor.exportGephi(nodes, relationships)extractor.exportECharts(nodes, relationships) 此时，我们可以分别在output目录和docs目录获得Gephi和ECharts相关的渲染结果。 结果展示这里，通过Gephi软件导入生成的节点和边信息，这两个信息默认情况下在output目录下。如果你熟悉这个软件的使用的话，你可以得到下面的结果： 使用Gephi渲染的小说人物关系图 作为对比，博主这里同时提供了使用ECharts渲染的小说人物关系图： 使用ECharts渲染的小说人物关系图 或者，可以直接访问博主托管在 Github Pages 上的 在线版本 。关于Gephi软件的使用，请参考： Gephi网络图极简教程。关于PyECharts的使用，请参考： PyECharts。 总结思考通过生成的人物关系图，可以发现下列规律： 大多数人物间的关系是正确的，譬如东田-&gt;浅野匡-&gt;半泽这条线，对应的是第一季西大阪钢铁5亿贷款的事件，而箕部-&gt;白井-&gt;半泽这条线，显然对应的第二季议员利用“炼金术”敛财的事件。 我们发现渡真利拥有仅次于半泽的“连线”数量，这符合他在剧中掌握大量信息来源、职场上八面玲珑的形象设定。相比之下，同样作为半泽好友的近藤和苅田，则没有这样强大的光环。 关于大和田，我们都知道他在第二季属于编剧强行“加戏”，一定程度上是在顶替内藤部长的作用，大和田实际上并未参与第二季的剧情，这一点从图中人物节点的联系和大小可以看出。 日本人似乎更喜欢使用姓氏，由于妻子要跟随丈夫的姓氏，剧中很多女性角色譬如半泽花、浅野利惠等似乎都不太好提取出来，除非是像白井、谷川、藤泽这些重要的剧情人物。 考虑到，小说中同一个人的称呼通常会有很多种，与之相关联的领域被称为“中文指代消解问题”，使用姓氏作为关键字会造成“女性角色”的缺失，而这种基于“共现”的理论，无法解决A在B交谈的过程中提到C的问题，此时，C和A、C和B可能并没有直接的联系，譬如图中的垣内，理论上与西大阪钢铁5亿贷款事件并无直接联系，因为剧情中参与融资的主要是新人中西，更不用说老员工角田居然“孤零零”的一个人，而主流的命名实体识别的理论基本都针对三元组，所以，在这里要心疼下角田这位老人。 在目前的人物关系抽取案例中，这种情况称为“无效的人名实体共现句”，所以，更好的做法是，采用文本分类模型，结合依存句法去识别实体间的关系，比如同事关系、朋友关系或者亲属关系等等，它有一个非常专业的名词，称为命名实体识别(NER)，而这会让我们的这张图变得更加丰富。在这个方向上，我个人推荐使用哈工大的语言技术平台(LTP)作为进一步改进，因为它可以更好地识别人名。好了，以上就是这篇博客的全部内容啦，欢迎大家在博客下面留言，喜欢我的博客话，请一键三连，点赞收藏，谢谢大家！","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"NLP","slug":"NLP","permalink":"https://qinyuanpei.github.io/tags/NLP/"},{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"半泽直树","slug":"半泽直树","permalink":"https://qinyuanpei.github.io/tags/%E5%8D%8A%E6%B3%BD%E7%9B%B4%E6%A0%91/"},{"name":"Gephi","slug":"Gephi","permalink":"https://qinyuanpei.github.io/tags/Gephi/"},{"name":"ECharts","slug":"ECharts","permalink":"https://qinyuanpei.github.io/tags/ECharts/"}]},{"title":"厉害了！打工人用Python分析西安市职位信息","date":"2020-12-05T12:49:47.000Z","path":"posts/2147036181/","text":"在上一篇博客中，我和大家分享了整个11月份找工作的心路历程，而在找工作的过程中，博主发现西安大小周、单休这种变相“996”的公司越来越多，感慨整个行业越来越“内卷”的同时，不免会对未来的人生有一点迷茫，因为深圳已经开始试运行“996”了，如果有一天“996”被合法化并成为一种常态，那么，我们又该如何去面对“人会一天天衰老，总有一天肝不动”的客观规律呢？我注意到Boss直聘移动端会展示某个公司的作息时间，所以，我有了抓取西安市职位和公司信息并对其进行数据分析的想法，我想知道，这到底是我一个人的感受呢？还是整个世界的确是这样子的呢？带着这样的想法，博主有了今天这篇博客。所以，在今天这篇博客里，博主会从Boss直聘、智联招聘以及前程无忧上抓取职位和公司信息，并使用MongoDB对数据进行持久化，最终通过pyecharts对结果进行可视化展示。虽然不大确定2021年会不会变得更好，可生活最迷人的地方就在于它的不确定性，正如数据分析唯一可以做的，就是帮助我们从变化的事物中挖掘出不变的规律一样。 爬虫编写其实，这种类似的数据分析，博主此前做过挺多的啦，譬如 基于Python实现的微信好友数据分析 以及 基于新浪微博的男女性择偶观数据分析(下) 这两篇博客。总体上来说，大部分学习Python的朋友都是从编写爬虫开始的，而在博主看来，数据分析是最终的目的，编写爬虫则是达到这一目的的手段。而从始至终，“爬”与“反爬”的较量从未停止过，Requests、BeautifulSoup、Selenium、Phantom等等的技术层出不穷。考虑到现在编写爬虫存在风险，所以，我不会在博客里透露过多的“爬虫”细节，换言之，我不想成为一个教别人写爬虫的人，因为这篇博客的标签是数据分析，关于爬虫的部分，我点到为止，不再过多地去探讨它的实现，希望大家理解。而之所以要从这三个招聘网站上抓取，主要还是为了增加样本的多样性，因为Boss直聘上西安市的职位居然只有3页，这实在是太让人费解了！ Boss直聘通过抓包，我们可以分析出Boss直聘的地址：https://www.zhipin.com/job_detail/?query={query}&amp;city={cityCode}&amp;industry=&amp;position=&amp;page={page}。其中，query为待查询关键词，cityCode为待查询城市代码，page为待查询的页数。可以注意到，industry和position两个参数没有维护，它们分别表示待查询的行业和待查询的职称。因为我们面向的是更一般的“打工人”，所以，这些都可以进行简化。对于cityCode这个参数，我们可以通过下面的接口获得：https://www.zhipin.com/wapi/zpCommon/data/city.json。这里，简单定义一个方法extractCity()来提取城市代码： 1234567891011121314151617181920212223def extractCity(self, cityName=None): if (os.path.exists('bossCity.json') and cityName != None): with open('bossCity.json', 'rt', encoding='utf-8') as fp: cityList = json.load(fp) for city in cityList: if (city['name'] == cityName): return city['code'] else: response = requests.get(self.cityUrl) response.raise_for_status() json_data = response.json(); if (json_data['code'] == 0 and json_data['zpData'] != None): cityList = [] for level in json_data['zpData']['cityList']: cityList.extend(self.unfoldLevel(level)) with open('bossCity.json', 'wt', encoding='utf-8') as fp: json.dump(cityList, fp) if (cityName != None): for city in cityList: if (city['name'] == cityName): return city['code'] else: return json_data['zpData']['locationCity']['code'] 接下来，我们可以编写searchJobs()方法来实现职位的检索： 1234567891011121314151617181920212223def searchJobs(self, cityName, query, page=1): cityCode = self.extractCity(cityName) if (cityCode != None): searchUrl = 'https://www.zhipin.com/job_detail/?query=&#123;query&#125;&amp;city=&#123;cityCode&#125;&amp;industry=&amp;position=&amp;page=&#123;page&#125;'.format(cityCode=cityCode, query=query, page=str(page)) html = self.makeRequest(searchUrl) soup = BeautifulSoup(html) details = soup.find_all(name='div',attrs=&#123;'class','job-primary'&#125;) jobItems = [] companyItems = [] for detail in details: jobItem = self.extractJob(detail) if (jobItem == None): continue else: jobItems.append(jobItem) companyItem = self.extractCompany(detail) if (companyItem == None): continue else: jobItem['company'] = companyItem['title'] jobItem['industry'] = companyItem['industry'] companyItems.append(companyItem) return (jobItems,companyItems) 这里我们会用到requests、fake_useragent以及BeautifulSoup，如果你经常编写爬虫的话，对它们应当不会感到陌生。唯一需要注意的有两点：第一，Boss直聘会封杀爬虫的IP，所以，可以考虑从互联网上抓取免费的代理IP作为代理池，每次发起请求时随机选取一个IP作为代理IP，这样可以有效地减少被封杀的可能。第二，Boss直聘的Cookie最多只能使用4次，超过4次后就需要重新获取Cookie。目前，我没有找到好的解决方案，有兴趣的朋友可以参考 2019年末逆向复习系列之Boss直聘Cookie加密字段zp_stoken逆向分析 这篇博客做一点逆向方面的研究，或者考虑使用PyExecJS载入前端JavaScript脚本来生成Cookie，因为逆向并不是我这篇博客的重点。在解决了这两个问题后，我们就可以提取出每一页的岗位和公司信息，而这些都可以通过BeautifulSoup解决，这里不再赘述，关于Boss直聘部分的源代码，请参考：https://github.com/qinyuanpei/job-analyse/blob/master/Spider/bossSpider.py。 智联招聘智联招聘相对于Boss直聘要简单一点，通过抓包分析，我们可以找到这样一个地址：https://fe-api.zhaopin.com/c/i/sou?at={at}&amp;_v={v}&amp;x-zp-page-request-id={x-zp-page-request-id}&amp;x-zp-client-id={v}&amp;MmEwMD={MmEwMD}。通过这个接口可以直接获得JSON格式的数据，可想要构造这几个参数出来，实在是有一点困难，因为它遇到和Boss直聘一样的问题，基本都需要一定的逆向功底，而如果尝试去解析DOM，你会发现它的前端使用了Vue.js，换句话说，这个网站是由前端完成渲染的，这意味着，如果我直接访问https://sou.zhaopin.com/?jl=854这个地址，是无法拿到可以解析的DOM结构的，这就多少会有一点尴尬。所以，实际上博主最后没有实现智联招聘的爬虫，因为在这上面投入太多的精力，实在有一点得不偿失。这里简单说一下思路，基本上我们需要以POST方式调用这个接口，然后在Body中写入下面的结构： 1&#123;\"pageSize\":\"30\",\"cityId\":854,\"workExperience\":\"-1\",\"companyType\":\"-1\",\"employmentType\":\"-1\",\"jobWelfareTag\":\"-1\",\"kt\":\"3\",\"at\":\"20673d42d62d48c38add329318fb9e2c\",\"rt\":\"84a950e77e054854b4d2f9d90826d063\",\"_v\":\"0.97312845\",\"userCode\":662040894,\"eventScenario\":\"pcSearchedSouIndex\",\"cvNumber\":\"JM620408945R90500002000\"&#125; 这里依然要解决Cookie的问题，它这个Cookie简直不能更恶心，因为参数实在是太多了： 这个Cookie相当变态 那么，我放弃了，感兴趣的朋友可以顺着这个思路继续探索，加油！ 前程无忧相对于Boss直聘和智联招聘，前程无忧要更简单一点，这种简单是从心智体验上来讲。经过分析，它的地址为：https://search.51job.com/list/200200,000000,0000,00,9,99,+,2,{page}.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare=。它的简单体现在，可以直接通过修改page这个参数来达到抓取某一页数据的目的，它本身没有特别强大的反爬机制，所以，事实上，它是整个数据分析主要的数据来源，在这个地址里可能有一点大家看不懂的东西，没关系，博主一样看不懂，我们只需要知道它表示西安就可以了，如果想抓取某个城市的职位信息，可以直接在前程无忧上搜索，地址栏会告诉你这一切是如何变化的。需要说明的是，前程无忧的职位信息是存储在window.__SEARCH_RESULT__这个变量里的，所以，我们通过这个正则直接去匹配它即可，不需要再去解析DOM，这再次体现出了它的简单： 123456789101112131415161718192021def searchJobs(self, cityName, query, page=1): cityCode = cityName if (cityCode != None): searchUrl = 'https://search.51job.com/list/200200,000000,0000,00,9,99,+,2,&#123;page&#125;.html?lang=c&amp;postchannel=0000&amp;workyear=99&amp;cotype=99&amp;degreefrom=99&amp;jobterm=99&amp;companysize=99&amp;ord_field=0&amp;dibiaoid=0&amp;line=&amp;welfare='.format(page=str(page)) html = self.makeRequest(searchUrl) data = re.findall('window.__SEARCH_RESULT__ =(.+)&#125;&lt;/script&gt;', str(html))[0] + \"&#125;\" details = json.loads(data)['engine_search_result'] jobItems = [] companyItems = [] for detail in details: jobItem = self.extractJob(detail) if (jobItem == None): continue else: jobItems.append(jobItem) companyItem = self.extractCompany(detail) if (companyItem == None): continue else: companyItems.append(companyItem) return (jobItems,companyItems) 因为这里真正起作用的实际上只有page这个参数，所以，我们只需要循环每一页就可以了，博主就是通过这个方法抓取了大量的职位信息。同样地，我们通过extractJob()和extractCompany()两个方法来组装职位和公司的信息，最终通过元组的形式返回，由调用者自己决定要如何去处理这些数据。虽然，我们选择了MongoDB这样的数据库，它不像关系型数据库那样重视Schema，可为了我们最终分析数据的时候方便一点，还是建议使用一致的数据结构。关于前程无忧部分的源代码，请参考：https://github.com/qinyuanpei/job-analyse/blob/master/Spider/job51Spider.py。 数据分析在开始今天的数据分析前，首先向大家展示下爬虫抓取到的数据。截止到写这篇的博客的时间，博主一共收集了20000个左右的职位/公司信息，如下图所示： 职位信息展示 公司信息展示 接下来，我们从数据库中读取这些数据以开始下面的分析： 123store = Store.mongoStore.MongoStore('default')jobs = list(store.find('job',&#123;&#125;))companies = list(store.find('company',&#123;&#125;)) 行业结构分析俗话说，“男怕入错行，女怕嫁错郎”。我们今天的社会是一个非常“苛刻”的社会，它要求每一个人在“合适”的年龄做“该做”的事情，可要达到这样一个“标准”则是非常不容易的。在综艺节目《令人心动的Offer》里，“大龄”、“裸辞”、“背水一战”的丁辉，受到了来自红圈律所的“精英”们的区别对待，仿佛一个人的人生不能有一丁点的差错。或许人生的“试错”成本真的非常高，高到人们在30岁左右的时候纷纷遭遇中年危机。所以，我们实在有必要去了解一个行业，它目前的求职现状到底是什么样的，这里以西安市为例： 123456789101112131415def analyse_industry(): industries = list(map(lambda x:x['industry'],companies)) counter = Counter(industries) counter = sorted(counter.items(),key = lambda x:x[1],reverse = True)[0:15] counter = dict(counter) c = ( Pie() .add(\"\",[list(z) for z in zip(counter.keys(), counter.values())],label_opts=opts.LabelOpts(is_show=True, position=\"center\"),) .set_global_opts( title_opts=opts.TitleOpts(title=\"西安市求职招聘行业结构分析(Top15)\",pos_left=325), legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"left\", orient=\"vertical\"), ) .set_series_opts(label_opts=opts.LabelOpts(formatter=\"&#123;b&#125;: &#123;c&#125;\")) .render(\"./Reports/西安市求职招聘行业结构分析(Top15).html\") ) 下面是整个西安市求职招聘排名前15位的行业结构： 西安市求职招聘行业结构分析(Top15) 可以注意到，其中占据份额较大的行业主要有：房地产、建筑/建材/工程、计算机软件、电子技术/半导体/集成电路、教育/培训/院校等。 学历结构分析作为一个“西漂”，博主对西安最深的一个印象就是，西安有着非常丰富的高校资源，正因为如此，博主一度认为西安遍历都是研究生。因为在过去的四年里，的确接触过不少研究生学历的同事，相比之下，博主这样一个普通211、非科班的本科生，着实显得有点相形见绌。我在之前的博客里有提到去中兴面试的经历，这个经历让我第一次意识到，学历和非科班的出身，终究有一天会成为你进入国企或者大厂的门槛，所以，博主在考虑要不要去读一个在职的研究生。这种认识到底是不是幸存者偏差呢，我们来看看数据分析的结果： 123456789101112131415def analyse_education(): eduInfos = list(map(lambda x:x['eduInfo'], jobs)) counter = Counter(eduInfos) counter = sorted(counter.items(),key = lambda x:x[1],reverse = True) counter = dict(counter) c = ( Pie() .add(\"\",[list(z) for z in zip(counter.keys(), counter.values())]) .set_global_opts( title_opts=opts.TitleOpts(title=\"西安市求职招聘学历结构分析\",pos_left=325), legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"left\", orient=\"vertical\"), ) .set_series_opts(label_opts=opts.LabelOpts(formatter=\"&#123;b&#125;: &#123;c&#125;\")) .render(\"./Reports/西安市求职招聘学历结构分析.html\") ) 我承认我在胡说八道，因为结果非常的Amazing啊，非常的毕导啊： 西安市求职招聘学历结构分析 我没有想到研究生以上的比例这么低，可能是因为我身边这些同事的层次都比较高吧，哈哈！可当学历逐渐成为一种门槛，即使你比本科生多上三年学，最后一样要在这世界上颠沛流离的时候，是不是会和博主有一样的疑问，为什么IT行业会变成劳动密集型产业？是因为门槛低让这个行业劣币驱逐良币呢，还是拥有高学历的人才一样要去拧螺丝？ 薪资待遇分析有时候，我会忍不住想，是不是在任何一个城市里，人们工资增长永远都赶不上房价增长？如果真的是这样，我们为什么又要从三线小城市出来呢？可能是觉得大城市有更好的机会吧，可转眼到了2020年，上大学时一心想从事这个行业的我，当时无论如何都想不到若干年后要面对“35岁”这个问题。当“996”作为一种“福报”的声音越来越强烈，曾经我们认为的那“一点点”机会，真的就是只剩下“一点点”。人有时候就是在靠着那点“不切实际”过日子，譬如固执的认为收入会越来越高，可其实任何工作都是有天花板的存在的，以大多数普通人的努力程度，一辈子连天花板都可能触碰不到，真实的薪资水平到底是什么样的呢？年薪30万果真如此寻常等闲？我们一起来看： 1234567891011121314151617181920212223242526272829def analyse_salary(): salaries = list(map(lambda x:x['avgSalary'], list(filter(lambda x:x['avgSalary'] != 0, jobs)))) counter = Counter(salaries) counter = sorted(counter.items(),key = lambda x:x[1],reverse = True) records = &#123;'3000元以下':0, '3000元-5000元':0, '5000元-8000元':0, '8000元-12000元':0, '12000元-15000元':0, '15000元以上':0&#125; for (k,v) in counter: if (k &lt; 3000): records['3000元以下'] += v if (k &gt;= 3000 and k &lt; 5000): records['3000元-5000元'] += v if (k &gt;= 5000 and k &lt; 8000): records['5000元-8000元'] += v if (k &gt;= 8000 and k &lt; 12000): records['8000元-12000元'] += v if (k &gt;= 12000 and k &lt; 15000): records['12000元-15000元'] += v if (k &gt;= 15000): records['15000元以上'] += v counter = dict(records) c = ( Pie() .add(\"\",[list(z) for z in zip(counter.keys(), counter.values())]) .set_global_opts( title_opts=opts.TitleOpts(title=\"西安市求职招聘平均工资分析\",pos_left=325), legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"left\", orient=\"vertical\"), ) .set_series_opts(label_opts=opts.LabelOpts(formatter=\"&#123;b&#125;: &#123;c&#125;\")) .render(\"./Reports/西安市求职招聘平均工资分析.html\") ) 由此，我们得到了整个西安市的收入分布情况。显然，*5000~8000这个收入区间才是大多数普通人的真实写照： 西安市求职招聘平均工资分析 我们继续分析，哪些行业的平均工资更高一点，因为这样你会找到同龄人的参考对象： 12345678910111213141516171819202122232425def analyse_industry_salary(): filtered = list(filter(lambda x:x['avgSalary'] != 0, jobs)) salaries = &#123;&#125; for job in filtered: if (job['industry'] == ''): continue if salaries.get(job['industry']) == None: salaries[job['industry']] = [job['avgSalary']] else: salaries[job['industry']].append(job['avgSalary']) counter = &#123;&#125; for (industry, data) in salaries.items(): counter[industry] = int(sum(data) / len(data)) counter = sorted(counter.items(),key = lambda x:x[1],reverse = True)[0:15] counter = dict(counter) c = ( Bar() .add_xaxis(list(counter.keys())) .add_yaxis(\"平均工资\", list(counter.values())) .set_global_opts( title_opts=opts.TitleOpts(title=\"西安市求职招聘行业工资分析(Top15)\", pos_left=325), legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"left\", orient=\"vertical\"), ) .render(\"./Reports/西安市求职招聘行业工资分析(Top15).html\") ) 类似地，我们这里取排名前15位的行业进行分析： 西安市求职招聘行业工资分析 可以注意到，工资收入靠前的行业主要集中在：互联网/移动互联网/计算机软件/电子商务、信托/拍卖/典当/担保、 智能硬件、法律、学术/科研、保险、房地产、金融/投资/证券、美容/保健等行业。可惜，从一名IT行业从业者的角度来看，西安实际上并没有真正的互联网公司。这个世界常常如此，每个月挣15K的人感慨自己买不起房，可还有那么多收入在8K以下的人群，还能再说什么呢？ 学历与薪资关系分析通常大家都认为，学历越高，薪资就会越高，那么，这个是否符合实际情况呢，我们一起来看一下： 12345678910111213141516171819202122232425262728def analyse_eduInfo_salary(industry=None): filtered = list(filter(lambda x:x['avgSalary'] != 0, jobs)) if (industry != None): filtered = list(filter(lambda x:x['industry'] == industry, filtered)) salaries = &#123;&#125; for job in filtered: if (job['eduInfo'] == ''): continue eduInfo = job['eduInfo'] if (eduInfo in ['学历不限','不限']): eduInfo = '学历不限' if salaries.get(eduInfo) == None: salaries[eduInfo] = [job['avgSalary']] else: salaries[eduInfo].append(job['avgSalary']) counter = &#123;&#125; for (eduInfo, data) in salaries.items(): counter[eduInfo] = int(sum(data) / len(data)) c = ( Bar() .add_xaxis(list(counter.keys())) .add_yaxis(\"平均工资\", list(counter.values())) .set_global_opts( title_opts=opts.TitleOpts(title=\"西安市求职招聘学历与薪资关系分析\", pos_left=325), legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"left\", orient=\"vertical\"), ) .render(\"./Reports/西安市求职招聘学历与薪资关系分析.html\") ) 下面给出可视化以后的结果： 西安市求职招聘学历与薪资关系分析 可以发现，整体上学历和薪资是呈正比的，甚至“不限学历”比“高中”的工资还要高一点。可如果有那么多“不限学历”的工作，为什么今年还有那么多人找不到工作呢？我想，这就是我们常说的选择，我们之所以付出努力，无非是想比别人多一点选择，可正如纳什均衡理论所言，如果我们大家都去选择相同的东西，最后的结果可能是大家都得不到这样东西。可话又说回来，明明都知道那个行业热门，如果不做这个选择，反而才是最奇怪的吧…… 经验与薪资关系分析如果说学历与薪资呈正比，那么经验与薪资则不一定满足这样的关系，因为经验其实是一个不准确的“度量”单位。以IT行业为例，在一家公司里，老员工的薪资被新员工的薪资“倒挂”是经常发生的事情。所以，人们似乎达成了某种共识，即期待公司主动涨薪是非常困难的，你唯一能做的就是在面试时争取更多的薪资。这就要说到经验这个话题，IT行业技术日新月异的特点，实在很难让经验变成一个“褒义词”，因为经验在积累的同时同样在“过期”，更不用说那些一直在“重复”的人了，所以，我觉得掌握通用型的知识譬如算法、数据结构等会更重要。 1234567891011121314151617181920212223242526272829303132333435def analyse_exps_salary(industry=None): filtered = list(filter(lambda x:x['avgSalary'] != 0, jobs)) if (industry != None): filtered = list(filter(lambda x:x['industry'] == industry, filtered)) salaries = &#123;&#125; for job in filtered: if (job['exps'] == ''): continue exps = job['exps'] exps = exps.replace('经验','') if (exps in ['1年','1年以内','2年','1-3年']): exps = '1-3年' if (exps in ['不限','经验不限']): exps = '经验不限' if (exps in ['3到4年','3到5年','3-4年','3-5年']): exps = '3-5年' if (exps in ['8到9年','5到10年','5到7年','8-9年','5-10年','5-7年']): exps = '5-10年' if salaries.get(exps) == None: salaries[exps] = [job['avgSalary']] else: salaries[exps].append(job['avgSalary']) counter = &#123;&#125; for (industry, data) in salaries.items(): counter[industry] = int(sum(data) / len(data)) c = ( Bar() .add_xaxis(list(counter.keys())) .add_yaxis(\"平均工资\", list(counter.values())) .set_global_opts( title_opts=opts.TitleOpts(title=\"西安市求职招聘工作经验与薪资关系分析\", pos_left=325), legend_opts=opts.LegendOpts(type_=\"scroll\", pos_left=\"left\", orient=\"vertical\"), ) .render(\"./Reports/西安市求职招聘工作经验与薪资关系分析.html\") ) 一切都会向着我们期待的方向发展吗？我们拭目以待： 西安市求职招聘工作经验与薪资关系分析 可以发现，整体上，经验越丰富，薪资待遇会越高。前提是你真的收获了经验，而不是在岁月的蹉跎里单单收获了皱纹和沧桑。这是我们每个人都应该去反思的一个问题，如果一切的经验都有过时的那一天，至少你真的拥有过它们，就像爱情这种东西一样。 招聘热词分析在招聘网站上，一般都会以标签的方式，对职位要求、公司福利等进行描述，譬如五险一金、弹性打卡等等，通过这些标签，我们就能对职位以及公司有个基本印象。所以，我们可以通过分析这些标签，来展示在求职过程中求职者和招聘方各自关注哪些因素。下面，我们将以词云的形式来展示这些标签： 1234567891011121314151617181920212223242526272829303132333435# 提取岗位关键字job_tags = []for item in map(lambda x:x['tags'], jobs): if (item != None): job_tags.extend(item)# 提取公司关键字company_tags = []for item in map(lambda x:x['tags'], companies): if (item != None): company_tags.extend(item)def analyse_extract_tags(words,title): words = list(filter(lambda x:x!='', words)) data = Counter(words) c= ( WordCloud() .add(series_name=\"热门词汇\", data_pair=data.items(), word_size_range=[6, 66]) .set_global_opts( title_opts=opts.TitleOpts( title=title, title_textstyle_opts=opts.TextStyleOpts(font_size=23) ), tooltip_opts=opts.TooltipOpts(is_show=True), ) .render('.\\Reports\\&#123;title&#125;.html'.format(title=title)) )analyse_extract_tags( words=job_tags, title='西安市求职者热词分析')analyse_extract_tags( words=company_tags, title='西安市招聘者热词分析') 西安市求职者热词分析 西安市招聘者热词分析 可以注意到，五险一金、年终奖金、专业培训、绩效奖金、节日福利、带薪年假是大家普遍关注的点。 本文小结本文主要抓取了Boss直聘、智联招聘、前程无忧三个招聘网站的职位信息和公司信息，并在此基础上对西安市的求职招聘进行了数据分析，主要从行业结构、学历结构、薪资待遇、学历与薪资关系、经验与薪资关系、招聘热词等方面入手，经分析，针对西安市的求职招聘的求职招聘，我们可以得出下面的结论：(1)西安市排名相对靠前的行业主要有：房地产、建筑/建材/工程、计算机软件、电子技术/半导体/集成电路、教育/培训/院校等；(2)西安市招聘的职位中大专和本科学历约占总职位的75%左右，硕士以及博士学历相对较低；(3)西安市的平均薪资中，5000~8000这个收入区间是大多数普通人的真实写照，工资收入靠前的行业主要集中在：互联网/移动互联网/计算机软件/电子商务、信托/拍卖/典当/担保、 智能硬件、法律、学术/科研、保险、房地产、金融/投资/证券、美容/保健等行业；(4)拥有高学历的人更有可能拥有高薪资；(5)整体上，经验越丰富，薪资待遇会越高。前提是你真的收获了经验，而不是在岁月的蹉跎里单单收获了皱纹和沧桑；(6)在整个求职招聘中，无论是求职者还是招聘者，普遍看重的因素有：五险一金、年终奖金、专业培训、绩效奖金、节日福利、带薪年假等。虽然一开始的目的是想知道西安有多少“996”的公司，不过在后续的实现过程中，发现从Boss直聘上抓取不到这些信息，所以，最终呈现出的结果就变成了现在这个样子，考虑到篇幅，关于公司规模、公司类型的分析，没有在这里写出来，如果大家感兴趣，可以参考：https://github.com/qinyuanpei/job-analyse/tree/master。以上就是这篇博客的全部内容啦，谢谢大家！","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"求职","slug":"求职","permalink":"https://qinyuanpei.github.io/tags/%E6%B1%82%E8%81%8C/"},{"name":"西安","slug":"西安","permalink":"https://qinyuanpei.github.io/tags/%E8%A5%BF%E5%AE%89/"},{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"可视化","slug":"可视化","permalink":"https://qinyuanpei.github.io/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/"}]},{"title":"一个西漂打工人的求职心路","date":"2020-11-18T12:49:47.000Z","path":"posts/1809438689/","text":"其实，这段故事说出来，多少有一点难为情，因为我实在没有想到，这一切会变得这样艰难。 10月份从上一家公司离职的时候，当时，我手上有两个Offer，一家是做旅游类产品的创业公司，一家则是声名狼藉的中软国际。因为刚来西安时，面对人生地不熟的新环境，曾经在这里有过一段时间的工作经历，所以，我从本能上排斥再回到那种地方。而创业公司本身的不稳定性，一度让我感到纠结，而最终的结果是，我放弃了这两份Offer。此时，对于一个工作刚满5年的人来说，一个月13K或14K的薪水，我感到相当的知足，可惜人生常常没有最优解，选择与妥协才是常态。 此后，我面试了奥博杰天(Objectiva)，在一轮面试后被评定为中级以后，我便再没有接到参加复试的通知，后来，HR告诉我他们只招高级以上的开发人员。关于这家公司，一件非常有趣的事情是，我的一位朋友在获得这家公司的工作后，因为适应不了终日远程办公的痛苦，最终还是选择从这里离开。大概这是为了印证围城里的那句话，“城外的人想进去，城里的人想出来”。虽然“面试造火箭，入职拧螺丝”有时是求职者的常态，可偏偏你连去拧螺丝的机会都没有。 后来找到一家做背调业务的公司，甚至都准备好要在这里开始新的旅程，可当我看到毫无架构可言的项目时，终于还是倒吸了一口冷气。虽然此前和面试官交流了很多相对前沿的内容，可真正入职以后，还是被安排去做维护遗留项目的工作，更让我感到沮丧的是，到第三天的时候，一位老员工突然告诉我，他要转岗去做前端，需要交接一部分工作给我。对于这一件事情，我之前的朋友都安慰我，这些问题你都知道该怎么去解决，因为企业招聘你过来就是希望你去解决这些问题。可从一个普通与昂工的角度来看，一个组织实在很难从底层去做出什么改变，何况这家公司采取了和上家公司一样的策略，寄希望于空降一个某个大公司的架构师。 现在回想起来，在试用期期间离开，或许有一点冲动使然，可听到后来接替我职位的新人，同样在呆了一周后离开了。所以，此时，你问我对这份工作感到后悔嘛？坦白说，我并不知道该怎么去说，而更戏剧性的反转，则是后来一家公司联系到我，问我有没有意向去做这些背调公司的外包，你要知道，在西安几乎没有互联网公司，所以，当绕了一大圈后，再回到原点的时候，我不禁哑然失笑。再后来，经过内推拿到了西安中兴的面试资格，我感觉不管是笔试还是面试，我的完成度都还可以，尤其是在第一轮面试中，从面试官那里收获了很多的东西。而在复试的过程中，领导们对我非科班出身的挑剔，多少让我想起令人心动的Offer中，因为非法本 + 年龄大被嫌弃的丁辉，和这些人相比，我们这些普通人根本称不上努力，可至少尊重那些一直在默默努力着的人啊。 这样辗转了一周，终于还是没能等到中兴的电话，我想应该是彻底凉了吧，果然人生没有那么多逆袭的可能，年少时虚度的光阴，终究会在未来某一天让你感到后悔。就这样，一直等一直面，陆陆续续地接到像软通动力这种外包性质的Offer，在面试中更是见识了大大小小的各种公司，我发现整个行业都在疯狂的内卷，996在道德上的批判声还没有褪去，人们又开始钻劳动法的空子，搞大小周、周一/三/四强制加班，这样做的不单单有华为、中兴这样的大厂，同样还有这些小公司。 今年因为疫情的原因，医疗行业应该赚得盆满钵满，可好多公司还是在疯狂地抢占市场，类似的还有物流行业，可在效益还不错的情况下，我只看到了越来越变本加厉的压榨，我看日剧《下町火箭》的时候就在想，虽然佃制作所这样一家小公司一样会加班，可人家的是火箭级别的阀门和加速器啊，人家愿意花时间去钻研工艺技术，而我们只能通过比别人早交付来赢得客户的青睐，那这是否说明，我们和竞争对手间的服务差异化其实并不大呢？ 现在，只要是个互联网公司，都能蹭一蹭双十一的热度，可在这场疫情背后，实体经济有多么的不景气，今天人们找工作就有多绝望，毕竟连房地产行业都表现出颓势，互联网行业不可能一直这样”热“下去，终有一天，一切都会回复到冷静。那么，对于没有“互联网”的西安IT圈子，程序员未来的退路又在哪里呢？我身边有很多30多岁的中年男人，那种说不出来的沉重感，时常让我对未来感到迷茫，他们都曾劝我回到三线小城市、考个公务员了却残生。也许我那个时候不大懂，而此时此刻终于感受到这种无奈，业内35岁的内卷化越来越严重，甚至我没想到，有一天大小周和周一/三/四强制加班会变成一种常态化。 这次面试中兴的经历，让我意识到，虽然进入IT行业的门槛非常低，可同样不幸的是，大厂/国企对相关岗位的门槛在不断加高，研究生起步基本就是标配啦，我甚至怀疑，我没有通过中兴的面试，是否和我非科班的出身以及没有考过的四级有关，这的确是一个现实问题，不管你想走技术路线，还是想走管理路线，一段大厂的经历能为你增加不少闪光点，可如果你拼进全力依然被这些门槛挡住，你是否会对未来感到迷茫呢？因为西安的IT圈子就这么大，你下一次换工作依然会面对这些公司，而人生又有多少个换工作的机会呢？ 所以，我一直在想要不要继续留在西安，在这边固然比老家多“一点”可能性，可就真的只是一点点而已，现在再次充满变数的时候，这一点点的优势就变得不再明显。四年前，为了离当时女朋友近一点而来西安，如今四年过去了，渐渐地很多问题再次浮现出来，也许，那个时候的她就想到了未来的各种可能吧！有天晚上，我找一位很久之前认识的朋友，向他询问关于35岁这道坎的想法。当多年未曾听到的声音再次传入耳朵，突然感到一阵亲切，他非常平静地对我说，“我今年已经36岁了，这道坎对我来说已经是过去了”。的确，我们总是对未来充满各种各样的担忧，可想到两年前，我一样是怀着忐忑的心情去了上家公司。 我和朋友在讨论这些问题的时候，都觉得未来去做个IT讲师是个好归宿，虽然再反过头去割新一茬年轻人的韭菜，有一点屠龙少年终成恶龙的意味，可我觉得，人生还是早一点考虑备选答案比较好。我们之所以敢去背负30年的房贷，是因为我们愿意去相信“未来越来越好”，可事实上是你的身体每一天都在衰老，虽然现在退休年龄延迟到60岁了，可想到还在幸苦忙碌着的父母，还是会觉得羞愧难当，古人说30而立，可我还没有立起来，父母已经在老去了。说了这么多，工作我还是会去努力地找，但应该不会不给自己留一点时间，因为除了找对象以外，我给自己订了几个学习计划，比如：软考的中/高级证书、英语练习(考个英语证书)、强化公开场合的演讲能力、Google PDE考试。 一个30+的朋友和我说，他想自己干点啥，因为他觉得他再找工作就没人要了，也许生活就是永远这么充满变化吧，就像不变的只有变化本身一样，提前焦虑未来没有什么用，现在的规划将来不一样会按部就班，我只能说，多去想想自己有什么，如果你只是比别人能加班，这实在算不上什么过人的长处，因为随时有年轻人可以替换你下来。人活着啊，不能光长年龄和皱纹，想想两度背水一战的丁辉，我们这点努力能叫做拼尽全力吗？这就是我，一个“西漂”四年的外地打工人的一点想法，如果你有更好的解决“内卷”的思路，我会非常感谢你告诉我这些。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"求职","slug":"求职","permalink":"https://qinyuanpei.github.io/tags/%E6%B1%82%E8%81%8C/"},{"name":"西漂","slug":"西漂","permalink":"https://qinyuanpei.github.io/tags/%E8%A5%BF%E6%BC%82/"},{"name":"程序员","slug":"程序员","permalink":"https://qinyuanpei.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"},{"name":"西安","slug":"西安","permalink":"https://qinyuanpei.github.io/tags/%E8%A5%BF%E5%AE%89/"}]},{"title":"使用 dotTrace 对 .NET 应用进行性能分析与优化","date":"2020-11-01T12:19:02.000Z","path":"posts/3672690776/","text":"前几天，有位朋友问我，你平时都是怎么去排查一个程序的性能问题的啊。不要误会，这位朋友不是我啦，因为我真的有这样一位叫做 Toby 的朋友。说到性能问题，可能大家立马会想到类似并发数、吞吐量、响应时间、QPS、TPS等等这些指标，这些指标的确可以反映出一个系统性能的好坏。可随着我们的系统结构变得越来越复杂，要找到这样一个性能的“损耗点”，同样会变得越来越困难。在不同的人的眼中，对于性能好坏的评判标准是不一样的，譬如在前端眼中，页面打开速度的快慢代表着性能的好坏；而在后端眼中，并发数、吞吐量和响应时间代表着性能的好坏；而在 DBA 眼中，一条 SQL 语句的执行效率代表着性能的好坏。更不用说，现实世界中的程序要在硬件、网络的世界里来回穿梭了，所以，从80%的功能堆积到100%，是件非常容易的事情；而从80%的性能优化到85%，则不是件非常轻松的事情。想清楚这一点非常简单，因为我们的系统从来都不是简单的1 + 1 = 2。此时，我们需要一个性能分析工具，而今天给大家分享的是 JetBrains 出品的 dotTrace 。 快速开始(Quick Start)安装软件的过程此处不表，这里建议大家同时安装 dotTrace 和 dotMemery。因为这都是 JetBrains 全家桶中的软件，安装的时候选一下就可以了，可谓是举手之劳。安装好以后的界面是这样的，可以注意到，它可以对进程中的 .NET 应用、本机的 .NET 应用以及远程的 .NET 应用进行检测，因为这里写一个 .NET Core 应用来作为演示，所以，我们选择 Profile Local App： dotTrace主界面 在这里，我们准备了一个简单的控制台程序： 1234567891011121314151617181920212223242526272829303132333435363738public class Program&#123; static void Main(string[] args) &#123; CPUHack(); MemeryHack(); &#125; public static void MemeryHack() &#123; Console.ReadLine(); var bytes = GC.GetTotalAllocatedBytes(); Console.WriteLine($\"AllocatedBytes: &#123; bytes &#125; bytes\"); var list = new List&lt;byte[]&gt;(); try &#123; while (true) &#123; list.Add(new byte[85000]); &#125; &#125; catch (OutOfMemoryException) &#123; Console.WriteLine(nameof(OutOfMemoryException)); Console.WriteLine(list.Count); bytes = GC.GetTotalAllocatedBytes(); Console.WriteLine($\"AllocatedBytes: &#123; bytes &#125; bytes\"); &#125; Console.ReadLine(); &#125; public static void CPUHack() &#123; Parallel.For(0, Environment.ProcessorCount, new ParallelOptions() &#123; MaxDegreeOfParallelism = Environment.ProcessorCount &#125;, i =&gt; &#123; &#125;); &#125;&#125; 其中，CPUHack()方法来自：打爆你的 CPU; MemeryHack()方法来自：通过代码实现 OutOfMemory。顾名思义，我们将利用这两个方法来分别测试 dotTrace 和 dotMemery。 dotTrace 目前支持以下平台：.NET、.NET Core、WPF、UWP(Universal Windows Platform)、ASP.NET、Windows服务、WCF、Mono 和 Unity。可以注意到它有四种监测方式，即Sampling、Tracing、Line by Line以及Timeline。按照界面上的描述，Sampling 适用于大多数场景下调用时间的精确测量、Tracing 适用于算法复杂度分析场景下调用次数的精确测量、Line by Line 适用于更高级别的使用场景，Timeline 适用于含多线程在内的数据处理的精确测量。所以，我们这里选择好一个可执行文件，然后选择 Sampling，再点击 “Run”： 对进行程序进行采样、生成快照 此时，我们会看到对应程序的的工具栏，我们可以点击 “Get Snapshot and Wait” 进行采样，每次采样会生成一个快照，默认情况下会自动打开生成的快照。我们还可以点击 “Start” 重新进行采样，直至采集到满意的样本为止，而在完成采样后，则可以点击 “Kill” 结束采样。下面来看看生成的快照： dotTrace性能快照 通过这两图，我们可以非常清晰的看到，最耗时的正是我们这里的CPUHack()方法，并且这里一共有四个线程，这是因为博主的计算机使用的是一款4核的i3处理器，并且在dotTrace中可以直接看到相关的代码片段，当然，这一切的前提是你没有对应用程序做过混淆处理，这样，我们就完成了一个简单的性能分析。类似地，我们启动dotMemery。此时，可以得到下面的结果： dotMemery内存分析 这里，我们通过&lt;YourApp&gt;.runtimeconfig.json文件，设定了GC堆的最大值是1M，而每次向列表中添加超过85K的byte数组时，当前对象会被分配到大对象堆上。通过这张图我们可以很清楚的看到，整个曲线中蓝色区域的 LOH 占了绝对的比例，换言之，几乎所有的内存都是分配到大对象堆(LOH)上的。此外，有些小对象从0代升到了1代，在这个例子中，由于可分配的内存不足，最终引发了OutOfMemoryException。而这和我们看到的结果是相符合的： 1234567891011121314&#123; \"runtimeOptions\": &#123; \"tfm\": \"netcoreapp3.1\", \"framework\": &#123; \"name\": \"Microsoft.NETCore.App\", \"version\": \"3.1.0\" &#125;, \"configProperties\": &#123; \"System.GC.HeapHardLimit\": 1048576 &#125; &#125;&#125; 从Dump文件进行分析到此为止，关于 dotTrace 和 dotMemery 的使用就基本上讲解完啦！可能这时候有些朋友会产生疑问，如果性能问题发生在生产环境怎么办啊。不错，这里我们调试的都是本地的程序，生产环境是没有机会让你这样去搞的。此时，我们可以借助内存转储文件(Dump)文件，它是进程的内存镜像，可以把程序的执行状态通过调试器保存在Dump文件中，试想一下，如果程序在前一秒崩溃了，而你在这一瞬间获得了当时程序的状态信息，相当于拿到了“故障”遗留在现场的“罪证”。在Windows系统中创建Dump文件是非常简单的，通过任务管理器-&gt;创建转储文件即可完成，我们继续使用上面提到的例子： 创建Dump文件 其实，拿到Dump文件以后，分析它的工具非常多，比如常见的WinDBG、DebugDiag等等，这里我们可以直接使用 dotMemery ，因为它本身就支持Dump文件的导入，相比前面两种在使用上要更加友好一点。此时，导入这个Dump文件，我们就可以获得下面的结果： 大对象堆分布情况 一、二代GC分布情况 这和我们前面分析出的结论是一致的，即，几乎所有的内存都是分配到大对象堆(LOH)上的。除此以外，针对.NET Core，官方提供了dotnet-dump和dotnet-gcdump两个命令行工具，可以通过下面的命令安装： 12dotnet tool install -g dotnet-dumpdotnet tool install -g dotnet-gcdump 这两个命令同样可以对内存进行分析，关于更多的.NET Core的诊断教程，请参考：https://docs.microsoft.com/zh-cn/dotnet/core/diagnostics/event-counter-perf，这些细节都是针对.NET Core的，可能不具有普适性，感兴趣的朋友可以自行前去了解。和大多数JetBrains的应用一样，这些程序都有 Visual Studio 的扩展程序，可以直接集成到 Visual Studio 中，这个同样看个人喜好，不再详细讲解。 本文小结结合一个简单的示例程序，本文简单地介绍了来自 JetBrains 的两款软件 dotTrace 和 dotMemery 的基本使用，以及如何通过内存转储文件(Dump)对生产环境中的内存进行诊断。在以往的关于程序性能优化的经历中，我个人还使用过 ANTS-Performance-Profiler 这个软件，但体验上感觉还是 dotTrace 和 dotMemery 稍微好用一点，而对于更一般的代码角度的性能分析，我推荐一个轻量级的项目MiniProfiler，性能优化不能靠猜，可是从初中就开始学的“控制变量法”未尝不是一个不错的思路。刷 LeetCode 的这段时间，一个最大的感悟就是，程序的性能，真的是一点一点的优化出来的，就拿最简单的排序来说，你真的要在上面提交很多次，才能渐渐地明白为什么说有些排序算法是“不稳定”的。也许，现在硬件水平越来越好，我们不必像前辈们一样“锱铢必较”，可这一切其实很都公平，你写代码的时候有多浪费，你玩游戏的时候就有多心疼，这里要特别表扬育碧对叛变这一作的优化。好了，这就是这篇博客的内容啦，谢谢大家，晚安！ 参考链接 https://www.jetbrains.com/zh-cn/profiler/ https://www.jetbrains.com/zh-cn/dotmemory https://docs.microsoft.com/zh-cn/dotnet/core/diagnostics/debug-linux-dumps https://docs.microsoft.com/zh-cn/dotnet/core/diagnostics/debug-memory-leak https://docs.microsoft.com/zh-cn/dotnet/core/diagnostics/debug-highcpu?tabs=windows","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"dotTrace","slug":"dotTrace","permalink":"https://qinyuanpei.github.io/tags/dotTrace/"},{"name":"JetBrain","slug":"JetBrain","permalink":"https://qinyuanpei.github.io/tags/JetBrain/"},{"name":"性能","slug":"性能","permalink":"https://qinyuanpei.github.io/tags/%E6%80%A7%E8%83%BD/"},{"name":"调优","slug":"调优","permalink":"https://qinyuanpei.github.io/tags/%E8%B0%83%E4%BC%98/"}]},{"title":"一道 HashSet 面试题引发的蝴蝶效应","date":"2020-10-20T12:19:02.000Z","path":"posts/3411909634/","text":"没错，我又借着“面试题”的名头来搞事情了，今天要说的是 HashSet ，而这确实是一个实际面试中遇到的问题。当时的场景大概是这样的，面试官在了解了你的知识广度以后，决心来考察一番你的基本功底，抛出了一个看起来平平无奇的问题：说一说你平时工作中都用到了哪些数据结构。你心想，这还不简单，Array、ArrayList、List、Dictionary、HashSet、Stack、Queue…等等各种集合类简直如数家珍，甚至你还能说出这些数据结构间的优劣以及各自使用的场景。可没想到，面试官话锋一转，直接来一句，“你能说说HashSet去重的原理吗”，好家伙，你这简直不按套路出牌啊…本着每次面试都有一点收获的初心，于是就有了今天这篇博客，不同的是，顺着这个思路继续深挖下去，博主又发现了几个平时关注不到的技术盲点，所以，博主称之为：一道 HashSet 面试题引发的蝴蝶效应。 HashSet源代码解读OK，首先，我们来回答第一个问题，即：HashSet去重的原理是什么？。为此，博主翻阅了 HashSet 的 源代码。首先，我们会注意到 HashSet 的构造函数，它需要一个类型为IEqualityComparer&lt;T&gt;的参数。从这个命名上我们就可以知道，这是一个用于相等性比较的接口，我们初步推测，HashSet 去重应该和这个接口有关： 12345678910111213public HashSet() : this(EqualityComparer&lt;T&gt;.Default) &#123; &#125; public HashSet(int capacity) : this(capacity, EqualityComparer&lt;T&gt;.Default) &#123; &#125; public HashSet(IEqualityComparer&lt;T&gt; comparer) &#123; &#125; public HashSet(IEnumerable&lt;T&gt; collection) : this(collection, EqualityComparer&lt;T&gt;.Default) &#123; &#125;public HashSet(IEnumerable&lt;T&gt; collection, IEqualityComparer&lt;T&gt; comparer) : this(comparer) &#123; &#125; 我们都知道 HashSet 可以去重，比如，我们向 HashSet 添加多个相同的元素，实际上 HashSet 中最终只会有一个元素。所以，我们自然而然地想到，看看 HashSet 中的 Add() 方法呗，或许能从这里看出一点端倪。HashSet 中一共有两个 Add() 方法，它们内部都调用了 AddIfNotPresent() 方法： 1234567void ICollection&lt;T&gt;.Add(T item) &#123; AddIfNotPresent(item);&#125; public bool Add(T item) &#123; return AddIfNotPresent(item);&#125; 继续循着蛛丝马迹一路 F12 ，我们来看看这个方法的具体实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849private bool AddIfNotPresent(T value) &#123; if (m_buckets == null) &#123; Initialize(0); &#125; int hashCode = InternalGetHashCode(value); int bucket = hashCode % m_buckets.Length; #if FEATURE_RANDOMIZED_STRING_HASHING &amp;&amp; !FEATURE_NETCORE int collisionCount = 0; #endif for (int i = m_buckets[hashCode % m_buckets.Length] - 1; i &gt;= 0; i = m_slots[i].next) &#123; if (m_slots[i].hashCode == hashCode &amp;&amp; m_comparer.Equals(m_slots[i].value, value)) &#123; return false; &#125; #if FEATURE_RANDOMIZED_STRING_HASHING &amp;&amp; !FEATURE_NETCORE collisionCount++; #endif &#125; int index; if (m_freeList &gt;= 0) &#123; index = m_freeList; m_freeList = m_slots[index].next; &#125; else &#123; if (m_lastIndex == m_slots.Length) &#123; IncreaseCapacity(); // this will change during resize bucket = hashCode % m_buckets.Length; &#125; index = m_lastIndex; m_lastIndex++; &#125; m_slots[index].hashCode = hashCode; m_slots[index].value = value; m_slots[index].next = m_buckets[bucket] - 1; m_buckets[bucket] = index + 1; m_count++; m_version++; #if FEATURE_RANDOMIZED_STRING_HASHING &amp;&amp; !FEATURE_NETCORE if (collisionCount &gt; HashHelpers.HashCollisionThreshold &amp;&amp; HashHelpers.IsWellKnownEqualityComparer(m_comparer)) &#123; m_comparer = (IEqualityComparer&lt;T&gt;) HashHelpers.GetRandomizedEqualityComparer(m_comparer); SetCapacity(m_buckets.Length, true); &#125; #endif // FEATURE_RANDOMIZED_STRING_HASHING return true;&#125; 可以注意到，在这段代码中，首先，会通过 InternalGetHashCode() 方法计算一个 HashCode。其中，Lower31BitMask 是一个常量 0x7FFFFFFF ： 123456private int InternalGetHashCode(T item) &#123; if (item == null) &#123; return 0; &#125; return m_comparer.GetHashCode(item) &amp; Lower31BitMask;&#125; 接下来，在 HashSet 内部使用了Slot 这个结构来存储元素，该结构设计上类似于链表，每一个 Slot 中都记录对应元素的值、HashCode 以及下一个元素的索引。所以，只需要对它做一次遍历，如果对应元素的 HashCode 和 值 都相等，则认为该元素在 HashSet中已经存在了。此时，AddIfNotPresent() 方法会返回 false。这就是 HashSet 去重的原理啦。在比较元素的值是否相等的时候，我们前面提到的 IEqualityComparer&lt;T&gt; 终于登场，它提供的 Equals() 方法恰好可以比较两个元素是否相等： 1234567891011internal struct Slot &#123; internal int hashCode; // Lower 31 bits of hash code, -1 if unused internal int next; // Index of next entry, -1 if last internal T value;&#125;public interface IEqualityComparer&lt;in T&gt;&#123; bool Equals(T x, T y); int GetHashCode(T obj); &#125; 再接下来，如果对应元素的 HashCode 或 值 都不相等，则认为该元素在 HashSet 中不存在。此时，需要考虑 HashSet 的容量是否足以放得下这个新元素。在容量不满足的情况下，就需要对 HashSet 进行扩容。值得一提的是，这里是使用质数进行扩容的： 1234567891011121314151617181920212223242526private void IncreaseCapacity() &#123; Debug.Assert(m_buckets != null, \"IncreaseCapacity called on a set with no elements\"); int newSize = HashHelpers.ExpandPrime(m_count); if (newSize &lt;= m_count) &#123; throw new ArgumentException(SR.GetString(SR.Arg_HSCapacityOverflow)); &#125; // Able to increase capacity; copy elements to larger array and rehash SetCapacity(newSize, false);&#125;public static int ExpandPrime(int oldSize)&#123; int newSize = 2 * oldSize; // Allow the hashtables to grow to maximum possible size (~2G elements) before encoutering capacity overflow. // Note that this check works even when _items.Length overflowed thanks to the (uint) cast if ((uint)newSize &gt; MaxPrimeArrayLength &amp;&amp; MaxPrimeArrayLength &gt; oldSize) &#123; Contract.Assert( MaxPrimeArrayLength == GetPrime(MaxPrimeArrayLength), \"Invalid MaxPrimeArrayLength\"); return MaxPrimeArrayLength; &#125; return GetPrime(newSize);&#125; IEqualityComparer接口OK，现在我们知道了，HashSet 之所以可以去重，一个重要的原因是 IEqualityComparer&lt;T&gt; 。而回到这个接口本身呢，它只有 Equals() 和 GetHashCode()，这其实非常符合我们的认知，因为这两个方法在对象相等的场景中十分常见，有一个准则是：如果重写了 Equals() 方法，那么，应该同时去重写 GetHashCode() 方法，即，两者在表达相等这个含义时应该具有一致性。这里可能会有一点疑问，那就是，我们平时使用 HashSet 的时候，完全不需要指定 IEqualityComparer&lt;T&gt; ，它一样可以正常工作啊？没错，这是因为微软提供了一个默认的实现：EqualityComparer&lt;T&gt;.Default。我们同样来看看它的实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445private static EqualityComparer&lt;T&gt; CreateComparer() &#123; Contract.Ensures(Contract.Result&lt;EqualityComparer&lt;T&gt;&gt;() != null); RuntimeType t = (RuntimeType)typeof(T); // Specialize type byte for performance reasons if (t == typeof(byte)) &#123; return (EqualityComparer&lt;T&gt;)(object)(new ByteEqualityComparer()); &#125; // If T implements IEquatable&lt;T&gt; return a GenericEqualityComparer&lt;T&gt; if (typeof(IEquatable&lt;T&gt;).IsAssignableFrom(t)) &#123; return (EqualityComparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(GenericEqualityComparer&lt;int&gt;), t); &#125; // If T is a Nullable&lt;U&gt; where U implements IEquatable&lt;U&gt; return a NullableEqualityComparer&lt;U&gt; if (t.IsGenericType &amp;&amp; t.GetGenericTypeDefinition() == typeof(Nullable&lt;&gt;)) &#123; RuntimeType u = (RuntimeType)t.GetGenericArguments()[0]; if (typeof(IEquatable&lt;&gt;).MakeGenericType(u).IsAssignableFrom(u)) &#123; return (EqualityComparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(NullableEqualityComparer&lt;int&gt;), u); &#125; &#125; // See the METHOD__JIT_HELPERS__UNSAFE_ENUM_CAST and METHOD__JIT_HELPERS__UNSAFE_ENUM_CAST_LONG cases in getILIntrinsicImplementation if (t.IsEnum) &#123; TypeCode underlyingTypeCode = Type.GetTypeCode(Enum.GetUnderlyingType(t)); // Depending on the enum type, we need to special case the comparers so that we avoid boxing // Note: We have different comparers for Short and SByte because for those types we need to make sure we call GetHashCode on the actual underlying type as the // implementation of GetHashCode is more complex than for the other types. switch (underlyingTypeCode) &#123; case TypeCode.Int16: // short return (EqualityComparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(ShortEnumEqualityComparer&lt;short&gt;), t); case TypeCode.SByte: return (EqualityComparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(SByteEnumEqualityComparer&lt;sbyte&gt;), t); case TypeCode.Int32: case TypeCode.UInt32: case TypeCode.Byte: case TypeCode.UInt16: //ushort return (EqualityComparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(EnumEqualityComparer&lt;int&gt;), t); case TypeCode.Int64: case TypeCode.UInt64: return (EqualityComparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(LongEnumEqualityComparer&lt;long&gt;), t); &#125; &#125; // Otherwise return an ObjectEqualityComparer&lt;T&gt; return new ObjectEqualityComparer&lt;T&gt;();&#125; 在这里，EqualityComparer&lt;T&gt; 类是一个抽象类，实现了 IEqualityComparer&lt;T&gt; 接口。简单来说，对于简单类型如整型、字节型等，微软实现了相应的 IEqualityComparer&lt;T&gt; 接口；而对于复杂的类型，微软提供了 ObjectEqualityComparer&lt;T&gt; 这一实现： 123456789101112131415161718internal class ObjectEqualityComparer&lt;T&gt;: EqualityComparer&lt;T&gt;&#123; [Pure] public override bool Equals(T x, T y) &#123; if (x != null) &#123; if (y != null) return x.Equals(y); return false; &#125; if (y != null) return false; return true; &#125; [Pure] public override int GetHashCode(T obj) &#123; if (obj == null) return 0; return obj.GetHashCode(); &#125;&#125; 所以，现在又回到我们刚刚聊起的话题，为什么说一个类型的 Equals() 和 GetHashCode() 方法非常重要呢？因为如果我们不能正确地实现这两个方法，微软实现的这个 ObjectEqualityComparer&lt;T&gt; 就会出现问题，导致 HashSet 在判断元素是否存在时出现问题，所以，这是一系列的连锁反应。有人可能会问，博主你说的这个好夸张耶，像我就从来没有重写过这两个方法。OK，现在来回答我的一个问题，如果你定义了一个类型 Foo ，并尝试用它作为一个字典中的 Key ，那么，你觉得这个字典应该怎么判断这个 Key 是否存在呢？我觉得这是一个好问题，因为它引发了我们在 .NET 知识体系中的蝴蝶效应。 排序与去重是亲家排序与去重，在我看来是亲家关系，因为两者都需要“比较”。所以，下面我想从 .NET 中选取一部分接口来阐述我的观点，以及当我们有了 LINQ 以后，是否就应该抛弃它们。可能这些接口大家平时都用不到多少，但我还是想花点时间来梳理这些知识盲点，因为我发现，与其为整个行业35岁的的职业生涯而焦虑，倒不如重新捡起这个行业的初心，好好地学一学数据结构、算法和数学。整个行业的火热，容易让每一个人都陷入一种“我非常厉害”的错觉，我写博客的时候，在心里想了这样一句话：战士上战场，整天就知道CRUD，连HashSet都不知道，早晚是个死。用王布斯的口吻说出来，会不会有一种紧迫感呢？ IEquatable接口IEquatable&lt;T&gt; 接口在微软官方文档中的定义是，定义值类型或类实现的通用方法，以创建用于确定实例相等性的类型特定方法。我承认，这不是一个特别好的定义，不过，我们可以换个角度来审视这个接口存在的意义。虽然 Object 这个基类提供了 Equals() 方法，但是这个方法只能接受一个 object 类型的参数， 所以，它本身会面临类型安全性缺失和装箱两个问题。为了解决这个问题，就必须要定义一个新的 Equals() 方法，确保它可以接收和当前类型一致的参数，所以就需要这样一个接口，你可以理解为它是 Equals() 方法的泛型版本，而众所周知 C# 是一门不支持多继承的语言，所以，这里只能以接口的形式提供出来。这里说一下我的结论，IEquatable&lt;T&gt; 接口对值类型更有用一点，相反，对引用类型就没有那么有用，因为它没有考虑到协变的问题，对引用类型的继承相对无力。下面是一个简单的例子： 12345678910111213141516171819202122//定义类型Foo，实现IEquatable&lt;Foo&gt;接口public class Foo : IEquatable&lt;Foo&gt;&#123; public decimal Value &#123; get; set; &#125; public decimal Weight &#123; get; set; &#125; public override bool Equals(object other) &#123; return Equals(other as Foo); &#125; public bool Equals(Foo other) &#123; if (other == null) return false; return (this.Value == other.Value &amp;&amp; this.Weight == other.Weight); &#125;&#125;//平平无奇的代码var foo1 = new Foo() &#123; Value = 10, Weight = 1.0M &#125;;var foo2 = new Foo() &#123; Value = 10, Weight = 1.0M &#125;;Assert.AreEqual(true, foo1.Equals(foo2)); ICompareable/ICompareable接口ICompareable 和 ICompareable&lt;T&gt;是是同一个接口的非泛型与泛型版本，都需要实现 CompareTo() 方法。可能大家会觉得这几个接口都差不多啊，实际上，大家细心观察就能发现它们的区别，“相等”这一类的接口的返回值是布尔型，关注的是两个对象是否相等；而“比较”这一类的接口的返回值是整数型，关注的是哪个大哪个小。我们继续以 Foo 这个类型为例，分别实现IComparerable 和 IComparerable&lt;T&gt;两个接口： 12345678910111213141516171819202122232425262728293031323334//继续实现IComparable, IComparable&lt;Foo&gt;接口public class Foo : IEquatable&lt;Foo&gt;, IComparable, IComparable&lt;Foo&gt;&#123; public decimal Value &#123; get; set; &#125; public decimal Weight &#123; get; set; &#125; public override bool Equals(object other) &#123; return Equals(other as Foo); &#125; public bool Equals(Foo other) &#123; if (other == null) return false; return (this.Value == other.Value &amp;&amp; this.Weight == other.Weight); &#125; public int CompareTo(object obj) &#123; var other = obj as Foo; return CompareTo(other); &#125; public int CompareTo([AllowNull] Foo other) &#123; if (other == null) return 1; return (int)((Value * Weight) - (other.Value * other.Weight)); &#125;&#125;//平平无奇的代码var foo1 = new Foo() &#123; Value = 10, Weight = 1.0M &#125;;var foo2 = new Foo() &#123; Value = 20, Weight = 1.0M &#125;;Assert.IsTrue(foo2.CompareTo(foo1) &gt; 0); IComparer接口对于排序来说，理论上有ICompareable 和 ICompareable&lt;T&gt;这两个接口就可以了，为什么还要再定义一组接口呢？其实，我们结合生活中的场景就能想明白，不管是判断两个对象是否相等，还是对两个对象进行排序，这些条件都属于“变量”。ICompareable 和 ICompareable&lt;T&gt;这两个接口设计上的确没什么问题，但这都是一锤子买卖，一旦实现了对应的接口，就意味着如何比较两个对象的逻辑是确定好了的。可生活常识告诉我们，同一组信息不同的人考虑的维度是不一样的，譬如学生的成绩，可以按照某一个科目的成绩来排序，还可以按照各个科目的总成绩甚至是平均分来排序。对于上面的类型 Foo，我们不妨考虑按照 Value 和 Weight 分别进行排序，此时可以这样写： 12345678910111213141516171819202122232425262728293031323334353637383940//按Value排序public class FooValueComparer : IComparer&lt;Foo&gt;&#123; public int Compare([AllowNull] Foo x, [AllowNull] Foo y) &#123; if (x == null &amp;&amp; y == null) return 0; if (x != null &amp;&amp; y == null) return 1; if (x == null &amp;&amp; y != null) return -1; return (int)(x.Value - y.Value); &#125;&#125;//按Weight排序public class FooWeightComparer : IComparer&lt;Foo&gt;&#123; public int Compare([AllowNull] Foo x, [AllowNull] Foo y) &#123; if (x == null &amp;&amp; y == null) return 0; if (x != null &amp;&amp; y == null) return 1; if (x == null &amp;&amp; y != null) return -1; return (int)(x.Weight - y.Weight); &#125;&#125;//平平无奇的代码var list= new List&lt;Foo&gt;&#123; new Foo() &#123; Value = 10, Weight = 2.0M &#125;, new Foo() &#123; Value = 10, Weight = 1.0M &#125;&#125;;//使用默认的排序器list.Sort(); //按Value进行排序list.Sort(new FooValueComparer());list.OrderBy(x =&gt; x.Value);//按Weight进行排序list.Sort(new FooWeightComparer());list.OrderBy(x =&gt; x.Weight); 在这里有一个点是，在不指定排序器的时候，微软帮我们提供了一个默认的排序器。而这个默认排序器会遵循这样的策略。如果类型 T 实现了 IComparable&lt;T&gt; 接口，则返回 GenericComparer&lt;int&gt; 实例；如果类型 T 实现是一个可空类型 Nullable&lt;U&gt; 并且类型 U 实现了 IComparable&lt;T&gt; 接口，则返回 NullableComparer&lt;int&gt; 实例；否则返回 ObjectComparer&lt;T&gt; 实例。 12345678910111213141516171819202122232425262728private static Comparer&lt;T&gt; CreateComparer() &#123; RuntimeType t = (RuntimeType)typeof(T); // If T implements IComparable&lt;T&gt; return a GenericComparer&lt;T&gt; #if FEATURE_LEGACYNETCF // Pre-Apollo Windows Phone call the overload that sorts the keys, not values this achieves the same result if (CompatibilitySwitches.IsAppEarlierThanWindowsPhone8) &#123; if (t.ImplementInterface(typeof(IComparable&lt;T&gt;))) &#123; return (Comparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(GenericComparer&lt;int&gt;), t); &#125; &#125; else #endif if (typeof(IComparable&lt;T&gt;).IsAssignableFrom(t)) &#123; return (Comparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(GenericComparer&lt;int&gt;), t); &#125; // If T is a Nullable&lt;U&gt; where U implements IComparable&lt;U&gt; return a NullableComparer&lt;U&gt; if (t.IsGenericType &amp;&amp; t.GetGenericTypeDefinition() == typeof(Nullable&lt;&gt;)) &#123; RuntimeType u = (RuntimeType)t.GetGenericArguments()[0]; if (typeof(IComparable&lt;&gt;).MakeGenericType(u).IsAssignableFrom(u)) &#123; return (Comparer&lt;T&gt;)RuntimeTypeHandle.CreateInstanceForAnotherGenericParameter((RuntimeType)typeof(NullableComparer&lt;int&gt;), u); &#125; &#125; // Otherwise return an ObjectComparer&lt;T&gt; return new ObjectComparer&lt;T&gt;();&#125; 更有意思的是，GenericComparer&lt;T&gt; 就是利用 IComparable&lt;T&gt; 的 CompareTo() 方法来说实现的： 123456789101112131415161718192021internal class GenericComparer&lt;T&gt; : Comparer&lt;T&gt; where T: IComparable&lt;T&gt;&#123; public override int Compare(T x, T y) &#123; if (x != null) &#123; if (y != null) return x.CompareTo(y); return 1; &#125; if (y != null) return -1; return 0; &#125; // Equals method for the comparer itself. public override bool Equals(Object obj)&#123; GenericComparer&lt;T&gt; comparer = obj as GenericComparer&lt;T&gt;; return comparer != null; &#125; public override int GetHashCode() &#123; return this.GetType().Name.GetHashCode(); &#125;&#125; 在我们有了 LINQ 以后，通过 OrderBy 和 OrderByDescending 就可以进行排序，如果这个排序字段是一个简单类型，比如字符型、整型、日期型，这些简单类型微软都已经实现了相应的“排序”逻辑，而如果这个排序字段是一个复杂类型，比如一个自定义的类或者结构，此时，为了让这些方法能够“适应”这些复杂类型，最好的还是去实现 IComparer&lt;T&gt; 或者 ICompareable&lt;T&gt; 接口，然后传递给这两个排序方法。类似地，还有 Distinct 这个方法，它接收一个 IEqualityComparer&lt;T&gt; 类型的参数，所以，当你对一个列表进行去重(Distinct)操作时，千万不要想当然地人为它会按照你的期望去去重，如果结果不符合你的期望，很大原因是你没有给它提供一个合适的IEqualityComparer&lt;T&gt; 。所以，你看，我们绕了一大圈，从 HashSet 说到 IEqualityComparer&lt;T&gt;，又从排序说到去重，最终又回到了起点，这是多么有趣的一件事情。而去重(Distinct)这件事情，其实涉及到Dictionary 和 HashSet 两个数据结构，通过结构来推演性质，又通过性质来扫清盲点，这可能是这段时间刷LeetCode最大的一个收获吧！ 本文小结面试中偶然遇到的 HashSet 问题，让我发现自己的知识体系中存在着盲点。通过解读 HashSet 源代码，我们认识到 HashSet 可以去重的一个重要原因是IEqualityComparer&lt;T&gt; 接口，它决定了两个对象的实例在什么情况下可以被判定为相等。而这个接口，不单单在 HashSet 出现，在 Dictionary 中同样会出现，甚至在我们最熟悉不过的去重(Distinct)中还会出现，所以，通过 HashSet 这一个点上的疑问，我搞清楚了很多相关联的内容，这不是蝴蝶效应又是什么呢？而与去重(Distinct)相关联的则是排序，在此基础上，对 IEquatable&lt;T&gt; 接口、ICompareable/ICompareable&lt;T&gt; 接口、IComparer&lt;T&gt; 接口等知识盲点进行梳理。总而言之，排序需要关注的是 ICompareable/ICompareable&lt;T&gt; 接口、IComparer&lt;T&gt; 接口，去重需要关注的是 IEqualityComparer&lt;T&gt; 接口。好了，今天的这只蝴蝶就飞到这里，欢迎大家在博客中留言，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://qinyuanpei.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"编程","slug":"编程","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E7%A8%8B/"},{"name":"源码","slug":"源码","permalink":"https://qinyuanpei.github.io/tags/%E6%BA%90%E7%A0%81/"},{"name":"HashSet","slug":"HashSet","permalink":"https://qinyuanpei.github.io/tags/HashSet/"}]},{"title":"当姜子牙遇见朱一旦","date":"2020-10-18T12:19:02.000Z","path":"posts/1085014581/","text":"当导演张策宣布，不再为朱一旦系列担任编剧和配音时，我终于意识到，“十佳员工”不再是一个梗，而是一个活生生的人。也许，身为老板的“朱一旦”，永远都没有读懂这些黑色幽默背后的含义。而显然，站在普通人对立面的资本家们，终究不会因此而洗心革面，代表劳苦大众向这个时代发声。不管是后浪还是非浪，资本家们不会选择和钱过不去，所以，即使有像鲁迅一般针砭时弊的张策，可在一个“屁股决定脑袋”的世界里，“十佳员工”突然就变成一个不再好笑的词汇，因为，这个人可以是你，可以是我，可以是我们中的任何一个。在新冠疫情肆虐的时候，『一块劳力士的回家之路』让我们感受到了现实的魔幻，可此时此刻，我们终于知道，“艺术来源于生活，而往往高于生活”，果然，如有雷同，是不胜荣幸的了。可能是因为我此刻在经历着同样的事情，所以，难免感同身受地想到C座802里这群真实存在着的人们。 我有一位为公司奉献11年青春的同事，可当他离开这家公司时，并没有我想象的中那样充满不舍，大概“鸟尽弓藏”、“大地茫茫真干净”这些句子，从古至今就是这样子的吧！马老师说，“996是一种福报”，而此前的一位马老师则说，“资本家生来就是剥削劳动者的一切剩余价值”。历史像个任人打扮的小姑娘，你方唱罢我登场，文过饰非，到底谁又讲得清对错？有人说，一个人开始成熟，就是从学习这几千年来的厚黑学、阴谋论开始，的确啊，连封神都开始变成一场阴谋，不同的是，这次的因果都落在原始天尊身上，每一个人都渴望像姜子牙一样，断天梯、破枷锁，似乎一定要执著于什么东西，这样的人生会显得更真实一点。可每个人自以为最完美的安排，终究无法让每一个人信服啊，正如“朱一旦”们喜欢“非洲安排”，马小策与张策，说到底不过是一种代号而已，当这种“安排”无法调和的时候，人和神仙一样，都会暴走，都会变身，唯一不同的是，人是要吃饭的，而神仙们早已学会辟谷。 所以，在“救一个人还是救苍生”这个问题上，其实谁都没有错，我特别喜欢李诞在『奇葩说』中表达的一个观点，“以自私却不伤害别人的方式活着，才能维持世界的运转。而正是那些为了宏图伟业不计后果的牺牲‘小猫’的人，频频地让我们的世界陷入「大火」”。朱一旦不想再做“任人摆布”的老板，张策不想再做“默默无名”的幕后英雄，马老师早已看破这一切，“钱没给到位”，“心委屈了”，身在其位时榨干身体的“996”，人走茶凉时送瘟神般“高效”，一冷一热，果然是“环球同此凉热”呢。在全球变暖的趋势下，如果我们以自私却不伤害别人的方式活着，虽然活得有一点清冷、没有人情味，但这样是不是会更安心一点，骨子里与生俱来就带着“竞争”的基因的我们，是不是一定要学会“狠”、学会“不择手段”、学会“伤害”。我二十多岁的时候，想努力去照顾好一个人，而等到我快要三十岁的时候，我终于能勉强照顾好自己，这简直是一种幸运。 这种感慨在某个场景下会更加明显，譬如一个人去看电影的时候，虽然我很喜欢和邻座的小朋友说话，可对方父母一句友善的“叔叔”，终于还是让两个人产生了距离。譬如找工作面试的时候，发觉三十上下的“哥哥姐姐”们，都开始面对“总监”级别职位时的恍惚感。也许，我们这一代人真的已经老了吧，而那个人早已离开你很久很久，我无意去对立资本家与劳动者间积怨久矣的矛盾，更无意去揣测封神台下蛰伏已久的阴谋。回想以前，乐无异在『古剑奇谭2』中说出一句，“众生虽苦，还请诸恶莫作”，当时大概只是觉得这句话酷到不行，倘若议论公平，C座802诸如三濑子、马小玲、马小浩等等角色，每一个都带着无数的梗，没有他们就没有整个朱一旦宇宙，当人们为张策惋惜的时候，是不是就选择性地遗忘了他们呢？朱一旦不会成为劳苦大众的代言人，而且任何人都不会，因为一切的流量到最后都是生意。 我在B站关注过一位阿婆主，起初，他在厂里打工，下班后的“入味儿”是他主要的拍摄内容。后来，因为疫情的原因，他开始学别人拍做菜的视频。再后来，发现他变成了一位外卖小哥。世人皆苦，家家有本难念的经，可我们除了祝福以外，又能做一点什么呢？成人世界里，利益、立场、观点……，该有的一切都有，唯独没有对错，希望一个组织有一致的步伐、一致的声音，可偏偏人是一根会思考的芦苇，我知道，当一个人在某一种身份下，他必须要去推动一种文化形成，可如果这些声音连他自己都不信，这种文化的底蕴应该不会特别丰富，很容易成为政治博弈的牺牲品。我从前天真地以为，在互联网这样一个相对开放的环境里，不会存在政治这种产物。而出于对这种东西的逃避，我没有选择成为三线小城市里的一个公务员，实际上我尝试过，结果证明我真的不适合。可后来我发现我错了，只要有人的地方就会存在政治，无论是公司还是社区，每天都有人宣扬这样或者那样的“文化”，这个时候，我希望我们每一个人都去用心甄别这些概念，因为作为人的自觉，他只会说对自己有利的话，正如择偶标准是最毫无标准可言的标准一样，王垠说编程世界里充满宗派，就是最好的证明。 所以，我不大愿意去统一什么东西，充满多样性、充满个性的世界，才是一个正常的世界，以结果论的观点而言，只要能送大家都目的地，是飞机还是高铁还是火车，真的重要吗？如果非要去统一什么，我希望是“语言”或者“领域语言”，因为，我们的沟通，因为存在太多的翻译而逐渐失真、甚至被曲解，我们一般把这样的沟通称之为扯皮，就像土味情话虽然美妙动听，但它携带了大量无用的信息。所以，即使冒着成为“钢铁直男”的危险，我依然想成为一个表达清晰的人。有人说，姜子牙就不能和原始天尊好好商量一下吗？非要自断天梯逼得鸿钧老祖出手吗？人类啊，归根到底，只愿意相信自己相信的，只愿意看见自己看见的，这种意念在成年后往往更加强烈，有多少遗憾就是得不到有效沟通造成的呢？九尾狐自觉被原始天尊欺骗、过河拆桥，而原始天尊认为“非我族类，其心必异”，都是选择性地相信了自己愿意去相信的东西。有人说，姜子牙有强迫症，为什么会任由师尊披头散发？因为不是每个人都能像约翰·纳什那样，在最亲密的人面前直抒胸臆，人类就是这么奇怪，和陌生人玩什么真心话大冒险，在亲人面前反而含蓄、羞怯起来，可能是因为某种特殊的磁力限制了声道发声吧，科学与玄学往往就是这么切换自如。 思绪就像一个无底黑洞，姜子牙与朱一旦，两个八竿子不十竿子都打不着的人，就这么神奇地在我脑海里，完成了一次对话。如果思维存在奇点，将会坍陷于何处，苏格拉有没有底不重要，马老师们谁说得对同样不重要，甚至你看我这满纸荒唐言依然不重要，它仅仅表明我此时此刻在思考，我是一个活生生的人，所谓“我思故我在”，无非给枯燥的人生多一点无用的点缀罢了，你说朱一旦都不枯燥了，我们却还停留在这里，你说，还有比这个更枯燥的事情吗？申公豹形神俱灭，从头开始修行，居然连基因都发生了突变，大概，在这世间，没有什么可以永恒。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://qinyuanpei.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"生活","slug":"生活","permalink":"https://qinyuanpei.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"}]},{"title":"基于选项模式实现.NET Core的配置热更新","date":"2020-10-11T12:19:02.000Z","path":"posts/835719605/","text":"最近在面试的时候，遇到了一个关于 .NET Core 配置热更新的问题，顾名思义，就是在应用程序的配置发生变化时，如何在不重启应用的情况下使用当前配置。从 .NET Framework 一路走来，对于 Web.Config 以及 App.Config 这两个配置文件，我们应该是非常熟悉了，通常情况下， IIS 会检测这两个配置文件的变化，并自动完成配置的加载，可以说它天然支持热更新，可当我们的视野伸向分布式环境的时候，这种配置方式就变得繁琐起来，因为你需要修改一个又一个配置文件，更不用说这些配置文件可能都是放在容器内部。而有经验的朋友，可能会想到，利用 Redis 的发布-订阅来实现配置的下发，这的确是一个非常好的思路。总而言之，我们希望应用可以随时感知配置的变化，所以，在今天这篇博客里，我们来一起聊聊 .NET Core 中配置热更新相关的话题，这里特指全新的选项模式(Options)。 Options三剑客在 .NET Core 中，选项模式(Options)使用类来对一组配置信息进行强类型访问，因为按照接口分隔原则(ISP)和关注点分离这两个工程原则，应用的不同部件的配置应该是各自独立的，这意味着每一个用于访问配置信息的类，应该是只依赖它所需要的配置信息的。举一个简单的例子，虽然 Redis 和 MySQL 都属于数据持久化层的设施，但是两者属于不同类型的部件，它们拥有属于各自的配置信息，而这两套配置信息应该是相互独立的，即 MySQL 不会因为 Redis 的配置存在问题而停止工作。此时，选项模式(Options)推荐使用两个不同的类来访问各自的配置。我们从下面这个例子开始： 1234567891011121314151617181920&#123; \"Learning\": &#123; \"Years\": 5, \"Topic\": [ \"Hotfix\", \".NET Core\", \"Options\" ], \"Skill\": [ &#123; \"Lang\": \"C#\", \"Score\": 3.9 &#125;, &#123; \"Lang\": \"Python\", \"Score\": 2.6 &#125;, &#123; \"Lang\": \"JavaScript\", \"Score\": 2.8 &#125; ] &#125;&#125; 此时，如果希望访问Learning节点下的信息，我们有很多种实现方式： 12345678//方式1var learningSection = Configuration.GetSection(\"Learning\");var careerYears = learningSection.GetValue&lt;decimal&gt;(\"Years\");var topicHotfix = learningSection.GetValue&lt;string&gt;(\"Topic:0\");//方式2var careerYears = Configuration[\"Learning:Years\"];var topicHotfix = Configuration[\"Learning:Topic:0\"); 而更好的方式是，定义一个类来访问这组配置信息： 1234567891011121314 [Serializable]public class LearningOptions&#123; public decimal Years &#123; get; set; &#125; public List&lt;string&gt; Topic &#123; get; set; &#125; public List&lt;SkillItem&gt; Skill &#123; get; set; &#125;&#125;[Serializable]public class SkillItem&#123; public string Lang &#123; get; set; &#125; public decimal? Score &#123; get; set; &#125;&#125; 同样地，茴香的茴字有几种写法，你可知道? 12345678910111213141516171819//写法1：手动绑定var leaningOptions = new LearningOptions();Configuration.GetSection(\"Learning\").Bind(leaningOptions);//写法2：自动绑定leaningOptions = Configuration.GetSection(\"Learning\").Get&lt;LearningOptions&gt;();//写法3：自动绑定 + 依赖注入services.Configure&lt;LearningOptions&gt;(Configuration.GetSection(\"Learning\"));//写法4：配置的二次加工services.PostConfigure&lt;LearningOptions&gt;(options =&gt; options.Years += 1);//写法5：委托绑定services.Configure&lt;AppInfoOptions&gt;(options =&gt;&#123; options.AppName = \"ASP.NET Core\"; options.AppVersion = \"1.2.1\";&#125;); 我们知道，在 .NET Core 里依赖注入被提升到了一等公民的位置，可谓是无处不在。当我们在 IoC 容器中注入LearningOptions以后，就可以在服务层或者控制器层直接使用它们，此时，我们就会遇到传说中的Options三剑客，即IOptions&lt;TOptions&gt;、IOptionsSnapshot&lt;TOptions&gt;和IOptionsMonitor&lt;TOptions&gt;。关于它们三个的区别，官方文档里给出了详细的说明： IOptions：生命周期为Singleton，在应用启动时完成初始化。应用启动后，对配置的修改是非响应式的。 IOptionsSnapshot：生命周期为Scoped，每次请求时会重新计算选项。应用启动后，对配置的修改是响应式的。 IOptionsMonitor：生命周期为Singleton，可以随时检索当前配置项。应用启动后，对配置的修改是响应式的。 是不是听起来有一点还有一点绕？长话短说就是，如果希望修改完配置立即生效，那么，更推荐使用IOptionsSnapshot&lt;TOptions&gt;和IOptionsMonitor&lt;TOptions&gt;，前者是在下一次请求时生效，后者则是访问CurrentValue的时候生效。而对于像3.14或者0.618这种运行时期间不会修改的“常量”，更推荐使用IOptions&lt;TOptions&gt;。下面是关于它们的一个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041[ApiController][Route(\"[controller]\")]public class WeatherForecastController : ControllerBase&#123; private readonly ILogger&lt;WeatherForecastController&gt; _logger; private readonly IOptions&lt;LearningOptions&gt; _learningOptions; private readonly IOptionsSnapshot&lt;LearningOptions&gt; _learningOptionsSnapshot; private readonly IOptionsMonitor&lt;LearningOptions&gt; _learningOptionsMonitor; private readonly IConfiguration _configuration; public WeatherForecastController(ILogger&lt;WeatherForecastController&gt; logger, IOptions&lt;LearningOptions&gt; learningOptions, IOptionsSnapshot&lt;LearningOptions&gt; learningOptionsSnapshot, IOptionsMonitor&lt;LearningOptions&gt; learningOptionsMonitor, IConfiguration configuration ) &#123; _logger = logger; _learningOptions = learningOptions; _learningOptionsSnapshot = learningOptionsSnapshot; _learningOptionsMonitor = learningOptionsMonitor; _configuration = configuration; _learningOptionsMonitor.OnChange((options, value) =&gt; &#123; _logger.LogInformation($\"OnChnage =&gt; &#123;JsonConvert.SerializeObject(options)&#125;\"); &#125;); &#125; [HttpGet(\"&#123;action&#125;\")] public ActionResult GetOptions() &#123; var builder = new StringBuilder(); builder.AppendLine(\"learningOptions:\"); builder.AppendLine(JsonConvert.SerializeObject(_learningOptions.Value)); builder.AppendLine(\"learningOptionsSnapshot:\"); builder.AppendLine(JsonConvert.SerializeObject(_learningOptionsSnapshot.Value)); builder.AppendLine(\"learningOptionsMonitor:\"); builder.AppendLine(JsonConvert.SerializeObject(_learningOptionsMonitor.CurrentValue)); return Content(builder.ToString()); &#125;&#125; 现在我们修改一下配置文件，因为我们为_learningOptionsMonitor注册了回调函数，可以在控制台看到对应的日志： 监听配置文件变化 此时，我们通过 Postman 调用接口，我们会得到下面的结果： learningOptions的值并未更新 可以注意到，此时，learningOptions中的值依然是更新前的值，这就是它们三者的区别，清楚了吗？ 除了这些以外，选项模式(Options)中还有一个需要注意的地方，是所谓的命名选项(IConfigureNamedOptions)，主要用在多个Section绑定统一属性时。譬如现在的应用程序都流行深色主题，实际上深色主题和浅色主题具有相同的结构，比如前景色和背景色，两者唯一的区别是这些颜色配置不一样。考虑下面的配置信息： 123456789101112&#123; \"Themes\": &#123; \"Dark\": &#123; \"Foreground\": \"#fff\", \"Background\": \"#000\" &#125;, \"White\": &#123; \"Foreground\": \"#000\", \"Background\": \"#fff\" &#125; &#125;&#125; 此时，我们该如何定义这个主题选项呢？ 12345public class ThemeOptions&#123; public string Foreground &#123; get; set; &#125; public string Background &#123; get; set; &#125;&#125; 接下来，我们通过命名的方式来注入两个不同的主题： 12services.Configure&lt;ThemeOptions&gt;(\"DarkTheme\", Configuration.GetSection(\"Themes:Dark\"));services.Configure&lt;ThemeOptions&gt;(\"WhiteTheme\", Configuration.GetSection(\"Themes:White\")); 在任何你希望使用它们的地方，注入IOptionsSnapshot&lt;ThemeOptions&gt;和IOptionsMonitor&lt;ThemeOptions&gt;即可，这两个类型都提供了一个Get()方法，传入前面定义好的主题就可以获取到对应的主题了。细心的朋友，应该会发现一件事情，这里三剑客只提到了后面两个，IOptions&lt;ThemeOptions&gt;直接被无视了。请记住下面这段话：命名的选项只能通过IOptionsSnapshot和IOptionsMonitor来访问。所有选项都是命名实例。 IConfigureOptions 实例将被视为面向 Options.DefaultName 实例，即 string.Empty。 IConfigureNamedOptions 还可实现 IConfigureOptions。 IOptionsFactory 的默认实现具有适当地使用每个实例的逻辑。 null 命名选项用于面向所有命名实例，而不是某一特定命名实例。 ConfigureAll 和 PostConfigureAll 使用此约定。 IChnageToken现在，让我们回到本文的主题，博主你不是要说配置热更新这个话题吗？截至到目前为止，我们修改配置文件的时候，ASP.NET Core 应用明明就会更新配置啊，所以，博主你到底想说什么？其实，博主想说的是，的确我们的目的已经达到了，但我们不能永远停留在“知其然”的水平，如果不试图去了解内在的机制，当我们去尝试实现一个自定义配置源的时候，就会遇到一些你没有办法想明白的事情。所以，接下来要讲的IChnageToken这个接口可以说是非常重要。 首先，我们把目光聚焦到CreateDefaultBuilder这个方法，它通常在入口文件Program.cs中被调用，主要作用是构造一个IWebHostBuilder实例并返回，下面是这个方法的内部实现，博主这里对其进行了精简： 123456789101112131415161718192021222324252627public static IWebHostBuilder CreateDefaultBuilder(string[] args)&#123; //以下简化后的代码片段 builder.ConfigureAppConfiguration((hostingContext, config) =&gt; &#123; var env = hostingContext.HostingEnvironment; config.AddJsonFile(\"appsettings.json\", optional: true, reloadOnChange: true) .AddJsonFile($\"appsettings.&#123;env.EnvironmentName&#125;.json\", optional: true, reloadOnChange: true); if (env.IsDevelopment()) &#123; var appAssembly = Assembly.Load(new AssemblyName(env.ApplicationName)); if (appAssembly != null) &#123; config.AddUserSecrets(appAssembly, optional: true); &#125; &#125; config.AddEnvironmentVariables(); if (args != null) &#123; config.AddCommandLine(args); &#125; &#125;)&#125; 可以注意到，通过ConfigureAppConfiguration()方法，框架主要做了下面的工作： 从appsettings.json和appsettings.${env.EnvironmentName}.json两个配置文件中加载配置 从机密管理器中加载配载 从环境变量中加载配置 从命令行参数中加载配置 实际上，.NET Core 可以从配置文件、环境变量、Azure Key Vault、Azure 应用程序配置、命令行参数、已安装或已创建的自定义提供程序、目录文件、内存中的 .NET 对象等各种各样的来源中加载配置，这里的appsettings.json使用的是JsonConfigurationProvider类，位于Microsoft.Extensions.Configuration.Json这个命名空间，可以注意到，它继承自FileConfigurationProvider类，并重写了Load()方法，通过这些关系，我们最终可以找到这样一段代码： 123456789101112131415161718public FileConfigurationProvider(FileConfigurationSource source)&#123; if (source == null) &#123; throw new ArgumentNullException(nameof(source)); &#125; Source = source; if (Source.ReloadOnChange &amp;&amp; Source.FileProvider != null) &#123; _changeTokenRegistration = ChangeToken.OnChange( () =&gt; Source.FileProvider.Watch(Source.Path), () =&gt; &#123; Thread.Sleep(Source.ReloadDelay); Load(reload: true); &#125;); &#125;&#125; 所以，真相就是,所有基于文件的配置提供者，都依赖于FileConfigurationSource，而通过FileConfigurationSource暴露出来的FileProvider都具备监视文件变化的能力，更本质上的代码其实应该是下面这样： 12345678910//ChangeToken + IFileProvider 实现对文件的监听var filePath = @\"C:\\Users\\admin\\Downloads\\孔乙己.txt\";var directory = System.IO.Path.GetDirectoryName(filePath);var fileProvider = new PhysicalFileProvider(directory);ChangeToken.OnChange( () =&gt; fileProvider.Watch(\"孔乙己.txt\"), () =&gt; &#123; _logger.LogInformation(\"孔乙己，你一定又偷人家书了吧！\"); &#125;); 所以，真相只有一个，真正帮助我们实现配置热更新的，其实是IChangeToken这个接口，我们只需要把这样一个实例传入到ChangeToken.OnChange()方法中，就可以在特定的时机触发这个回调函数，而显然，对于大多数的IConfigurationProvider接口而言，这个回调函数其实就是Load()方法，关于微软提供的ChangeToken静态类的实现，大家如果有兴趣去了解的话，可以参考这里：https://github.com/dotnet/extensions/blob/release/3.1/src/Primitives/src/ChangeToken.cs。话说回来，我们说IOptionsSnapshot&lt;T&gt;和IOptionsMonitor&lt;T&gt;是响应式的，当配置发生改变的时候，它们对应的值会跟着改变，从某种意义上来说，是因为IChangeToken提供了这样一个可以监听变化的的能力，试想一下，我们只需要给每一个IConfigurationProvider对应的IChangeToken注册相同的回调函数，那么，当某一个IConfigurationProvider需要重新加载的时候，我们就可以针对这个IConfigurationProvider里对应的键值对进行处理。事实上，微软官方在实现IConfigurationRoot的时候，的确就是这样做的： 12345678910111213141516171819202122232425262728293031public class ConfigurationRoot : IConfigurationRoot&#123; private ConfigurationReloadToken _changeToken = new ConfigurationReloadToken(); private IList&lt;IConfigurationProvider&gt; _providers; public ConfigurationRoot(IList&lt;IConfigurationProvider&gt; providers) &#123; _providers = providers; foreach (var provider in providers) &#123; provider.Load(); ChangeToken.OnChange(() =&gt; provider.GetReloadToken(), this.RaiseChanged); &#125; &#125; public IChangeToken GetReloadToken() =&gt; return _changeToken; private void RaiseChanged() &#123; Interlocked.Exchange&lt;ConfigurationReloadToken&gt;(ref _changeToken, new ConfigurationReloadToken()).OnReload(); &#125; public void Reload() &#123; foreach (var provider in _providers) &#123; provider.Load(); &#125; this.RaiseChanged(); &#125; &#125; 自定义配置源好了，现在你可以说你了解 .NET Core 的配置热更新这个话题了，因为截至到此时此刻，我们不仅仅达到了一开始的目的，而且深刻地理解了它背后蕴含的原理。这样，我们就可以向着下一个目标：自定义配置源努力了。前面提到过，.NET Core里面支持各种各样的配置源，实际中可能会遇到更多的配置源，比如不同的数据库、YAML格式以及Apollo、Consul、Nacos这些配置中心等等，所以，了解如何去写一个自定义的配置源还是非常有必要的。我们在一开始的时候提到了Redis的发布-订阅，那么，下面我们就来基于发布-订阅实现一个简单的配置中心，当我们需要修改配置时，只需要通过可视化的Redis工具进行修改，然后再给指定的客户端发一条消息即可。 实现自定义配置源，需要实现IConfigurationSource和IConfigurationProvider两个接口，前者实现起来非常简单，因为只要返回我们定义的RedisConfigurationProvider实例即可： 1234567891011121314public class RedisConfigurationSource : IConfigurationSource&#123; private readonly RedisConfigurationOptions _options; public RedisConfigurationSource(RedisConfigurationOptions options) &#123; _options = options; &#125; public IConfigurationProvider Build(IConfigurationBuilder builder) &#123; return new RedisConfigurationProvider(_options); &#125;&#125; 接下来是RedisConfigurationProvider类的实现： 123456789101112131415161718192021public class RedisConfigurationProvider : ConfigurationProvider&#123; private CSRedisClient _redisClient; private readonly RedisConfigurationOptions _options; public RedisConfigurationProvider(RedisConfigurationOptions options ) &#123; _options = options; _redisClient = new CSRedisClient(_options.ConnectionString); if (options.AutoReload) &#123; //利用Redis的发布-订阅重新加载配置 _redisClient.Subscribe((_options.HashCacheChannel, msg =&gt; Load())); &#125; &#125; public override void Load() &#123; Data = _redisClient.HGetAll&lt;string&gt;(_options.HashCacheKey) ?? new Dictionary&lt;string, string&gt;(); &#125;&#125; 为了用起来更得心应手，扩展方法是少不了的： 1234567public static class RedisConfigurationExtensions&#123; public static IConfigurationBuilder AddRedisConfiguration(this IConfigurationBuilder builder, RedisConfigurationOptions options) &#123; return builder.Add(new RedisConfigurationSource(options)); &#125;&#125; 现在，我们改一下入口类Program.cs，因为在这个阶段依赖注入是无法使用的，所以，看起来有一点难受，从命名就可以看出来，内部使用了Hash这种结构，理论上每个客户端应该使用不同的Key来进行缓存，应该使用不同的Channel来接收配置更新的通知： 12345678910111213141516public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .ConfigureAppConfiguration(configurationBuilder =&gt; &#123; configurationBuilder.AddRedisConfiguration(new Models.RedisConfigurationOptions() &#123; AutoReload = true, ConnectionString = \"127.0.0.1:6379\", HashCacheKey = \"aspnet:config\", HashCacheChannel = \"aspnet:config:change\" &#125;); &#125;) .ConfigureWebHostDefaults(webBuilder =&gt; &#123; webBuilder.UseStartup&lt;Startup&gt;(); &#125;); 假设现在Redis里存储着下图所示的信息： Redis中的存储结构 相应地，我们可以在Startup中进行绑定： 1services.Configure&lt;AppInfoOptions&gt;(Configuration.GetSection(\"App\")); 调一下接口看看？完全一致！Yes！ Redis与客户端的配置一致 本文小结回想起这个面试中“邂逅”的问题，针对对这块内容，其实当时并没有和面试官进行太深的交流，提到了分布式配置、配置中心以及像缓存的雪崩、击穿等等常见的问题，我隐约记得配置文件appsettings.json配置的部分有热更新的配置项，但我并没有对选项模式(Options)里的三剑客做过深入的挖掘，所以，这篇博客，一方面是系统地了解了一下选项模式(Options)的使用，而另一方面是由配置热更新这个话题引申出来的一系列细节，在没有理解IChangeToken的时候，实现一个自定义的配置源是有一点困难的，在这篇博客的最后，我们基于Redis的发布-订阅实现了一个简单的配置中心，不得不说，Redis里用:来分割Key的方式，实在是太棒了，因为它可以完美地和 .NET Core 里的配置系统整合起来，这一点只能用赏心悦目来形容，好了，国庆节以后的第一篇博客就是这样了，谢谢大家！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"配置中心","slug":"配置中心","permalink":"https://qinyuanpei.github.io/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/"},{"name":"配置","slug":"配置","permalink":"https://qinyuanpei.github.io/tags/%E9%85%8D%E7%BD%AE/"}]},{"title":"Dapper.Contrib在Oracle环境下引发ORA-00928异常问题的解决","date":"2020-09-05T14:28:20.000Z","path":"posts/3086300103/","text":"话说最近这两周里，被迫官宣996的生活实在是无趣，在两周时间里安排三周的工作量，倘若用丞相的口吻来说，那便是: 我从未见过有如此厚颜无耻之人。无法为工作的紧急程度排出优先级，这便是身为肉食者们的鄙。古人云：肉食者鄙，未能远谋，诚不欺我也。一味地追求快速迭代，“屎”山越滚越高没有人在乎；一味地追求功能叠加，技术债务越来越多没有人在乎。所以，本着“多一事不如少一事”的原则，直接通过 Dapper 写 SQL 语句一样没有问题，因为被压榨完以后的时间只能写这个。在今天的这篇博客里，我想和大家分享的是，Dapper.Contrib在操作 Oracle 数据库时引发 ORA-00928: 缺失 SELECT 关键字 这一错误背后的根本原因，以及 Dapper 作为一个轻量级 ORM 在设计上做出的取舍。 问题回顾在使用 Dapper.Contrib 操作 Oracle 数据库的时候，通过 Insert() 方法来插入一个实体对象，此时，会引发 ORA-00928: 缺失 SELECT 关键字 这种典型的 Oracle 数据库错误，对于经常使用 Dapper 的博主而言，对于 @ 还是 : 这种无聊的语法还是有一点经验的，在尝试手写 SQL 语句后，发现使用 Dapper 提供的 Execute() 扩展方法一点问题都没有，初步判定应该是 Dapper.Contrib 这个扩展库的问题，在翻阅 Dapper 的源代码以后，终于找到了问题的根源所在，所以，下面请跟随博主的目光，来一起解读解读 Dapper.Contrib 这个扩展库，相信你看完以后就会明白，为什么这里会被 Oracle 数据库摆上一道，以及为什么它至今都不考虑合并 Oracle 数据库相关的PR。 原因分析众所周知，Dapper 的核心其实就是一个 SqlMapper ，它提供的 Query() 和 Execute() 接口本身都是附加在 IDbConnection 接口上的扩展方法，所以，最基础的 Dapper 用法其实是伴随着 SQL 语句和以匿名对象为主的参数化查询，这可以说是 Dapper 的核心，而 Dapper.Contrib 在这个基础上提供了 Get()、Insert()、Delete() 和 Update() 等等常见的 CRUD 方法，这些方法都针对的是单主键的表，让 Dapper有了一点 ORM 的感觉，可惜的是 Dapper.Contrib 的实现是不完整的，主要是指下面两个方面，即：第一，官方未能提供 Oracle 版本的 ISqlAdapter。第二，兼容不同数据库自增ID的实现，让官方在处理Id的参数化查询时束手束脚，对 ISqlAdapter 的设计并不全面。 Oracle版本的ISqlAdapter首先，第一个结论，Dapper.Contrib 没有实现 Oracle 版本的 ISqlAdapter 。关于这个接口，我们可以在 SqlMapperExtensions 这个类中找到定义，而 Dapper.Contrib 内部实际上是维护了一个字典 AdapterDictionary ，在 SqlMapperExtensions.cs 文件的第 62 行 ~ 第 73 行，我们可以注意到，其内部提供了6种 ISqlAdapter 的实现，且默认为 SqlServerAdapter ： 1234567891011private static readonly ISqlAdapter DefaultAdapter = new SqlServerAdapter();private static readonly Dictionary&lt;string, ISqlAdapter&gt; AdapterDictionary = new Dictionary&lt;string, ISqlAdapter&gt;(6) &#123; [\"sqlconnection\"] = new SqlServerAdapter(), [\"sqlceconnection\"] = new SqlCeServerAdapter(), [\"npgsqlconnection\"] = new PostgresAdapter(), [\"sqliteconnection\"] = new SQLiteAdapter(), [\"mysqlconnection\"] = new MySqlAdapter(), [\"fbconnection\"] = new FbAdapter() &#125;; 一个自然而然的问题是，这个 ISqlAdapter 接口是做什么的呢？为什么说 Dapper.Contrib 没有实现 Oracle 版本的 ISqlAdapter 呢？如果我们看一下 ISqlAdapter 的定义，就可以了解到其作用是告诉 Dapper ，应该怎么样处理数据库里的自增ID、怎么样表示 Column = Value 这样的结构，以及怎么样处理列名： 12345678910public partial interface ISqlAdapter&#123; int Insert(IDbConnection connection, IDbTransaction transaction, int? commandTimeout, string tableName, string columnList, string parameterList, IEnumerable&lt;PropertyInfo&gt; keyProperties, object entityToInsert ); void AppendColumnName(StringBuilder sb, string columnName); void AppendColumnNameEqualsValue(StringBuilder sb, string columnName);&#125; 这里以 MySqlAdapter 的实现为例： 123456789101112131415161718192021222324252627282930313233public partial class MySqlAdapter : ISqlAdapter&#123; public int Insert(IDbConnection connection, IDbTransaction transaction, int? commandTimeout, string tableName, string columnList, string parameterList, IEnumerable&lt;PropertyInfo&gt; keyProperties, object entityToInsert ) &#123; var cmd = $\"insert into &#123;tableName&#125; (&#123;columnList&#125;) values (&#123;parameterList&#125;)\"; connection.Execute(cmd, entityToInsert, transaction, commandTimeout); var r = connection.Query(\"Select LAST_INSERT_ID() id\", transaction: transaction, commandTimeout: commandTimeout); var id = r.First().id; if (id == null) return 0; var propertyInfos = keyProperties as PropertyInfo[] ?? keyProperties.ToArray(); if (propertyInfos.Length == 0) return Convert.ToInt32(id); var idp = propertyInfos[0]; idp.SetValue(entityToInsert, Convert.ChangeType(id, idp.PropertyType), null); return Convert.ToInt32(id); &#125; public void AppendColumnName(StringBuilder sb, string columnName) &#123; sb.AppendFormat(\"`&#123;0&#125;`\", columnName); ｝ public void AppendColumnNameEqualsValue(StringBuilder sb, string columnName) &#123; sb.AppendFormat(\"`&#123;0&#125;` = @&#123;1&#125;\", columnName, columnName); &#125;&#125; 相信看到这里的时候，大家会和我一样感到失望，因为 Dapper 的底层依然是在拼 SQL ，尤其是看到 AppendColumnNameEqualsValue() 这个方法的时候，会有一种恍然大明白的感觉，因为 @ 这个符号对于 Dapper 的参数化查询而言，实在是熟悉得不能再熟悉了。我们都知道为 Dapper 写 SQL 语句的时候，要对 Oracle 区别对待，因为这个奇葩非要用 : 这个奇怪的符号。回到我们一开始的问题，为啥 Dapper.Contrib 在 Oracle 环境下会提示 ORA-XXXXX 这种鬼都看不明白的错误，因为它在处理 SQL 的语句的时候依然使用的是 @ 这个符号。这又是为什么呢？因为当指定的 IDbConnection 在 AdapterDictionary 中不存在的时候，它会使用默认的 SqlServerAdapter ，显然，全世界只有 Oracle 这个奇葩会用 : 这个奇怪的符号。我们不是在调用 Insert() 方法的时候提示这个错误吗？那么 Dapper.Contrib 是怎么实现 Insert() 方法的呢？这个部分实现主要在第 352 行 ~ 第 360 行： 123456789var adapter = GetFormatter(connection);for (var i = 0; i &lt; allPropertiesExceptKeyAndComputed.Count; i++) &#123; var property = allPropertiesExceptKeyAndComputed[i]; adapter.AppendColumnName(sbColumnList, property.Name); //fix for issue #336 if (i &lt; allPropertiesExceptKeyAndComputed.Count - 1) sbColumnList.Append(\", \"); &#125; 显然，这部分是按照属性名去组织 columnList 和 parameterList 的过程，对于 Oracle ，永远是充满吐槽的，比如不加双引号则强制大写的设定，这意味着如果你的表名或者字段名是区分大小写的话，在 Oracle 这里都要加上双引号，这对 Dapper.Contrib 有什么影响呢？原本我们只需要给实体添加[Table]标签即可，而现在你不得不考虑带上反斜杠转义，甚至当你需要为 DBeaver 下载一个JDBC的驱动的时候，甲骨文这家公司居然要强制你去注册，对于一个习惯像·.NET Core、GCC、Python、Lua 和 Node 这样开箱即用的人来说，这就像强迫你注册一大堆真实信息，然后发现 API 接口完全无法匹配你的需求一样痛苦。关于 GetFormatter() 方法，它和我们猜想的完全一致： 12345private static ISqlAdapter GetFormatter(IDbConnection connection)&#123; var name = GetDatabaseType?.Invoke(connection).ToLower() ?? connection.GetType().Name.ToLower(); return AdapterDictionary.TryGetValue(name, out var adapter) ? adapter : DefaultAdapter;&#125; 好了，在明白了以上种种因果关系以后，我们现在来考虑如何解决 Oracle 的问题。按照人类最直观的思维，既然它没有实现 Oracle 版本的 ISqlAdapter ，我自己实现一个不就好啦： 1234567891011121314151617181920212223242526public class OracleSqlAdapter : ISqlAdapter&#123; public void AppendColumnName(StringBuilder sb, string columnName) &#123; sb.AppendFormat(\"&#123;0&#125;\", columnName); &#125; public void AppendColumnNameEqualsValue(StringBuilder sb, string columnName) &#123; sb.AppendFormat(\"&#123;0&#125; = :&#123;1&#125;\", columnName, columnName); &#125; public int Insert(IDbConnection connection, IDbTransaction transaction, int? commandTimeout, string tableName, string columnList, string parameterList, IEnumerable&lt;PropertyInfo&gt; keyProperties, object entityToInsert) &#123; var sql = $\"insert into &#123;tableName&#125; (&#123;columnList&#125;) values (&#123;parameterList&#125;)\"; return connection.Execute(sql, entityToInsert, transaction, commandTimeout); &#125; public Task&lt;int&gt; InsertAsync(IDbConnection connection, IDbTransaction transaction, int? commandTimeout, string tableName, string columnList, string parameterList, IEnumerable&lt;PropertyInfo&gt; keyProperties, object entityToInsert) &#123; var sql = $\"insert into &#123;tableName&#125; (&#123;columnList&#125;) values (&#123;parameterList&#125;)\"; return connection.ExecuteAsync(sql, entityToInsert, transaction, commandTimeout); &#125;&#125; 坦白说， Dapper.Contrib 这种纯静态类的设计，完全就不给别人留扩展的口子，为此，扩展方法 + 反射搞一个突破口： 123456789101112131415 public static class SqlAdapterrExtensions &#123; public static void UseSqlAdapter&lt;TSqlAdapter&gt;(this IDbConnection connection, TSqlAdapter sqlAdapter) where TSqlAdapter : ISqlAdapter, new() &#123; var adapters = (Dictionary&lt;string, ISqlAdapter&gt;) typeof(SqlMapperExtensions) .GetField(\"AdapterDictionary\", BindingFlags.NonPublic | BindingFlags.Instance | BindingFlags.Static) ?.GetValue(null); var connectionType = connection.GetType().Name.ToLower(); if (adapters != null &amp;&amp; !adapters.ContainsKey(connectionType)) adapters?.Add(connectionType, sqlAdapter); &#125;&#125; 这样，我们不但可以满足眼下，还可以着眼未来，虽然未来有时候挺遥远，但梦想还是要有的，开闭原则，我做到了！改进后，我们这样处理即可： 12connection = new OracleConnection(ConnectionStrings.Default);connection.UseSqlAdapter(new OracleSqlAdapter()); 此时，我们发现，我们解决了 Insert() 的问题，但随之而来的，Get()、Delete()、Update() 这一系列和主键相关的方法，都因为 Dapper.Contrib 中的主键设计而出现了问题，而这就是我们接下来要讲的主键Id参数化问题。 主键Id参数化问题当我谈起这个问题的时候，我对于 Dapper.Contrib 中支持自增ID的坚持是怀疑的，因为在分布式盛行的今天，有大量的分布式ID生成方案供我们选择，比如基于 Redis 的号段策略，基于雪花算法的ID生成等等。大家会注意到我实现的 OracleSqlAdapter 在实现 Insert() 方法的时候简化了大量代码，这是因为我真的不知道，怎么从 Oracle 中获取一个新生成的ID，尤其是这个ID居然还要依赖一个我听都没有听说过的“序列”，而之所以要在 ISqlAdapter 中实现 Insert() 方法，最根本的原因就是，各个数据库对于自增ID的实现是不一样的，比如 MySQL 中使用的是 SCOPE_IDENTITY()，而 MSSQL 中使用的则是 SCOPE_IDENTITY() ，就因为这一点点差异，我们就必须要去折腾一遍，可以说， Dapper.Contrib 不支持 Oracle 的一个重要原因，就是在 Oracle 下实现自增ID太麻烦了。 既然大家都不用自增ID了，为什么还要在一个通用的ORM里折腾这个呢？说实话，我真担心有一天自增ID会溢出，谁让每个数据库里的上限都不一样呢？另一方面，既然Id在每个数据库的实现都不一样，那么，作为Id本身应该考虑放到 ISqlAdapter 接口中由使用者来实现啊，可偏偏 ISqlAdapter 里只定义了一个 Insert() 方法，所以，就算我们实现了 OracleSqlAdapter ，一样无法解决 Insert() 方法以外的其它方法在 Oracle 下面的问题，正因为如此，默认的 @ 符号在 Oracle 环境下下没有被完全替换掉，这就需要修改 Dapper.Contrib 的底层代码，这真的是一个不好的设计，因为使用者完全没有办法通过重写来覆盖某些默认行为，我们一起来看看，需要修改哪些地方： 123456789101112131415161718192021public static T Get&lt;T&gt;(this IDbConnection connection, dynamic id, IDbTransaction transaction = null, int? commandTimeout = null) where T : class&#123; var type = typeof(T); if (!GetQueries.TryGetValue(type.TypeHandle, out string sql)) &#123; var key = GetSingleKey&lt;T&gt;(nameof(Get)); var name = GetTableName(type); //第一个坏事儿的地方，为什么不用AppendColumnName()方法? sql = $\"select * from &#123;name&#125; where &#123;key.Name&#125; = @id\"; GetQueries[type.TypeHandle] = sql; &#125; var dynParams = new DynamicParameters(); //第二个坏事的地方，什么不用AppendColumnName()方法?? dynParams.Add(\"@id\", id); //以下代码已省略&#125; 1234567891011121314151617public static long Insert&lt;T&gt;(this IDbConnection connection, T entityToInsert,IDbTransaction transaction = null, int? commandTimeout = null) where T : class&#123; //以上代码已省略 var sbParameterList = new StringBuilder(null); for (var i = 0; i &lt; allPropertiesExceptKeyAndComputed.Count; i++) &#123; //第三个坏事的地方，什么不用AppendColumnName()方法??? var property = allPropertiesExceptKeyAndComputed[i]; sbParameterList.AppendFormat(\"@&#123;0&#125;\", property.Name); if (i &lt; allPropertiesExceptKeyAndComputed.Count - 1) sbParameterList.Append(\", \"); &#125; //以下代码已省略&#125; 其实，仔细阅读 Update() 和 Delete() 两个方法的实现，就会发现它们都非常完美地避开了这一点，就是不知道为什么只有两个方法采用了不同地方式去拼接 SQL ，当然，这里我们会意识到有个列名的问题，尤其是在需要区分大小写的情况下，为此，我们可能需要去定义一个 ColumnAttribute，还能说什么呢？请和我大声地吐槽：垃圾 Oracle ！你看，就为了这一点点差异，我们不得不去额外写一点代码，所以，喊了很多年的去IOE，我表示举双手赞成。 事实上，社区里已经有类似的PR，可因为改动的范围比较大，官方至今都没有考虑过将其合并到主干分支上，所以，这个问题一直没有解决，这是一个悲伤的故事。 相关思考在阅读 Dapper 源码的同时，我查阅了一个和 Dapper.Contrib 类似的项目：DapperExtension，我发现这个项目目前处在“荒废”的状态，因为它遇到了相同的问题，即 SQL 这门看起来统一实则相当不统一的语言，因为每一个数据库厂商几乎都在给标准“添砖加瓦“，就以自增ID为例，MySQL、MSSQL、Oracle 居然是三种不同的实现方式，尤其是 Oracle 这个奇葩，居然还需要定义一个序列来解决这个问题，这个奇葩给数据库加注释都那么另类，这带来的问题是什么？Dapper.Contrib 无力去实现 Oracle 的自增ID而放弃了 Oracle ，所以，即使社区里提交了PR，因为实现方式有点脏，官方一直没有合并到主干上去。 再回过头来看 Dapper.Contrib 支持自增ID的举动，总会觉得有点不合时宜，因为不同数据库自增ID的上限不一样不说，现在都普遍在分布式的环境中，数据库的自增ID其实是非常鸡肋的功能，而实际应用中常常会用 Redis 、雪花算法等来实现分布式ID，所以，当你回顾历史发展的趋势的时候，就会感慨有标准化的东西该多好，并不是说这个世界不需要多样性，显然这是一个标准约束性不强的领域，看起来大家都实现了SQL，无一例外地都夹藏了私货，对于商业行为而言，这无可厚非；可对于这个世界而言，这无疑增加了工作量。 有时候，当一个行业没有什么标准的时候，到底是突破勇气去率先制定标准，还是放弃自我去迎合各种不成文的规则，对于企业而言，是战略上的一种选择；而对于个人而言，其实是人生的一种选择。当彼时青春年少的人们，竞相以标新立异为荣的时候，如果想到有一天，终究要活成千篇一律的人生，为了生活而选择跪着的时候，内心又会有什么不一样的举动呢？ 本文小结本文分析了 Dapper.Contrib 这个扩展库，在搭配 Oracle 数据库使用时遇到 ORA-XXXXX 系列错误的原因及相应地处理方法，这个问题的表象是 Dapper.Contrib 没有实现 OracleSqlAdapter ，而更深层的原因，实际上是 Dapper.Contrib 选择支持自增ID而带来的 SQL 标准差异化问题。因为不同的数据库在实现自增ID时的机制不同，Oracle 甚至需要引入序列这个概念，这种差异化，增加了 Dapper 各个扩展库维护的工作量，这是官方一直不愿意实现 OracleSqlAdapter 的原因，其次， Dapper.Contrib 底层设计不合理，除了Insert() 方法以外，其它依赖主键的方法都没有提供扩展接口，导致使用者只能通过修改底层代码的方式解决问题，这严重违反开闭原则。好了，这是一篇利用996闲暇(可能是指做梦)写的一篇博客，如果文章中有什么不周到的地方，欢迎大家在博客下面给我留言，谢谢，晚安！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"Dapper","slug":"Dapper","permalink":"https://qinyuanpei.github.io/tags/Dapper/"},{"name":"ORM","slug":"ORM","permalink":"https://qinyuanpei.github.io/tags/ORM/"},{"name":"数据库","slug":"数据库","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"源码","slug":"源码","permalink":"https://qinyuanpei.github.io/tags/%E6%BA%90%E7%A0%81/"}]},{"title":".NET Core中对象池(Object Pool)的使用","date":"2020-08-15T16:37:23.000Z","path":"posts/2414960312/","text":"在此前的博客中，博主参考 eShopOnContainers 实现了一个基于RabbitMQ的事件总线(EventBus)。在这个项目中，它提供了一个持久化连接的类DefaultRabbitMQPersistentConnection，主要解决了RabbitMQ在连接断开后自动重连的问题，可实际上我们都知道，RabbitMQ提供的连接数是有一个上限的，如果频繁地使用短连接的方式，即通过ConnectionFactory的CreateConnection()方法来创建一个连接，从本质上讲，一个Connection对象就是一个TCP连接，而Channel则是每个Connection对象下有限的虚拟连接，注意“有限”这个限定词，这意味着Channel和Connection一样，都不能毫无节制的创建下去。此时，官方推荐的做法有两种：(1)：一个Connection对应多个Channel同时保证每个Channel线程独占；(2)：创建一个Connection池同时定期清除无效连接。这里的第二种做法，显然就是我们今天要说的对象池(Object Pool)啦，我们将从这里拉开这篇博客的帷幕。 什么是对象池首先，我们来回答第一个问题，什么是对象池？简单来说，它就是一种为对象提供可复用性能力的软件设计思路。俗话说“有借有还，再借不难”，而对象池就是通过“借”和“还”这样两个动作来保证对象可以被重复使用，进而节省频繁创建对象的性能开销。对象池在游戏设计中使用的更普遍一点，因为游戏中大量存在着像子弹、怪物等等这类可复用的对象，你在玩第一人称射击游戏(FPS)时，总是有源源不断的子弹或者丧尸出现，可事实上这不过是数字世界的循环再生，因为玩家的电脑内存始终都有一个上限。而在数据库的世界里，则存在着一个被称为“连接池”的东西，每当出现数据库无法连接的情况时，经验丰富的开发人员往往会先检查“连接池”是否满了，这其实就是对象池模式在特定领域的具体实现啦，所以，对象池本质上就是负责一组对象创建和销毁的容器，下面是一个基本的对象池示意图： 对象池示意图 可以注意到， 对象池最大的优势就是可以自主地管理“池子”内的每个对象，决定它们是需要被回收还是可以重复使用。我们都知道，创建一个新的对象，需要消耗一定的系统资源，而一旦这些对象可以重复地使用，就能有效地节省系统资源的开销，这对于我们提高系统性能会非常有帮助。也许，现在计算机的硬件水平越来越好，可我们还是要重新拾起这个领域的基础知识，即数据结构、算法、数学和英语。如果你完全理解了对象池模式，你应该可以非常轻松地给出你的实现： 123456789101112131415161718192021222324public class ObjectPool&lt;T&gt; : IObjectPool&lt;T&gt;&#123; private Func&lt;T&gt; _instanceFactory; private ConcurrentBag&lt;T&gt; _instanceItems; public ObjectPool(Func&lt;T&gt; instanceFactory) &#123; _instanceFactory = instanceFactory ?? throw new ArgumentNullException(nameof(instanceFactory)); _instanceItems = new ConcurrentBag&lt;T&gt;(); &#125; public T Get() &#123; T item; if (_instanceItems.TryTake(out item)) return item; return _instanceFactory(); &#125; public void Return(T item) &#123; _instanceItems.Add(item); &#125;&#125; 注：以上代码片段来自微软的一篇文档：How to: Create an Object Pool by Using a ConcurrentBag。实际上，除了ConcurrentBag&lt;T&gt;，我们可以选择的数据结构还可以是Stack&lt;T&gt;、Queue&lt;T&gt;以及BlockingCollection&lt;T&gt;，此中差别，大家可以自己去体会。 .NET Core中的对象池在.NET Core中，微软已经为我们提供了对象池的实现，即Microsoft.Extensions.ObjectPool。它主要提供了三个核心的组件，分别是ObjectPool、ObjectPoolProvider和IPooledObjectPolicy，关于这三者间的关系，我绘制了下面的UML图来作为说明： ObjectPool核心组件及其关系 可以注意到，ObjectPool&lt;T&gt;是一个抽象类，它对外提供了Get()和Return()两个方法，所谓的“有借有还”，这一点没什么可说的。接下来，ObjectPoolProvider同样是一个抽象类，它的职责就是创建ObjectPool&lt;T&gt;，所以，它提供了两个Create&lt;T&gt;()方法，两者的区别是，无参数版本本质上使用的是DefaultPooledObjectPolicy&lt;T&gt;。顾名思义，它同DefaultObjectPool&lt;T&gt;、DefaultObjectPoolProvider一样，都是微软提供的默认实现，其中IPooledObjectPolicy&lt;T&gt;可以为不同的对象池定义不同的策略，来决定对象如何“借”、是否可以“还”。默认的对象池DefaultObjectPool&lt;T&gt;内部使用ObjectWrapper[]这个数组来管理对象，数组的大小等于maximumRetained - 1，因为它单独指定了首项，默认情况下，这个maximumRetained等于Environment.ProcessorCount * 2，这里主要用到了Interlocked.CompareExchange()方法： 123456789101112131415161718192021222324252627282930313233343536373839public override T Get()&#123; var item = _firstItem; if (item == null || Interlocked.CompareExchange(ref _firstItem, null, item) != item) &#123; var items = _items; for (var i = 0; i &lt; items.Length; i++) &#123; item = items[i].Element; if (item != null &amp;&amp; Interlocked.CompareExchange(ref items[i].Element, null, item) == item) &#123; return item; &#125; &#125; item = Create(); &#125; return item;&#125;// Non-inline to improve its code quality as uncommon path[MethodImpl(MethodImplOptions.NoInlining)]private T Create() =&gt; _fastPolicy?.Create() ?? _policy.Create();public override void Return(T obj)&#123; if (_isDefaultPolicy || (_fastPolicy?.Return(obj) ?? _policy.Return(obj))) &#123; if (_firstItem != null || Interlocked.CompareExchange(ref _firstItem, obj, null) != null) &#123; var items = _items; for (var i = 0; i &lt; items.Length &amp;&amp; Interlocked.CompareExchange(ref items[i].Element, obj, null) != null; ++i) &#123; &#125; &#125; &#125;&#125; 这里主要用到Interlocked.CompareExchange()这个方法，对于Get()方法而言，它将items[i].Element和null进行交换，相当于将指定元素设为null并返回原始值；而对于Return()方法而言，如果将items[i].Element和obj交换后的值不为null，则表示指定元素已经“归还”，因为这个方法只有在第一个参数和第三个参数相等时才会发生交换。好了，了解了.NET Core中对象池的实现以后，我们来一起看看具体的使用： 12345678910111213141516171819202122232425262728293031var service = new ServiceCollection();//使用DefaultObjectPoolProviderservice.AddSingleton&lt;ObjectPoolProvider, DefaultObjectPoolProvider&gt;();//使用默认策略service.AddSingleton&lt;ObjectPool&lt;Foo&gt;&gt;(serviceProvider =&gt;&#123; var objectPoolProvider = serviceProvider.GetRequiredService&lt;ObjectPoolProvider&gt;(); return objectPoolProvider.Create&lt;Foo&gt;();&#125;);//使用自定义策略service.AddSingleton&lt;ObjectPool&lt;Foo&gt;&gt;(serviceProvider =&gt;&#123; var objectPoolProvider = serviceProvider.GetRequiredService&lt;ObjectPoolProvider&gt;(); return objectPoolProvider.Create(new FooObjectPoolPolicy());&#125;);var serviceProvider = _service.BuildServiceProvider();var objectPool = _serviceProvider.GetService&lt;ObjectPool&lt;Foo&gt;&gt;();//有借有还，两次是同一个对象var item1 = objectPool.Get();objectPool.Return(item1);var item2 = objectPool.Get();Assert.AreEqual(item1, item2);//true//有借无还，两次是不同的对象var item3 = objectPool.Get();var item4 = objectPool.Get();Assert.AreEqual(item3, item4);//false 其中，Foo和FooObjectPoolPolicy是两个非常典型的“工具类”，类似我们所说的“工具人”： 123456789101112131415161718192021222324public class Foo&#123; public string Id &#123; get; set; &#125; public DateTime? CreatedAt &#123; get; set; &#125; public string CreatedBy &#123; get; set; &#125;&#125;public class FooObjectPoolPolicy : IPooledObjectPolicy&lt;Foo&gt;&#123; public Foo Create() &#123; return new Foo() &#123; Id = Guid.NewGuid().ToString(\"N\"), CreatedAt = DateTime.Now, CreatedBy = \"Ezio\" &#125;; &#125; public bool Return(Foo obj) &#123; return true; &#125;&#125; 当你需要控制对象池内的对象如何被创建的时候，你可以考虑实现自定义的IPooledObjectPolicy&lt;T&gt;，否则，DefaultPooledObjectPolicy&lt;T&gt;这个默认实现完全可以满足你的使用，而这就是.NET Core中对象池的所有用法，一个实现起来并不复杂但是在某些场景下非常有用的软件设计模式。 回到起点好了，回到我们一开始的问题，即：如何解决RabbitMQ在多次重连后提示连接数不足的问题。由于Channel对象本质上是Connection对象上的TCP连接的软连接，所以，每当创建一个新的Channel的时候，实际上会独占一个TCP连接。考虑到在使用RabbitMQ的时候，发布消息/消费消息每次都是创建一个Channel，在高并发场景下可能会导致TCP连接数被用完，进而出现无法连接或者响应过慢等一系列问题。既然TCP连接数是有限的，为什么不考虑复用这些TCP连接呢？从这个角度上来看，数据库连接池承担了相同的角色，增加连接数说到底是一种“治标不治本”的做法。在具体实现上，可以考虑Connection“池”和Channel“池”，我们我们像官方推荐的做法一样，一个Connection对应多个Channel，实际上只需要实现Channel“池”。除非在多个Connection对应多个Channel的情况下，我们需要考虑同时实现Connection“池”和Channel“池”。坦白说，我这里一直没能找到实现Connection“池”的相关资料，高冷的 Catcher 大神只是让我去认真读官方文档，搞清楚Connection和Channel的关系。而这个Channel“池”的实现，结合这篇博客里的内容，实现起来是非常简单的： 12345678910111213141516171819202122232425public class ChannelObjectPoolPolicy : IPooledObjectPolicy&lt;IModel&gt;&#123; private readonly IConnectionFactory _connectionFactory; public ChannelObjectPoolPolicy(IConnectionFactory connectionFactory) &#123; _connectionFactory = connectionFactory; &#125; public IModel Create() &#123; var connection = _connectionFactory.CreateConnection(); return connection.CreateModel(); &#125; public bool Return(IModel obj) &#123; if (!obj.IsOpen) &#123; obj?.Dispose(); return false; &#125; return true; &#125;&#125; 第一步是实现IPooledObjectPolicy&lt;IModel&gt;，注意到，这里通过构造函数注入了ConnectionFactory，所以，除了常规的注入项以外，这里还需要注入ConnectionFactory: 123456789101112services.AddSingleton&lt;IConnectionFactory, ConnectionFactory&gt;(sp =&gt; new ConnectionFactory() &#123; HostName = \"localhost\", UserName = \"guest\", Password = \"guest\" &#125;);services.AddSingleton&lt;ObjectPoolProvider, DefaultObjectPoolProvider&gt;();services.AddSingleton&lt;ObjectPool&lt;IModel&gt;&gt;(serviceProvider =&gt;&#123; var objectPoolProvider = serviceProvider.GetRequiredService&lt;ObjectPoolProvider&gt;(); var connectionFactory = serviceProvider.GetRequiredService&lt;ConnectionFactory&gt;(); return objectPoolProvider.Create(new ChannelObjectPoolPolicy(connectionFactory));&#125;); 然后，我们只需要在EventBus里注入ObjectPool&lt;IModel&gt;即可，此时，我们调用Channel的画风是下面这样子的： 1234567var channel = _channelPool.Get();try &#123; //在这里做点什么吧 &#125;finally&#123; //好借好还，再借不难 _channelPool.Return(channel);&#125; 关于Connection“池”的实现，我认为我的想法还不太成熟，暂时列入未来的思考计划中，所以，这篇博客就先写到这里。 本文小结对象池(ObjectPool)是一种通过复用对象来减少资源开销进而实现提高系统性能的软件设计模式，其核心是控制容器内对象的生命周期来规避系统的主动回收，从对象池中(ObjectPool)“借”出的对象必须要及时“归还”，否则会造成对象池(ObjectPool)中没有可用资源。实现对象池可以考虑ConcurrentBag&lt;T&gt;、Stack&lt;T&gt;、Queue&lt;T&gt;以及BlockingCollection&lt;T&gt;等多种数据结构，而微软在.NET Core中已经为我们实现了一个简单的对象池，大多数情况下，我们只需要定义自己的IPooledObjectPolicy&lt;T&gt;去决定对象应该怎么样“借”、怎么样“还”。因为此前实现基于RabbitMQ的EventBus的时候，我们是每次创建一个Channel，即官方所谓的“短连接”的方式，因为Channel本质上是Connection在TCP连接上的一个虚拟连接，所以，每次创建Channel都会占用一个TCP连接，当我们系统中的TCP连接被用完的时候，就会出现无法连接、连接过慢的问题，为了解决这个问题，我们最终引入了对象池，实际上这里是实现了一个Channel“池”，关于是否应该实现Connection“池”，这一点我还没有想好，总而言之，游戏世界里可以复用的GameObject、各种数据库里的连接池，都是对象池模式在各自领域中的具体实现，这就是这篇博客的内容啦，欢迎大家在评论中留言，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"技巧","slug":"技巧","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E5%B7%A7/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"对象池","slug":"对象池","permalink":"https://qinyuanpei.github.io/tags/%E5%AF%B9%E8%B1%A1%E6%B1%A0/"},{"name":"设计模式","slug":"设计模式","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"}]},{"title":"利用MySQL的Binlog实现数据同步与订阅(下)：EventBus篇","date":"2020-07-31T12:01:14.000Z","path":"posts/3424138425/","text":"终于到这个系列的最后一篇，在前两篇博客中，我们分别了介绍了Binlog的概念和事件总线(EventBus)的实现，在完成前面这将近好几千字的铺垫以后，我们终于可以进入正题，即通过EventBus发布Binlog，再通过编写对应的EventHandler来订阅这些Binlog，这样就实现了我们“最初的梦想”。坦白说，这个过程实在有一点漫长，庆幸的是，它终于还是来了。 Binlog读取与解析首先，我们通过 Python-Mysql-Replication 这个项目来读取Binlog，直接通过pip install mysql-replication安装即可。接下来，我们编写一个简单的脚本文件，这再次印证那句名言——人生苦短，我用Python： 1234567891011121314151617181920212223242526272829303132333435363738394041def readBinLog(): stream = BinLogStreamReader( # 填写IP、账号、密码即可 connection_settings = &#123; 'host': '', 'port': 3306, 'user': '', 'passwd': '' &#125;, # 每台服务器唯一 server_id = 3, # 主库Binlog读写完毕时是否阻塞连接 blocking = True, # 筛选指定的表 only_tables = ['order_info', 'log_info'], # 筛选指定的事件 only_events = [DeleteRowsEvent, WriteRowsEvent, UpdateRowsEvent]) for binlogevent in stream: for row in binlogevent.rows: event = &#123; \"schema\": binlogevent.schema, \"table\": binlogevent.table, \"log_pos\": binlogevent.packet.log_pos &#125; if isinstance(binlogevent, DeleteRowsEvent): event[\"action\"] = \"delete\" event[\"origin\"] = dict(row[\"values\"].items()) event[\"current\"] = None event = dict(event.items()) elif isinstance(binlogevent, UpdateRowsEvent): event[\"action\"] = \"update\" event[\"origin\"] = dict(row[\"before_values\"].items()) event[\"current\"] = dict(row[\"after_values\"].items()) event = dict(event.items()) elif isinstance(binlogevent, WriteRowsEvent): event[\"action\"] = \"insert\" event[\"origin\"] = None event[\"current\"] = dict(row[\"values\"].items()) event = dict(event.items()) stream.close() 发布Binlog在读取到Binlog以后，我们需要将其发布到EventBus里，为此，在.NET Core这边提供一个Web API接口，只需要注入IEventBus然后调用Publish()即可： 1234567891011// Post: /&lt;controller&gt;/Publish[HttpPost][Route (\"PublishBinLog\")]public Task PublishBinLog (BinLogEventModel&lt;dynamic&gt; eventModel) &#123; if (eventModel.action == \"insert\" &amp;&amp; eventModel.table.StartsWith (\"log_\")) _eventBus.Publish (eventModel.MapTo&lt;WriteLogEvent&gt; ()); if (eventModel.action == \"insert\" &amp;&amp; eventModel.table == \"order_info\") _eventBus.Publish (eventModel.MapTo&lt;OrderInfoCreateEvent&gt; ()); return Task.CompletedTask;&#125; 相应地，我们需要在脚本中添加调用Web API的逻辑代码，使用我们最熟悉的requests库即可： 12345678910def sendBinLog(event): url = \"https://localhost:44348/EventBus/PublishBinLog\" headers = &#123; 'Content-Type': \"application/json\", &#125; try: payload = json.dumps(event,cls=ComplexEncoder) response = session.request(\"POST\", url, data=payload, headers=headers, verify=False) except Exception: pass 在这里，在处理Binlog的序列化的问题时，我们可能会遇到默认的JSON序列化器无法对event进行序列化的问题，此时，我们可以编写一个自定义的序列化器，下面是博主目前在使用的序列化器： 123456789101112class ComplexEncoder(json.JSONEncoder): def default(self, obj): if isinstance(obj, datetime): return obj.strftime('%Y-%m-%d %H:%M:%S') elif isinstance(obj, date): return obj.strftime('%Y-%m-%d') elif isinstance(obj, decimal.Decimal): return str(obj) elif isinstance(obj, bytes): return obj.decode('utf-8') else: return json.JSONEncoder.default(self, obj) 订阅Binlog现在，为了订阅这些Binlog，我们来编写对应的EventHandler，这里我们定义两个EventHandler，一个用于打印日志编号、日志内容、日志级别等信息，一个用于统计不同级别的日志的数目。代码实现如下： 123456789101112131415161718192021222324252627282930//打印日志的EventHandlerpublic class WriteLogEventHandler : IEventHandler&lt;WriteLogEvent&gt; &#123; private ILogger&lt;WriteLogEventHandler&gt; _logger; public WriteLogEventHandler (ILogger&lt;WriteLogEventHandler&gt; logger) &#123; _logger = logger; &#125; public Task Handle (WriteLogEvent @event) &#123; _logger.LogInformation ($\"日志编号：&#123;@event.TRANSACTION_ID&#125;，日志级别：&#123;@event.LOG_LEVEL&#125;，主机：&#123;@event.HOST_NAME&#125;，IP：&#123;@event.HOST_IP&#125;，内容：&#123;@event.CONTENT&#125;\"); return Task.CompletedTask; &#125;&#125;//分析日志的EventHandlerpublic class AnalyseLogEventHandler : IEventHandler&lt;WriteLogEvent&gt; &#123; private readonly ILogger&lt;AnalyseLogEventHandler&gt; _logger; private readonly IDistributedCache _cache; public AnalyseLogEventHandler (ILogger&lt;AnalyseLogEventHandler&gt; logger, IDistributedCache cache) &#123; _logger = logger; _cache = cache; &#125; public Task Handle (WriteLogEvent @event) &#123; var cacheCount = _cache.GetString (@event.LOG_LEVEL); if (string.IsNullOrEmpty (cacheCount)) cacheCount = \"1\"; else cacheCount = (int.Parse (cacheCount) + 1).ToString (); _cache.SetString (@event.LOG_LEVEL, cacheCount);; return Task.CompletedTask; &#125;&#125; 注意，这里需要在Startup中注入EventHandler、EventBus以及各种必要的依赖项，你可以手动注册，或者参考下面的代码，实现扫描注册： 1234567891011121314151617181920212223services.AddSingleton&lt;IRabbitMQPersistentConnection, DefaultRabbitMQPersistentConnection&gt; ();services.AddSingleton&lt;IEventBusSubscriptionManager, EventBusSubscriptionManager&gt; (sp =&gt; new EventBusSubscriptionManager ());services.AddSingleton&lt;IConnectionFactory, ConnectionFactory&gt; (sp =&gt; new ConnectionFactory () &#123; HostName = \"localhost\", UserName = \"guest\", Password = \"guest\" &#125;);services.AddSingleton&lt;ObjectPoolProvider, DefaultObjectPoolProvider&gt; ();services.AddControllers ().AddNewtonsoftJson ();services.AddDistributedMemoryCache (options =&gt; &#123; options.ExpirationScanFrequency = TimeSpan.FromMinutes (5); options.SizeLimit = 10;&#125;);//自动注册services.AddEventBus();//手动注册services.AddSingleton&lt;IEventBus, RabbitMQEventBus&gt; (sp =&gt; &#123; var eventBus = new RabbitMQEventBus (sp.GetRequiredService&lt;IRabbitMQPersistentConnection&gt; (), sp.GetRequiredService&lt;IEventBusSubscriptionManager&gt; (), sp.GetRequiredService&lt;ILogger&lt;RabbitMQEventBus&gt;&gt; (), sp, \"eventbus-exchange\", \"eventbus-queue\"); eventBus.Subscribe&lt;WriteLogEvent, WriteLogEventHandler&gt;(): eventBus.Subscribe&lt;WriteLogEvent, AnalyseLogEventHandler&gt;(); return eventBus;&#125;);services.AddTransient&lt;WriteLogEventHandler&gt;();services.AddTransient&lt;AnalyseLogEventHandler&gt;(); 一起来看看效果，简直太完美了，我就是不想写中间表啊，这样多好！！！ Python 读取 Binlog 演示 .NET Core 消费 Binlog演示 RabbitMQ Dashboard 演示 本文小结通过三篇博客的篇幅，我们实现了“利用MySQL的Binlog实现数据同步与订阅”的想法。在这个过程中，我们了解了Binlog的相关概念，参考微软的 eShopOnContainers 项目实现了一个基于RabbitMQ的EventBus，而这一切都在这篇博客中完成了最终的“拼合”，通过 Python-Mysql-Replication 实现了Binlog解析，而EventBus则作为整个事件系统的“上帝”对所有事件处理器(EventHandler)进行统一调度，最终我们不需要关心这些事件是如何被发布到EventBus中的，只需要知道它对应哪一个Event并为它编写对应的EventHandler即可，除了这篇博客中提到的Binlog以外，实际上它还可以作为系统内的“领域事件”来实现业务上的事件驱动，譬如OrderInfoCreateEvent这个事件可以表示一个订单被创建，而关心订单状态的人则可以通过EventHandler来实现订阅，实现类似发短信、发邮件、发微信等等的功能，或者可以让第三方的Web API来消费事件中携带的信息。同理，第三方的数据在流入系统时，可以先发布到消息队列中，再通过对应的EventHandler来进行异步处理，极大地改善系统接口的吞吐性能，而如果在这中间抽象出来一个数据交换层出来，那么就能收获更多不一样的东西，就在写这篇博客的时候，我在Github上的代码被收入了微软的”北极冰川火种计划”，虽然数字世界远比现实世界宽广得多，可能为这个世界减少一点“无用”的数据或者代码，应该一样可以算作是环保行为吧！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://qinyuanpei.github.io/tags/MySQL/"},{"name":"Binlog","slug":"Binlog","permalink":"https://qinyuanpei.github.io/tags/Binlog/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://qinyuanpei.github.io/tags/RabbitMQ/"}]},{"title":"利用MySQL的Binlog实现数据同步与订阅(中)：RabbitMQ篇","date":"2020-07-15T14:39:07.000Z","path":"posts/580694660/","text":"紧接上一篇博客中的思路，这次我们来说说事件总线(EventBus)，回首向来，关于这个话题，我们可能会联想到发布-订阅模式、观察者模式、IObservable与IObserver、消息队列等等一系列的概念。所以，当我们尝试着去解释这个概念的时候，它到底是什么呢？是一种设计模式？是一组API接口？还是一种新的技术？显而易见，发布-订阅模式和观察者模式都是设计模式，而IObservable与IObserver、消息队列则是具体的实现方式，就像你可以用委托或者事件去实现一个观察者模式，而Redis里同样内置了发布-订阅模型，换言之，这是抽象与具体的区别，消息队列可以用来实现EventBus，而EventBus主要的用途则是系统间的解耦，说到解耦，你可能会对观察者模式和发布-订阅模式这两种模式感到困惑，因为它们实在是太像了，一个最本质的区别在于发布者(主题)是否与订阅者(观察者)存在强依赖关系，而发布-订阅引入了类似主题/Topic/Channel的中介者，显然从解耦的角度要更彻底一些，所以，我们今天就来一起实现一个事件总线(EventBus)。 EventBus整体设计通过前面的探讨，我们可以知道，EventBus其实是针对事件的发布-订阅模式的实现，所以，在设计EventBus的时候，我们可以结合发布-定阅模式来作为对照，而一个典型的发布-订阅模式至少需要三个角色，即发布者、订阅者和消息，所以，一般在设计EventBus的时候，基本都会从这三个方面入手，提供发布消息、订阅消息、退订消息的接口。由于EventBus本身并不负责消费消息，所以，还需要借助IEventHandler&lt;T&gt;来编写对应的事件处理器，这是EventBus可以实现业务解耦的重要原因。而为了维护事件和事件处理器的关系，通常需要借助IoC容器来注册这些EventHandler，提供类似Castle或者Autofac从程序集中批量注册的机制，下面是博主借鉴 eShopOnContainers 设计的EventBus，首先是IEventBus接口，其定义如下： 12345678910public interface IEventBus &#123; void Publish&lt;TEvent&gt; (TEvent @event) where TEvent : EventBase; void Subscribe&lt;T, TH&gt; () where T : EventBase where TH : IEventHandler&lt;T&gt;; void Unsubscribe&lt;T, TH&gt; () where TH : IEventHandler&lt;T&gt; where T : EventBase;&#125; 注意到，这里对事件(EventBase)和事件处理器(EventHandler)均有一定约束，这是为了整个EventBus的实现，在某些EventBus的实现中，可能会支持非泛型的EventHandler，以及Func这样的委托类型，这里不考虑这种情形，因为从Binlog中获取的数据，基本上都是格式固定的JSON。关于这部分，下面给出对应的定义： 1234567891011public interface IEventHandlerBase &#123; &#125;public interface IEventHandler&lt;TEvent&gt; : IEventHandlerBase where TEvent : EventBase &#123; Task Handle (TEvent @ebent);&#125;public class EventBase &#123; public Guid EventId &#123; get; set; &#125; = Guid.NewGuid (); public DateTime CreatedAt &#123; get; set; &#125; = DateTime.UtcNow;&#125; 而为了维护事件(EventBase)和事件处理器(EventHandler)间的订阅关系，博主这里定义了IEventBusSubscriptionManager接口，相信以你对发布-订阅模式的理解，你可以非常容易地想到，这里应该会用到一个字典来存储每一个事件以及该事件对应的事件处理器的类型信息。你猜对了，事实上大多数的EventBus都是这样实现的，尤其当你在实现一个基于内存或者进程内通信的EventBus的时候, 到这一步其实已经完成了大多数的功能。理论上你还应该定义一个IEventStore接口，显而易见，这是针对事件的持久化接口，不过当我们选择RabbitMQ的时候，它无形中就自动帮我们实现了这个接口。 123456789101112131415161718public interface IEventBusSubscriptionManager &#123; EventHandler&lt;EventBusSubscriptionEventArgs&gt; OnSubscribe &#123; get; set; &#125; EventHandler&lt;EventBusSubscriptionEventArgs&gt; OnUnsubscribe &#123; get; set; &#125; void Subscribe&lt;T, TH&gt; () where T : EventBase where TH : IEventHandler&lt;T&gt;; void Unsubscribe&lt;T, TH&gt; () where T : EventBase where TH : IEventHandler&lt;T&gt;; bool IsEventSubscribed&lt;T&gt; () where T : EventBase; bool IsEventSubscribed (string eventName); Type GetEventTypeByName (string eventName); void Clear (); IEnumerable&lt;Type&gt; GetHandlersForEvent&lt;T&gt; () where T : EventBase; IEnumerable&lt;Type&gt; GetHandlersForEvent (string eventName); string GetEventKey&lt;T&gt; () where T : EventBase;;&#125; IEventBusSubscriptionManager接口主要提供了维护事件(Event)和事件处理器(EventHnadler)两者关系的一系列方法，我个人认为理解起来相对容易一点，实际上看 eShopOnContainers 的时候，我每次都是从其中的一个微服务开始研究的，因为这样你才能发现其中的神秘之处，不得不说，平时看那种流水账代码看惯了，看到这样清晰、优雅的代码，内心还是觉得幸福啊，对技术的热爱再度被燃起。 基于RabbitMQ的实现Publish好了，下面我们来看如何基于RabbitMQ实现上面定义的IEventBus接口，首当其冲的是Publish()方法的实现： 123456789101112131415161718public void Publish&lt;TEvent&gt; (TEvent @event) where TEvent : EventBase &#123; if (!_persistentConnection.IsConnected) _persistentConnection.TryConnect (); using (var channel = _persistentConnection.CreateModel ()) &#123; channel.ExchangeDeclare (_exchangeName, \"direct\", true, false, null); var eventName = @event.GetType ().FullName; var message = JsonConvert.SerializeObject (@event); var body = Encoding.UTF8.GetBytes (message); var properties = channel.CreateBasicProperties (); properties.DeliveryMode = 2; channel.BasicPublish (exchange: _exchangeName, routingKey: eventName, mandatory: true, basicProperties: properties, body: body); _logger.LogDebug ($\"Publish message with RabbmitMQ BasicPublish: &#123;message&#125;\"); &#125;&#125; 这里首先介绍下RabbitMQ中的两个概念，即Connection和Channel。其中，Connection是操作RabbitMQ的基础，就像我们操作数据库的时候，需要首先建立数据库连接一样。那么，Channel又是什么东西呢？它是真正去操作RabbitMQ的东西。继续以数据库作为例子，那么Channel可以理解为ADO.NET中的Command，即，那个真正负责执行SQL语句的家伙。一个典型的使用RabbitMQ的过程，大概是下面这个样子： 123var connectionFactory = new ConnectionFactory() &#123; HostName = \"Your IP\", UserName = \"You User\", Password = \"Your Pass\" &#125;;var connection = connectionFactory.CreateConnection();var channel = connection..CreateModel(); 回到我们的EventBus中，因为RabbitMQ的链接可能会在一段时间后自动关闭，所以，在微软的 eShopOnContainers 项目，它设计了一个支持自动重连的链接持久化类，我们这里同样有这个机制，当发现链接断开的时候，自动尝试重连，而接下来就由我们熟悉的Channel登场啦！这个时候，我们发现又出现了一个新面孔——交换器(Exchange)，好吧，这又要引出RabbitMQ中消息投递的原理，即RabbitMQ中消息并非由发布者直接发送给消费者，而是需要经过交换器这个中介者，虽然你可以直接去读写队列，但是实际应用中通常都不会这么做。其实，在某种意义上，我们的EventBus一样承担着中介者的角色，我们只需要关注怎么发布消息，这个消息将由哪一个订阅者来消费完全不需要我来关心，一个典型的消息投递过程如下图所示： RabbitMQ消息投递示意图 在这里，我们对消息进行序列化以后，按照事件的类型信息生成routingKey，并指定交换器的类型为direct，这是一个RabbitMQ中自带的发布-订阅实现，因为交换器会根据routingKey投递消息到对应的队列中，关于RabbitMQ中四种交换器的说明，可以在下一节找到答案。注意到在声明交换器的时候，第二个参数被设为true，这是在RabbitMQ需要对这个交换器进行持久化；而第三个参数被设为false，这是在告诉RabbitMQ这个交换器内的消息不允许自动删除；DeliveryMode设为2则表示消息需要持久化到磁盘上，这样即使RabbitMQ发生意外宕机，依然可以从磁盘上恢复消息。最终，我们调用BasicPublish()将消息投递到指定的交换机中，这样就完成了事件的发布功能。 Subscribe/Unsubscribe接下来，我们来看Subscribe()和Unsubscribe()两个方法的实现过程。这里实际上需要实现两部分的功能，一个是管理事件(EventBase)与事件处理器(EventHandler)间的关系，一个是管理消费者、消费者队列与交换器间的关系。因为考虑到后续可能需要实现类似MediatR的进程内通信的功能，所以，我们考虑将这两部分剥离开来，这样方便对EventBus进行扩展。为此，我们定义了IEventSubscriptionManager这个接口，它的定义我们在前面已经见过，最终我们会在EventBus里引用这个中间层，这样可以让EventBus显得更加清爽一点，一起来看它的具体实现： 1234567891011121314151617181920212223242526272829public void Subscribe&lt;T, TH&gt; () where T : EventBase where TH : IEventHandler&lt;T&gt; &#123; var eventName = GetEventKey&lt;T&gt; (); if (_eventHandlers.ContainsKey (eventName) &amp;&amp; !_eventHandlers[eventName].Any (x =&gt; x == typeof (TH))) &#123; _eventHandlers[eventName].Add (typeof (TH)); &#125; else &#123; _eventHandlers[eventName] = new List&lt;Type&gt; () &#123; typeof (TH) &#125;; _eventTypes.Add (typeof (T)); &#125; if (OnSubscribe != null) OnSubscribe (this, new EventBusSubscriptionEventArgs () &#123; EvenType = typeof (T), HandlerType = typeof (TH) &#125;);&#125;public void Unsubscribe&lt;T, TH&gt; () where T : EventBase where TH : IEventHandler&lt;T&gt;&#123; var eventName = GetEventKey&lt;T&gt; (); if (_eventHandlers.ContainsKey (eventName) &amp;&amp; _eventHandlers[eventName].Any (x =&gt; x == typeof (TH))) &#123; _eventHandlers[eventName].Remove (typeof (TH)); &#125; if (_eventHandlers.ContainsKey (eventName) &amp;&amp; !_eventHandlers[eventName].Any ()) &#123; _eventHandlers.Remove (eventName); _eventTypes.RemoveAll (x =&gt; x.FullName == eventName); &#125; if (OnUnsubscribe != null &amp;&amp; !GetHandlersForEvent&lt;T&gt; ().Any ()) OnSubscribe (this, new EventBusSubscriptionEventArgs () &#123; EvenType = typeof (T), HandlerType = typeof (TH) &#125;);&#125; 可以注意到，订阅就是注册EventHandler到对应的键的过程，而取消订阅就是从对应的键里移除EventHandler的过程。为了确保在订阅或者退订的时候，可以通知到具体的EventBus实现者，譬如RabbitMQ、Kafka等，我们定义了OnSubscribe和OnUnsubscribe两个委托，实际设计中，我们会在EventBus初始化的时候，将这两个委托指向EventBus内部订阅和退订的方法。对于订阅，我们需要用到RabbitMQ的BasicConsume()方法；而对于取消订阅，我们需要用到RabbitMQ的UnbindQueue()方法。下面给出关键部分的代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556//RabbitMQ中订阅指定的routingKeyprivate void StartBasicConsume (string routingKey)&#123; _logger.LogTrace (\"Starting RabbitMQ BasicConsume...\"); if (!_persistentConnection.IsConnected) _persistentConnection.TryConnect (); var queueName = GetQueueName (routingKey); var channel = _persistentConnection.CreateModel (); channel.ExchangeDeclare (_exchangeName, \"direct\", true, false, null); channel.QueueDeclare (queueName, true, false, false, null); channel.QueueBind (queueName, _exchangeName, routingKey, null); var consumer = new EventingBasicConsumer (channel); consumer.Received += async (s, e) =&gt; &#123; var routingKey = e.RoutingKey; var message = Encoding.UTF8.GetString (e.Body.ToArray ()); var tasks = ProcessEvent (routingKey, message); await Task.WhenAll (tasks); channel.BasicAck (e.DeliveryTag, false); &#125;; channel.BasicConsume (queue: $\"Q:&#123;routingKey&#125;\", autoAck : false, consumer : consumer);&#125;//调用EventHandler处理事件private IEnumerable&lt;Task&gt; ProcessEvent (string eventName, string message) &#123; if (_subscriptionManager.IsEventSubscribed (eventName)) &#123; //基于Polly构建超时合重试策略 var policy = BuildProcessEventPolicy (); using (var serviceScope = _serviceProvider.CreateScope ()) &#123; foreach (var handlerType in _subscriptionManager.GetHandlersForEvent (eventName)) &#123; var handler = serviceScope.ServiceProvider.GetRequiredService (handlerType); if (handler == null) continue; var eventType = _subscriptionManager.GetEventTypeByName (eventName); var integrationEvent = JsonConvert.DeserializeObject (message, eventType); var concreteType = typeof(IEventHandler&lt;&gt;).MakeGenericType (eventType); _logger.LogInformation ($\"Process event \\\"&#123;eventName&#125;\\\" with \\\"&#123;handler.GetType().Name&#125;\\\"...\"); yield return (Task)policy.Execute(() =&gt; concreteType.GetMethod (\"Handle\").Invoke (handler, new object[] &#123; integrationEvent &#125;)); &#125; &#125; &#125;&#125;//RabbitMQ中退订某个事件private void UnbindQueue (string routingKey) &#123; if (!_persistentConnection.IsConnected) _persistentConnection.TryConnect (); var channel = _persistentConnection.CreateModel (); var queueName = GetQueueName (routingKey); channel.QueueUnbind (queueName, _exchangeName, routingKey, null);&#125; 其中，ProcessEvent()方法是EventBus通过一个或多个EventHandler处理业务的核心方法。当从RabbitMQ中接收到消息时，首先检查当前事件是否已注册。如果已注册，则获取当前事件对应的EventHandler集合，然后通过IoC容器逐个地取得对应实例，因为在定义EventHandler的时候，我们让Handle()方法返回了一个Task，所以，我们可以顺利成章地使用Task.WhenAll()，而当所有的EventHandler都处理完成的时候，我们就可以认为这条消息被处理完了，此时，我们可以手动进行ACK，这样这条消息就会从队列中移除，至此，我们已经实现了一个完整的EventBus。 RabbitMQ进阶与释疑我在写这篇博客的时候，周围有很多人都劝我不要用RabbitMQ，而主要的理由则是RabbitMQ的吞吐量不如Kafka。我怀疑我们有时候会严重地高估自己，“面试造火箭，入职拧螺丝”，这种事情难道还少吗？与其一张嘴就是高并发、高可用，不如诚实一点结合实际来选择，我相信RabbitMQ里遇到的问题，可能有一些同样会在Kafka里遇到，因为这个世界上就没有最完美的解决方案，对于我写这篇博客的初心而言，我是为了把Binlog发布到RabbitMQ上，方便第三方来订阅这些数据的“变化”，所以，可靠性是不是要比吞吐量更重要一点呢？好了，下面，我们来看一些“杞人忧天”式的RabbitMQ的进阶话题，就是当你熟悉了RabbitMQ的API以后，需要去着重考虑的东西。 RabbitMQ丢消息怎么办？第一个问题是最普遍的一个问题，按照“生产者 -&gt; 交换器 -&gt; 队列 -&gt; 消费者”的模式，一旦发生丢消息的情况，无非有三种情况：生产者丢消息、消息队列丢消息、消费者丢消息。下面我们逐个进行分析： 1、对于生产者丢消息，RabbitMQ提供的transaction和confirm机制可以保证生产者不丢消息，transaction机制类似数据库的事务，只有当消息发送成功，事物才会被提交，否则事务被被回滚。因为每次发消息都必须开启事物，所以transaction机制会导致RabbitMQ吞吐量降低，一般建议使用confirm机制，即消息被正确投递则发送ACK给生产者，否则发送NACK给生产者。 2、对于消息队列丢消息，解决方案我们在前面有提到过，主要有两点，第一，声明队列的时候设置durable为true，这表示这是一个支持持久化的队列。第二，发送消息的时候，设置DeliveryMode为2，这表示消息支持持久化的磁盘，如果有一天RabbitMQ遭遇不幸，消息会被持久化到磁盘上，所以说，习惯性保存是个好习惯啊…… 3、对于消费者丢消息，解决方案是手动ACK，因为只有队列收到ACK时，它才会从队列中删除这条消息，否则，这条消息会重新回到队列中，只要它能重新回到队列、重新处理，它怎么会丢呢？你说对吧？ RabbitMQ重试与超时先说结论，关于重试与超时这个话题，我们有两种实现思路，一种是像博主这样，采用Polly定义超时+重试的组合策略，然后将这个策略附加到每一个Handle()方法上，通过程序来实现重试与超时。而第二种思路，则是利用消息/队列的TTL实现超时，利用死信实现重试，消息TTL和队列TTL的不同在于，一个队列超时则队列内的消息会被全部清空，而一个消息超时则可以在清空前决定是否要清空。 重试与超时最大的问题其实在于幂等性，因为在以往的实践中，当我们的消费者变成一个第三方的API接口的时候，我们很难知道，一个消息到底需要处理多久，我一直不明白，为什么宝洁这样的公司，它一个API接口居然能等将近30分钟，而更加令人难以忍受的，是大量只能调用一次的接口，这类接口既无法保证能100%调用成功，同样无法保证，第二次调和第一次调效果完全一样，所以，关于重试与超时这部分，其实应该结合实际业务去设计，因为每个人的诉求可能都不一样。 RabbitMQ的四种模式在实现EventBus的过程中，博主用到了direct类型的交换器，并说这是RabbitMQ内置的发布-订阅实现，实际上，这里应该有direct、fanout、topic和head四种类型的交换器，下面我们来逐个地进行说明。 1、fanout相当于广播，所有绑定了该交换器的队列都会收到消息。如下图所示： RabbitMQ-fanout模式 2、direct相当于发布订阅，只有绑定了该交换器且routingKey完全匹配的队列会收到消息。如下图所示： RabbitMQ-driect模式 3、topic相当于direct + 模糊匹配，所有绑定了该交换器的队列，且routingKey符合给定的模式，就会收到消息。如下图所示： RabbitMQ-topic模式 4、header相当于给每条消息定义了一个“头”，只有当头中的一个键值对(Any)或者全部键值对(All)匹配的时候，才会收到消息，这种实际应用中非常少，如下图所示： RabbitMQ-header模式 RaabitMQ的死信机制RabbitMQ中的死信(Dead Letter)机制，我认为是一个非常有意思的东西，因为从实用性的角度来讲，它可以帮助我们实现“延时队列”，虽然在更多的场景下，我们希望消息能被立即处理，因为这样看起来更像一个“实时”的行为。可在实际应用过程中，我们难免会遇到这样一种情况，一条消息经过手动ACK以后从队列中移除，结果消费者端问你能不能再消费一次这条消息，所以，Kafka里就提供了两种策略，即最多一次和至少一次，最多一次保证的是消息不会被重复消费，而至少一次保证的是消息100%被成功消费。所以，简单来说，在为RabbitMQ配置了死信的情况下，可以让部分消息有机会重新进入队列、重新被消费。那么，什么情况下会产生死信呢？主要有下面三种情况： 消息被否定确认，使用channel.basicNack或channel.basicReject，并且此时requeue属性被设置为false。 消息在队列的存活时间超过设置的TTL时间。 消息队列的消息数量已经超过最大队列长度。 接下来，为了配合死信机制，我们必须要声明死信队列，建议为每一个需要配置死信的事件单独定义一个死信队列，声明方法如下： 12345678910//声明死信交换器channel.ExchangeDeclare(\"exchange.with.dlx\", \"direct\", true, false);//声明死信队列var args = new Dictionary&lt;string, object&gt;();//该队列中所有消息都进入死信交换器args.Add(\"x-dead-letter-exchange\", \"exchange.with.dlx\");//该队列中指定routingKey的消息进入死信交换器args.Add(\"x-dead-letter-routing-key\", \"foo.bar\");channel.QueueDeclare(\"queue.with.dlx\", true, false, false, args); 本文小结本文参考微软的 eShopOnContainers 项目，实现一个基于RabbitMQ的事件总线，事件总线是发布-订阅模式的一种延伸，可以在分布式的环境中令消息的发布者、订阅者完美地解耦，是领域驱动设计(DDD)中重要的基础设施之一，对于实现业务上的“事件驱动”非常有帮助。而实现EventBus最关键的三个方法，即Publish()、Subscribe()和Unsubscribe()，这其中需要了解一部分RabbitMQ的知识，所以，在这篇博客中，你可以了解到RabbitMQ的四种交换器、死信机制、重试超时机制等等，在此基础上，我们将在下一篇博客中，通过 Python-Mysql-Replication 实现Binlog的发布，而一旦我们将Binlog发布到消息队列中，本文实现的EventBus就可以作为消息的中介者而登场啦，欢迎大家继续关注我的博客，我们下一篇见！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"事件订阅","slug":"事件订阅","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%8B%E4%BB%B6%E8%AE%A2%E9%98%85/"},{"name":"RabbitMQ","slug":"RabbitMQ","permalink":"https://qinyuanpei.github.io/tags/RabbitMQ/"},{"name":"EventBus","slug":"EventBus","permalink":"https://qinyuanpei.github.io/tags/EventBus/"}]},{"title":"利用MySQL的Binlog实现数据同步与订阅(上)：基础篇","date":"2020-07-07T09:23:59.000Z","path":"posts/1333693167/","text":"终于等到了周末，在经历了一周的忙碌后，终于可以利用空闲写篇博客。其实，博主有一点困惑，困惑于这个世界早已“堆积”起人类难以想象的“大”数据，而我们又好像执着于去“造”一个又一个“差不多”的“内容管理系统”，从前我们说互联网的精神是开放和分享，可不知从什么时候起，我们亲手打造了一个又一个的“信息孤岛”。而为了打通这些“关节”，就不得不去造一张巨大无比的蜘蛛网，你说这就是互联网的本质，对此我表示无法反驳。我更关心的是这其中最脆弱的部分，即：一条数据怎么从A系统流转到B系统。可能你会想到API或者ETL这样的关键词，而我今天想说的关键词则是Binlog。假如你经常需要让数据近乎实时地在两个系统间流转，那么你应该停下来听我——一个不甘心整天写CRUD换取996福报的程序员，讲讲如何通过Binlog实现数据同步和订阅的故事。 什么是Binlog首先，来回答第一个问题，什么是Binlog？Binlog 即 Binary Log，是MySQL中的一种二进制日志文件。它可以记录MySQL内部对数据库的所有修改，故，设计Binlog最主要的目的是满足数据库主从复制和增量恢复的需要。对于主从复制，想必大家都耳熟能详呢，因为但凡提及数据库性能优化，大家首先想到的所谓的“读写分离”，而无论是物理层面的一主多从，还是架构层面的CQRS，这背后最大的功臣当属主从复制，而实现主从复制的更底层原因，则要从Binlog说起。而对于数据库恢复，身为互联网从业者，对于像“rm -f”和“删库”、“跑路”这些梗，更是喜闻乐见，比如像今年的绿盟删库事件，在数据被删除以后，工程师花了好几天时间去抢救数据，这其中就用到了Binlog。 可能大家会好奇，为什么Binlog可以做到这些事情。其实，从Binlog的三种模式上，我们就可以窥其一二，它们分别是：Statement、Row、Mixed，其中Statement模式记录的是所有数据库操作对应的SQL语句，如INSERT、UPDATE 、DELETE 等DML语句，CREATE 、DROP 、ALTER 等DDL，所以，从理论上讲，只要按顺序执行这些SQL 语句，就可以实现不同数据库间的数据复制。而Row模式更关心每一行的变更，这种在实际应用中会更普遍一点，因为有时候更关心数据的变化情况，例如一个订单被创建出来，司机通过App接收了某个运输任务等。而Mixed模式可以认为是Statement模式和Row模式的混合体，因为Statement模式和Row模式都有各自的不足，前者可能会导致数据不一致，而后者则会占用大量的存储空间。在实际使用中，我们往往会借助各种各样的工具，譬如官方自带的mysqlbinlog、支持Binlog解析的StreamSets等等。 好了，下面我们简单介绍下Binlog相关的知识点。在使用Binlog前，首先需要确认是否开启了Binlog，此时，我们可以使用下面的命令： 1SHOW VARIABLES LIKE 'LOG_BIN' 如果可以看到下面的结果，则表示Binlog功能已开启。 Binlog已开启示意图 如果Binlog没有开启怎么办呢？此时，就需要我们手动来开启，为此我们需要修改MySQL的my.conf文件，通常情况下，该文件位于/etc/my.cnf路径，在[mysqld]下写入如下内容： 12345678910# 设置Binlog存储目录log_bin = /var/lib/mysql/bin-log# 设置Binlog索引存储目录log_bin_index = /var/lib/mysql/mysql-bin.index# 删除7天前的Binlogexpire_logs_days = 7# 集群内MySQL服务器的IDserver_id = 0002# 设置Binlog日志模式binlog_format = ROW 除此之外，我们还可以设置下面这些选项： 12345678910# 设置Binlog文件最大的大小max_binlog_size# 设置当前多少个事务缓存在内存中binlog_cache_size# 设置当前多少个事务暂存在磁盘上binlog_cache_disk_use# 设置最大有多少个事务缓存在内存中max_binlog_cache_size# 设置选取或者忽略的数据库binlog_do_db/binlog_ingore_db 设置完以后，通过下面的命令重启MySQL即可： 1service mysql restart 或者 1service mysqld restart 通常，我们可以通过下面的命令来获取Binlog的当前状态，请注意，该命令必须要在主库上执行： 1SHOW MASTER STATUS 此时，我们会得到下面的结果： 查看Binlog状态 这里可以得到三个重要的信息，即从日志文件mysql-bin.000388的特定位置135586062开始，可以获得一组新的日志信息，而这些日志信息都是来自数据库实例b1328d03-0b5c-11ea-8ee8-005056a1616f:1-27768340。有了这三个信息以后，我们就可以去查看对应的BinLog，此时，我们需要使用到下面的命令： 1SHOW BINLOG EVENTS IN 'MYSQL-BIN.000388' FROM 135586062 此时，ROW模式下的Binlog如下图所示： ROW模式下的Binlog 可以注意到，这些Binlog由不同的事件构成。如果你是在MySQL终端下输入命令，那么，你还可以使用官方自带的工具mysqlbinlog，博主这里使用的开源的数据库工具DBeaver，如果你经常需要和不同的数据库打交道，而又不想每一种数据库都去安装一个客户端的话，我认为这是一个非常不错的选择。关于Binlog的使用我们就先暂时说到这里，因为还有更重要的事情要做。 Binlog有什么用实现数据库审计你可能觉得我明知故问，你刚刚不是说Binlog 主要用来做主从复制和增量恢复吗？自然，这是Binlog在设计之初的主要用途。可我们都知道，事物有时候并不会想着我们期待的方向发展，譬如原子弹成为战争机器、社交软件成为“约炮神器”、共享单车成为“城市垃圾”等等。还记得博主曾经写过一篇关于数据库审计的[博客](https://blog.yuanpei.me/posts/1289244227/吗？当时，我们是重写了EF/EF Core中DbContext的SaveChanges()方法，并借助ChangeTracker对获取实体修改前后的值。其实，从现在的角度来看，我们有更好的选择，毫无疑问，Row模式下的Binlog本身就是天然的数据库审计，每一行数据变化前后的情况，我们都可以获得，并且可以区分出它是Insert ，还是Update，还是Delete，所以，Binlog 的第一个用途就是可以用来做数据库审计，因为它发生在数据库层，从某种意义上来讲，消解了EF和Dapper这种ORM间的差异。 实现事件驱动其次，我们在实际业务中，常常需要用到”领域事件“这个概念，即使项目并没有采用领域驱动设计(DDD)的思想，即使项目中并没有采用”事件驱动“的业务模式，可事实就是，总有人关心着数据的产生和变更，而能提供给第三方系统订阅自己感兴趣的事件的能力，无疑要比开发一个又一个大同小异的同步接口要好得多，推(Push)模式在大多数情况下要比拉(Pull)模式要好，为什么呢？因为数据传输的压力更小，更能满足数据实时性的要求。然而，由于没有按照领域模型去设计业务，导致事件代码与业务代码耦合非常严重，基于Binlog的事件分发机制显然有更好的普适性。以博主最近处理的业务为例，A系统中的司机、设备、用户在新建/更新更新时，需要把新数据推送到B系统，因为这类纯数据类的”变化”没有实际业务意义，所以，人们不舍得为这些变化去分发事件，而要想分发事件，又不得不去面对强耦合带来的阵痛，所以，Binlog的第二个用途是可以作为事件源来实现事件驱动。 业内主流方案如果你觉得通过第一节的内容，可以非常容易地实现Binlog的解析，那么，我觉得你并没有想清楚Binlog处理过程中的难点在哪里？首先，每次读取Binlog，必须要知道对应的日志文件和位置，而如果在新的Binlog 产生前，没有处理完原来的Binlog，就必须要记录对应的日志文件和位置，而且经过博主本人测试，Binlog无法直接给查询语句追加过滤条件，来达到筛选某些数据库、表以及事件的目的，而且日志文件的格式会因为模式的不同而不同，最主要的一点是，直接在主库上读取Binlog会给数据库带来访问压力，所以，主流的方案，是让客户端伪装成“从库”，关于一点，我们可以配合下面的图片来理解。 MySQL主从复制原理 可以注意到，完成主从复制需要一个Relaylog + 两个线程，即，主库产生的Binlog，首先由从库的I/O线程进行读取，这一步会产生Relaylog，顾名思义，这是一个处在中间状态的中继日志，而中继日志最终会交由从库的SQL线程来处理，所以，这是从库执行SQL语句的阶段，整个过程是异步化的操作，所以，不会对主库产生太大的压力。如果我们直接读取主库的Binlog，实际上是把所有压力都转移到主库，不仅需要负责“读”，还需要复杂“写”。主流的方案，目前比较推荐的是阿里的Canal、Zendesk的Maxwell、以及来自社区的Python-Mysql-Replication，下面是一个简单的对比，方便大家做技术选型。 Cancal Maxwell Python-Mysql-Rplication 开源方 阿里巴巴 Zendesk 社区 开发语言 Java Java Python 活跃度 活跃 活跃 活跃 高可用 支持 支持 不支持 客户端 Java/Go/PHP/Python/Rust 无 Python 消息落地 Kafka/RocketMQ等 Kafka/RabbitNQ/Redis等 自定义 消息格式 自定义 JSON 自定义 文档详略 详细 详细 详细 Boostrap 不支持 支持 不支持 说说我的构想众所知周，我是一个有一点“懒惰”的人，考虑到前面两种方案都比较重，即使通过Docker来安装。对我来说，这是一个验证想法的过程，所以，我选择的搭配是RabbitMQ + .NET Core + Python的方案，因为Kafka需要ZooKeeper，而在验证想法的阶段，自然是越简单越好。我正打算参考微软的eShopOnContainers的项目， 实现一个消息总线(EventBus)，恰好这个项目中使用了RabbitMQ，而且从某种意义上来说，RabbitMQ更接近传统意义上的消息队列，它提供的重试、确认、死信等这些机制都比较完善，可以让我把精力集中在快速实现上，毕竟你看到这些博客，都是我挤出时间来完成的。选择Python就更直接了，因为安装、运行都非常容易，或许Kafka的吞吐性能更好，但我觉得掌握核心思想才是最重要的吧！ 总而言之，在这里，我选择了自己最熟悉的技术栈。整体思路是，首先，.NET Core + RabbitMQ 实现一个消息总线，并对外提供发布事件的API接口。其次，利用Python-Mysql-Replication实现一个读取Binlog的后台程序，这些Binlog最终会以JSON的形式发布到RabbitMQ上。最后，实现针对特定事件的IEventHandler接口，消息总线会自动调用这些Handler去处理消息。至此，就实现了针对Binlog的订阅和消费。众所周知，消息总线的一大优点就是解耦，我们就可以摆脱以往定时轮询 + 打标记(Flag)的宿命轮回，只需要编写对应的Handler即可，其实我觉得这是一种思维上的转变，就是”主动”到”被动”的转变，并不是说我们帮客户做得越多越好，而是我们能让客户意识到它可以做哪些事情。同样的，我绘制了一个简单的流程图来作为说明： 基于RabbitMQ的EventBus实现 本文小结其实，重复的工作做久了都会感到厌烦的，所以，真正让你摆脱“体力劳动”的只能是换一种高度来看问题。这几年做2B业务下来，最大的体会是企业级软件最难的是，如何在各种种类繁多的软件，譬如OA 、金蝶、用友、SAP 、ERP 、CRM等中做好一个“配角”，数据如果无法在这张网络中流通，则永远都是一潭死水，而如果要打通各个系统间的数据，则免不了写一个又一个的同步接口。这篇博客以MySQL的Binlog为切入点，试图通过Binlog来实现特定业务的“事件驱动”。Binlog是实现主从复制的重要机制，而基于这一机制，业界普遍的做法是利用MySQL的交换协议，让客户端”伪装”成一个从库，在比较了Canal 、Maxwell 以及Python-Mysql-Replication后，博主选择了. NET Core + RabbitMQ + Python的方案，目标是让Binlog可以发布到消息总线(EventBus)中供消费者订阅和消费。在下一篇博客中，我们讲介绍基于RabbitMQ实现一个消息总线(EventBus)的相关细节，欢迎大家继续关注我的博客，今天这篇博客就先写到这里，大家晚安！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"MySQL","slug":"MySQL","permalink":"https://qinyuanpei.github.io/tags/MySQL/"},{"name":"Binlog","slug":"Binlog","permalink":"https://qinyuanpei.github.io/tags/Binlog/"},{"name":"事件订阅","slug":"事件订阅","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%8B%E4%BB%B6%E8%AE%A2%E9%98%85/"}]},{"title":"记一次从已损坏的Git仓库中找回代码的经历","date":"2020-06-23T17:08:17.000Z","path":"posts/686567367/","text":"突然发觉，古人其实特别有趣，譬如有古语云：『常在河边走，哪有不湿鞋』，实在是富有生活气息的一句俗语，可古人又有言语：『光脚的不怕穿鞋的』，更是朴实无华的一句话。上周下班适逢天降大雨，我撑伞送一位同事到地铁站，结果走到半路人家来一句，“你快点走吧，我穿着凉鞋”，一时竟无语凝噎。常在河边走，固然会有湿鞋的顾虑，可真正的气度绝不是光着脚满地跑，如何做到湿了鞋子而不慌呢？答案是脚上无凉鞋而心中有凉鞋。今天，我将为大家我在使用Git过程中如何“湿鞋”、如何不怕“湿鞋”的一个故事(逃 蓝屏重启后Git居然坏了？中国传统小说喜欢从神话讲起，端的是汪洋恣肆、纵横捭阖。而国外小说则喜欢从一片常青藤叶这种不显眼的事物写起，足可见二者见天地众生视角之不同。而我这个故事，是再普通不过的一次蓝屏。重启后Visual Studio提示恢复了未保存的代码，此时，我并未注意到Git仓库损坏的情况，就这样，我在一个“游离态”的版本上编写代码，直到我打开SourceTree的时候(作者注：我就是那个命令行和GUI混合使用的奇葩)，发现左侧本地分支全部消失，在命令行里git status，发现根本没有这个分支，而.git/refs/对应分支指向了一个错误的Hash，我意识到我的Git仓库文件可能损坏了，这意味着我写的新feature可能丢失了，此时，Git中提示的类似的错误信息： 1$ error: refs/remotes/origin/HEAD: invalid sha1 pointer 0000000000000000000000000000000000000000 在此之前，其实博主已经经历过类似的事情，在没有未提交的代码的情况下，其实可以暴力删除. git目录，然后在git init即可，这相当于重新初始化仓库啦，在这种情况下，本地的分支会被删掉，你需要重新建新分支。可是这次不一样啊，在做的是一个即将发版的新feature，不允许我出这样的选择啊！博主双掌合一，像夏洛克一样冷静思考，缓缓地在命令行下敲出git reflog，这条命令相当于你在Git 中的监控日志，你对Git所做的一切都会成为呈堂证供。此时，你会得到下面的信息——沉默是今晚的康桥…… 1$ fatal: You are on a branch yet to be born 这是什么意思呢？意思就是这个分支还是一个“新生儿“的状态，新生儿怎么可能又活动记录呢？所以，使用Git的准则之一，只要仓库没有坏，通过git reflog找到对应的Hash ，git checkout就可以找回代码，哪怕你刚刚手滑删除了一个未提交的分支，这种情况下都可以找回来。But 现在这种状况下，这条路显然是走不通啦。继续双掌合一，像夏洛克一样冷静思考，每个分支里其实是记录着一个hash ，对应着最后的一次提交，现在是这个hash不对，那就要找到正确的hash啊。命令行已经非常明确地告诉你，是因为某些object丢失或者损坏了，那不妨先用git fsck试试。 1234567891011$ git fscknotice: HEAD points to an unborn branch (master)Checking object directories: 100% (256/256), done.Checking objects: 100% (589/589), done.error: refs/remotes/origin/HEAD: invalid sha1 pointer 0000000000000000000000000000000000000000notice: No default referencesdangling tag 92d0fe18f9a55177d955edf58048b49db7987d5bdangling commit aa7856977e80d11833e97b4151f400a516316179dangling commit 16e449da82ec8bb51aed56c0c4c05473442db90adangling commit 864c345397fcb3bdb902402e17148e19b3f263a8dangling tag be9471e1263a78fd765d4c72925c0425c90d3d64 此时，我们就会得到这样的信息。我天，这简直太良心了好吧，连哪一个object丢了都明明白白地告诉你。既然是提示解包(unpack)的时候失败，不妨先手动解包看看呗，好吧，果然程序是不会欺骗人的。这个时候，我注意到这些里面有一些提交(commit)，我在想这些有没有可能是残留的有效分支，于是使用下面的命令创建临时分支，一番折腾发现这些分支都离我的分支比较远，所以，基本可以排除了。 12345//尝试手动解包$ mv .git/objects/pack/pack-0672bd01813664b80248dbe8330bf52da9c02b9f.pack .$ git unpack-objects -r &lt; pack-0672bd01813664b80248dbe8330bf52da9c02b9f.pack//从某个commit新建临时分支$ git update-ref refs/heads/recovery-1 aa7856977e80d11833e97b4151f400a516316179 我又不甘心地看了看git fsck命令，发现它居然有一个--lost-found的参数可以用，这样子，我居然就得到一个名为lost-found的文件夹，它里面有一些以hash命名的文件，我挑选了一个离我蓝屏时间最近的文件，直接git checkout过去，发现这正是我需要的内容，赶紧git checkout –b存档，这实在是太珍贵了！ 12345678910111213$ git fsck --lost-founderror: inflate: data stream error (unknown compression method)error: unable to unpack header of .git/objects/67/781ba4991aee01c0bc0d640ae9ee8b674b2f47error: 67781ba4991aee01c0bc0d640ae9ee8b674b2f47: object corrupt or missing: .git/objects/67/781ba4991aee01c0bc0d640ae9ee8b674b2f47error: inflate: data stream error (unknown compression method)error: unable to unpack header of .git/objects/6f/34f2bbde304619622f77f9ca159ed97b6ddafderror: 6f34f2bbde304619622f77f9ca159ed97b6ddafd: object corrupt or missing: .git/objects/6f/34f2bbde304619622f77f9ca159ed97b6ddafderror: inflate: data stream error (unknown compression method)error: unable to unpack header of .git/objects/89/6e969a25c2238ebbb41e895753e82da1cdc7aferror: 896e969a25c2238ebbb41e895753e82da1cdc7af: object corrupt or missing: .git/objects/89/6e969a25c2238ebbb41e895753e82da1cdc7aferror: inflate: data stream error (unknown compression method)error: unable to unpack header of .git/objects/d8/a180969f6cf8047def4b50c7c920dcd2b6f5cderror: d8a180969f6cf8047def4b50c7c920dcd2b6f5cd: object corrupt or missing: .git/objects/d8/a180969f6cf8047def4b50c7c920dcd2b6f5cd 其实，接触Git的这些年里，使用命令行并没有让我觉得Git难以接近，相反它让我对GUI理解更深一点，就像好多人分不清pull和fetch，因为你不看命令行的输出啊；有好多人每次SourceTree一报错就不知道该怎么办 ，其实Git给的提示真的相当清晰了；我之前一直不知道什么叫cherry-pick，后来发现这玩意儿就是我们所说的“补丁”。平时这种问题可能就放过去了，可这次“扶大厦于将顷”，让代码失而复得的经历，的确令人难忘，所以，我更想把它写下来，当你都能真正驾驭它了，是用命令行还是用GUI 就真的不在重要啦！这次的一个例外是索引没有坏，如果索引坏了，可以试试下面的命令：git reset --mixed。我还是坚持一个观点，Git仓库坏了，能修复尽量去修复，不到万不得已，千万不要去删. git目录。 各种场景下的Git恢复/撤销在这篇文章刚开始的时候，我问大家，如何做到湿了鞋子而不慌呢？答案是脚上无凉鞋而心中有凉鞋。虽然Git本身是一款非常复杂的软件，可我们依然有很多的策略去应对各种“失误”，正如这篇文章 Undoing all kinds of mistakes 所言，Git深知人类都是不完美的，面对平时使用Git过程中的各种失误，我们可以尝试使用下面的思路来解决。 更改未提交到暂存区1234//放弃所有文件的更改$ git reset --hard//放弃指定文件的更新$ git checkout -- &lt;path/to/file&gt; 更改已提交到暂存区12345678910//回到最近的一次提交(改变指针)$ git reset --hard HEAD^//回到某一次提交(改变指针)$ git reset --hard &lt;commitId&gt;//全部放弃=回到最近的一次提交(改变指针)$ git reset --hard 全部放弃//放弃提交指定文件$ git reset HEAD &lt;path/to/file&gt;//修改提交信息$ git commit --amend 更改已推送到远程服务器123456//撤销前一次提交(产生新的提交)$ git revert HEAD //撤销前前一次提交(产生新的提交) $ git revert HEAD^//撤销某一个提交(产生新的提交)$ git revert commit 万能公式12345//万能公式$ git reflog$ git checkout &lt;commitId&gt;//退而求其次$ git fsck --lost-found 除了SourceTree，我想安利第二个Git GUI工具：Fork，大家感兴趣的话可以安装试用。 参考链接 Repairing and recovering broken git repositories Git撤销&amp;回滚操作 Git撤销合并 How to get the parents of a merge commit in git?","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://qinyuanpei.github.io/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://qinyuanpei.github.io/tags/Git/"},{"name":"工具","slug":"工具","permalink":"https://qinyuanpei.github.io/tags/%E5%B7%A5%E5%85%B7/"},{"name":"软件","slug":"软件","permalink":"https://qinyuanpei.github.io/tags/%E8%BD%AF%E4%BB%B6/"}]},{"title":".NET Core原生DI扩展之属性注入实现","date":"2020-06-20T13:10:31.000Z","path":"posts/1658310834/","text":"在上一篇博客里，我们为.NET Core原生DI扩展了基于名称的注入功能。而今天，我们要来聊一聊属性注入。关于属性注入，历来争议不断，支持派认为，构造函数注入会让构造函数变得冗余，其立意点主要在代码的可读性。而反对派则认为，属性注入会让组件间的依赖关系变得模糊，其立意点主要在代码是否利于测试。我认识的一位前辈更是留下一句话：只要构造函数中超过5个以上的参数，我就觉得无法忍受。我个人是支持派，因为我写这篇博客的动机，正是一位朋友向我吐槽公司项目，说一个控制器里单单是构造函数里的参数就有十来个。在这其中最大的痛点是，有些在构造函数中注入的类型其实是重复的，譬如ILogger&lt;&gt;、IMapper、IRepository&lt;&gt;以及用户上下文信息等，虽然继承可以让痛苦减轻一点，可随之而来的就是冗长的base调用链。博主参与的项目里不乏有大量使用静态类、静态方法的，譬如LogEx、UserContext等等，可这种实践显然与依赖注入的思想背道而驰，为吾所不取也，这就是这篇博客产生的背景啦！ 好了，当视角正式切入属性注入的时候，我们不妨先来考虑这样一件事情，即：当我们从容器里Resolve一个特定的类型的时候，这个实例到底是怎么被创建出来的呢？这个问题如果给到三年前的我，我会不假思索的说出两个字——反射。的确，这是最简单的一种实现方式，换句话说，首先，容器收集构造函数中的类型信息，并根据这些类型信息Resolve对应的实例；其次，这些实例最终会被放到一个object[]里，并作为参数传递给Activator.CreateInstance()方法。这是一个一般意义上的Ioc容器的工作机制。那么，相对应地，关于属性注入，我们可以认为容器Reslove一个特定类型的时候，这个类型提供了一个空的构造函数(这一点非常重要)，再创建完实例以后，再去Reslove这个类型中的字段或者是属性。所以，为了在微软自带的DI上实现属性注入，我们就必须实现自己的ServiceProvider——AutowiredServiceProvider，这个ServiceProvider相比默认的ServiceProvider多了一部分功能，即反射属性或者字段的过程。一旦想通这一点，我们可以考虑装饰器模式。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class AutowiredServiceProvider : IServiceProvider, ISupportRequiredService &#123; private readonly IServiceProvider _serviceProvider; public AutowiredServiceProvider (IServiceProvider serviceProvider) &#123; _serviceProvider = serviceProvider; &#125; public object GetRequiredService (Type serviceType) &#123; return GetService (serviceType); &#125; public object GetService (Type serviceType) &#123; var instance = _serviceProvider.GetService (serviceType); Autowried (instance); return instance; &#125; private void Autowried (object instance) &#123; if (_serviceProvider == null || instance == null) return; var flags = BindingFlags.Public | BindingFlags.NonPublic; var type = instance as Type ?? instance.GetType (); if (instance is Type) &#123; instance = null; flags |= BindingFlags.Static; &#125; else &#123; flags |= BindingFlags.Instance; &#125; //Feild foreach (var field in type.GetFields (flags)) &#123; var autowriedAttr = field.GetCustomAttribute&lt;AutowiredAttribute&gt; (); if (autowriedAttr != null) &#123; var dependency = GetService (field.FieldType); if (dependency != null) field.SetValue (instance, dependency); &#125; &#125; //Property foreach (var property in type.GetProperties (flags)) &#123; var autowriedAttr = property.GetCustomAttribute&lt;AutowiredAttribute&gt; (); if (autowriedAttr != null) &#123; var dependency = GetService (property.PropertyType); if (dependency != null) property.SetValue (instance, dependency); &#125; &#125; &#125;&#125; 装饰器模式，又被称之为“静态代理”，是面向切面编程(AOP)的实现方式之一，我们在这里为默认的ServiceProvider增加了Autowired()方法，它会扫描所有含[Autowired]标签的字段或属性，并尝试从容器中获取对应类型的实例。所以，这又说到了反对属性注入第二个理由，即：使用反射带来的性能问题，尤其是当依赖项间的引用关系异常复杂的时候。当然，所谓“兵来将挡，水来土掩”，反射产生性能损失，可以考虑用Emit或者表达书树作来替代反射，不过，微软貌似在.NET Core中阉割了一部分Emit的API，这些都是Todo啦你懂就好，我们继续往下说。接下来，为了替换掉微软默认的ServiceProvider，我们还必须实现自己的ServiceProviderFactory，像Autofac、Unity、Castle等容器，都是采用类似的做法来支持.NET Core。 1234567891011public class AutowiredServiceProviderFactory : IServiceProviderFactory&lt;IServiceCollection&gt; &#123; public IServiceProvider CreateServiceProvider (IServiceCollection containerBuilder) &#123; var serviceProvider = containerBuilder.BuildServiceProvider (); return new AutowiredServiceProvider (serviceProvider); &#125; IServiceCollection IServiceProviderFactory&lt;IServiceCollection&gt;.CreateBuilder (IServiceCollection services) &#123; if (services == null) return new ServiceCollection (); return services; &#125;&#125; 因为我们是以微软内置的DI为基础来进行扩展的，所以，在实现AutowiredServiceProviderFactory的时候，提供的泛型参数依然是IServiceCollection。它需要实现两个方法：CreateBuilder和CreateServiceProvider，在这里我们需要返回我们“装饰”过的ServiceProvider。接下来，万事俱备，只欠东风，我们需要在项目入口(Program.cs)调用UseServiceProviderFactory()方法，如果你在.NET Core 使用Autofac，应该会对此感到亲切： 1234567public static IHostBuilder CreateHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .ConfigureWebHostDefaults(webBuilder =&gt; &#123; webBuilder.UseStartup&lt;Startup&gt;(); &#125;) .UseServiceProviderFactory(new AutowiredServiceProviderFactory()); 至此，我们就完成了对微软默认的ServiceProvider的替换。假设我们有两个接口：IFooService和IBarService： 1234567891011121314151617181920//IFooService &amp;&amp; FooServicepublic interface IFooService &#123; string Foo (); IBarService Bar &#123; get; set; &#125;&#125;public class FooService : IFooService &#123; [Autowired] public IBarService Bar &#123; get; set; &#125; public string Foo () =&gt; \"I am Foo\";&#125;//IBarService &amp;&amp; BarServicepublic interface IBarService &#123; string Bar();&#125;public class BarService : IBarService &#123; public string Bar () =&gt; \"I am Bar\";&#125; 注意到FooService依赖IBarService，而我们只需要给Bar加上[Autowired]标签即可，风格上借鉴了Spring的@Autowired。只要这两个接口被注入到Ioc容器中，这个属性就可以自动获得相应的服务实例。一起来看下面的代码： 12345services.AddTransient&lt;IFooService,FooService&gt;();services.AddTransient&lt;IBarService, BarService&gt;();var serviceProvider = new AutowiredServiceProvider(services.BuildServiceProvider());var fooService = serviceProvier.GetRequiredService&lt;IFooService&gt;();Console.WriteLine($\"&#123;fooService.Foo()&#125; , &#123;fooService.Bar.Bar()&#125;\"); 回到我们一开始遇到的那个问题，如果我们让IFooService变成Controller中的一个属性，是否就能解决构造函数参数冗余的问题了呢？下面是一段简单的代码： 1234567891011121314151617[ApiController][Route(\"[controller]\")]public class WeatherForecastController : ControllerBase&#123; [Autowired] public IFooService Foo &#123; get; set; &#125; [Autowired] public ILogger&lt;WeatherForecastController&gt; Logger &#123; get; set; &#125; [HttpGet] [Route(\"Autowired\")] public ActionResult GetAutowriedService() &#123; return Content($\"&#123;Foo.Foo()&#125; , &#123;Foo.Bar.Bar()&#125;\"); &#125;&#125; 此时，我们会发现Foo属性提示空引用错误，这是为什么呢？这是因为Controller并不是通过IoC容器来负责创建和销毁的，为了实现属性注入的目的，我们就必须让IoC容器来全面接管Controller的创建和销毁，此时，我们需要做两件事情，其一，注册Controller到IoC容器中；其二，实现自定义的IControllerActivator，并替换默认的ControllerActivator: 123services.AddControllers();services.AddControllersWithViews().AddControllersAsServices();services.Replace(ServiceDescriptor.Transient&lt;IControllerActivator, AutowiredControllerActivator&gt;()); 其中，AutowiredControllerActivator实现如下： 12345678910111213141516171819202122232425262728public class AutowiredControllerActivator : IControllerActivator&#123; public object Create(ControllerContext context) &#123; if (context == null) throw new ArgumentNullException(nameof(ControllerContext)); var controllerType = context.ActionDescriptor.ControllerTypeInfo.AsType(); var serviceProvider = context.HttpContext.RequestServices; if(!(serviceProvider is AutowiredServiceProvider)) serviceProvider = new AutowiredServiceProvider(context.HttpContext.RequestServices); var controller = serviceProvider.GetRequiredService(controllerType); return controller; &#125; public void Release(ControllerContext context, object controller) &#123; if (context == null) hrow new ArgumentNullException(nameof(ControllerContext)); if (controller == null) throw new ArgumentNullException(nameof(controller)); var disposeable = controller as IDisposable; if (disposeable != null) disposeable.Dispose(); &#125; &#125;&#125; 此时，一切都会像我们期待的那样美好，返回正确的结果。目前，这个方案最大的问题是，在非Controller层使用的时候，还是需要构造AutowirdServiceProvider实例。其实，在AutowiredControllerActivator里同样有这个问题，就是你即使实现IServiceProviderFactory接口，依然没有办法替换掉默认的ServiceProvider实现，只能说它能解决一部分问题，同时又引入了新的问题，最直观的例子是，你看到一个接口的时候，你并不能找全所有加了[Autowired]标签的依赖项，所以，直接造成了依赖关系模糊、不透明、难以测试等等的一系列问题，我认为，在一个可控的、小范围内使用还是可以的。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"技巧","slug":"技巧","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E5%B7%A7/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"DI","slug":"DI","permalink":"https://qinyuanpei.github.io/tags/DI/"},{"name":"依赖注入","slug":"依赖注入","permalink":"https://qinyuanpei.github.io/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"}]},{"title":".NET Core原生DI扩展之基于名称的注入实现","date":"2020-06-10T13:08:03.000Z","path":"posts/1734098504/","text":"接触 .NET Core 有一段时间了，最大的感受无外乎无所不在的依赖注入，以及抽象化程度更高的全新框架设计。想起三年前 Peter 大神手写 IoC 容器时的惊艳，此时此刻，也许会有不一样的体会。的确，那个基于字典实现的 IoC 容器相当“简陋”，就像 .NET Core 里的依赖注入，默认(原生)都是采用构造函数注入的方式，可其实从整个依赖注入的理论上而言，属性注入和方法注入的方式，同样是依赖注入的实现方式啊。最近一位朋友找我讨论，.NET Core 里该如何实现 Autowried，这位朋友本身是 Java 出身，一番攀谈了解到原来是指属性注入啊。所以，我打算用两篇博客来聊聊 .NET Core 中的原生 DI 的扩展，而今天这篇，则单讲基于名称的注入的实现。 Autofac是一个非常不错的 IoC 容器，通常我们会使用它来替换微软内置的 IoC 容器。为什么要这样做呢？其实，微软在其官方文档中早已给出了说明，即微软内置的 IoC 容器实际上是不支持以下特性的： 属性注入、基于名称的注入、子容器、自定义生存期管理、对迟缓初始化的 Func 支持、基于约定的注册。这是我们为什么要替换微软内置的 IoC 容器的原因，除了Autofac 以外，我们还可以考虑 Unity 、Castle 等容器，对我个人而言，其实最需要的一个功能是“扫描”，即它可以针对程序集中的组件或者服务进行自动注册。这个功能可以让人写起代码更省心一点，果然，人类的本质就是让自己变得更加懒惰呢。好了，话题拉回到本文主题，我们为什么需要基于名称的注入呢？它其实针对的是“同一个接口对应多种不同的实现”这种场景。 OK ，假设我们现在有一个接口ISayHello，它对外提供一个方法SayHello： 1234public interface ISayHello&#123; string SayHello(string receiver);&#125; 相对应地，我们有两个实现类，ChineseSayHello和EnglishSayHello： 1234567891011121314151617//ChineseSayHellopublic class ChineseSayHello : ISayHello&#123; public string SayHello(string receiver) &#123; return $\"你好，&#123;receiver&#125;\"; &#125;&#125;//EnglishSayHellopublic class EnglishSayHello : ISayHello&#123; public string SayHello(string receiver) &#123; return $\"Hello，&#123;receiver&#125;\"; &#125;&#125; 接下来，一顿操作猛如虎： 12345var services = new ServiceCollection();services.AddTransient&lt;ISayHello, ChineseSayHello&gt;();services.AddTransient&lt;ISayHello, EnglishSayHello&gt;();var serviceProvider = services.BuildServiceProvider();var sayHello = serviceProvider.GetRequiredService&lt;ISayHello&gt;(); 没想到，尴尬的事情就发生了，大家来猜猜看，这个时候我们获取到的ISayHello到底是哪一个呢？事实上，它会获取到EnglishSayHello这个实现类，为什么呢？因为它后注册的呀！当然，微软的工程师们不可能想不到这个问题，所以，官方推荐的做法是使用IEnumerable&lt;ISayHello&gt;，这样我们就能拿到所有注册的ISayHello，然后自己决定到底要使用一种实现，类似下面这样： 123var sayHellos = _serviceProvider.GetRequiredService&lt;IEnumerable&lt;ISayHello&gt;&gt;();var chineseSayHello = sayHellos.FirstOrDefault(x =&gt; x.GetType() == (typeof(ChineseSayHello)));var englishSayHello = sayHellos.FirstOrDefault(x =&gt; x.GetType() == (typeof(EnglishSayHello))); 可这样还是有一点不方便啊，继续改造： 12345678910111213141516171819services.AddTransient&lt;ChineseSayHello&gt;();services.AddTransient&lt;EnglishSayHello&gt;();services.AddTransient(implementationFactory =&gt;&#123; Func&lt;string, ISayHello&gt; sayHelloFactory = lang =&gt; &#123; switch (lang) &#123; case \"Chinese\": return implementationFactory.GetService&lt;ChineseSayHello&gt;(); case \"English\": return implementationFactory.GetService&lt;EnglishSayHello&gt;(); default: throw new NotImplementedException(); &#125; &#125;; return sayHelloFactory;&#125;); 这样子，这个工厂类看起来就消失了对吧，其实并没有(逃 123var sayHelloFactory = _serviceProvider.GetRequiredService&lt;Func&lt;string, ISayHello&gt;&gt;();var chineseSayHello = sayHelloFactory(\"Chinese\");var englishSayHello = sayHelloFactory(\"English\"); 这距离我们的目标有一点接近了哈，唯一的遗憾是这个工厂类对调用方是透明的，可谓是隐藏细节上的失败。有没有更好的方案呢？好了，我不卖关子啦，一起来看下面的实现。 首先，我们定义一个接口INamedServiceProvider, 顾名思义，就不需要再解释什么了: 1234public interface INamedServiceProvider&#123; TService GetService&lt;TService&gt;(string serviceName);&#125; 接下来，编写实现类NamedServiceProvider: 1234567891011121314151617public class NamedServiceProvider : INamedServiceProvider&#123; private readonly IServiceProvider _serviceProvider; private readonly IDictionary&lt;string, Type&gt; _registrations; public NamedServiceProvider(IServiceProvider serviceProvider, IDictionary&lt;string, Type&gt; registrations) &#123; _serviceProvider = serviceProvider; _registrations = registrations; &#125; public TService GetService&lt;TService&gt;(string serviceName) &#123; if(!_registrations.TryGetValue(serviceName, out var implementationType)) throw new ArgumentException($\"Service \\\"&#123;serviceName&#125;\\\" is not registered in container\"); return (TService)_serviceProvider.GetService(implementationType); &#125;&#125; 可以注意到，我们这里用一个字典来维护名称和类型间的关系，一切仿佛又回到三年前Peter大神手写IoC的那个下午。接下来，我们定义一个INamedServiceProviderBuilder, 它可以让我们使用链式语法注册服务： 12345678public interface INamedServiceProviderBuilder&#123; INamedServiceProviderBuilder AddNamedService&lt;TService&gt;(string serviceName, ServiceLifetime lifetime) where TService : class; INamedServiceProviderBuilder TryAddNamedService&lt;TService&gt;(string serviceName, ServiceLifetime lifetime) where TService : class; void Build();&#125; 这里，Add和TryAdd的区别就是后者会对已有的键进行检查，如果键存在则不会继续注册，和微软自带的DI中的Add/TryAdd对应，我们一起来看它的实现： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class NamedServiceProviderBuilder : INamedServiceProviderBuilder&#123; private readonly IServiceCollection _services; private readonly IDictionary&lt;string, Type&gt; _registrations = new Dictionary&lt;string, Type&gt;(); public NamedServiceProviderBuilder(IServiceCollection services) &#123; _services = services; &#125; public void Build() &#123; _services.AddTransient&lt;INamedServiceProvider&gt;(sp =&gt; new NamedServiceProvider(sp, _registrations)); &#125; public INamedServiceProviderBuilder AddNamedService&lt;TImplementation&gt;(string serviceName, ServiceLifetime lifetime) where TImplementation : class &#123; switch (lifetime) &#123; case ServiceLifetime.Transient: _services.AddTransient&lt;TImplementation&gt;(); break; case ServiceLifetime.Scoped: _services.AddScoped&lt;TImplementation&gt;(); break; case ServiceLifetime.Singleton: _services.AddSingleton&lt;TImplementation&gt;(); break; &#125; _registrations.Add(serviceName, typeof(TImplementation)); return this; &#125; public INamedServiceProviderBuilder TryAddNamedService&lt;TImplementation&gt;(string serviceName, ServiceLifetime lifetime) where TImplementation : class &#123; switch (lifetime) &#123; case ServiceLifetime.Transient: _services.TryAddTransient&lt;TImplementation&gt;(); break; case ServiceLifetime.Scoped: _services.TryAddScoped&lt;TImplementation&gt;(); break; case ServiceLifetime.Singleton: _services.TryAddSingleton&lt;TImplementation&gt;(); break; &#125; _registrations.TryAdd(serviceName, typeof(TImplementation)); return this; &#125;&#125; 相信到这里，大家都明白博主的意图了吧，核心其实是在Build()方法中，因为我们最终需要的是其实是NamedServiceProvider，而在此之前的种种，都属于收集依赖、构建ServiceProvider的过程，所以，它被定义为NamedServiceProviderBuilder，我们在这里维护的这个字典，最终会被传入到NamedServiceProvider的构造函数中，这样我们就知道根据名称应该返回哪一个服务了。 接下来，为了让它和微软自带的DI无缝粘合，我们需要编写一点扩展方法： 123456789101112131415161718public static class ServiceCollectionExstension&#123; public static TService GetNamedService&lt;TService&gt;(this IServiceProvider serviceProvider, string serviceName) &#123; var namedServiceProvider = serviceProvider.GetRequiredService&lt;INamedServiceProvider&gt;(); if (namedServiceProvider == null) throw new ArgumentException($\"Service \\\"&#123;nameof(INamedServiceProvider)&#125;\\\" is not registered in container\"); return namedServiceProvider.GetService&lt;TService&gt;(serviceName); &#125; public static INamedServiceProviderBuilder AsNamedServiceProvider(this IServiceCollection services) &#123; var builder = new NamedServiceProviderBuilder(services); return builder; &#125;&#125; 现在，回到我们一开始的问题，它是如何被解决的呢？ 12345678services .AsNamedServiceProvider() .AddNamedService&lt;ChineseSayHello&gt;(\"Chinese\", ServiceLifetime.Transient) .AddNamedService&lt;EnglishSayHello&gt;(\"English\", ServiceLifetime.Transient) .Build();var serviceProvider = services.BuildServiceProvier();var chineseSayHello = serviceProvider.GetNamedService&lt;ISayHello&gt;(\"Chinese\");var englishSayHello = serviceProvider.GetNamedService&lt;ISayHello&gt;(\"English\"); 这个时候，对调用方而已，依然是熟悉的ServiceProvider，它只需要传入一个名称来获取服务即可，由此，我们就实现了基于名称的依赖注入。回顾一下它的实现过程，其实是一个逐步推进的过程，我们使用依赖注入，本来是希望依赖抽象，即针对同一个接口，可以无痛地从一种实现切换到另外一种实现。可我们发现，当这些实现同时被注册到容器里的时候，容器一样会迷惑于到底用哪一种实现，这就让我们开始思考，这种基于字典的IoC容器设计方案是否存在缺陷。所以，在.NET Core里的DI设计中还引入了工厂的概念，因为并不是所以的Resolve都可以通过Activator.Create来实现，更不必说Autofac和Castle中还有子容器的概念，只能说人生不同的阶段总会有不同的理解吧！好了，这篇博客就先写到这里，欢迎大家给我留言，晚安！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"技巧","slug":"技巧","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E5%B7%A7/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"DI","slug":"DI","permalink":"https://qinyuanpei.github.io/tags/DI/"},{"name":"依赖注入","slug":"依赖注入","permalink":"https://qinyuanpei.github.io/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/"}]},{"title":"原生JavaScript实现Hexo博客推荐功能","date":"2020-06-08T12:30:54.000Z","path":"posts/478946932/","text":"有时候，我不禁在想，我们到底处在一个什么样的时代呢？而之所以会有这样的疑问，则是因为我们的习惯在不断地被这个时代向前推进，就像我用了两年多的魅蓝Note6屏幕出现了问题，扫视了一圈新手机，居然再找不出一款带实体键的手机，刘海屏、水滴屏、破孔屏、异形屏、曲面屏等等简直令人眼花缭乱，唯独没有一款让我感到熟悉的非全面屏手机。做软件的时候，会不明白那些似是而非的定制需求的差异，可为什么偏偏到了硬件的时候，大家就能被迫适应这些越来越同质化的东西呢？也许有和我一样怀念非全面屏的人，可对于这个时代而言，一切都好像无足轻重，喜欢魅族对产品的设计，喜欢小而美的不妥协，可当大家都越来越相似的时候，也许，是因为我们终于都长大了吧，而怀念则是一种可有可无、甚至有一点多余的东西。在被告知一切向前看的路上，我们能拥有、用留住的东西本就不多，可偏偏我们就在给世间一切东西，努力地刻上时间的温度，经历着花繁叶茂，经历着落叶归根。 写博客，曾经是件很有意思的事情，透过网页去读每条留言背后的人，常常令你产生神交已久的感觉，即便网络如此发达的今天，让一个人失散，无非是动动手指拉黑、删除。陈星汉先生有一款游戏作品叫做《风之旅人》，游戏里的玩家依靠某种微弱的信号相互联系，而一旦失散彼此，将永远迷失在浩瀚无际的沙海里，你说，这是不是有人生本身的意味在里面呢？再后来140个字符的微博开始流行，而这些沉迷在博客时代里的人们，或固执地继续在博客这一方天地里挥洒，或搭乘移动互联网的“高铁”通往新的彼岸。有人这样比喻朋友圈和微博，说朋友圈装饰别人梦境的月亮，而微博则是装饰自己梦境的镜子。其实呢，在隐私问题基本荡然无存的今天，我们都只是在装饰资本的“窗户”吧！ 曾经运营过一段时间的微信公众号，最后发觉还是博客的载体更适合自己，虽然这些年没少为博客投入“钱财”，在博客时代一去不复返的时间禁锢里，通过博客来盈利的想法堪堪聊以自慰，更不必说后来流行起来的“在线教育”和Vlog。有人说，靠工资是没有办法挣到钱的，挣钱要靠这些“睡后收入”，可当一件事物风头正盛的时候，彼时的你不足以追逐这一切的时候，这种感觉该如何言明呢？大概就像你在最落魄的时候，遇到一生中最想要保护的那个人一样，这听起来多少有点讽刺，人在不成熟的时候，总是后知后觉，可有一天真成熟了，再难有那时的运气或是豪气。所以呢，继续写下去吧，也许有一天，当你看着从前写的幼稚的文字，或哭或笑皆可入题，这不就是“嬉笑怒骂，皆成文章”了吗？ 果然，一不小心又扯远了。虽然说博客平时没什么流量，可像搜索引擎优化(SEO)、前端构建(CI/CD)、PWA等等这些东西倒是有所钻研，提高博客访问量的方式除了增加搜索引擎里的权重和曝光率以外，其实，还有一种方式就是减少跳出时间。换句话说，访客在你博客里停留的时间越长，这意味着你有更多的内容可以被对方访问到，所以，增加内链是一个不错的思路。最直接的方式，就是在每篇博客结束以后推荐相关的博客供访客继续阅读。之前曾经尝试过像 hexo-recommended-posts 这样的插件，坦白说效果不是特别好，因为有时候加载这些站外的内容，导致博客页面打开的时候异常卡顿，所以，我们今天将采用原生的JavaScript来为Hexo实现博客推理功能，希望对大家有所启发。 首先，我们来说说原理，推荐系统一般是需要一部分量化的指标来表征不同内容的相关性的。譬如通过TF-IDF来计算文本的相似度，通过公共词袋中的词频构造向量再配合余弦公式来计算，通过TextRank这类借鉴PageRank思想的方法来计算等等。这里呢，我们不采用这些方法来实现，主要是考虑到200篇左右的博客，两两计算相似度特别耗费时间，对于Hexo这种静态博客而言，我们还是应该节省生成静态页面的时间，虽然这部分时间都是Travis CI去跑的(逃……。我们采用的方案是基于标签和日期的推荐方式，即根据当前文章的标签筛选相同标签的文章，根据当前文章的日期筛选相同日期的文章。有了这两种策略，配合Hexo中提供的全局变量，我们可以很容易地编写出下面的代码： 123456789101112131415161718192021222324252627282930313233&lt;% function shuffle(a) &#123; for (let i = a.length; i; i--) &#123; let j = Math.floor(Math.random() * i); [a[i - 1], a[j]] = [a[j], a[i - 1]]; &#125; return a; &#125; function recommended_posts(page, site, limit = 5) &#123; page.tags = page.tags || [] if (page.tags.length == 0) return []; let pageTags = page.tags.map(x=&gt;x.name); let sitePosts = site.posts.toArray().map(x=&gt; &#123; return &#123;tags:x.tags.toArray().map(y=&gt;y.name), title:x.title, permalink:x.permalink, date:x.date&#125; &#125;); let relatedPosts = pageTags.map(x=&gt;sitePosts.filter(y=&gt;y.title != page.title &amp;&amp; (y.tags.indexOf(x) != -1 || y.date.format('MM/DD') == page.date.format('MM/DD')))).reduce((prev,next)=&gt;&#123; return prev.concat(next); &#125;,[]); return shuffle(Array.from(new Set(relatedPosts))).slice(0, limit); &#125;%&gt;&lt;% var post_list = recommended_posts(page, site, config.recommended_posts.limit) %&gt;&lt;% if(post_list.length &gt; 0 &amp;&amp; config.recommended_posts.enable) &#123; %&gt;&lt;div class=\"recommended_posts\"&gt; &lt;h1&gt;&lt;%= config.recommended_posts.title %&gt;&lt;/h1&gt; &lt;ul&gt; &lt;% post_list.forEach(function(link) &#123; %&gt; &lt;li&gt;&lt;a href=\"&lt;%= link.permalink %&gt;\"&gt;&lt;%= link.title %&gt;&lt;/a&gt;&lt;/li&gt; &lt;% &#125;) %&gt; &lt;/ul&gt;&lt;/div&gt;&lt;% &#125; %&gt; 代码非常直白，按照标签和日期两种策略筛选出文章，打乱顺序后从中提取出若干个返回，而剩下的工作，就是将其渲染到页面中。在这里，博主单独定义了一个模板文件，所以，我们在博客的适当位置引入即可，博主是放在博客结束以后的位置： 1234&lt;div class=\"post-content\" id=\"post-content\" itemprop=\"postContent\"&gt; &lt;%- post.content %&gt; &lt;%- partial('post/recommended_posts') %&gt;&lt;/div&gt; 最终实现的效果如下图所示： 本文实现的相关文章推荐功能 当然，当你看到这篇博客的时候，你已经看到博主为你推荐的内容了，是否有兴趣继续读下去呢？如果这样的话，就说明这两个内容是相关的。而基于日期的推荐，即所谓的“去年今日”，它本身的相关性可能并不强，但可以让你产生一种强烈的对比感，原来，这一天我是这样度过的啊。好了，这就是这篇博客的内容啦，晚安～","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"插件","slug":"插件","permalink":"https://qinyuanpei.github.io/tags/%E6%8F%92%E4%BB%B6/"},{"name":"Hexo","slug":"Hexo","permalink":"https://qinyuanpei.github.io/tags/Hexo/"},{"name":"推荐","slug":"推荐","permalink":"https://qinyuanpei.github.io/tags/%E6%8E%A8%E8%8D%90/"}]},{"title":"使用Dynamic Linq构建动态Lambda表达式","date":"2020-05-08T12:27:11.000Z","path":"posts/118272597/","text":"相信大家都有这样一种感觉，Linq和Lambda是.NET中一以贯之的存在，从最早的Linq to Object到Linq to SQL，再到EF/EF Core甚至如今的.NET Core，我们可以看到Lambda表达式的身影出现地越来越频繁。虽然Linq to Object和Linq to SQL，分别是以IEnumerable&lt;T&gt;和IQueryable &lt;T&gt;为基础来实现的。我个人以为，Lambda呢，其实就是匿名委托的“变种”，而Linq则是对Lambda的进一步封装。在System.Linq.Expressions命名空间下，提供大量关于表达式树的API，而我们都知道，这些表达式树最终都会被编译为委托。所以，动态创建Lambda表达式，实际上就是指从一个字符串生成对应委托的过程，而一旦这个委托被生成，可以直接传递给Where()方法作为参数，显然，它可以对源数据进行过滤，这正是我们想要的结果。 事出有因在今天这篇博客中，我们主要介绍System.Linq.Dynamic.Core这个库，即我所说的Dynamic Linq。本着“艺术源于生活的态度”，在介绍它的用法之前，不妨随博主一起看看，一个“简单“的查询是如何随着业务演进而变得越来越复杂。从某种意义上来说，正是它让博主想起了Dynamic Linq。我们为客户编写了一个生成订单的接口，它从一张数据表中“消费”订单数据。最开始，它只需要过滤状态为“未处理”的记录，对应的CRUD可以表示为这样： 1var orderInfos = repository.GetByQuery&lt;tt_wg_order&gt;(x =&gt; x.STATUS == 10); 后来，因为业务方存在重复/错误下单的情况，业务数据有了“软删除”的状态，相应地查询条件再次发生变化，这看起来还行对吧： 1var orderInfos = repository.GetByQuery&lt;tt_wg_order&gt;(x =&gt; x.STATUS == 10 &amp;&amp; x.Isdelete == 0); 再后来，因为接口处理速度不理想，无法满足客户的使用场景，公司大佬们建议“加机器”，而为了让每台服务器上消费的订单数据不同(据说是为了避免发生并发)，大佬们要求博主开放所有字段作为查询条件，这样，每台服务器上可以配置不同查询条件。自此，又双叒叕改： 123456var repository = container.Resolve&lt;CrudRepositoryBase&gt;();var searchParameters = new SearchParameters() &#123; PageInfo = new PageInfo() &#123; PageSize = parameters.PAGE_SIZE.Value &#125;&#125;;searchParameters.QueryModel.Items.Add(new ConditionItem &#123; Field = \"STATUS\", Method = QueryMethod.Equal, Value = 10 &#125;);searchParameters.QueryModel.Items.Add(new ConditionItem &#123; Field = \"Isdelete\", Method = QueryMethod.Equal, Value = 0 &#125;);//此处省略更多的查询条件:)var orderInfos = repository.GetByPage&lt;tt_wg_order&gt;(searchParameters); 可以想象得出，终极终终极的查询会变成下面这张图。这种方式看起来很美好对不对？可谁能想到，就在五一放假前的某一天里，博主还在替某个“刁钻”客户排查一组同样“刁钻”的过滤条件为什么没有生效。显然，我需要有一种更友好的方式，它可以从一个字符串变成一个委托，就像JavaScript里”邪恶”的Eval()函数一样，说它邪恶，是因为它的输入是不可控的，”机智”的人类习惯把事件万物都当成SQL语句，其实，RESTful接口里传SQL、调存储过程难道不可以吗？同样，是因为这种做法太”邪恶”。 过滤条件在风中凌乱] ParseLambda首先，通过nuget安装：System.Linq.Dynamic.Core。这里主要介绍的是介绍的是其中的ParseLambda()方法，顾名思义，它可以把一个字符串转换为指定类型的委托，一起来看下面的例子。首先，我们定义一个通用方法BuildLambda： 12345678910111213141516171819202122232425Func&lt;T, bool&gt; BuildLambda&lt;T&gt;(string exps)&#123; var sourceType = typeof(T); var sourceParameter = Expression.Parameter(sourceType); var lambdaExps = DynamicExpressionParser.ParseLambda( new[] &#123; sourceParameter &#125;, typeof(bool), exps ); return lambdaExps.Compile() as Func&lt;T, bool&gt;;&#125;var students = new List&lt;Student&gt;()&#123; new Student() &#123; Name = \"长安书小妆\", Age = 25, Address = \"洛阳市洛龙区\", Teacher = new Teacher() &#123; Name = \"孔子\" &#125; &#125;, new Student() &#123; Name = \"飞鸿踏雪\", Age = 28, Address = \"宁夏中卫市\", Teacher = new Teacher() &#123; Name = \"孔子\" &#125; &#125;,&#125;;var exps = \"Age&lt;=25 &amp;&amp; Address.Contains(\\\"洛阳市\\\") &amp;&amp; Teacher.Name=\\\"孟子\\\"\";var lambda = BuildLambda&lt;Student&gt;(exps);var results = students.Where(lambda); 注意到，核心的代码其实只有DynamicExpressionParser.ParseLambda()这一句，这充分暴露了博主“调包侠”的本质。按照示例代码中的过滤条件，我们知道给定数据中是没有符合条件的数据的。假如你真的运行了这段代码，你就会得到真正的结果：我说的是对的(逃 One More Thing其实，我们今天所说这一切，从本质上来讲，还是属于表达式树的范畴，因为上面的例子，我们同样可以使用表达式树来编写，无非是这个第三方库帮我们隐藏了这部分细节。对于上面这个例子，如果用表达式树来写，会是什么样子的呢？相信熟悉表达式树的朋友，可以非常容易地写出下面的代码： 12345678910//xvar parameter = Expression.Parameter(typeof(tt_wg_order), \"x\");//x.STATUS == 10var condStatus = Expression.Equal(Expression.Property(parameter, \"STATUS\"), Expression.Constant(10));//x.Isdelete == 0var condIsDelete = Expression.Equal(Expression.Property(parameter, \"Isdelete\"), Expression.Constant(0));//x.STATUS == 10 &amp;&amp; x.Isdelete == 0var condAndAlso = Expression.AndAlso(condStatus, condIsDelete);//x =&gt; x.STATUS == 10 &amp;&amp; x.Isdelete == 0var lambda = Expression.Lambda&lt;Func&lt;tt_wg_order,bool&gt;&gt;(condAndAlso, parameter); 我们可以注意到，一个Lmabda表达式，可以抽象为:参数(Parameter)和函数体(Body)两部分，而Body实际上是由一个操作符和一个值组成。譬如这里的第一个条件：x.STATUS == 10。在这里基础上，我们可以定义一个类型：SearchParameters，它将每个条件抽象为字段(Field)、查询方法(QueryMethod)、值(Value)和或分组(OrGroup)。所以，它的处理逻辑就是，将相同OrGroup的条件放在一起用Or连接，然后再和其它条件放在一起用And连接。故而，它可以通过表达式构造出一个Predict类型的委托，而我们的数据持久层是使用EF来实现的，所以，它可以顺利成章地和IQueryable搭配使用，这就是我们这个SearchParameters的实现原理，它唯一让我觉得不好的地方是，字段(Field)不能通过一个Lambda表达式去构造，而必须传入一个字符串，这给了使用者写错字段名称的机会(逃： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778public static class LambdaExpressionBuilder &#123; private static Expression GetExpression (ParameterExpression parameter, Condition condition) &#123; var propertyParam = Expression.Property (parameter, condition.Field); var propertyInfo = propertyParam.Member as PropertyInfo; if (propertyInfo == null) throw new ArgumentException ($\"Invalid field \\\"&#123;condition.Field&#125;\\\"\"); var realPropertyType = Nullable.GetUnderlyingType (propertyInfo.PropertyType) ?? propertyInfo.PropertyType; if (condition.Op != Operation.StdIn &amp;&amp; condition.Op != Operation.StdNotIn) condition.Value = Convert.ChangeType (condition.Value, realPropertyType); var constantParam = Expression.Constant (condition.Value); switch (condition.Op) &#123; case Operation.Equals: return Expression.Equal (propertyParam, constantParam); case Operation.NotEquals: return Expression.NotEqual (propertyParam, constantParam); case Operation.Contains: return Expression.Call (propertyParam, \"Contains\", null, constantParam);; case Operation.NotContains: return Expression.Not (Expression.Call (propertyParam, \"Contains\", null, constantParam)); case Operation.StartsWith: return Expression.Call (propertyParam, \"StartsWith\", null, constantParam); case Operation.EndsWith: return Expression.Call (propertyParam, \"EndsWith\", null, constantParam); case Operation.GreaterThen: return Expression.GreaterThan (propertyParam, constantParam); case Operation.GreaterThenOrEquals: return Expression.GreaterThanOrEqual (propertyParam, constantParam); case Operation.LessThan: return Expression.LessThan (propertyParam, constantParam); case Operation.LessThanOrEquals: return Expression.LessThanOrEqual (propertyParam, constantParam); case Operation.StdIn: return Expression.Call (typeof (Enumerable), \"Contains\", new Type[] &#123; realPropertyType &#125;, new Expression[] &#123; constantParam, propertyParam &#125;); case Operation.StdNotIn: return Expression.Not (Expression.Call (typeof (Enumerable), \"Contains\", new Type[] &#123; realPropertyType &#125;, new Expression[] &#123; constantParam, propertyParam &#125;)); &#125; return null; &#125; private static Expression GetGroupExpression (ParameterExpression parameter, List&lt;Condition&gt; orConditions) &#123; if (orConditions.Count == 0) return null; var exps = orConditions.Select (c =&gt; GetExpression (parameter, c)).ToList (); return exps.Aggregate&lt;Expression, Expression&gt; (null, (left, right) =&gt; &#123; if (left == null) return right; return Expression.OrElse (left, right); &#125;); &#125; public static Expression&lt;Func&lt;T, bool&gt;&gt; BuildLambda&lt;T&gt; (IEnumerable&lt;Condition&gt; conditions) &#123; if (conditions == null || !conditions.Any ()) return x =&gt; true; var parameter = Expression.Parameter (typeof (T), \"x\"); //简单条件 var simpleExps = conditions.ToList ().FindAll (c =&gt; string.IsNullOrEmpty (c.OrGroup)) .Select (c =&gt; GetExpression (parameter, c)) .ToList (); //复杂条件 var complexExps = conditions.ToList ().FindAll (c =&gt; !string.IsNullOrEmpty (c.OrGroup)) .GroupBy (x =&gt; x.OrGroup) .Select (g =&gt; GetGroupExpression (parameter, g.ToList ())) .ToList (); var exp = simpleExps.Concat (complexExps).Aggregate&lt;Expression, Expression&gt; (null, (left, right) =&gt; &#123; if (left == null) return right; return Expression.AndAlso (left, right); &#125;);; return Expression.Lambda&lt;Func&lt;T, bool&gt;&gt; (exp, parameter); &#125;&#125; 接下来，我们就可以以一种优雅的方式来对编写查询条件： 12345678var searchParameters = new SearchParameters();searchParameters.Query = new QueryModel();searchParameters.Query.Add(new Condition() &#123; Field = \"IntValue\", Op = Operation.LessThan, Value = 30 &#125;);searchParameters.Query.Add(new Condition() &#123; Field = \"StringValue\", Op = Operation.Contains, Value = \"山\", OrGroup = \"StringValue\" &#125;);searchParameters.Query.Add(new Condition&lt;Foo&gt;() &#123; Field = x =&gt; x.StringValue, Op = Operation.Contains, Value = \"有朋\", OrGroup = \"StringValue\" &#125;);var lambda = LambdaExpressionBuilder.BuildLambda&lt;Foo&gt;(searchParameters.Query);var where = lambda.Compile();var result = list.Where(where); 这种实现可以说相当巧妙啦，因为通过有限的条件，我们就可以覆盖到大部分查询的场景，而如果直接去解析一个Lambda表达式，难度显然会增加不少。这里是以一个普通的泛型列表作为示例的，而在实际使用中，常常是结合EntityFramework这类ORM来使用的。相应地，我们只需要为IQueryable接口扩展出支持SearchParameter作为参数进行查询地扩展方法即可，这分别对应了我们在文章一开头所提到的IEnumerable&lt;T&gt;和IQueryable &lt;T&gt;。 可如果遇上Dapper这样的轻量级ORM，我们要考虑的问题就变成了怎么通过Lambda表达式生成SQL语句，所以，通过Dapper来扩展功能的时候，最困难的地方，往往在于没法儿像EF/EF Core一样去随心所欲地Where()，像Dapper.Contrib则只能先查询出所有结果再去做进一步的过滤，这种在数据量特别大的时候就会出问题。通过Lambda生成SQL，最难的地方是，你压根不知道，人家会写一个什么样的表达式，而这个表达式，又怎么通过SQL去表达。那么，退而求其次，我们继续用SearchParameters来实现，因为它里面的QueryMethod是有限的，下面给出一个简单的实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889public static class SearchParametersExtension &#123; public static (string, Dictionary&lt;string, object&gt;) BuildSqlWhere (this SearchParameters searchParameters) &#123; var conditions = searchParameters.Query; if (conditions == null || !conditions.Any ()) return (string.Empty, null); var sqlExps = new List&lt;string&gt; (); var sqlParam = new Dictionary&lt;string, object&gt; (); //构建简单条件 var simpleConditions = conditions.FindAll (x =&gt; string.IsNullOrEmpty (x.OrGroup)); sqlExps.Add (simpleConditions.BuildSqlWhere (ref sqlParam)); //构建复杂条件 var complexConditions = conditions.FindAll (x =&gt; !string.IsNullOrEmpty (x.OrGroup)); sqlExps.AddRange (complexConditions.GroupBy (x =&gt; x.OrGroup).ToList ().Select (x =&gt; \"( \" + x.BuildSqlWhere (ref sqlParam, \" OR \") + \" )\")); var sqlWhwere = sqlExps.Count &gt; 1 ? string.Join (\" AND \", sqlExps) : sqlExps[0]; return ($\" WHERE &#123;sqlWhwere&#125; \", sqlParam); &#125; public static string BuildSqlWhere (this IEnumerable&lt;Condition&gt; conditions, ref Dictionary&lt;string, object&gt; sqlParams, string keywords = \" AND \") &#123; if (conditions == null || !conditions.Any ()) return string.Empty; var sqlParamIndex = 1; var sqlExps = new List&lt;string&gt; (); foreach (var condition in conditions) &#123; var index = sqlParams.Count + sqlParamIndex; switch (condition.Op) &#123; case Operation.Equals: sqlExps.Add ($\"&#123;condition.Field&#125; = @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = condition.Value; break; case Operation.NotEquals: sqlExps.Add ($\"&#123;condition.Field&#125; &lt;&gt; @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = condition.Value; break; case Operation.Contains: sqlExps.Add ($\"&#123;condition.Field&#125; LIKE @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"%&#123;condition.Value&#125;%\"; break; case Operation.NotContains: sqlExps.Add ($\"&#123;condition.Field&#125; NOT LIKE @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"%&#123;condition.Value&#125;%\"; break; case Operation.StartsWith: sqlExps.Add ($\"&#123;condition.Field&#125; LIKE @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"%&#123;condition.Value&#125;\"; break; case Operation.EndsWith: sqlExps.Add ($\"&#123;condition.Field&#125; LIKE @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"&#123;condition.Value&#125;%\"; break; case Operation.GreaterThen: sqlExps.Add ($\"&#123;condition.Field&#125; &gt; @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"&#123;condition.Value&#125;\"; break; case Operation.GreaterThenOrEquals: sqlExps.Add ($\"&#123;condition.Field&#125; &gt;= @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"&#123;condition.Value&#125;\"; break; case Operation.LessThan: sqlExps.Add ($\"&#123;condition.Field&#125; &lt; @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"&#123;condition.Value&#125;\"; break; case Operation.LessThanOrEquals: sqlExps.Add ($\"&#123;condition.Field&#125; &lt;= @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"&#123;condition.Value&#125;\"; break; case Operation.StdIn: sqlExps.Add ($\"&#123;condition.Field&#125; IN @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"&#123;condition.Value&#125;\"; break; case Operation.StdNotIn: sqlExps.Add ($\"&#123;condition.Field&#125; NOT IN @Param&#123;index&#125;\"); sqlParams[$\"Param&#123;index&#125;\"] = $\"&#123;condition.Value&#125;\"; break; &#125; sqlParamIndex += 1; &#125; return sqlExps.Count &gt; 1 ? string.Join (keywords, sqlExps) : sqlExps[0]; &#125;&#125; 现在，我们可以换一种方式来查Dapper，果然是因为手写SQL没有安全感的缘故啊！ 1234567var searchParameters = new SearchParameters();searchParameters.Page = new PageModel() &#123; PageSize = 10, CurrentPage = 1 &#125;;searchParameters.Query = new QueryModel();searchParameters.Query.Add(new Condition() &#123; Field = \"OrgCode\", Op = Operation.Contains, Value = \"飞天御剑流\", OrGroup = \"OrgCode\" &#125;);searchParameters.Query.Add(new Condition() &#123; Field = \"OrgCode\", Op = Operation.Equals, Value = \"新选组\", OrGroup = \"OrgCode\" &#125;);searchParameters.Query.Add(new Condition() &#123; Field = \"CreatedAt\", Op = Operation.GreaterThenOrEquals, Value = new DateTime(2020, 1, 1)&#125;);_repository.GetByQuery&lt;BusinessUnit&gt;(searchParameters); 对于定义Condition时，Field属性安全感缺失的问题，我们可以这样来解决： 1234567891011121314151617181920212223public class Condition&lt;T&gt; : Condition public new Expression&lt;Func&lt;T, dynamic&gt;&gt; Field &#123; get; set; &#125; public Operation Op &#123; get; set; &#125; public object Value &#123; get; set; &#125; public string OrGroup &#123; get; set; &#125;&#125;public class QueryModel : List&lt;Condition&gt;&#123; public void Add&lt;T&gt;(Condition&lt;T&gt; condition) where T : class &#123; var filedName = string.Empty; var memberExp = condition.Field.Body as MemberExpression; if (memberExp == null) &#123; var ubody = (UnaryExpression)condition.Field.Body; memberExp = ubody.Operand as MemberExpression; &#125; filedName = memberExp.Member.Name; Add(new Condition() &#123; Field = filedName, Op = condition.Op, Value = condition.Value, OrGroup = condition.OrGroup &#125;); &#125; &#125; 其实，这还是表达式树的内容，在上面的代码片段中，早已出现过它的身影，回想起多年前用这个东西改造INotifyPropertyChanged的时候，总觉得一切似曾相识： 1searchParameters.Query.Add(new Condition&lt;Foo&gt;() &#123; Field = x =&gt; x.StringValue, Op = Operation.Contains, Value = \"有朋\", OrGroup = \"StringValue\" &#125;); 本文小结和博主的大多数博客一样，这篇博客是一个“醉翁之意不在酒”的博客。听起来在说如何动态创建Lambda表达式，实际上讲的还是表达式树，至于原因，则还是博客开篇所提到的“一以贯之”。博主想写这篇博客，是源于实际工作中遇到的“查询”问题，而最后解决的还真就是查询的问题。不管是Dynamic Linq中的ParseLambda()还是表达式树中的LambdaExpression，本质上都是同一个东西，最终的命运都是Predict这个委托。SearchParameters则是对前者的一种简化，通过控制Lambda表达式的复杂度来简化问题，相比起直接传一个字符串过来，这种在风险的控制上要更高一点，之所以要传字符串，则是又一个非关技术的无聊的问题了，用Jira里的概念说应该叫做设计如此(By Design)。好了，以上就是这篇博客的内容啦，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Linq","slug":"Linq","permalink":"https://qinyuanpei.github.io/tags/Linq/"},{"name":"Lambda","slug":"Lambda","permalink":"https://qinyuanpei.github.io/tags/Lambda/"},{"name":"表达式树","slug":"表达式树","permalink":"https://qinyuanpei.github.io/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A0%91/"}]},{"title":"通过EF/Dapper扩展实现数据库审计功能","date":"2020-04-24T08:20:32.000Z","path":"posts/1289244227/","text":"相信大家都有过周末被电话“吵醒”的经历，这个时候，客服同事会火急火燎地告诉你，客户反馈生产环境上某某数据“异常”，然后你花费大量时间去排查这些错误数据，发现这是客户使用某一种“骚”操作搞出来的“人祸”。可更多的时候，你不会这么顺利，因为你缺乏有力的证据去支持你的结论。最终，你不情愿地去处理了这些错误数据。你开始反思，为什么没有一种流程去记录客户对数据的变更呢？为什么你总要花时间去和客户解释这些数据产生的原因呢？好了，这就要说到我们今天这篇博客的主题——审计。 什么是审计？结合本文引言中的描述的场景，当我们需要知道某条数据被什么人修改过的时候，或者是希望在数据变更的时候去通知某个人，亦或者是我们需要追溯一条数据的变更历史的时候，我们需要一种机制去记录数据表中的数据变更，这就是所谓的审计。而实际的业务中，可能会有类似，查询某一个员工一天内审批了多少单据的需求。你不要笑，人类常常如此无聊，就像我们有一个异常复杂的计费逻辑，虽然审计日志里记录了某个费用是怎么计算出来的，可花时间最多的地方，无一例外是需要开发去排查和解释的，对于这一点，我时常感觉疲于应对，这是我这篇文章里想要写审计的一个重要原因。 EF/EF Core实体跟踪EF和EF Core里都提供了实体跟踪的功能，我的领导经常吐槽我，在操作数据库的时候，喜欢显式地调用repository.Update()方法，因为他觉得项目中的实体跟踪是默认打开的。可当你学习了Vue以后，你了解到Vue中是检测不到数组的某些变化的，所以，这个事情我持保留意见，显式调用就显式调用呗，万一哪天人家把实体跟踪给关闭了呢？不过，话说回来，实体跟踪确实可以帮我们做一点工作的，其中，就包括我们今天要说的审计功能。 EF和EF Core中的实体追踪主要指DbContext类的ChangeTracker，而通过DetachChanges()方法，则可以获得那些变化了的实体的集合。所以，使用实体追踪来实现审计功能，本质上就是在SaveChanges()方法调用前后，记录实体中每一个字段的变化情况。为此，我们考虑编写下面的类——AuditDbContextBase，顾名思义，这是一个审计相关的DbContext基类，所以，希望实现审计功能的DbContext都会继承这个类。这里，我们重写其SaveChanges()方法，其基本定义如下： 12345678910111213141516171819202122public class AuditDbContextBase : DbContext, IAuditStorage&#123; public DbSet&lt;AuditLog&gt; AuditLog &#123; get; set; &#125; public AuditDbContextBase(DbContextOptions options, AuditConfig auditConfig) : base(options) &#123; &#125; public virtual Task BeforeSaveChanges() &#123; &#125; public virtual Task AfterSaveChanges() &#123; &#125; public override async Task&lt;int&gt; SaveChangesAsync(bool acceptAllChangesOnSuccess, CancellationToken cancellationToken = default) &#123; await BeforeSaveChanges(); var result = await base.SaveChangesAsync(acceptAllChangesOnSuccess, cancellationToken); await AfterSaveChanges(); return result; &#125; public void SaveAuditLogs(params AuditLog[] auditLogs) &#123; AuditLog.AddRange(auditLogs); base.SaveChangesAsync(); &#125;&#125; 接下来，就是去实现BeforeSaveChanges()和AfterSaveChanges()两个方法： 123456789101112131415161718192021222324252627282930313233343536373839//BeforeSaveChangespublic virtual Task BeforeSaveChanges()&#123; ChangeTracker.DetectChanges(); _auditEntries = new List&lt;AuditEntry&gt;(); foreach (var entityEntry in ChangeTracker.Entries()) &#123; if (entityEntry.State == EntityState.Detached || entityEntry.State == EntityState.Unchanged) continue; if (entityEntry.Entity.GetType() == typeof(AuditLog)) continue; if (_auditConfig.EntityFilters.Any(x =&gt; x(entityEntry))) continue; var auditEntry = new AuditEntry(entityEntry, _auditConfig); _auditEntries.Add(auditEntry); &#125; return Task.CompletedTask;&#125;//AfterSaveChangespublic virtual Task AfterSaveChanges()&#123; if (_auditEntries == null || !_auditEntries.Any()) return Task.CompletedTask; _auditEntries.ForEach(auditEntry =&gt; auditEntry.UpdateTemporaryProperties()); var auditLogs = _auditEntries.Select(x =&gt; x.AsAuditLog()).ToArray(); if (!_auditConfig.AuditStorages.Any()) _auditConfig.AuditStorages.Add(this); _auditConfig.AuditStorages.ForEach( auditStorage =&gt; auditStorage.SaveAuditLogs(auditLogs) ); return Task.CompletedTask;&#125; 可以注意到，我们会在SaveChanges()方法执行前，通过ChangeTracker.DetectChanges()方法显式地捕获“变化”，这些“变化”会被存储到一个临时的列表中。而在SaveChanges()方法执行后，则会更新那些只有在数据提交后才可以获得的“临时”数据，最典型的例子是自增的ID，在数据提交前，我们是无法获得真正的ID的。这个列表中的内容最终会通过AsAuditLog()方法进行转化。下面是AuditEntry中的部分代码片段： 12345678910111213141516171819202122232425262728293031323334353637383940414243//SetValuesCollectionprivate void SetValuesCollection(List&lt;PropertyEntry&gt; properties)&#123; foreach (var property in properties) &#123; var propertyName = property.Metadata.GetColumnName(); if (_auditConfig.PropertyFilters.Any(x =&gt; x(_entityEntry, property))) continue; switch (OperationType) &#123; case OperationType.Created: NewValues[propertyName] = property.CurrentValue; break; case OperationType.Updated: if (_auditConfig.IsIgnoreSameValue &amp;&amp; property.OriginalValue.ToString() == property.CurrentValue.ToString()) continue; OldValues[propertyName] = property.OriginalValue; NewValues[propertyName] = property.CurrentValue; break; case OperationType.Deleted: OldValues[propertyName] = property.OriginalValue; break; &#125; &#125;;&#125;//AsAuditLogpublic AuditLog AsAuditLog()&#123; return new AuditLog() &#123; Id = Guid.NewGuid().ToString(\"N\"), TableName = TableName, CreatedBy = string.Empty, CreatedDate = DateTime.Now, NewValues = NewValues.Any() ? JsonConvert.SerializeObject(NewValues) : null, OldValues = OldValues.Any() ? JsonConvert.SerializeObject(OldValues) : null, ExtraData = ExtraData.Any() ? JsonConvert.SerializeObject(ExtraData) : null, OperationType = (int)OperationType &#125;;&#125; 在此基础上，我们可以编写我们实际的DbContext，这里以CustomerContext为例，当我们向其中添加、修改和删除Customer的时候，就会触发审计相关的逻辑，默认情况下，审计产生的数据AuditLog和Customer在同一个数据库上下文中，当然，我们可以通过注入IAuditStore来实现更精细的控制，例如，可以将审计日志输入到文本文件，甚至是Mongodb这样的非关系型数据库里，因为有依赖注入的存在，这些实现起来会非常的简单！ 12345678910111213141516171819202122//注入AuditLog配置services.AddAuditLog(config =&gt; config .IgnoreTable&lt;AuditLog&gt;() .IgnoreProperty&lt;AuditLog&gt;(x =&gt; x.CreatedDate) .WithExtraData(\"Tags\", \".NET Core\") .WithStorage&lt;FileAuditStorage&gt;() .WithStorage&lt;MongoAuditStorage&gt;());//注入DbContextservices.AddDbContext&lt;CustomerContext&gt;(options =&gt; options.UseSqlServer(Configuration.GetConnectionString(\"DefaultConnection\")));//像平时一样使用EFvar entity = _context.Customer.Where(x =&gt; x.Id == customer.Id).FirstOrDefault();entity.Name = customer.Name;entity.Email = customer.Email;entity.Address = customer.Address;entity.Tel = customer.Tel;_context.Customer.Update(entity);await _context.SaveChangesAsync(); 下面是最终生成的审计日志信息： 审计日志表展示 Castle动态代理而对于像Dapper这种轻量级的ORM，它本身没有类似EF/EF Core的ChangeTracker的设计，如果我们在项目中使用Dapper，并且希望实现审计的相关功能，直观上看就会有一点困难。其实，平时在混合使用EF/Dapper的过程中，经常遇到的问题就是，如何确保传统的ADO.NET和EF在一个数据库事务中，如何确保Dapper和EF在一个数据库事务中等等。此时，我们就需要一点抽象，首先去实现一个Dapper的仓储模式，然后再借助Castle这类动态代理库实现对接口的拦截。这里以Dapper的扩展库Dapper.Contrib为例。首先，我们定义一个仓储接口IRepository: 123456789101112131415161718192021222324252627public interface IRepository&#123; TEntity GetByID&lt;TEntity&gt;(object id) where TEntity : class; TEntity GetByKeys&lt;TEntity&gt;(object keys) where TEntity : class; TEntity QueryFirst&lt;TEntity&gt;(string sql, object param) where TEntity : class; TEntity QuerySingle&lt;TEntity&gt;(string sql, object param) where TEntity : class; [AuditLog(OperationType.Created)] void Insert&lt;TEntity&gt;(params TEntity[] entities) where TEntity : class; [AuditLog(OperationType.Updated)] void Update&lt;TEntity&gt;(params TEntity[] entities) where TEntity : class; [AuditLog(OperationType.Deleted)] void Delete&lt;TEntity&gt;(params TEntity[] entities) where TEntity : class; void Delete&lt;TEntity&gt;(params object[] ids) where TEntity : class; IEnumerable&lt;TEntity&gt; GetByQuery&lt;TEntity&gt;(Expression&lt;Func&lt;TEntity,bool&gt;&gt; exps) where TEntity : class; IEnumerable&lt;TEntity&gt; GetByQuery&lt;TEntity&gt;(string sql, object param) where TEntity : class; IEnumerable&lt;TEntity&gt; GetAll&lt;TEntity&gt;() where TEntity : class;&#125; 接下来，我们就可以在拦截器中实现数据审计功能，因为Dapper本身没有ChangeTracker，所以，我们必须要在先从数据库中查出来OldValue，所以，实际效率应该并不会特别高，这里权当做为大家扩展思路吧！ 1234567891011121314151617181920212223242526272829303132333435public class AuditLogInterceptor : IInterceptor&#123; public void Intercept(IInvocation invocation) &#123; var repository = invocation.Proxy as IRepository; var entityType = GetEntityType(invocation); var tableName = GetTableName(entityType); var tableIdProperty = entityType.GetProperty(\"Id\"); var auditLogAttrs = invocation.Method.GetCustomAttributes(typeof(AuditLogAttribute), false); if (auditLogAttrs == null || auditLogAttrs.Length == 0 || entityType == typeof(AuditLog)) &#123; invocation.Proceed(); return; &#125; var auditLogAttr = (auditLogAttrs as AuditLogAttribute[])[0]; var auditLogs = new List&lt;AuditLog&gt;(); switch (auditLogAttr.OperationType) &#123; case Domain.OperationType.Created: auditLogs = GetAddedAuditLogs(invocation, tableName); break; case Domain.OperationType.Updated: auditLogs = GetUpdatedAuditLogs(invocation, tableName, entityType, tableIdProperty, repository); break; case Domain.OperationType.Deleted: auditLogs = GetDeletedAuditLogs(invocation, tableName); break; &#125; invocation.Proceed(); repository.Insert&lt;AuditLog&gt;(auditLogs.ToArray()); &#125;&#125; 同样地，这里需要需要使用Autofac将其注册到IoC容器中： 1234builder.RegisterType&lt;DapperRepository&gt;().As&lt;IRepository&gt;() .InterceptedBy(typeof(AuditLogInterceptor)) .EnableInterfaceInterceptors();builder.RegisterType&lt;AuditLogInterceptor&gt;(); 思路延伸：领域事件最近这段时间，对于数据同步这类“需求”略有感触，譬如某种单据在两个互为上下游的系统里流转，譬如不同系统间实时地对基础资料进行同步等。这类需求可能会通过ETL、DBLink这类“数据库”手段实现，亦有可能是通过互相调用API的方式实现，再者无非是通过数据库实现类似消息队列的功能……而我个人，更推崇通过事件来处理，因为它更接近人类思考的本质，希望在适当的时机来“通知”对方，而论询实际上是一种相当低效的沟通方式。一个订单被创建，一条记录被修改，本质上都是一个特定事件，而在业务上对此感兴趣的任何第三方，都可以去订阅这个事件，这就是事件驱动的思想。 领域事件 我拜读了几篇关于“领域驱动设计(DDD)”文章，了解到DDD中有领域事件和集成事件的概念。最直接的体会就是，DDD是主张“充血模型”的，它把事件附加到实体上，最大的好处就是，可以让“发送(Dispatch)”事件的代码，集中地放在一个地方。而我们现在的业务代码，基本是高度耦合的，每次去添加一个事件的时候，最担心地就是遗漏了某个地方。按照DDD的思想，实现领域事件，最常用的伎俩是重写DbContext的SaveChanges()方法，或者在EF中去指定DbContext的Complate事件。这里同样借助了ChangeTracker来实现： 123456789public class OrderContext : DbContext&#123; public async Task&lt;bool&gt; SaveChangesAsync(CancellationToken cancellationToken = default(CancellationToken)) &#123; var aggregateRoots = dbContext.ChangeTracker.Entries().ToList(); await _eventDispatcher.DispatchAsync(aggregateRoots,cancellationToken); var result = await base.SaveChangesAsync(); &#125;&#125; 其中，_eventDispatcher作为事件分发器来分发事件，它实现了IEventDispatcher接口。相对应地，事件订阅者需要实现IDomainEventHandler接口。如果是最简单的进程内通信，那么你需要一个容器来管理IDomainEvent和IDomainEventHandler间的关系；而如果是不同微服务间的通信，那么你需要引入RabbitMQ或者kafka这类消息队列中间件。 1234567891011121314151617public interface IDomainEvent&#123;&#125;public interface IDomainEventHandler&lt;in TDomainEvent&gt; where TDomainEvent : IDomainEvent&#123; Task HandleAysnc(TDomainEvent @event, CancellationToken cancellationToken = default);&#125;public interface IEventDispatcher&#123; Task DispatchAsync&lt;TDomainEvent&gt;( TDomainEvent @event, CancellationToken cancellationToken = default) where TDomainEvent :IDomainEvent;&#125; 所以，你现在问我怎么样做数据同步好，我一定会说，通过事件来处理。因为这样，每一条数据的新增、更新、删除，都可以事件的形式发布出去，而关心这些数据的下游系统，则只需要订阅这些事件，该干嘛好嘛，何乐而不为呢？搞什么中间表，打什么标记，用数据库一遍遍地实现消息队列有意思吗？同样地，你会意识到，仓储模式，哪怕ORM换成Dapper，我们一样可以去发布这些事件，增量同步自然是要比全量同步优雅而且高效的。最重要的是，程序员再不需要到处找地方埋点了，你看我博客更新频率这么低，不就是因为这些事情浪费了时间吗(逃？因为，全量 + 实时同步就是一个非常愚蠢的决定。 本文小结本文分别针对EF Core和Dapper实现了数据库审计的功能。对于前者，主要是通过重写DbContext的SaveChanges()方法来实现，而EF及EF Core中的ChangeTracker则提供了一种获取数据库表记录变化前后值的能力。而对于后者，主要是实现了Dapper的仓储模式，在此基础上结合Castle的动态代理功能，对仓储接口进行拦截，以此实现审计日志的记录功能。整体来看，后者对代码的侵入性要更小一点，理论上我们可以实现EF或EF Core的仓储模式，这样两者在实现上会更接近一点，当然，更直接的方案是去拦截SaveChanges()方法，这和我们使用继承的目的是一样的，由于Dapper本身没有ChangeTracker，所以，在处理Update()相关的仓储接口时，都需要先查询一次数据库，这一点是这个方案里最大的短板。而顺着这个方案扩展下去，我们同样可以挖掘出一点DDD里领域事件的意味，这就变得很有意思了，不是吗？这篇博客就先写到这里吧……再见","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"Dapper","slug":"Dapper","permalink":"https://qinyuanpei.github.io/tags/Dapper/"},{"name":"EF","slug":"EF","permalink":"https://qinyuanpei.github.io/tags/EF/"},{"name":"审计","slug":"审计","permalink":"https://qinyuanpei.github.io/tags/%E5%AE%A1%E8%AE%A1/"}]},{"title":"WebApiClient中动态路由的实现与使用","date":"2020-04-02T10:26:53.000Z","path":"posts/2488769283/","text":"博主曾经在「声明式RESTful客户端WebApiClient在项目中的应用」这篇博客中，介绍过.NET平台下的“Retrofit”——WebApiClient，它是一种声明式的RESTful客户端，通过动态代理来生成Http调用过程代码，而调用方只需要定义一个接口，并使用相关“注解”对接口进行修饰即可，类似的实现还有Refit，是一种比HttpWebRequest、HttpClient和RestSharp更为优雅的接口调用方式。在今天这篇博客中，我想聊聊WebApiClient中动态路由的实现与使用。 一个典型的WebApiClient使用流程如下，首先定义一个接口，并使用“注解”对接口进行修饰： 123456789101112public interface ISinoiovApiClient : IHttpApiClient&#123; /// &lt;summary&gt; /// 运单取消接口 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; [HttpPost(\"/yl/api/waybill/cancel\")] [AuthorizeFilter] [LoggingFilter] [JsonReturn] ITask&lt;BaseApiResult&lt;object&gt;&gt; CancelShipment([JsonContent]BaseShipmentDto shipment);&#125; 接下来，调用就变得非常简单： 123456var config = new HttpApiConfig () &#123; HttpHost = new Uri (baseUrl) &#125;;using (var client = HttpApiClient.Create&lt;ISinoiovApiClient&gt; (config)) &#123; var result = await client.CancelShipment (new BaseShipmentDto () &#123; &#125;); //TODO：TODO的意思就是永远都不做&#125; 有多简单呢？简单到调用的时候我们只需要给一个baseUrl就可以了！然而，如果你真这么想的话，就太天真了！虽然现在是一个遍地都是微服务和容器的时代，可是因为RESTful风格本身的约束力并不强，实际使用中难免会出现以下情况： 1234//测试环境http://your-domain.com/test/api/waybill/cancel//正式环境http://your-domain.com/prod/api/waybill/cancel 是的，你猜对了，实际运作过程中，测试环境和正式环境不单单会使用不同的域名，可能还会使用不同的路由，虽然，理论上两个环境的程序应该完全一样，应该使用相同的路由。这样子就让我们有一点尴尬，因为我们的路由是写在特性(Attribute)里的，这玩意儿的实例化是附着在对应的类上面的，并且在整个运行时期间是不允许修改的。所谓“兵来将挡水来土掩”，接下来，我们来考虑如何解决这个问题。 使用[Uri]第一种思路是给接口加一个Url参数，此时，调整接口方法声明如下： 123456789/// &lt;summary&gt;/// 运单取消接口/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpPost][AuthorizeFilter][LoggingFilter][JsonReturn]ITask&lt;BaseApiResult&lt;object&gt;&gt; CancelShipment([Uri]string url, [JsonContent]BaseShipmentDto shipment); 这种方式可以解决问题，可我使用WebApiClient的原因之一，就是我不喜欢在客户端(调用方)维护这些地址。作为一个ApiCaller，在微服务架构流行以来，接口越来越多，逐渐呈现出爆炸式增加的趋势。当我作为一个后端工程师的时候，编写接口是件非常惬意的事情。可当我为了”全栈工程师”的虚名，去做一个面无表情的ApiCaller的时候，我是不情愿去配置这些Url的，有本事你把配置中心搭起来啊！所以，道理我都懂，But，我拒绝！ 使用{foobar}第二种思路是同样是给接口增加一个片段参数，此时，调整接口方法声明如下: 123456789/// &lt;summary&gt;/// 运单取消接口/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpPost('/&#123;prefix&#125;/api/waybill/cancel)][AuthorizeFilter][LoggingFilter][JsonReturn]ITask&lt;BaseApiResult&lt;object&gt;&gt; CancelShipment([JsonContent]BaseShipmentDto shipment, string prefix = \"yl\"); 这种方式和第一种方式原理一致，无非是需要配置的参数从多个变成一个。我个人更喜欢这种方式，为什么呢？可能我认为专业的Api接口会有版本的概念，类似于： 1234//版本号路由/api/v2.0/abc/xyz//查询参数路由/api/abc/xyz?v=2.0 这样，我们就在无形中解决了一类问题，对于第二种形式，版本号以查询参数的方式出现，我们选择在过滤器中AddUrlQuery()或者使用[PathQuery]来解决。如果让我选择，我一定会选择这种方式，因为它更优雅一点吗？不，因为我懒，写程序的终究目的就是为了不写代码，就好像一个程序试图去杀死它自己的进程。 使用服务发现第三种思路，我承认有一点赌的成份，你猜对接客户的接口的时候，会不会提供服务发现这套基础设施给你？可如果在自己的项目里有服务发现，还需要再配置每个服务的Url吗？这样想是不是觉得还不错，的确，我们在微服务架构里引入WebApiClient这种类Retrofit的库，本质上还是为了弱化服务的界限感，如果我调用一个服务和调用本地方法的体验一样，那么，这是什么呢？不用怀疑，这就是RPC(大雾)。这里，我实现了一个简单的示例： 1234567891011//通过Consul获取可用地址var services = await _consul.Health.Service(\"SinoiovApi\", string.Empty, true);var serviceUrls = services.Response.Select(s =&gt; $\"&#123;s.Service.Address&#125;:&#123;s.Service.Port&#125;\").ToList();serviceUrl = serviceUrls[new Random().Next(0, serviceUrls.Count - 1)];//今天的你我，怎样重复昨天的故事var config = new HttpApiConfig () &#123; HttpHost = new Uri (serviceUrl) &#125;;using (var client = HttpApiClient.Create&lt;ISinoiovApiClient&gt; (config)) &#123; var result = await client.CancelShipment (new BaseShipmentDto () &#123; &#125;); //TODO：TODO的意思就是永远都不做&#125; 当然，我说了这有赌的成份，前提是这些服务在Consul中提前注册，这一点相信大家都知道啦！WebApiClient的作者提供了类似扩展:WebApiClient.Extensions.DiscoveryClient，该扩展基于Steeltoe打造，感兴趣的朋友，可以前去了解一下。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"RESTful","slug":"RESTful","permalink":"https://qinyuanpei.github.io/tags/RESTful/"},{"name":"Retrofit","slug":"Retrofit","permalink":"https://qinyuanpei.github.io/tags/Retrofit/"},{"name":"WebApi","slug":"WebApi","permalink":"https://qinyuanpei.github.io/tags/WebApi/"}]},{"title":".NET Core + ELK搭建可视化日志分析平台(上)","date":"2020-02-15T16:01:13.000Z","path":"posts/3687594958/","text":"Hi，各位朋友，大家好！欢迎大家关注我的博客，我的博客地址是: https://blog.yuanpei.me。今天是远程办公以来的第一个周末，虽然公司计划在远程两周后恢复正常办公，可面对着每天都有人离开的疫情，深知这一切都不会那么容易。窗外的阳光透过玻璃照射进屋子，这一切都昭示着春天的脚步渐渐近了。可春天来了，有的人却没有再回来。那些在2019年结束时许下的美好期待、豪言壮语，在这样一场灾难面前，终究是如此的无力而苍白。可不管怎么样，生活还是要继续，在这些无法出门的日子里，在这样一个印象深刻的春节长假里，除了做好勤洗手、多通风、戴口罩这些防疫保护措施以外，博主还是希望大家能够抽空学习，通过知识来充实这“枯燥”的生活。所以，从今天开始，我将为大家带来 .NET Core + ELK搭建可视化日志分析平台 系列文章，希望大家喜欢。 什么是ELK当接触到一个新的事物的时候，我们最好是从它的概念开始入手。那么，什么是ELK呢？ELK，是Elastaicsearch、Logstash和Kibana三款软件的简称。其中，Elastaicsearch是一个开源的全文搜索引擎。如果你没有听说过它，那至少应该听说过Lucene这个开源搜索引擎。事实上，Elastaicsearch是Lucene的封装，它提供了REST API 的操作接口 。而Logstash则是一个开源的数据收集引擎，具有实时的管道，它可以动态地将不同的数据源的数据统一起来。最后，Kibana是一个日志可视化分析的平台，它提供了一系列日志分析的Web接口，可以使用它对日志进行高效地搜索、分析和可视化操作。至此，我们可以给ELK一个简单的定义： ELK是一个集日志收集、搜索、日志聚合和日志分析于一身的完整解决方案。 下面这张图，展示了Elastaicsearch、Logstash和Kibana三款软件间的协作关系。可以注意到，Logstash负责从应用服务器收集日志。我们知道，现在的应用程序都是跨端应用，程序可能运行在PC、移动端、H5、小程序等等各种各样的终端上，而Logstash则可以将这些不同的日志信息通过管道转换为统一的数据接口。这些日志将被存储到Elasticsearch中。我们提到Elastaicsearch是一个开源的全文搜索引擎，故而它在数据查询上相对传统的数据库有着更好的优势，并且Elasticsearch可以根据需要搭建单机或者集群。最终，Kibana从Elasticsearch中查询数据并绘制可视化图表，并展示在浏览器中。在最新的ELK架构中，新增了FireBeat这个软件，它是它是一个轻量级的日志收集处理工具(Agent)，适合于在各个服务器上搜集日志后传输给Logstash。 ELK-01.png 总而言之，ELK可以让我们以一种更优雅的方式来收集日志，传统的日志收集通常会把日志写到文件或者数据库中。前者，不利于日志的集中管理和查询；后者，则无法应对海量文本检索的需求。所以，使用ELK可以为我们带来下面这些便利：分布式日志数据集中式查询和管理；系统监控，譬如对系统硬件和应用各个组件的监控；故障排查；报表功能；日志查询，问题排查，上线检查； 服务器监控、应用监控、错误报警；性能分析、用户行为分析、时间管理等等。 如何安装ELK安装ELK的方式，首推以Docker方式安装。关于Docker的安装、使用请大家查阅官方文档：https://docs.docker.com/。这里我假设大家都已经掌握了Linux和Docker的使用。首先我们拉取ELK镜像： 1docker pull sebp/elk 接下来，我们利用此镜像来运行一个容器: 1docker run -p 5601:5601 -p 9200:9200 -p 5044:5044 --name elk sebp/elk 通常情况下，完成这两个步骤以后，我们就完成了ELK安装。此时，我们可以在浏览器中输入地址：http//localhost:9200，这是Elasticsearch的默认端口。如果浏览器中返回了了类似下面的信息，则表示ELK安装成功。这里是博主获得的关于Elasticseach的信息： 1234567891011121314151617&#123; \"name\" : \"elk\", \"cluster_name\" : \"elasticsearch\", \"cluster_uuid\" : \"GGlJrOvtT2uSfoHioLCWww\", \"version\" : &#123; \"number\" : \"7.5.2\", \"build_flavor\" : \"default\", \"build_type\" : \"tar\", \"build_hash\" : \"8bec50e1e0ad29dad5653712cf3bb580cd1afcdf\", \"build_date\" : \"2020-01-15T12:11:52.313576Z\", \"build_snapshot\" : false, \"lucene_version\" : \"8.3.0\", \"minimum_wire_compatibility_version\" : \"6.8.0\", \"minimum_index_compatibility_version\" : \"6.0.0-beta1\" &#125;, \"tagline\" : \"You Know, for Search\"&#125; 接下来，我们继续在浏览器中输入地址：http://localhost:5601/app/kibana。显然，这是Kibana的默认地址，至此ELK的“庐山真面目”终于揭晓，首次安装完ELK，Kibana的界面应该试类似下面这样： ELK的庐山真面目 按照指引，我们可以添加示例数据来感受下ELK全家桶的魅力： ELK示例 - Global Flight Dashboard 这样，我们就完成ELK环境的快速搭建。下面，按照惯例，我们将实现一个“Hello World”级别的实例，即：通过ELK来收集一个ASP .NET Core应用的日志信息。为了让这个示例尽可能地简单一点，我们选择了直接向Elasticsearch写入日志的方式，这里选择的日志库是Serilog。 Hello ELK本文所用的例子已发布到Github。首先，我们准备一个ASP.NET Core的项目，MVC或者Web API都可以。接下来，在项目中引入三个依赖项：Serilog、Serilog.Extensions.Logging和Serilog.Sinks.ElasticSearch。对于前两个，如果大家用过Log4Net或者NLog应该会感到非常熟悉啦，这一点不在赘述。而第三个，从名字就可以看出来这是冲着Elasticsearch来的，因为这是这个系列的第一篇文章，所以，我们直接写Elasticsearch即可。Logstash管道相关的内容，是一个非常复杂的东西，我们会在下一篇文章中单独来讲。 接下来，主要是Serilog在ASP.NET Core中的配置。首先是Startup类，在构造函数中初始化Serilog： 1234567891011121314public Startup(IConfiguration configuration)&#123; Log.Logger = new LoggerConfiguration() .Enrich.FromLogContext() .MinimumLevel.Debug() .WriteTo.Elasticsearch( new ElasticsearchSinkOptions(new Uri(\"http://localhost:9200\")) &#123; MinimumLogEventLevel = LogEventLevel.Verbose, AutoRegisterTemplate = true &#125;) .CreateLogger(); Configuration = configuration;&#125; 还记得http://localhost:9200这个地址是什么吗？不错，这是Elasticsearch的默认地址，所以，这部分代码主要的作用就是告诉Elasticsearch，接下来的日志信息都写到Elasticsearch中。为了让日志的信息更丰富一点，我们这里设置最小的日志事件级别为Verbose。 接下来，在ConfigureServices()方法中注册ILogger实例： 1services.AddLogging(loggingBuilder =&gt; loggingBuilder.AddSerilog(dispose: true)); 接下来，在业务层增加日志： 12345678private readonly ILogger _logger = Log.Logger; [HttpGet]public double Add(double n1, double n2)&#123; _logger.Information($\"Invoke &#123;typeof(CoreCalculatorService).Name&#125;/Add: &#123;n1&#125;,&#123;n2&#125;\"); return n1 + n2;&#125; 至此，ELK在ASP.NET Core中的集成已经全部结束，这意味着我们所有的日志都会写入到ELK中。那么，要到那里去找这些日志信息呢？且听博主娓娓道来。我们在Kibana中点击左侧导航栏最底下的设置按钮，然后再点击右侧的Create index pattern按钮创建一个索引。什么叫做索引呢？在Elasticsearch中索引相当于一张”表”，而这个“表”中的一条行记录则被称为Document，如图： 为Kibana创建索引1 创建索引的时候，会发现列表中列出了目前Elasticsearch中可用的数据。以博主为例，这里的logstash-2020.02.15就是本文中的ASP.NET Core应用产生的日志信息。在这里，我们可以通过一个模糊匹配来匹配同种类型的数据。通常这里需要我们选择一个过滤字段，我们选择时间戳即可： 为Kibana创建索引2 创建完索引，就可以看到目前收集的日志信息了，在此基础上，我们可以做进一步的检索、过滤，来生成各种各样的“查询”。而每一个“查询”实际上就是一个数据源。我们就可以利用这些数据源来完成可视化，这是利用ELK进行可视化分析的一般流程： 在Kibana中查看当前日志信息 下面是博主自己制作的一个简单的可视化看板，果然很长时间没有再用过Kibana，我都快忘记了要怎么做一个折线图。这实在是一篇迟到的博客，我早该在2019年的时候就完成这个系列的，这要命的拖延症啊，虽然没有新冠病毒恐怖，可终究不是什么好习惯！ 一个简单的可视化看板 本文小结这篇博客是这个系列的第一篇，是一篇珊珊来迟的博客，因为博主早在2019年就开始着手学习ELK。考虑最新公司有使用ELK的打算，而因疫情又让博主有充足的时间，所以，博主决定把ELK相关的内容花点时间梳理出来。ELK是一个集日志收集、搜索、日志聚合和日志分析于一身的完整解决方案。博主计划在接下来的篇幅中介绍Logstash/FireBeat管道配置、Docker容器内的日志收集、以及自定义日志组件开发这些话题，希望大家继续关注我的博客。以上就是这篇博客的全部内容啦，晚安！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"ELK","slug":"ELK","permalink":"https://qinyuanpei.github.io/tags/ELK/"},{"name":"日志","slug":"日志","permalink":"https://qinyuanpei.github.io/tags/%E6%97%A5%E5%BF%97/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"监控","slug":"监控","permalink":"https://qinyuanpei.github.io/tags/%E7%9B%91%E6%8E%A7/"}]},{"title":"使用 jsDelivr 为 Hexo 博客提供高效免费的CDN加速","date":"2020-02-05T19:01:00.000Z","path":"posts/1417719502/","text":"最近给博客做了升级，从3.x升级到了4.x，主要是在官网看到了关于静态页面生成效率提升的内容。众所周知，Hexo在文章数目增加以后会越来越慢。博主大概是从14年年底开始使用Hexo这个静态博客的，截止到目前一共有176篇博客，其中的“慢”可想而知，中间甚至动过使用Hugo和VuePress的念头，所以，听说有性能方面的提升，还是决定第一时间来试试。整个升级过程挺顺利的，唯一遇到的问题是关于外部链接检测方面的，具体可以参考这里。今天，博主主要想和大家分享下关于如何使用jsDelivr来为博客提供免费、高效的CDN服务，希望对大家有所帮助。 jsDelivr是一个免费、快速和可信赖的CDN加速服务，官网上声称它每个月可以支撑680亿次的请求。博主是在去年年底的时候，偶然了解到这个服务的存在，这次趁着疫情肆虐的间隙，终于把这个服务集成到了博客中。更重要的是，这个服务在Github上是开源的。目前，它提供了针对npm、Github和WordPress的加速服务，只需要一行代码就可以获得加速效果，以常用的jQuery和Bootstrap为例： 12345// load jQuery v3.2.1https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js// load bootstrap v4.4.1https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.js 这意味着我们只需要发布一个npm的包，就可以使用它提供的加速服务。CDN加速的好处我这里就不再多说了，只要我们的项目中用到了第三方的静态资源，譬如JavaScript/CSS等等都应该考虑接入到CDN中。有人常常担心CDN挂掉或者是私有化部署无法接入外网环境。我想说，我们目光应该长远一点，现在早已不是早年那种单打独斗式的开发模式了，我们不可能把所有资源都放到本地来。随着云计算的概念越发地深入人心，越来越多的基础服务都运行在一台又一台虚拟化的“云服务器”上，这种情况下，搞这种集中化配置的做法，是完全违背分布式的发展趋势的。 如果说，针对npm包的CDN加速服务离我们还有点遥远，因为我们大多数情况下都是在使用别人写好的库。那么，接下来，针对Github的CDN加速服务应该会让我们无比兴奋吧，毕竟Github Pages的“慢”大家是可以感受得到的。不然，为什么大家要用Coding Pages做国内/国外的双线部署呢？首先，我们在浏览器里输入下面这个地址：https://cdn.jsdelivr.net/gh/qinyuanpei/qinyuanpei.github.io@latest/ jsDelivr提供的CDN加速资源 此时，可以注意到，jsDelivr可以把我们Github上的资源呈现出来，只要我们在Github上发布过相应的版本即可。这里的版本，可以理解为一次Release，对应Git中tag的概念，虽然Github现在引入了包管理器的概念，试图统一像npm、nuget、pip等等这样的包管理器。它提供的CDN服务有一个基本的格式： https://cdn.jsdelivr.net/gh/user/repo@version/file 如果大家感兴趣，可以把这里的user和repo改成自己的来体验一番。需要注意的是，这里的版本号同样可以换成Commit ID或者是分支的名称。我个人建议用tag，因为它通常携带了版本号信息，语义上要更好一点。那么，顺着这个思路，我们只要把Hexo中的资源的相对路径改为jsDelivr的CDN加速路径就好啦！为了让切换更加自如，这里我们为Hexo写一个Helper，它可以理解为Hexo中的辅助代码片段。我们在&lt;YouTheme&gt;/scripts/目录下新建一个plugins.js文件，这样Hexo会在渲染时自动加载这个脚本文件： 1234567891011const source = (path, cache, ext) =&gt; &#123; if (cache) &#123; const minFile = `$&#123;path&#125;$&#123;ext === '.js' ? '.min' : ''&#125;$&#123;ext&#125;`; const jsdelivrCDN = hexo.config.jsdelivr; return jsdelivrCDN.enable ? `//$&#123;jsdelivrCDN.baseUrl&#125;/gh/$&#123;jsdelivrCDN.gh_user&#125;/$&#123;jsdelivrCDN.gh_repo&#125;@latest/$&#123;minFile&#125;` : `$&#123;minFile&#125;?v=$&#123;version&#125;` &#125; else &#123; return path + ext &#125;&#125;hexo.extend.helper.register('theme_js', (path, cache) =&gt; source(path, cache, '.js'))hexo.extend.helper.register('theme_css', (path, cache) =&gt; source(path, cache, '.css')) 接下来，修改布局文件，项目中的JavaScript和CSS文件，均通过theme_js()和thems_css()两个函数引入： 1234//加载JavaScript&lt;script src=\"&lt;%- url_for(theme_js('assets/scripts/search', cache)) %&gt;\" async&gt;&lt;/script&gt;//加载CSS&lt;link rel=\"stylesheet\" href=\"&lt;%- url_for(theme_css('/assets/styles/style', cache)) %&gt;\"&gt; 既然是否使用CDN加速是可配置的，我们要在_config.yml文件中添加相应的配置项： 123456# jsdelivr CDNjsdelivr: enable: true gh_user: qinyuanpei gh_repo: qinyuanpei.github.io baseUrl: cdn.jsdelivr.net 除此以外，我们还需要在部署博客的时候，生成一个名为latest的tag。虽然官网上说，在引用CDN的时候版本号可以省略，不过经过博主反复尝试，不带版本号并不会指向正确的版本，有些资源文件会报404，因为这部分资源文件回滚以后发现还是没有。所以，最后博主只好把这个版本号给固定下来了，这样又引入一个新问题，即：每次部署的时候都要先删除远程的latest。所以，这块儿的Travis CI脚本看起来会有点讨厌，如果大家有更好的方案，欢迎大家在博客中留言： 12git tag latestgit push --force --quiet \"https://$&#123;CI_TOKEN&#125;@$&#123;GH_REF&#125;\" master:master --tags 好了，现在重新生成、部署，来看看效果吧： Coding Pages速度 Github Pages速度 感觉效果还不错，Github Pages比平时要快很多，博主顺便就给Coding Pages启用了CDN加速。话说，看到这张图的时候总是感慨，如果肺炎疫情地图能像这两张图一样就好啦！面对这场无声的战役，有很多人一直在一线抗击病魔，还有很多人默默无闻地在支援武汉。或许，宅在家里的你我，什么都做不了，可即便如此，还是让我们一起来祈祷疫情快点结束吧，因为春天都要来了呢……好了，这就是这篇博客的全部内容啦，谢谢大家！ 2020/02/13 更新在此之前，博主提到版本号的问题，即每一次在CDN上生成的版本，怎样体现到Hexo中引用的资源上面。当时采用了一个取巧的方法，Hexo中固定版本号为latest，然后每次都推送这个tag。这样引发一个问题，每次都先去远程删除这个tag，显然这不是我期望的解决方案。最终，我采用的方案是，通过Travis CI编译部署的时候，首先导出变量$TRAVIS_BUILD_NUMBER到一个文本文件中，然后Hexo在生成静态页面的时侯，从这个文本文件中读取该变量的值作为版本号，这样每次编译部署的时候，我们总能获得一个新的tag，而这个tag和Hexo中引用的资源版本一致，这样就彻底解决了这个遗留问题。修改后的plugins.js文件内容如下： 123456789101112131415161718192021var fs = require('fs');var version = 'latest'fs.readFile('./BUILD_NUMBER.txt', function (error, data) &#123; if (error) &#123; console.log('load BUILD_NUMBER.txt fails, ' + error) &#125; else &#123; version = data.toString().trim(); &#125;&#125;);const source = (path, cache, ext) =&gt; &#123; if (cache) &#123; const minFile = `$&#123;path&#125;$&#123;ext === '.js' ? '.min' : ''&#125;$&#123;ext&#125;`; const jsdelivrCDN = hexo.config.jsdelivr; return jsdelivrCDN.enable ? `//$&#123;jsdelivrCDN.baseUrl&#125;/gh/$&#123;jsdelivrCDN.gh_user&#125;/$&#123;jsdelivrCDN.gh_repo&#125;@$&#123;version&#125;/$&#123;minFile&#125;` : `$&#123;minFile&#125;?v=$&#123;version&#125;` &#125; else &#123; return path + ext &#125;&#125;hexo.extend.helper.register('theme_js', (path, cache) =&gt; source(path, cache, '.js'))hexo.extend.helper.register('theme_css', (path, cache) =&gt; source(path, cache, '.css')) 修改后的.travis.yml文件可以在这里获取。","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://qinyuanpei.github.io/tags/Hexo/"},{"name":"CDN","slug":"CDN","permalink":"https://qinyuanpei.github.io/tags/CDN/"},{"name":"jsDelivr","slug":"jsDelivr","permalink":"https://qinyuanpei.github.io/tags/jsDelivr/"}]},{"title":"从 .NET Core 2.2 升级到 3.1 的踩坑之旅","date":"2020-01-22T10:23:08.000Z","path":"posts/3099575458/","text":"有时候，版本更新太快并不是一件好事。虽然，两周一个迭代的“敏捷”开发依然被客户嫌弃交付缓慢，可一边是前端领域“求不要再更新了，学不动了”的声音，一边则是.NET Core从1.x到2.x再到3.x的高歌猛进。版本更新太快，带来的是API的频繁变动，无法形成有效的知识沉淀，就像转眼到了2020年，Python 2.x和Windows 7都引来了“寿终正寝”，可能你都还没有认真地学习过这些知识，突然就被告知这些知识要过期了，想想还是觉得挺疯狂啊。最近一直在捣鼓，如何让.NET Core应用跑在Heroku平台上，因为Docker镜像里使用最新的.NET Core 3.1运行时，所以，痛定思痛之余，决定把手头项目升级到3.1。上一次痛苦还是在2.1升级2.2，这还真没过多长时间。所以呢，这篇博客主要梳理下从2.2升级到3.1过程中遇到的问题。 更新项目文件 调整目标框架为netcoreapp3.1 删除引用项：Microsoft.AspNetCore.App、Microsoft.AspNetCore.Razor.Design 删除AspNetCoreHostingModel，如果项目文件中的值为InProcess(因为ASP.NET Core 3.0 或更高版本项目默认为进程内承载模型） 更新程序入口 CreateWebHostBuilder()方法的返回值类型由IWebHostBuilder调整为IHostBuilder 增加引用项：Microsoft.Extensions.Hosting Kestrel配置变更至ConfigureWebHostDefaults()方法 12345678910public static IHostBuilder CreateWebHostBuilder(string[] args) =&gt; Host.CreateDefaultBuilder(args) .ConfigureWebHostDefaults(webBuilder =&gt; &#123; webBuilder.ConfigureKestrel(serverOptions =&gt; &#123; // Set properties and call methods on options &#125;) .UseStartup&lt;Startup&gt;(); &#125;); 如果通过 HostBuilder手动创建宿主，则需要在 ConfigureWebHostDefaults()方法中显式调用·UseKestrel()： 1234567891011121314151617public static void Main (string[] args) &#123; var host = new HostBuilder () .UseContentRoot (Directory.GetCurrentDirectory ()) .ConfigureWebHostDefaults (webBuilder =&gt; &#123; webBuilder.UseKestrel (serverOptions =&gt; &#123; // Set properties and call methods on options &#125;) .UseIISIntegration () .UseStartup&lt;Startup&gt; (); &#125;) .Build (); host.Run ();&#125; 更新Startup Configure()方法第二个参数由``IHostingEnvironment调整为IWebHostEnvironment(需要引用Microsoft.Extensions.Hosting`) 从管道中删除UseMvc()扩展方法，相应地，删除AddMvc()及其链式调用相关方法 AddMvc()等价于AddRazorPages() + AddControllersWithViews() AddControllers()对应WebApi模板，AddControllersWithViews()对应MVC模板，AddRazorPages()对应SPA模板 路由注册由传统路由调整为终结点路由： 12345678910111213141516171819public void Configure(IApplicationBuilder app, IWebHostEnvironment env)&#123; app.UseStaticFiles(); app.UseRouting(); app.UseCors(); app.UseAuthentication(); app.UseAuthorization(); app.UseEndpoints(endpoints =&gt; &#123; //SignalR路由 endpoints.MapHub&lt;ChatHub&gt;(\"/chat\"); //RazorPages路由 endpoints.MapRazorPages() //特性路由(WebApi) endpoints.MapControllers(); //控制器路由(MVC) endpoints.MapControllerRoute(\"default\", \"&#123;controller=Home&#125;/&#123;action=Index&#125;/&#123;id?&#125;\"); &#125;);&#125; 如果希望继续使用传统路由，则可以使用下列方法任一： 1234services.AddMvc(options =&gt; options.EnableEndpointRouting = false);services.AddControllers(options =&gt; options.EnableEndpointRouting = false);services.AddControllersWithViews(options =&gt; options.EnableEndpointRouting = false);services.AddRazorPages().AddMvcOptions(options =&gt; options.EnableEndpointRouting = false); 序列化/反序列化 从.NET Core 3.0 开始，System.Text.Json默认作为替代Newtonsoft.json的新一代JSON API 直接从.NET Core 3.0 创建的SignalR项目，服务端返回的JSON数据存在大小写的问题，这是由System.Text.Json引起的。解决方案是： 12services.AddSignalR() .AddJsonProtocol(options =&gt; options.PayloadSerializerOptions.PropertyNamingPolicy = null); 同理，对于该方案对于services.AddControllers()一样有效，前提是项目中使用了System.Text.Json。同理，对于SignalR的客户端项目，我们有： 1234567new HubConnectionBuilder() .WithUrl(\"/chatHub\") .AddJsonProtocol(options =&gt; &#123; //TODO &#125;) .Build(); SignalR的JavaScript客户端由@aspnet/signalr 调整为为@microsoft/signalr： 12const signalR = require(\"@microsoft/signalr\");let connection = new signalR.HubConnectionBuilder().withUrl(url).build(); 如果希望继续使用Newtonsoft.json，则需要安装AspNetCore NewtonsoftJson。相应地，需要显式调用AddNewtonsoftJson()扩展方法： 12345services.AddControllers() .AddNewtonsoftJson(options =&gt; &#123; options.SerializerSettings.ContractResolver = new CamelCasePropertyNamesContractResolver(); &#125;); 同样地，AddNewtonsoftJson()支持AddControllers()， AddControllersWithViews()， AddRazorPages()所有方法 疑难杂症 升级后提示无法加载类型：Microsoft.AspNetCore.Mvc.MvcJsonOptions，解决方案是：升级Swashbuckle.AspNetCore至最新版本(5.0+)，调整Swagger中间件配置代码： 12345services.AddSwaggerGen(swagger =&gt;&#123; //这里发生了变化，需要引用：Microsoft.OpenApi.Models swagger.SwaggerDoc(\"v1\", new OpenApiInfo &#123; Title = \"ynamic WebApi\", Version = \"v1.0\" &#125;);&#125;); 安装完 .NET Core 3.x，使用dotnet build编译项目提示找不到Microsoft.NET.Sdk.Web。解决方案是：升级2.2的时候，调整项目文件中的Microsoft.NET.Sdk.Web为Microsoft.NET.Sdk可以解决，而这个方法在3.x以后失效。此时，可以检查环境变量MSBuildSDKsPath中的SDK版本和实际版本是否一致，尤其是像博主这样从2.0一路升级到3.x的朋友，应该都会遇到这个问题。 参考链接 从 ASP.NET Core 2.2 迁移到3.0 升级 ASP.NET Core 3.0 设置 JSON 返回 PascalCase 格式与 SignalR 问题 Incompatibility with ASP.NET Core 3.0","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"SignalR","slug":"SignalR","permalink":"https://qinyuanpei.github.io/tags/SignalR/"},{"name":"迁移","slug":"迁移","permalink":"https://qinyuanpei.github.io/tags/%E8%BF%81%E7%A7%BB/"}]},{"title":"不知老之将至","date":"2020-01-01T08:46:24.000Z","path":"posts/888549816/","text":"我以为，时间是这个世界上最残忍的存在。因为，无论如何，你都无法阻止这如齿轮般互相咬合的时光机器，即使这世界上并没有所谓的“永动机”。习惯于沉默的时间之轮，你在或者不在，丝毫不影响它衡量宇宙万物的尺度。也许，是因为我们所拥有的时间太过短暂，所以，当一切都流失殆尽时，我们所能寄托的便只有不那么确定的未来。时间怎么会变得残忍呢？它无喜无悲俯视众生，倒像是一位入定参禅的老僧，有情感的分明是我们这些人类啊。 孔夫子说：发奋忘食，乐以忘忧，不知老之将至。而有时候，你甚至都没有怎么“发奋”、“快乐”，就不知老之将至了。也许，花了不少时间在工作甚至加班上面，如果这些可以算作“发奋”，老之将至才是符合人类生理趋势的必然。上个周末去看了《叶问4》的完结篇，突然发现，无论是戏里的叶师傅，还是戏外的甄子丹，居然都出现衰老的迹象。而童年记忆中的黄飞鸿则永远是白鹤亮翅的宗师气象，大概是因为《黄飞鸿》系列不曾像《叶问》系列，在功夫片的体裁外，多了一点传记电影的味道。有人说，这是华语功夫片的一次谢幕，而我更愿意理解为，这是演员同过去的自己的阶段性告别。人总是会老的，从公交车上为老人让座的宣传广播，到父母见一次就白一次的鬓角，再到一天比一天翻得飞快的日历……你，又是如何同过去的自己告别的呢？ Flag这种东西，是一种不立没有所谓“仪式感”，而立了又难免让你自愧虚度时光的存在。在过去的一年里，索性一个Flag都不立，这样看过来的时候，人生充满了一种荒芜感：微信公众号运营失败，因为缺少那个想让你运营下去的观众；博客写作无功无过，每月1至2篇文章，作为阶段性的回顾尚可；懒散/拖延症中晚期，此时此刻还有来自2019年的Todo；通过微软小英练习单词和口语，这一点没能坚持下来，更不必说连50音图都没学会的日语；没有被消费主义洗脑，量入为出、精简开支(穷得如此清新脱俗)；一个人做饭没怎么坚持下来，单单是准备食材就挺麻烦了，更何况炒菜锅坏了一直没换新的呢；工作快5年了，我还是没太大长进，还是喜欢怼人怼空气，沟通能力是挺重要了，可惜精力都被开会、扯皮这种事情消耗得差不多了啊；阅读量还是太少，从公司/图书馆借来的书，一般都能找时间去读，而下载下来放Kindle里的，读着读着就被遗忘了，订阅的RSS读起来倒没有这种压力，果然“书非借不能读也”。《一代宗师》里说，人活得是一个起伏，而我这一年是没能活成一杯烈酒的。人喜欢用平凡是真自我安慰，可都怕活成最平庸的样子，用天哥的话说，做人没意思啊！ 醒来的时候和往常一样，一样到和平时上班没什么区别，直到我坐上公交车，惊诧于路上行人为何如此稀少时，我突然意识到，原来今天是2020年的第一天啊，原来2019年就这样失去了啊，原来今天元旦放假啊……习惯其实是件可怕的事情，我妈和我说，是我工作太认真了，确切地说，来到这家新公司后，太多的习惯都被改变了，譬如Deadline驱动开发而导致的加班，譬如身为乙方这个弱势群体的被动，譬如周末一样要被同事电话打扰的无力感……互联网在深入到这个世界的各个角落的同时，互联网从业者的生存环境反倒更加举步维艰，资本家们鼓吹996是一种福报，某企业用251来对待离职的员工，因为加班而过劳死留下孤儿遗孀的软通员工，因为被裁员而无力维持生活选择跳楼的员工…… 詹青云在《奇葩说》里的一段话令我印象深刻，她说，整个社会都在选择性忽视对与错的问题，仅仅是因为这样子做更划算些，一群活生生的人就被当做冰冷的数字一样计算。《红楼梦》里说，“机关算尽太聪明，反误了卿卿性命”，一个大家都互相算计的世界是绝望的，而这种“划算”的想法有一天变成主流则是可怕的。有好几次工作到深夜凌晨，回到家困到直接穿着衣服睡着的我，恍惚中应该会同我的灵魂对话：到底是一件多么惊天动地的事情，需要我连命都不要地熬到这个点。对企业对说，它需要的是“划算”的员工。而对员工来说，生命比一切都重要。即使为社会这部大机器而殚精竭虑甚至牺牲生命，这部如永动机一般的大机器依旧不会停止，我们不需要去追赶整个社会的效率。如果追赶会有什么下场呢？卓别林的《摩登时代》已经告诉过你答案。 可笑的是，人类能接受同类所指定规则，唯独要抗衡比人类更高层次的自然规律。你、我，这个世界上的每一个人都会死，这是所有人都无法逃脱的自然规律，即使是同为人类的医生一样会死，难道医生都是神灵或者天使吗？《白色巨塔》中的財前医生医术精湛，可当面对身患癌症的自己时，一样回天乏术。医学的发展自始至终都是建立在死亡上的，我们不能在享受医学带来的好处的同时，仅仅因为那个人是你或我的亲人，就去伤害这些医疗工作者，因为他们和我们一样，都是普普通通的人，他们唯一比我们多的就是医术，可医术甚至于这世界上一切人类发明的东西，都不是万能的啊。 伤害别人，永远无法弥补我们对逝者的愧疚。生命原本就如此脆弱，如果身为医生而没能抢救过来自己的亲人，按照这套“划算”但不“正确”的理论，那么医生是不是应该选择自杀？我说，这个问题根本不需要多想，因为逝者已逝，让更多的人活下来，九泉之下有知的逝者或许会感到欣慰吧……如果你相信人死后灵魂会得到转世，那么，让逝者的生命从下一个新生命中得到延续不好吗？我们这个世界有一种病态的观念，对待客户要毕恭毕敬，对待患者要高风亮节，可如果有一天这些人要对你做出过分的事情，难道你还要一忍再忍吗？ 人有时候会刻意拉大时空的疏离感，就像我第一次看《叶问》还是在同学的MP4上，我甚至都没有看过《叶问1》里“我要打10个”的名场面，因为第一次看《叶问》的时候，叶师傅已经在大圆桌上同洪师傅切磋武艺了。可当你回首时，时间已经过去10年啦，虽然在这10年里，罗师傅的武功一直没什么长进，而叶师傅的对手则一直在变强。翻过年以后，我就28岁啦，如果回头看我的10年，时间大概一样会变得空泛，因为有的人来来回回地从你生命里来了又去，而有的人甚至从未真正进入过你生命里。当时过境迁，你唯一能留下的就只有自己，我虽庆幸见证过那些花儿的开放，可那些花儿终究不是我的。也许，她们和我一样都渐渐老去了吧，听起来有些矫情对不对？其实，昨天和这些年里的每一天没有什么不同，甚至还要更普通些，因为我又没能控制住情绪发了火，记忆啊，终究带着些美化的滤镜……","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"回顾","slug":"回顾","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%9E%E9%A1%BE/"},{"name":"2019","slug":"2019","permalink":"https://qinyuanpei.github.io/tags/2019/"},{"name":"年度","slug":"年度","permalink":"https://qinyuanpei.github.io/tags/%E5%B9%B4%E5%BA%A6/"}]},{"title":"使用Liquid实现简单的数据交换","date":"2019-12-22T09:36:42.000Z","path":"posts/3742212493/","text":"在平时的开发工作中，接口对接是一件无可避免的事情。虽然在“前后端分离”的大趋势下，后端的角色逐渐转换为数据接口的提供者，然而在实际的应用场景中，我们面对的往往是各种不同的“数据”，譬如企业应用中普遍使用的企业服务总线(ESB)，这类服务要求服务接入者必须使用WebService来作为数据交换格式；再譬如电子数据交换(EDI)这种特定行业中使用的数据交换格式，从可读性上甚至还不如基于XML的WebService……而更为普遍的则可能是需要使用Word、Excel、CSV来作为数据交换的媒介。顺着这个思路继续发散下去，进入我们失业的或许还有各种数据库，譬如MySQL和MongoDB；各种大数据平台，譬如Hadoop和Spark；各种消息队列，譬如RabbitMQ和Kafka等等。 注意到，这里反复提到的一个概念是数据交换(Data Switching)，它是指在多个数据终端设备间，为任意两个终端设备建立数据通信临时互联通路的过程。自从阿里提出“中台”的概念以来，越来越多的公司开始跟风“中台”概念，并随之衍生出譬如组织中台、数据中台、业务中台、内容中台等等的概念。今天这篇博客，我并不打算故弄玄虚地扯这些概念，我的落脚点是接口级别的数据交换，主要通过Liquid这款模板引擎来实现。它对应我在这篇博客开头提到的场景：一个对外提供RESful风格API的系统，如何快速地和一个WebService实现对接。总而言之，希望能对这篇博客对大家有所启发吧！ 关于Liquid首先，我们来介绍Liquid，通过它的官方网站，我们应该它是一门模板语言。对于模板语言，我们应该是非常熟悉啦，JavaScript里的Handlebars和Ejs就是非常著名的模板语言。如大家所见，这个博客就是用Ejs模板渲染出来的。而到了三大前端框架并驾齐驱的时代，模版语法依然被保留了下来，比如Vue中{{model.userName}}标记常常用来做文本插值。所以，如果要认真追溯起来的话，也许这些框架都或多或少的收到了Liquid的影响，因为它的基本语法如下： 12//使用page实例的title属性插值&#123;&#123; page.title&#125;&#125; 假设page是一个对象，它的title属性值为：Introduction，此时，渲染后的结果即为：Introduction。是不是感觉非常简单呢? 我们继续往下看。除了基本的“插值”语法以外，我们可以用{% tag %}这种结构(Liquid称之为Tag)： 12345678910//声称变量author并赋值&#123;% sssign author = '猫先森' %&#125;//条件语句&#123;% if author == '猫先森' %&#125;帅哥，你好&#123;% endif %&#125;//循环语句&#123;% for post in posts %&#125;&#123;&#123;post.date&#125;&#125;-&#123;&#123;post.title&#125;&#125;&#123;% endfor %&#125; 这里仅仅展示了一部分Liquid的特性，但对于我们了解一门“语言”已经足够了，因为对于一门编程语言来说，只要学会顺序、条件和循环三种结构足矣。言下之意呢，像常规else、elseif、break和continue，Liquid都是支持的，这样子是不是更有编程语言的感觉了呢？除此之外，它还支持像tablerow这样的Tag，主要用来渲染HTML里的表格。 也许有人想说，这玩意儿有什么用呢？抱歉啊，这玩意儿还真有用。像发送邮件、发送短信这种一般都需要写个字符串模板的，简单的大家可以用String.Format()或者$来搞定，可一旦遇上循环的场景，这种基于字符串替换的方式就有点力不从心了。不开玩笑地说，在代码里用StringBuilder拼接HTML的方式，实在是太傻逼了。如果用Liquid写可能就是： 1234567亲爱的&#123;&#123; model.UserID &#125;&#125;: 您好！您有以下设备即将超过校验有效期，请及时采取有效行动。 &#123;% for equipment in model.Equipments %&#125; &#123;&#123; equipment.EquipmentID &#125;&#125; &#123;% endfor %&#125; &#123;&#123; model.SendBy &#125;&#125; 显然，这个代码比拼接字符串要优雅很多。博主曾经在一个前端页面看到过大量的HTML拼接操作，果然是jQuery操作DOM一时爽，jQuery操作DOM一直爽，可明明前端就有Handlebars和Ejs这样的模板语言。最近一位同事写前端页面的经历不由得让我感慨，眼睛觉得简单的事情，为什么总是要求手去做呢？直接操作DOM带来的弊端就是，业务逻辑永远和DOM纠缠在一起，那些没有人敢改的JavaScript代码，那些未经模块化全局引入的JavaScript代码，虽然马上就要2020年了，写下这些句子的时候还是感到魔幻，可能这就是所谓的魔幻现实主义吧。 OK, 我们把思绪拉回到Liquid。除了使用各种Tag实现流程控制以外，Liquid中还提供了过滤器(Filter)的概念，过滤器主要是配合{{ variable | filter }}语法来使用的。比如说，数据层返回了一个负数，而展示层希望展示正数，在不确定这个数值是否被别人使用的情况下，贸然去修改数据层的返回值是件危险的事情。此时，我们可以： 123456//对绑定的变量或者值取绝对值&#123;&#123; -17 | abs&#125;&#125;//保留小数位&#123;&#123; 183.357 | round: 2 &#125;&#125;//日期/时间格式&#123;&#123; article.created_date | data: %b %d, %Y&#125;&#125; 类似小数点位数、日期/时间格式等问题，均可以在Liquid中找到相应的过滤器。需要说明的是，Liquid使用Ruby进行开发的。也许在读到这篇博客前，大家都没有听说过Liquid，那么至少听说过Jekyll这个著名的静态博客生成器吧。实际上，在我写这篇博客的时候，我刚刚了解到一件事情，Jekyll就是基于Liquid而开发的，想到当初搭建这个博客时被Ruby劝退的回忆，我大概想不到有一天会再次接触它吧，不得不说，人生还真是奇妙啊！ 一个简单的想法好了，关于Liquid的介绍我们先了解到这里。写到这里，再回头去看我们一开始的问题，即：怎么把上游的数据(Model)转化为下游的数据(Template)。这里暂且抛开它到底是XML、JSON还是EDI这种细节性的问题，我想我们大概会有一个简单的想法，如果把需要传输给对方的接口报文做成模板，然后通过Liquid语法完成数据的绑定，那么数据映射这一层的工作就可以减轻不少，毕竟写A.XXX=B.XXX这种赋值语句是没什么前途的啦，而AutoMapper则需要提前写好Map并注册，经过一番权衡，我们来验证一下我们的想法吧！ 这段时间一直在和金蝶K3Cloud接口做对接，坦白说我觉得金蝶的接口设计得非常糟糕，从它那个奇葩的FNumber字段就能看出来，而且它试图用一个接口做完所有事情的做法恕我不敢苟同，在我看来它违反了单一职责原则。因为要对接的接口数量多、字段多，我首先根据字段对应关系制作了一份Liquid模板，并根据业务上的需要，用主表(Main) + 明细表(Details)的方式来定义数据，这意味着我接下来只需要根据业务实现不同的数据源即可： 基于Liquid的JSON报文模板 好了，现在我们使用Liquid的.NET版本DotLiquid来负责模板的解析和渲染，这个库可以直接通过Nuget安装，可以注意到这个代码非常的简单： 1234567string RenderTpl(string filePath, dynamic model)&#123; var content = File.ReadAllText(filePath); var template = Template.Parse(content); var output = template.Render(Hash.FromAnonymousObject(model)); return output;&#125; 实际上渲染后的文本就是对方需要的接口报文了，此时，该怎么样就怎么样处理，只需要把这个报文发送给对方就可以了。唯一需要花时间的就是对字段、写绑定，相比写实体类的方式效率要高更多。这种方式的话，我个人觉得更适合分工合作，如果需要数据加字段，那在数据层(Model)里增加就好了，而像改字段映射关系、字段默认值都可以由别人来完成。我一直相信，开发并不是帮别人做越多事情越好，而是可以提供一种能力让别人去做更多的事情，这就是我们常常听到的“赋能”。继续延伸下去的话，传统的MVC其实和Liquid是一个道理，都是根据数据去生成视图，无非是我们这里的”视图”变成了数据报文。 本文小结通过日常工作中的接口对接这一典型场景，我们引出了“数据交换”的概念，而最低层级的数据交换实际上是接口报文的交换。为此，我们介绍了Liquid模板引擎，它提供的语法可以让我们完成一系列的绑定，顺着这个思路，博主为大家展示了这种想法的可行性。Liquid是一个非常成熟的模板引擎，无论是编写邮件、短信的文本模板，还是轻量级的文本表达式实现，都是一个非常不错的选择。即使是做一个ApiCaller，一定要做一个有头脑的ApiCaller。好了，以上就是这篇博客的全部内容啦，欢迎大家留言，谢谢大家。 2020-01-09 更新在组织JSON中的数组结构时，需要在各元素间添加,，同时最后一个元素不需要,，此时，可以使用以下语法： 123456789101112131415\"FEntity\": [ &#123;% for Detail in Details %&#125; &#123; \"FCOSTID\": &#123; \"FNumber\": \"&#123;&#123;Detail.FCOSTID&#125;&#125;\" &#125;, \"FCOSTDEPARTMENTID\": &#123; \"FNumber\": \"BM000005\" &#125;, \"FINVOICETYPE\": \"0\", \"FTOTALAMOUNTFOR\": &#123;&#123;Detail.FEE_AMOUNT&#125;&#125;, &#125; &#123;% if forloop.last == false %&#125;,&#123;% endif %&#125; &#123;% endfor %&#125; ]","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"Liquid","slug":"Liquid","permalink":"https://qinyuanpei.github.io/tags/Liquid/"},{"name":"数据交换","slug":"数据交换","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE%E4%BA%A4%E6%8D%A2/"},{"name":"模板引擎","slug":"模板引擎","permalink":"https://qinyuanpei.github.io/tags/%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/"}]},{"title":"Referrer还是Referer? 一个迷人的错误","date":"2019-12-04T17:22:33.000Z","path":"posts/2015300310/","text":"诗人郑愁予曾经在一首诗中写道：我达达的马蹄是个美丽的错误，我不是归人，是个过客。而对我来说，十九岁之前的我，一样是个沉浸在诗歌中的文艺少年。十九岁之后的我，作为一名程序员，更多的是邂逅各种错误。可偏偏人类世界对待错误从来都不宽容，所以，错误本身既不美丽，亦不浪漫。接近中年的我，无论如何，都写不出年轻时令人惊艳的句子，这或许和我们面对错误时的不同心境，有着莫大的关联，而今天这篇博客，同样要从一个历史上的错误说起。 因拼写而怀疑人生话说，博主这天做了一个非常“简单”的功能，它允许用户通过富文本编辑器来编写HTML，而这些HTML会被插入到页面的特定位置，譬如用户可以为页脚的备案号添加一个超链接，当用户点击备案号的时候，就可以调转到工信部备案号查询的网站上。这个功能非常简单吧，因为这就是HTML中a标签的作用。博主快速了引入UEditor，虽然这个项目百度都不再继续维护了，虽然它直接把跨域问题甩锅给使用者，可我还是完成了这个功能。相信你能感受到我的不情愿吧，显然这不是重点，因为剧情的反转才是…… 结果没高兴多久，测试同事就同我讲，客户提供的地址填进去以后，点击链接浏览器直接返回4XX，可明明这个地址敲到浏览器里就能打开啊……我脑海中快速地浮现出那道经典的面试题，浏览器里敲完地址按下回车的瞬间到底发生了什么？习惯性怀疑人生后，我发现居然是因为Referer的问题，从我们站点调转到客户站点的时候携带了Referer，虽然有很多种方法可以让浏览器禁止携带Referer，但我还是被这种历史性的错误搞得怀疑人生。因为人生最难的事情，就是“揣着明白装糊涂”和“揣着糊涂装明白”，所谓“假作真时真亦假”。 请注意区分Referer和Referrer这两个单词，眼尖的人会发现后者多了一个r，这有点像什么呢，大概类似于usr和user。我们总是不情愿地相信这是历史的错误，而固执地想要找到一种能自圆其说的理由。诚然，“前人栽树，后人乘凉”，可我实在不肯承认，这是一群卓越而智慧的先驱们，所创造出的某种高效简写。回顾一下，使用Referer的场合，基本都是在HTTP头部，最常见的场景就是防盗链，Nginx能用Referer判断访问者来源，爬虫就能用Referer和UserAgent伪造访问者身份。那什么时候用Referrer呢？我目前发现是在a标签的rel属性里，例如下面的例子： 1&lt;a rel=\"noreferrer\" href=\"https://www.w3school.com.cn/tags/att_a_rel.asp\"&gt;w3school&lt;/a&gt; 除此之外，rel属性还支持像nofollow、friend、licence这样的属性，详细地大家可以参考这里。相信大家想到博主经历了什么了，没错，我就是按照平时的书写习惯写了Referer，然后被Web标准委员会给疯狂地嘲讽了。那么，为什么表达同一个含义的词会有两种写法？为什么有时候要用Referer，而有时候要用Referrer? 这特么到底是怎么一回事儿……带着这些疑问，让我们一起回顾野蛮生长的Web标准，为什么要埋这样一个坑在这里。 后世不忘，前世之锅？故事要追溯到上个世纪90年代，当时HTTP协议中需要有一个用来表示页面或资源来源的请求头部，Philip Hallam-Baker将这个请求头部定义为Referer，并将其写入了RFC1945，这就是著名的HTTP/1.0协议。 HTTP/1.0协议中定义的Referer 然而这里发生一件有趣的事情，这个单词实际上是被作者给拼错了，即正确的拼写应该是Referrer。因为发现这个错误时为时已晚，大量的服务端和客户端都采用了这个错误的拼写，谁让它被写到了HTTP协议里呢？这其中就有像Nginx里的ngx_http_referer_module、Django里的HttpRequest.META.HTTP_REFERER等等。考虑到这个错误波及的范围过大，HTTP标准制定者奉决心将错就错，于是在接下来的RFC2616，即HTTP/1.1中，HTTP标准制定者追加了针对这个错误的说明: HTTP/1.1协议中定义的Referer 说到这里，大家至少明白了一件事情，这个错误的Referer其实是指Referrer。对于标准写错了这件事情，大家其实都能理解，因为只要是人就免不了会出错。可为什么不能一错到底呢？既然要使用Referer这个错误的拼写，那就一直这样错下去好了，为什么特么又冒出来个Referrer，虽然它的拼写的确是对的，可不统一的写法还是会让人抓狂啊！君不见main和mian傻傻分不清，君不见C++里false与flase的神奇宏定义。假如没有今天这个事情，我完全不知道还有Referrer的存在啊，可都拼错多少年了，我都把假当作真了，你突然这样搞，我还是会感到手足无措的啊！就像Configuration这个单词，虽然博主英语并不算太好，可至少敢拍着胸脯说这个单词没写错，结果有次我写对了反而让测试给我提了Bug，因为特么项目里定义的实际上是Configuation。你说，你这样让人崩溃不？ 那么，为什么会有Referrer这个正确的拼写呢？这就要说到Referrer-Policy这个HTTP头部。不错，这次你没有看错，标准制定老爷们这次终于写对了。顾名思义，这是一种用来告诉浏览器应该如何发送Referer的策略。常见的取值有：no-referrer、no-referrer-when-downgrade、origin、origin-when-cross-origin、same-origin、strict-origin、strict-origin-when-cross-origin、unsafe-url，关于它们的含义及用途，大家可以参考这里。虽然我们经常吐槽JavaScript是一门垃圾语言，但是这一次，大家居然都非常齐心地统一了写法，譬如DOM Level 2里定义的 document.referrer、Fetch API中的Request接口的referrer属性等，这一次都写对了。而Referrer-Policy除了和JavaScript可以集成以外，同样可以和HTML、CSS集成。博主一开始遇到的问题，实际上就是和HTML集成的一个场景。 123456//meta标签里的'referrer'&lt;meta name=\"referrer\" content=\"origin\"&gt;//出现在a, area, img, iframe, script, &lt;link&gt;等元素里的'referrer'&lt;a href=\"http://example.com\" referrerpolicy=\"origin\"&gt;//出现在a, area, link等标签的rel属性里的'referrer'&lt;a href=\"http://example.com\" rel=\"noreferrer\"&gt; 而和CSS集成实际上就是style标签中的referrerpolicy属性，它默认是no-referrer-when-downgrade，我们可以在返回一个CSS文件的时候设置响应流的Referrer-Policy，或者是设置style标签中的referrerpolicy属性，这个就不展开讲啦！ 本文小结通过这次被标准制定者按在地上摩擦的经历，居然无意中收获了这样一段”迷人”的历史。假如JavaScript这里为了兼容历史错误而使用Referer的话，可能博主就不会一边吐槽这个错误，一边又乖乖地滚去读RFC2616。从这里可以得出一个结论：HTTP 请求中的 Referer 是一个典型的拼写错误，历史悠久，可以预见还会一直错下去，以后 Referer 变成一个专有名词也说不定。所以一般涉及到读取 HTTP 请求头的场景，我们需要用 Referer 这种错误拼写(后端)；除此之外一般都要用 Referrer 这种正确的拼写(前端)。有人说，使用JavaScript开发同构应用的体验非常好，恐怕从今天这篇博客以后要打个折扣，因为你刚刚在后端写完referer，转眼就要在前端写referrer，希望像博主这样的伪全栈工程师不会因此而精神分裂。实用主义者能用就行的策略，让这个错误在很多年以后还被人提起，假如这些标准制定者尚在人世的话，不知道会不会在浏览网页的时候，想起第一次起草RFC1945的那个下午。果然，历史还真是迷人啊！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"历史","slug":"历史","permalink":"https://qinyuanpei.github.io/tags/%E5%8E%86%E5%8F%B2/"},{"name":"Referrer","slug":"Referrer","permalink":"https://qinyuanpei.github.io/tags/Referrer/"}]},{"title":"关于单位转换相关问题的常见思路","date":"2019-11-15T09:43:54.000Z","path":"posts/2318173297/","text":"请原谅我使用了这样一个“直白”的标题，因为我实在想不到更好的描述方法。或许，是因为临近年底的“996”式冲刺，让许久没有读完一本书的我，第一次感受到输出时的闭塞。是时候为自己的知识体系补充新鲜血液啦，而不是输给那些“无聊”的流程和关系。说这句话的缘由，是想到《Unnatural》中的法医三澄美琴，一个视非正常死亡为敌人的女法医。而对程序员来说，真正的敌人则是难以解决Bug和问题。可更多的时间，我们其实是在为流程和关系方面的事情消耗精力。 我越来越发现，人类所面对的绝大多数问题，都并非是寻求一个最优解，而是在于平衡和牵制。人类总是不可避免地堕入熵增的圈套，伴随着流程产生的除了规范还有复杂度。每当人们试图为这种复杂度找一种友好的说辞的时候，我终于意识到，有的人不愿意去寻找问题的本质，它们需要的就只是一种友好的说辞，仿佛只要有了这种说辞，问题就能自动解决一样。我想，我大概知道这段时间感到焦灼的原因了，因为这样的事情在工作中基本是常态。人类每天面对的事情，无外乎两种：”明知不可为而为之”和”什么都想兼顾的美好理想”。 我今天想说的是，一个业务中遇到的单位转换的问题，我们平时在存储货物的重量时，默认都是以千克作为单位来存储的，直到我们对接了一家以大宗商品交易作为主要业务的客户，对方要求我们在界面上统一用吨来展示数据，因为这样更符合客户方的使用习惯。按理说，这是一个非常简单的需求，是不需要用一篇博客来说这件事情的，可我觉得这是个有意思的话题，还是想和大家一起来聊聊相关方案的思路。带着问题，我首先拜访了Cather Wong大佬，大佬微微一笑，表示在视图层上加个字段就可以了嘛。的确，这是最简单的做法，大概是下面这个样子： 123456789101112131415class OrderInfoQueryDTO&#123; /// &lt;summary&gt; /// 以千克为单位的净重 /// &lt;/summary&gt; public decimal? NET_WEIGHT &#123; get; set; &#125; /// &lt;summary&gt; /// 以吨为单位的净重 /// &lt;/summary&gt; public decimal? NET_WEIGHT_WITH_TON &#123; get &#123; return NET_WEIGHT / 1000; &#125; &#125;&#125; 我不甘心地追问，客户要在原来的字段上显示这个数值啊，这样能行吗？大佬稍作沉思，随即问道：“你们公司的项目就算做不到DDD，AutoMapper这种实体间映射转换的东西总有吧！”。我连忙接话道：“这个自然是有的”。其实我心里想的是，总算有点符合我的心理预期啦，这样的方案还像个大佬的样子。按照大佬的提示，使用AutoMapper来做单位的转换，应该是下面这样： 1234var config = new MapperConfiguration(cfg =&gt; &#123; cfg.CreateMap&lt;order_info, OrderInfoQueryDTO&gt;() .ForMember(d =&gt; d.NET_WEIGHT, opt =&gt; opt.MapFrom(x =&gt; x.NET_WEIGHT/1000));&#125;); 这样看起来是比加字段要好一点，可实际项目中，我们往往会把单位作为一种配置持久化到数据库中，以我们公司为例，我们实际上是支持千克和吨两种单位混合使用的，不过在表头汇总的时候，为了统一到一起，所以使用了千克作为单位。这样就引申出一个新问题，假如我在数据库里存了多行明细的重量，当需要在表头展示汇总以后的总重量，那么，这个总重量到底是汇总好存在数据库里，还是展示的时候交由调用方Sum()呢？ 我个人倾向于第二种，因为它能有效避免表头和明细行数据不一致的问题，当然缺点是给了调用方一定的计算压力。我们项目中采用的第一种方案，我印象非常深刻，在计算件数、重量和体积的时候，必须要等所有明细行都计算完以后，再通过调用Sum()方法给表头赋值，实际上这个表头字段，完全可以通过只读属性的方式取值啊，更何况我们还使用了外键，表头实体本身就引用了明细表实体，因为有外键的存在，序列化表头实体的时候会出现循环引用，对此，我想说，干得漂亮！ 通过AutoMapper中的ForMember扩展方法，可以实现我们这里这个功能。可考虑到要在AutoMapper里引入权限啊、角色啊这些东西，AutoMapper作为实体映射的纯粹性就被彻底破坏了。为此，我们考虑使用AutoMapper中提供的Value Converters和Type Converters。关于这两者的区别，大家可以参考官方文档中的描述。此时，我们可以通过下面的方式使用这些“转换器”： 1234567891011121314var config = new MapperConfiguration(cfg =&gt; &#123; cfg.CreateMap&lt;order_info,OrderInfoQueryDTO&gt;() .ForMember(d =&gt; d.NET_WEIGHT, opt =&gt; opt.ConvertUsing&lt;WeightValueConverter,decimal?&gt;());&#125;); var mapper = config.CreateMapper();var orderInfo = new order_info() &#123; ORDER_ID = Guid.NewGuid().ToString(\"N\"), NET_WEIGHT = 1245.78M, CREATED_DATE = DateTime.Now, CREATED_BY = \"灵犀一指陆小凤\"&#125;;var orderInfoQueryDTO = mapper.Map&lt;order_info,OrderInfoQueryDTO&gt;(orderInfo); 而对于WeightValueConverter这个类而言，它实现了IValueConverter接口： 12345678910 public class WeightValueConverter : IValueConverter&lt;decimal?, decimal?&gt; &#123; public decimal? Convert (decimal? sourceMember, ResolutionContext context) &#123; //TODO：可以查数据库或者是由规则决定，是否转换以及如何转换 if (!sourceMember.HasValue) return null; return sourceMember.Value / 1000; &#125;&#125; 现在，虽然代码还是这个代码，可至少我们不用在MapFrom里写太重的业务逻辑了，而且这个转换器是可以复用的。显然，我们的系统中不会只有订单模块会涉及到重量、体积的转换。此时，我们可以考虑使用ITypeConverter接口，遗憾地是，这个接口在实现的时候就必须指定源类型和目标类型，这样离我们设想地全局转换器实际上是有一点差距的。例如，我们有时候希望源类型中Null值不会覆盖到目标类型，最常见的情况是，从一个EditDTO转化为数据库实体对象并更新数据库。为了解决这个问题，AutoMapper下面的做法就非常棒： 1cfg.ForAllMaps((a, b) =&gt; b.ForAllMembers(opt =&gt; opt.Condition((src, dest, sourceMember) =&gt; sourceMember != null))); 可对于我们这里这个场景，显然，我们必须要提供一部分类型信息，我们几乎很难给所有的Map增加一个通用的类型转换器。我最终还是通过反射解决了这个问题，即在使用AutoMapper前，从数据库查出数据后，首先要做的第一件事情就是对数值进行转换： 123456789101112131415161718192021222324252627282930313233343536var userSetting = UserContext.GetLoginUser().UserSettng;var formatSetting = userSetting.FormatSetting;//当默认重量单位为KG时不做任何处理if (formatSetting.DefaultWeightUom == WeightUnit.KG) return;var properties = typeof(TDestination).GetProperties() .Where(p =&gt; p.Name.EndsWith(\"WEIGHT\") || p.Name.EndsWith(\"Weight\"));if (properties == null || !properties.Any()) return;foreach(var item in destList)&#123; //转化结果为吨 foreach(var property in properties) &#123; var weightValue = property.GetValue(item, null); if(property.PropertyType == typeof(decimal)) &#123; property.SetValue(item, (decimal)weightValue / 1000); &#125; else if(property.PropertyType == typeof(Nullable&lt;decimal&gt;)) &#123; if (weightValue != null) property.SetValue(item, (decimal)weightValue / 1000); &#125; else if(property.PropertyType == typeof(string)) &#123; if (!string.IsNullOrEmpty(weightValue.ToString())) property.SetValue(item, decimal.Parse(weightValue.ToString()) / 1000); &#125; &#125; &#125;&#125; 不得不说，这段代码相当无聊，可无论多么无聊的功能，只要客户觉得好就给积极地去做，对吧！其实，说到底，这是我们在设计数据库表结构时遗留的一个问题。假如我们在存储的时候就存储为吨，问题还不会有什么不一样呢？实际上，它还是会有问题，因为你不得不去设计一个单位转换表，类似下面这样的： 原始单位 目标单位 进率 Kg T 1/1000 T Kg 1000 g Kg 1/1000 Kg g 1000 我们目前设计的表结构中实际上是有重量单位的，不同的是，我们以千克为单位存储的量，数据库中对应的WEIGHT_UOM存储的是1，而以吨为单位存储的量，数据库中对应的WEIGHT_UOM存储的是1000。所以，理论上真实的重量都应该是数据库中存储的量 X WEIGHT_UOM。这样看起来是没有问题的，可当你结合今天这篇博客的背景来看是，就会发现一个问题，所有的数值在展示的时候都必须要知道，数据库里存储的数值的原始单位是什么，而使用者希望在界面上看到的数值的单位又是什么。 不单单如此，当用户通过界面查询的时候，一个简单的数字便不等再用简单地使用像大于、小于、等于、不等于这样的查询条件，因为现在每个量都带着单位，你必须明确得知道，用户认为的单位是什么，而数据库里对应的单位又是什么？这样听起来貌似还是统一使用一种单位比较好，正因为如此，博主可以在查询前把吨转化为千克，而在查询后则可以把千克转换为吨。 人类世界总是存在着这些奇奇怪怪的规则，不同的小数位精度要求，不同的货币金额展示方式，不同的日期格式显示要求，就在我写下这篇博客的时候，产品同事反馈我千克转成吨展示以后，应该至少保留三位小数，否则会让人觉得数字会丢失了精度。我还能说什么呢？联想到最近软通因为加班而猝死的同行，我大概只能说一句：恭喜你，还请节哀顺变，欢迎来到无法随心所欲的爱与欲望的世界！作为拖延症中晚期的博主，努力写完每月一篇的博客，抽空读读书、看看电影，这已然是种简单的幸福了呢！好了，这篇博客就先写到这里！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"单位","slug":"单位","permalink":"https://qinyuanpei.github.io/tags/%E5%8D%95%E4%BD%8D/"},{"name":"设计","slug":"设计","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%BE%E8%AE%A1/"}]},{"title":"Valine搭配Server酱实现博客评论推送","date":"2019-11-06T18:15:14.000Z","path":"posts/369095810/","text":"Valine是一个基于LeanCloud的评论系统，在很长的一段时间里，一直作为多说、Gitalk、Gitment等等的一个替代品，博主所使用的评论系统实际上就是Valine，虽然独立博客的整体活跃度无法媲美专业博客，可还是想在这纷扰的世界里有自己的一方天地啊。多说评论的关闭，某种意义上来说，是很多90后站长们关于互联网的集体记忆，因为从博主搭建第一个WordPress博客的时候，多说就一直作为首选的评论系统而存在。那个时候通过多说就能接入主流的社交媒体，对于一个还不大会编写Web应用的博主来说，此刻想来实在是有种时过境迁的感觉。所以，Valine作为一个相当优秀的评论系统，凭借着简洁大方的界面和开箱即用的优势，在这个时间点进入人们的视野，我们就不难理解，为什么它会成为博客作者们的“新宠”。 Valine本身是利用LeanCloud的数据存储SDK来实现评论的读写的，所以，它相对于“多说”这种第三方的服务，在数据安全性上更有保障一点，虽然“多说”在关闭评论服务以前，提供了导出JSON格式评论信息的功能。可话说回来，以国内这种“敏感”的网络环境，其实没有一家云服务提供商敢打这样的包票，像阿里云、LeanCloud、七牛云存储这些服务，都曾经出现过宕机或者封杀域名的事情，所以，趁着数据还在自己手上，尽可能地做好备份工作吧！Valine本身并没有提供评论推送的功能，我还是挺怀念过去“多说”推送评论到邮箱的功能。虽然Valine-Admin这个项目提供了类似的功能，但我感觉使用起来并不顺手，尤其是配置邮箱的时候，国内像QQ、163这些都非常麻烦，遇到一两个废弃的手机号，你就会发现短信验证码，是件多么尴尬而繁琐的事情，如同扫码使用的共享电话一般魔幻。 为了解决这个问题，我想到了Valine搭配Server酱实现评论推送的方案。首先，Valine是基于LeanCloud而开发的，用户发表评论实际上就是向Comment表插入记录。因此，我们可以利用LeanCloud提供的Hooks来捕获写入评论的事件。所谓“Hooks”呢，通俗地说就是数据库里触发器的概念，我们可以在数据写入前后做点“小动作”。而Server酱则是一个消息推送服务，它提供了一个基于HTTP的请求接口，通过这个接口，我们就能实现向微信推送消息，前提是关注“方糖”公众号。关于Server酱的原理大家可以进一步去看它的文档，我们这里只需要考虑怎么样把它们结合起来，这就是工程师和科学家的区别所在[doge]。 运行在Valine云引擎中代码 LeanCloud提供了一个称作“云引擎”的环境，它可以提供运行比如Nodejs、Python等等的环境，实际上，Valine-Admin这个项目就是用Nodejs编写的，你可以理解为，只要你的应用符合它的规范，就能在它的环境里运行，这就是所谓的“FAAS”(函数即软件)和“BAAS”(后端即软件)。所以，说白了我们就是想利用它这个“云引擎”来调用Server酱的接口，幸运的是，LeanCloud提供的Hooks目前是支持Nodejs的，所以，到这里思路就非常清晰了，我们给Comment这张表加一个AfterSave类型的Hooks，在保存完以后调用Server酱接口推送评论信息即可。创建Hooks是在部署-&gt;云引擎选项下，我们来看下面的代码： 1234567891011121314151617181920212223242526272829AV.Cloud.afterSave('Comment', async function(request) &#123; var http = require(\"request\"); var obj = request.object; console.log('收到一条新的评论：' + JSON.stringify(obj)); var title = \"收到一条新的评论\"; var url = request.object.get('url'); var nick = obj.get('nick'); if (nick == 'Anonymous')&#123; nick = '陌生人'; &#125; var comment = obj.get('comment'); var content = nick + \"给你留言：\\n\\n\" + comment + \"\\n\\n详情请访问：\\n\\n\" + url; var options = &#123; method: 'GET', url: 'https://sc.ftqq.com/&lt;在这里输入你的token&gt;.send', qs: &#123; text: title, desp: content &#125;, headers: &#123; &#125; &#125;; http(options, function (error, response, body) &#123; if (error) throw new Error(error); console.log(body); &#125;);&#125;); 这里主要利用了Nodejs中的requests模块来发送HTTP请求，其中token是Server酱经过Github授权以后获得的，具体可以参考Server酱的文档。这里有一点要注意，Comment表里的记录是无法区分发出人的，因为有时候我们可能忘记填写邮箱或者昵称，所以，目前只要写入记录都会发送消息到手机。这个消息模板是Server酱作者提供的，我们无法对它的样式进行自定义，收到消息以后需要点击查看详情。不过，我认为这个方案可以满足我的日常使用，因为博客的评论数量并不多，而Servet酱的接口调用次数完全足够。免费的LeanCloud实例虽然会强制休眠，只要大部分时间能覆盖到就可以啦，谁让这些东西都是免费的呢，博主表示已经相当知足啦，哈哈！好了，看看消息推送到手机的效果吧！ 博客评论推送到手机上的展示效果 如果大家想调整消息的格式，参考文章中给出的代码即可，每次调整完可以直接部署到线上，这是我在这个过程中体验到的Serverless的魅力，相比我们中华田园式的996敏捷开发，这种方式真的能缩短部署的周期。我还是那句话，敏捷开发是大家一起敏捷，不是只有开发苦哈哈地加班加点干活，快速交付的前提是基础设施完善，具备自动化测试、自动化部署的能力，让开发安心地写代码比什么都重要，就像LeanCloud里提供的云函数和Hooks，开发写完代码就能自动部署，这是真正的敏捷、真正的灵活。好了，这篇博客就先写到这里。想试试博主能不能第一时间收到你们的留言？欢迎在博客评论区留下你的足迹，谢谢大家！","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"Valine","slug":"Valine","permalink":"https://qinyuanpei.github.io/tags/Valine/"},{"name":"Server酱","slug":"Server酱","permalink":"https://qinyuanpei.github.io/tags/Server%E9%85%B1/"},{"name":"评论","slug":"评论","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%84%E8%AE%BA/"}]},{"title":"浅析网站PV/UV统计系统的原理及其设计","date":"2019-10-22T12:50:49.000Z","path":"posts/3494408209/","text":"国庆节前有段时间，新浪的“图床”一直不大稳定，因为新浪开启了防盗链，果然免费的永远是最贵的啊。为了不影响使用，我非常粗暴地禁止了浏览器发送Referer，然后我就发现了一件尴尬的事情，“不蒜子”统计服务无法使用了。这是一件用脚后跟想都能想明白的事情，我禁止了浏览器发送Referer，而“不蒜子”正好使用Referer来识别每个页面，所以，这是一个再明显不过的因为需求变更而引入的Bug。这个世界最离谱的事情，就是大家都认为程序员是一本“十万个为什么”，每次一出问题就找到程序员这里。其实，程序员是再普通不过的芸芸众生里的一员，人们喜欢听/看到自己愿意去听/看到的事物，而程序员同样喜欢解决自己想去解决的问题。所以，今天的话题是关于如何设计一个PV/UV统计系统。OK，Let’s Hacking Begin。 PV/UV的概念首先，我们从两个最基本的概念PV和UV开始说起。我们都知道，互联网产品的核心就是流量，前期通过免费的产品吸引目标客户的目的，在积累了一定用户流量以后，再通过广告等增值服务实现盈利，这可以说是互联网产品的典型商业模式啦。而在这个过程中，为了对一个产品的流量进行科学地分析，就产生了譬如访客数(UV)、浏览量(PV)、访问次数(VV)等等的概念，这些概念通常作为衡量流量多少的指标。除此以外，我们还有类似日活跃用户(DAU)、月活跃用户(MAU)等等这种衡量服务用户粘性的指标，以及平均访问深度、平均访问时间、跳出率等等这种衡量流量质量优劣的指标。如果各位和我一样都写博客的话，对这些概念应该都不会感到陌生，因为我们多多少少会使用到诸如百度站长、站长统计、腾讯统计、Google Analytics这样的统计服务，这些统计服务可以让我们即时掌握博客的访问情况。博主目前使用了腾讯统计来查看整个博客的流量情况，而每一篇博客的访问量则是通过“不蒜子”这个第三方服务，这里再次对作者表示感谢。 使用腾讯统计来查看网站的流量情况 回到问题本身，PV，即Page View，表示页面浏览量或者点击量，每当一个页面被打开或者被刷新，都会产生一次PV，只要这个请求从浏览器端发送到了服务器端。聪明的各位肯定会想到，如果我写一个爬虫不停地去请求一个页面，那么这个页面的PV不就会一直增长下去吗？理论上的确是这样，所以，我们有第二个指标UV，来作为进一步的参考，所谓UV，即Unique Visitor，表示独立访客数。在上面这个问题中，尽管这个页面的PV在不断增长，可是因为这些访客的IP都是相同的，所以，这个页面只会产生一次UV，这就是PV和UV的区别。所以，我们结合这两个指标，可以非常容易得了解到，这个页面实际的访问情况是什么样的。这让我想起数据分析中的一个例子，虽然以统计学为背景的数学计算不会欺骗人类，可如果人类片面地相信某一个方面的分析结果，数据分析一样是带有欺骗性的。就像有人根据《战狼2》和《前任3》两部电影的观众购买冷/热饮的情况，得出下面的结论：看动作片的观众更喜欢喝冷饮来清凉紧绷着的神经，而看爱情片的观众更喜欢喝热饮来温暖各自的内心。其实想想就知道这里混淆了因果性和相关性，选择冷饮还是热饮无非是两部电影上映的季节不同而已。 如何设计一个访问统计系统OK，了解了PV和UV的概念后，我们来思考如何去设计一个访问统计系统，这是今天这篇博客的主题内容。我知道，如果问如何设计一个访问系统，大家可能都会不由自主地想到建两张表。的确，这是最简单的做法。可问题是，我们对于PV的认识，其实一直都在不断地变化着。比如PV的定义是是一个页面被打开或者被刷新时视为一次有效PV，所以，我们通常的做法是在页面底部嵌入JavaScript脚本，这种方式一直工作得非常好。可在引入AJAX以后，用户几乎不会主动去刷新页面，那么，在这个过程中用户点击更多或者使用下拉刷新时，是否应该算作一次有效PV呢？甚至在PC端网页逐渐式微以后，越来越多的工作转移到手机等移动设备上来，越来越多的原生+Web混合App或者是单页面应用(SPA)或者是渐进式应用(PWA)，此时我们又该如何认识PV呢？微信公众号里的PV甚至更为严格，必须通过微信内置的浏览器访问才能算作一次有效PV。 可以发现，我们对PV的认识其实一直在不断的变化着，更多的时候，我们想追踪的并非页面被加载(Page Load)的次数，而是页面被浏览(Page View)的次数。这时候，我们可以Page Visiblity和History API结合的方式。前者在页面的visibilityState可见或者由隐藏变为可见时发送一次Page View，而后者则是在浏览器地址发生变化的时候发送一次Page View。这听起来非常像单页面应用(SPA)里前端路由的那套玩法，的确，当一个地址中的pathname或者search部分发生变化时，应该发送一次Page View请求，而hash部分的变化则应该忽略，因为它表示的是应用内部页面的跳转。对于页面的visibilityState由隐藏变为可见，不同的人有不同的看法，因为有时我们像合并多次Page View，而有时候则想通过Page View了解所谓的”回头客“，所以，这里面还可以继续引入Session的概念，比如Google Analytics默认会在30分钟内无交互的情况下结束。所以，这个问题要考虑的东西实际上比想象中的要多。 现在，我们至少可以前端部分达成共识，即通过在前端页面上埋点的方式收集PV和UV。就像我们设计一个Page View的表结构会非常简单，而一旦要开始考虑Unique Visitor，可能我们就需要收集诸如IP、省市、UA等等的信息，这些信息的数量会非常大，而Page View的数据规模实际上取决于一个站点下有多少个页面。所以，这些数据在后端要怎么样处理，这是我们接下来要去考虑的问题。直接去写数据库是万不得已的做法，因为如果你处理不好并发的问题，这些统计数据的正确性就会让人产生怀疑，所以，接下来，我们介绍三种不同的方法来处理这类问题，它们分别是：通过Nginx的access_log实现统计、通过Redis的Hyperlog实现统计，以及通过LeanCloud的Hook实现统计。同大家一样，我是第一次考虑这类问题，如果有什么不周到的地方，希望大家可以谅解。 通过Nginx的access_log实现统计我们首先来介绍Nginx的access_log，顾名思义，这是Nginx的访问日志，由ngx_http_log_module模块提供相应功能。Nginx会把每一个用户访问网站的日志信息记录到指定文件里，从而帮助网站提供者分析用户的浏览行为。而PV/UV则是分析用户的浏览行为的最基础指标，所以，通过Nginx的访问日志来统计UV和PV是再合适不过的啦！在Nginx里主要使用log_format和access_log 两条指令来完成相关的配置。这里以博主自己使用的配置为例来说明： 12345log_format main '$remote_addr - $remote_user [$time_iso8601] \"$request\" ' '$status $body_bytes_sent \"$http_referer\" ' '\"$http_user_agent\" \"$http_x_forwarded_for\"'; access_log logs/access.log main; 可以注意到，我们在这里首先通过log_format命令定义了一个日志格式，而这个日志格式则被定义为main，这表示我们我们可以在Nginx的配置文件中定义多个日志格式。它其实就是一个日志模板，相信大家在使用NLog、Log4Net这类日志库的时候，都接触过Layout这个概念，这里就是Nginx中访问日志的Layout。那么，在定义了这样一个日志格式以后，我们该怎么使用这个日志格式呢？这就要说到下面的access_log指令，它的基本用法就是一个路径 + 一个模板，在这里我们使用了定义好的main模板，然后指定了日志路径为：\\logs\\localhost.access_log.log。当然啦，大家使用NLog和Log4Net时，日志对应的Layout中都会有“变量”这样的概念，同样地，在Nginx中我们有一些常用的“变量”： Nginx日志变量 说明 $remote_addr 记录访问网站的客户端地址 $http_x_forward_for 当前端有代理服务器时，设置Web节点记录客户端地址的配置 $remote_user 远程客户端用户名称 $time_local 记录带时区的访问时间 $request 记录用户HTTP请求起始行信息 $status 记录用户HTTP请求状态码 $body_bytes_sents 记录服务端返回给客户端响应Body字节数 $http_referer 记录本次请求是从哪一个链接访问过来的 $http_user_agent 记录客户端类型信息，比如Chrome、微信等等 为什么说这些时最常用的“变量”呢？因为通过这些，我们想要统计PV和UV的想法就能变成现实，关于更多的Nginx日志变量，大家可以从这里来了解：http://nginx.org/en/docs/http/ngx_http_log_module.html。现在，通过Nginx托管一个简单的静态页面，然后在浏览器中访问：localhost:9090，此时，我们应该可以在前面设置的日志路径里找到Nginx生成的日志文件，它大概长下面这个样子： Nginx日志长什么样子 OK，现在有日志文件啦，这PV/UV到底从哪里来呢？其实，到这里已经无所谓用什么方法啦，因为你可以用ELK全家桶把给它收集了去，或是选一门你喜欢的语言用正则给它匹配出来，这都完全没有问题，无非就是一个工具选择的问题。为了简单起见，我们直接用Shell命令： 123456789#统计指定页面的PVgrep / localhost.access.log | wc -lgrep /favicon.ico localhost.access.log | wc -l#统计站点PVawk '&#123;print $6&#125;' localhost.access.log | wc -l #$6表示模板中的第6个变量，即Referer#统计访客IPawk '&#123;print $1&#125;' localhost.access.log | sort -r |uniq -c |wc -l #$1表示模板中第一个变量，即客户端IP 至此，我们就达到了基于Nginx访问日志实现PV/UV统计的目的。我知道有同学要问啦，你不是说要在前端通过埋点的方式来收集访客的信息吗，你这说了半天，完全就是说Nginx的事情嘛！的确，我们现在可以统计出自己网站的PV/UV了，可如果我们想对外提供一个访问统计的服务，我们又该如何做呢？这里简单分享下博主的思路，因为开发环境一直不是很稳定，所以，一直没有时间动手去实践(逃。 一种PV/UV统计的思路 通过这张图片，我们可以大致梳理出整个流程，即前端页面中通过JavaScript来调用后端提供的Analysis Service，此时这个请求会携带一个Referer信息，而这个Referer对应被访问的站点。注意到这个后端服务经过了一层Nginx转发，显然Nginx可以获得客户端的IP地址，这两个结合起来，表示的就是某个IP访问了某个站点，即PV。像百度站长和腾讯统计会在页面中注入一个token或者Id，主要用途就是确保请求的确是从当前站点中发出的，这就是这类访问统计产品统计的原理。也许在计算PV/UV的算法上存在差异，然而核心的原理应该没多大差别啦！ 通过Redis的HyperLogLog实现统计不知道大家有没有发现，统计PV其实蛮简单的，因为它只需要对访问量做更新即可。可统计UV就会有点麻烦啦，因为同一个人可以多次访问同一篇文章。有时候我们希望统计一天内的访客数，而有时候我们希望统计一周甚至一个月内的访客数，所以，UV并不像PV那样简单，PV更多的时候是作为一种“汇总”数据，而UV则有“实时”的属性。简而言之，我们需要一张表来记录访客数据，博主在设计这张表的时候，更是引入了地理位置、UserAgent等等相关的字段设计，因为我们会有了解访客来源、访客设备等等一系列“行为”相关的数据记录。对应到数据库的概念，VisitorRecored这张表实际上是在不停地写入记录的。那么，面对每一个查看实时访客数的请求，我们真的要每次都要去这张表里统计一遍吗？也许我们会想到使用数据库任务去做定时的汇总，或者是任意形式的定时任务譬如CORN、Hangfire，在这里，我们有更好的选择——HyperLogLog。 什么是HyperlLogLog呢？我们提到的统计UV的这个场景，实际上是一个基数计数(Cardinality Counting)的问题，即统计一个集合中不重复的元素个数，例如集合{1,3,5,7,5,7,8}的基数为5。所以，HyperLogLog实际上就是一个在误差允许的范围内，快速统计元素数目的算法。为什么说是误差允许范围内呢？因为它来源于一个经典的概率分布——伯努利分布。高中时候，老师讲到这个知识，我们笑称它为“白努力”，因为有一段时间，排列组合属于我怎么学都学不会东西，可不就是白努力吗？HyperLogLog是在LogLog的基础上优化的一种算法，它主要的改进是采用了桶算法作为每一轮伯努利实验的估计值，同时使用调和平均数代替平均数，进而求出最终的估算值。它可以在不存储整个集合的情况下，使用极小的内存统计出集合元素的个数。 对应到Redis里，主要体现在PFADD、PFCOUNT、PFMERGE三个命令上。 PFADD：将多个值存入指定的HyperLogLog。 PFCOUNT：获取指定HyperLogLog的基数。 PFMERGE：合并多个HyperLogLog，合并前与合并后的基数一致(取并集)。 博主在写这篇博客的时候，基于LeanCloud的访问统计LeanCloud-Counter已经再线上运行了一段时间。下面，我们就以这些数据为例来展示下HyperLogLog的用法。为了方便起见，我选择使用Python来读写Redis： 1234567891011121314151617# 连接Redisr = redis.Redis(host='localhost', port=6379, db=0)# 查询访客记录VisitorRecord = leancloud.Object.extend('VisitorRecord')query = VisitorRecord.queryquery.limit(1000)queryResults = query.find()# 对每个页面使用PFADDfor result in queryResults: r.pfadd(result.get('page_url'),result.get('visitor_ip'))# 使用PFCOUNT返回每个页面的基数pageUrls = list(set(map(lambda x:(x.get('page_url'),x.get('page_title'),r.pfcount(x.get('page_url'))), queryResults)))pageUrls = sorted(pageUrls,key=lambda x:x[2],reverse=True)print(pageUrls[0:10]) 运行完脚本，我们可以统计出访客数目： 使用HyperLogLog统计访客数目 通过LeanCloud的Hooks实现统计像Hexo、Jekyll这类静态博客，本质上是非常依赖Valine、不蒜子等等的第三方服务，而使用LeanCloud作为访问量统计的服务提供商，更是早就在博客圈子里流行了。不过我注意到，这些设计都少都会有一点不足，那就是网上的各种设计都没有实现站点的PV/UV统计。当我被迫从”不蒜子“上迁移过来以后，我其实非常想实现一个和”不蒜子“一模一样的统计服务，因为这样子的话，我对博客的修改会非常非常小。所以， 我不得不在现有方案上扩展更多的功能，实现单篇文章的UV、整个站点的PV/UV、访客IP/地理位置、客户端UA等的统计功能。 在这个过程中，我发现LeanCloud不支持传统关系型数据库里的Sum()操作，而我更不想在客户端通过分页去对表记录做Sum()操作。官方提供了离线分析和云函数，可这两个东西都是商业版里支持的东西。最终我找到了，通过Hooks来实现站点PV/UV统计的这样一种方法。所谓Hooks，你可以理解为传统关系型数据库里的触发器，它可以在你更新或者插入某个对象的时候，去做一点额外的工作。所以，单篇文章会根据文章链接+访客IP生成一条UV，而PV则是每次打开文章就视为一条PV。所以，最终的方案是插入访客记录(VisitorRecord)时更新文章的对应的访问次数(VisitorCounter)，而单篇文章的更新则会触发站点UV/PV的更新。听起来有点绕人，我们直接来看下面的代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//新建访客记录时，更新对应的UV记录AV.Cloud.afterSave('VisitorRecord', async function(request) &#123; var query = new AV.Query('VisitorCounter'); var page_url = request.object.get('page_url'); console.log('query page_url: ' + page_url); query.equalTo('page_url', page_url); return query.find().then(function (counters) &#123; if (counters.length &gt; 0)&#123; counters[0].increment('page_uv'); console.log('increment UV of page_url: ' + page_url + \", \" + counters[0].get('page_pv')); return counters[0].save() &#125; &#125;);&#125;);//页面PV/UV更新时，更新站点PV/UVAV.Cloud.afterUpdate('VisitorCounter', async function(request) &#123; var page_url = request.object.get('page_url'); if(page_url.indexOf('//') == -1)&#123; return; &#125; var site_url = page_url.split('//')[1]; site_url = site_url.substring(0, site_url.indexOf('/')); console.log('now to update site PV/UV with: ' + site_url); if (request.object.updatedKeys.indexOf('page_pv') != -1) &#123; var query = new AV.Query('VisitorCounter'); query.equalTo('page_url',site_url); query.find().then(function(counters)&#123; if(counters.length&gt;0)&#123; counters[0].increment('page_pv'); console.log('update site PV of ' + site_url + \", \" + counters[0].get('page_pv')); return counters[0].save(); &#125; &#125;); &#125; else if (request.object.updatedKeys.indexOf('page_uv') != -1) &#123; var query = new AV.Query('VisitorCounter'); query.equalTo('page_url',site_url); query.find().then(function(counters)&#123; if(counters.length&gt;0)&#123; counters[0].increment('page_uv'); console.log('update site PV of ' + site_url + \", \" + counters[0].get('page_uv')); return counters[0].save(); &#125; &#125;); &#125;&#125;); 实际上这里整个站点的UV统计是不严谨的，因为严格地来讲，同一个IP访问了同一个站点下的N篇文章，它的UV严格地来说应该算1次，可我们这个方案本身就是向LeanCloud妥协的一种做法，就像我这里直接使用了location.href和document.title，它带来的问题就是，一个网站的域名或者链接发生变化的时候，访问统计就会被重置从0开始。“不蒜子”本身就有这个问题。所以，博主这个博客从15年到现在，总访问量只有3万多，就是因为中间更换过两次域名。从我切换到自己写的统计服务以后，我发现每天来读我博客的人居然不少，我实在不忍心写下这种夸自己的句子啊！ 想解决这个问题，并不是没有办法。像博主一开始设计的时候，是打算用每个页面唯一的Id来存储的，而这就要通过HTML5中的data-或者通过JavaScript来传参。可当你打算设计一个更通用的东西的时候，这些想法就显得有点多余，我和大部分人一样，喜欢开箱即用的东西，所以，最好它可以像大多数统计服务一样，只需要在页面里加入一行JavaScript脚本。所以，最终采用这样的设计是为了最大限度的开箱即用。考虑到“不蒜子”里因为更换域名而导致的访问统计重置的问题，我增加了一个初始化站点UV/PV的功能，满足了像博主这样虚荣心爆棚的人的需要。这一刻，我突然觉得，我和产品经理们一样“自信”啊。正如你所看到的这样，博客底部的访问统计已经从“不蒜子”切换到“LeanCloud-Counter”，为此我在博客上增加了LeanCloud的链接，也许下一阶段会加上Heroku，总之，我已经完成了访问统计的平滑切换。关于这个项目，如果大家感兴趣，可以参考这个地址：LeanCloud-Counter。 本文小结这篇文章写下来，最大的感受或许是，有一台Linux环境的服务器是多么的重要。起初，是在Windows10下面的WSL里搭了Docker环境，再通过Docker镜像搭建Nginx，因为之前的Consul、ELK几乎都是这样运作的，而且一直运行的相当稳定，唯一的缺点大概就是Docker太容易吃硬盘，有时候难免搞出个内存不足。Nginx搭好以后，发现需要经常改配置文件，Docker环境里改起来相当痛苦。直接在WSL里安装Nginx的话，因为和Windows共享端口，和IIS明显搞不到一起。想通过Docker挂载本机分区，突然想起来WSL里的Docker只是一个客户端，真正的主角是跑在Windows上的Docker for Windows。最后被迫装了Windows版本的Nginx，果然还是会和IIS冲突，我想说，心好累有木有啊_(:з」∠)_。好了，这篇博客总算写完了！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"访问量","slug":"访问量","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%BF%E9%97%AE%E9%87%8F/"},{"name":"Nginx","slug":"Nginx","permalink":"https://qinyuanpei.github.io/tags/Nginx/"},{"name":"Hyperlog","slug":"Hyperlog","permalink":"https://qinyuanpei.github.io/tags/Hyperlog/"}]},{"title":"使用Python开发插件化应用程序","date":"2019-10-11T08:56:27.000Z","path":"posts/1960676615/","text":"插件化应用是个老话题啦，在我们的日常生活中更是屡见不鲜。无论是多年来臃肿不堪的Eclipse，亦或者是扩展丰富著称的Chrome，乃至近年来最优秀的编辑器VSCode，插件都是这其中重要的组成部分。插件的意义在于扩展应用程序的功能，这其实有点像iPhone手机和AppStore的关系，没有应用程序的手机无非就是一部手机，而拥有了应用程序的手机则可以是Everything。显然，安装或卸载应用程序并不会影响手机的基本功能，而应用程序离开了手机同样无法单独运行。所以，所谓“插件”，实际上是一种按照一定规范开发的应用程序，它只能运行在特定的软件平台/应用程序且无法运行。这里，最重要的一点是应用程序可以不依赖插件单独运行，这是这类“插件式”应用的基本要求。 好了，在了解了插件的概念以后，我们来切入今天的正文。博主曾经在《基于Python实现Windows下壁纸切换功能》这篇文章中编写了一个小程序，它可以配合Windows注册表实现从 Unsplash 上抓取壁纸的功能。最近，博主想为这个小程序增加 必应壁纸 和 WallHaven 两个壁纸来源，考虑到大多数的壁纸抓取流程是一样的，博主决定以“插件”的方式完成这次迭代，换句话说，主程序不需要再做任何调整，当我们希望增加新的数据源的时候，只需要写一个.py脚本即可，这就是今天这篇文章的写作缘由。同样的功能，如果使用Java/C#这类编译型语言来做，我们可能会想到为插件定义一个IPlugin接口，这样每一个插件实际上都是IPlugin接口的实现类，自然而然地，我们会想到通过反射来调用接口里的方法，这是编译型语言的做法。而面对Python这样的解释型语言，我们同样有解释型语言的做法。 首先，我们从一个最简单的例子入手。我们知道，Python中的import语法可以用来引入一个模块，这个模块可以是Python标准库、第三方库和自定义模块。现在，假设我们有两个模块：foo.py 和 bar.py。 12345678910#foo.pyimport sysclass Chat: def send(self,uid,msg): print('给&#123;uid&#125;发送消息：&#123;msg&#125;'.format(uid=uid,msg=msg)) def sendAll(self,msg): print('群发消息：&#123;msg&#125;'.format(msg=msg)) 12345678910#bar.pyimport sysclass Echo: def say(self): print(\"人生苦短，我用Python\")def cry(): print(\"男人哭吧哭吧不是罪\") 通常, 为了在当前模块(main.py)中使用这两个模块，我们可以使用以下语句： 12import foofrom bar import * 这是一种简单粗暴的做法，因为它会导入模块中的全部内容。一种更好的做法是按需加载，例如下面的语句： 1from foo import Chat 到这里，我们先来思考第一个问题，Python是怎么样去查找一个模块的呢？这和Python中的导入路径有关，通过sys.path我们可以非常容易地找到这些路径，常见的导入路径有当前目录、site-package目录和PYTHONPATH。熟悉Python的朋友应该都知道，site-package和PYTHONPATH各自的含义，前者是通过pip安装的模块的导入目录，后者是Python标准库的导入目录。当前目录这个从何说起呢？事实上，从我们写下from…import…语句的时候，这个机制就已经在工作了，否则Python应该是找不到foo和bar这两个模块的了。这里还有相对导入和绝对导入的问题，一个点(.)和两个点(..)的问题，这些我们在这里暂且按下不表，因为我们会直接修改sys.path(逃 在Python中有一种动态导入模块的方式，我们只需要告诉它模块名称、导入路径就可以了，这就是下面要说的importlib标准库。继续用foo和bar这两个神奇的单词来举例，假设我们现在不想通过import这种偏“静态”的方式导入一个模块，我们应该怎么做呢？一起来看下面代码： 123456789101112131415161718192021import foofrom foo import Chatfrom bar import *import importlib#调用foo模块Chat类方法foo.Chat().send('Dear','I Miss You')moduleFoo = importlib.import_module('.','foo')classChat = getattr(moduleFoo,'Chat')classChat().send('Dear','I Miss You')#调用bar模块Echo类方法Echo().say()moduleBar = importlib.import_module('.','bar')classEcho = getattr(moduleBar,'Echo')classEcho().say()#调用bar模块中的cry()方法cry()methodCry = getattr(moduleBar,'cry')methodCry() 可以注意到，动态导入可以让我们在运行时期间引入一个模块(.py)，这恰恰是我们需要的功能。为了让大家对比这两种方式上的差异，我给出了静态引入和动态引入的等价代码。其中，getattr()其实可以理解为Python中的反射，我们总是可以按照模块-&gt;类-&gt;方法的顺序来逐层查找,即：通过dir()方法，然后该怎么调用就怎么调用。所以，到这里整个“插件化”的思路就非常清晰了，即：首先，通过配置来为Python增加一个导入路径，这个导入路径本质上就是插件目录。其次，插件目录内的每一个脚本文件(.py)就是一个模块，每个模块都有一个相同的方法签名。最终，通过配置来决定要导入哪一个模块，然后调用模块中类的实例方法即可。顺着这个思路，博主为 WallPaper 项目引入了插件机制，核心代码如下： 123456789101112if(pluginFile == '' or pluginName == ''): spider = UnsplashSpider() imageFile = spider.getImage(downloadFolder) setWallPaper(imageFile) else: if(not check(pluginFile,addonPath)): print('插件%s不存在或配置不正确' % pluginName) return module = importlib.import_module('.',pluginFile.replace('.py','')) instance = getattr(module,pluginName) imageFile = instance().getImage(downloadFolder) setWallPaper(imageFile) 接下来，我们可以很容易地扩展出 必应壁纸 和 WallHaven 两个“插件”。按照约定，这两个插件都必须实现getImage()方法，它接受一个下载目录作为参数，所以，显而易见，我们在这个插件里实现壁纸的下载，然后返回壁纸的路径即可，因为主程序会完成剩余设置壁纸的功能。 1234567891011121314151617181920# 必应每日壁纸插件class BingSpider: def getImage(self, downloadFolder): searchURL = 'https://cn.bing.com/HPImageArchive.aspx?format=js&amp;idx=0&amp;n=1&amp;mkt=zh-CN' response = requests.get(searchURL) data = json.loads(response.text) resultId = data['images'][0]['hsh'] resultURL = 'https://cn.bing.com' + data['images'][0]['url'] print(u'正在为您下载图片:%s...' % resultId) if(not path.exists(downloadFolder)): os.makedirs(downloadFolder) jpgFile = resultId + '.jpg' jpgFile = os.path.join(downloadFolder, jpgFile) response = requests.get(resultURL) with open(jpgFile,'wb') as file: file.write(response.content) return jpgFile 1234567891011121314151617181920# WallHaven壁纸插件class WallHavenSpider: def getImage(self,downloadFolder): url = 'https://alpha.wallhaven.cc/wallpaper/' response = requests.get(url) print(response.text) soup = BeautifulSoup(response.text,'html.parser') imgs = soup.find_all('img') length = len(imgs) if length &gt; 0: match = random.choice(imgs) rawUrl = match.get('src') rawId = rawUrl.split('/')[-1] rawUrl = 'https://w.wallhaven.cc/full/' + rawId[0:2] + '/wallhaven-' + rawId raw = requests.get(rawUrl) imgFile = os.path.join(downloadFolder, rawId) with open(imgFile,'wb') as f: f.write(raw.content) return imgFile 好了，现在功能是实现了，我们来继续深入“插件化”这个话题。考虑到Python是一门解释型的语言，我们在编写插件的时候，更希望做到“热插拔”，比如修改了某个插件后，希望它可以立刻生效，这个时候我们就需要重新加载模块，此时importlib的reload就能满足我们的要求，这正是博主一开始就要使用importlib，而不是import语法对应内建方法import()的原因。以C#的开发经历而言，虽然可以直接更换DLL实现更新，可更新的过程中IIS会被停掉，所以，这种并不能被称之为“热更新”。基于以上两点考虑，博主最终决定使用watchdog配合importlib来实现“热插拔”，下面是关键代码： 1234567891011class LoggingEventHandler(FileSystemEventHandler): # 当配置文件修改时重新加载模块 # 为节省篇幅已对代码进行精简 def on_modified(self, event): super(LoggingEventHandler, self).on_modified(event) what = 'directory' if event.is_directory else 'file' confPath = os.path.join(sys.path[0],'config.ini') if(what =='file' and event.src_path == confPath): importlib.reload(module) logging.info(\"Modified %s: %s\", what, event.src_path) 好了，现在我们就完成了这次“插件化”的迭代，截止到目前为止，博主共完成了 Unsplash 、 Bing壁纸 、 WallHaven 和 国家地理 四个“源”的接入，这些插件在实现上基本大同小异，本质上来讲它们是一个又一个的爬虫，只要实现了getImage()这个方法都可以接入进来，这就是我们通常说的“约定大于配置”，关于更多的代码细节，大家可以通过Github来了解。 简单回顾下这篇博客，核心其实是importlib模块的使用，它可以让我们在运行时期间动态导入一个模块，这是实现插件化的重要前提。以此为基础，我们设计了基于Python脚本的单文件插件，即从指定的目录加载脚本文件，每个脚本就是一个插件。而作为插件化的一个延伸，我们介绍了watchdog模块的简单应用，配合importlib模块的reload()方法，就可以实现所谓的“热更新”。好了，以上就是这篇博客的所有内容了，我们下一篇见！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"插件化","slug":"插件化","permalink":"https://qinyuanpei.github.io/tags/%E6%8F%92%E4%BB%B6%E5%8C%96/"},{"name":"壁纸","slug":"壁纸","permalink":"https://qinyuanpei.github.io/tags/%E5%A3%81%E7%BA%B8/"}]},{"title":"百度地图加载海量标注性能优化策略","date":"2019-09-10T09:44:18.000Z","path":"posts/3131944018/","text":"在上一篇博客中关于Vue表单验证的话题里，我提到了这段时间在做的城市配载功能，这个功能主要着眼于，如何为客户提供一条路线最优、时效最短、装载率最高的路线。事实上，这是目前物流运输行业智能化、专业化的一个趋势，即面向特定行业的局部最优解问题，简单来说，怎么样能在装更多货物的同时满足运费更低的条件，同时要考虑超载等等不可抗性因素，所以，这实际上是一个数学问题。而作为这个功能本身，在地图上加载大量标注更是基础中的基础，所以，今天这篇博客想说说，通过百度地图API加载海量标注时，关于性能优化方面的一点点经验。 问题还原根据IP定位至用户所在城市后，后台一次性查询出近一个月内的订单，然后将其全部在地图上展示出来。当用户点击或者框选标注物时，对应的订单配载到当前运单中。当用户再次点击标注物，则对应的订单从当前运单中删除。以西安市为例，一次性加载850个左右的订单，用户操作一段时间后，Chrome内存占用达250多兆，拖拽地图的过程中可以明显地感觉到页面卡顿。因为自始至终，地图上的订单数量不变，即不会移除覆盖物，同时需要在内存中持久化订单相关的信息。所以，在城市配载1.0版本的时候，测试同事给我提了一个性能方面的Bug。可开始提方案并坚持这样做的，难道不是产品吗？为什么要给开发提Bug呢？OK，我们来给不靠谱的产品一点点填坑吧，大概想到了下面三种方案，分别是标注物聚合、Canvas API和视野内可见。 密密麻麻的地图 标注物聚合方案所谓“标注物聚合”，就是指在一定的地图层级上，地图上的覆盖物主要是以聚合的形式显示的，譬如显示某一个省份里共有多少个订单，而不是把所有订单都展示出来，除非地图放大到一定的层级。这种其实在我们产品上是有应用的，比如运单可视化基本上是全国范围内的车辆位置，这个时候在省一级缩放比例上使用聚合展示就非常有必要。可在城市配载这里就相当尴尬啦，因为据说客户会把地图放大到市区街道这种程度来对订单进行配载，所以，这种标注物聚合方案的效果简直是微乎其微，而且更尴尬的问题在于，官方的 MarkerClusterer 插件支持的是标准的覆盖物，即Marker类。而我们的产品为了好看、做更复杂的交互，设计了更复杂的标记物原型，这就迫使我们必须使用自定义覆盖物，而自定义覆盖物通常会用HTML+CSS来实现。 标注聚合器MarkerClusterer 所以，一个简洁的Marker类和复杂的DOM结构，会在性能上存在巨大差异，这恰恰是我们加载了800多个点就产生性能问题的原因，因为一个“好看”的标注物，居然由4个DOM节点组成，而这个“好看”的标注物还不知道要怎么样实现Marker类里的右键菜单。所以，追求“好看”有问题吗？没有，可华而不实的“好看”，恰恰是性能降低的万恶之源，更不用说，因为覆盖物不会从地图上删除，每次框选都要进行800多次的点的检测了，而这些除了开发没有人会在乎，总有人摆出一副“这个需求很简单，怎么实现我不管”的态度……虽然这种方案已经被Pass掉了，这里我们还是通过一个简单的示例，来演示下MarkerClusterer插件的简单使用吧！以后对于前端类的代码，博主会优先使用CodePen进行展示，因为这样子显然比贴代码要生动呀！ 这里稍微提带说一下这个插件的优化，经博主测试，在标记物数目达到100000的时候，拖拽地图的时候可以明显的感觉的卡顿，这一点大家可以直接在CodePen中进行测试。产生性能问题的原因主要在以下代码片段： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * 向该聚合添加一个标记。 * @param &#123;Marker&#125; marker 要添加的标记。 * @return 无返回值。 */ Cluster.prototype.addMarker = function(marker)&#123; if(this.isMarkerInCluster(marker))&#123; return false; &#125;//也可用marker.isInCluster判断,外面判断OK，这里基本不会命中 if (!this._center)&#123; this._center = marker.getPosition(); this.updateGridBounds();// &#125; else &#123; if(this._isAverageCenter)&#123; var l = this._markers.length + 1; var lat = (this._center.lat * (l - 1) + marker.getPosition().lat) / l; var lng = (this._center.lng * (l - 1) + marker.getPosition().lng) / l; this._center = new BMap.Point(lng, lat); this.updateGridBounds(); &#125;//计算新的Center &#125; marker.isInCluster = true; this._markers.push(marker); var len = this._markers.length; if(len &lt; this._minClusterSize )&#123; this._map.addOverlay(marker); //this.updateClusterMarker(); return true; &#125; else if (len === this._minClusterSize) &#123; for (var i = 0; i &lt; len; i++) &#123; this._markers[i].getMap() &amp;&amp; this._map.removeOverlay(this._markers[i]); &#125; &#125; this._map.addOverlay(this._clusterMarker); this._isReal = true; this.updateClusterMarker(); return true; &#125;; 这段代码主要的问题在于频繁地向地图添加覆盖物，换言之，在这里产生了对DOM的频繁修改，具体可参考_addToClosestCluster方法。一种比较好的优化是，等所有计算结束后再一次性应用到DOM。所以，这里我们可以封装一个render()方法： 123456789101112Cluster.prototype.render = function()&#123; var len = this._markers.length; if (len &lt; this._minClusterSize) &#123; for (var i = 0; i &lt; len; i++) &#123; this._map.addOverlay(this._markers[i]); &#125; &#125; else &#123; this._map.addOverlay(this._clusterMarker); this._isReal = true; this.updateClusterMarker(); &#125;&#125; 关于原理介绍及性能对比方面的内容，大家可以参考这篇文章：百度地图点聚合MarkerClusterer性能优化 Canvas API方案OK，接下来介绍第二种方案，其实从Canvas API你就可以想到我要说什么了。Canvas API是HTML5中提供的图形绘制接口，类似于我们曾经接触过的GDI/GDI+、Direct2D、OpenGL等等。有没有觉得和游戏越来越近啦，哈哈！百度地图API v3中提供了基于Canvas API的接口，我们可以把这些“好看”的覆盖物绘制到一个层上面去，显然这种方式会比DOM更高效，因为博主亲自做了实验，一次性绘制10万个点放到地图上，真的是一点都不卡诶，要说缺点的话嘛，嗯，你想嘛，这都是不是DOM了，产品经理那些吊炸天的脑洞还怎么搞？比如最基本的点击，可能要用简单的2D碰撞来处理啦，然后就是常规的坐标系转换，听起来更像是在做游戏了，对不对？谁让那么多的游戏都是用HTML5开发的呢？同样的，这里给出一个简单的示例： 这个方案真正尝试去做的时候，发现最难的地方是给Canvas里的元素绑定事件，细心的朋友会发现，博主在这里尝试了两种方案。第一种，通过判断点是否在矩形内来判断是否完成了点击，主要的问题是随着点的数目的增加判断的量级会越来越大。第二种，通过addHitRegion()增加一个可点击区域，这种的性能明显要比第一种好，唯一的限制在于浏览器的兼容性。目前，需要在Chrome中开启Experimental Web Platform features。这个探索的过程是相当不易的，大家可以通过CodePen进一步感受一下哈！ 视野内可见方案相信大家听完前两个方案都相当失望吧，一个方案用不了，一个方案太麻烦，那这个肯定就是最终可行的方案了吧！猜对了，这真的是体现了大道至简，一开始试着从内存里持久化的数据入手，可最终收到效果的反而是这个最不起眼的方案。简单来说，就是把视野内的覆盖物设为visible，而把视野外的覆盖物设置hidden。相当朴素的一种思维对吧，百度地图API中有一个返回当前视野的接口GetBounds()，它回返回一个矩形。所以，我们只需要调用百度接口判断覆盖物在不在这个矩形里就可以了，显然，这里又会循环800多次，不过产品经理们都不在乎对吧……顺着这个思路，我们可以写出下面的代码，并在拖动地图和缩放地图的时候调用它： 1234567891011121314151617//监听地图缩放/拖拽事件map.addEventListener(\"moveend\", showOverlaysByView);map.addEventListener(\"zoomend\", showOverlaysByView);//根据视野来显示或隐藏覆盖物function showOverlaysByView() &#123; var bounds = map.getBounds(); for (var i = 0; i &lt; overlays.length; i++) &#123; var overlay = overlays[i]; var point = overlay._point; if (BMapLib.GeoUtils.isPointInRect(point, bounds) || BMapLib.GeoUtils.isPointOnRect(point, bounds)) &#123; overlay.show(); &#125; else &#123; overlay.hide(); &#125; &#125; &#125; 现在，我只能说，效果挺显著，拖动地图的时候不会卡顿了，因为visible和hidden的切换会引发浏览器重绘，对于这一切我个人表示满意。当然，这一切离好还很遥远，因为，人类的需要是永无止境的啊。 本文小结就在我写下这篇博客的时候，产品经理热情洋溢地给我描述了城市配载2.0的设想。看了看同类产品的相关设计，我预感这个功能会变成一个以地图为核心的可视化运输系统，这符合国内用户一贯的“大而全”的使用习惯，地图上的交互会更加复杂，需要展示的信息会越来越多，所以，这篇文章里提到的优化，在未来到底有没有用犹未可知。我只能告诉你这样几个原则：尽可能的使用Marker类；尽可能的简化DOM结构；地图层级变化越大越要考虑使用聚合；视野外的覆盖物该隐藏就隐藏(反正看不到咯……)。一次性加载百万级别数据要求，我从来不觉得合理，因为就算我能加载出来，你能看的过来吗？本身就是伪需求好吧(逃……好了，这就是这篇博客的全部内容啦，以上……","categories":[{"name":"前端开发","slug":"前端开发","permalink":"https://qinyuanpei.github.io/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"地图","slug":"地图","permalink":"https://qinyuanpei.github.io/tags/%E5%9C%B0%E5%9B%BE/"},{"name":"标注","slug":"标注","permalink":"https://qinyuanpei.github.io/tags/%E6%A0%87%E6%B3%A8/"},{"name":"配载","slug":"配载","permalink":"https://qinyuanpei.github.io/tags/%E9%85%8D%E8%BD%BD/"}]},{"title":"Vue快速实现通用表单验证","date":"2019-09-06T14:53:46.000Z","path":"posts/169430744/","text":"本文开篇第一句话，想引用鲁迅先生《祝福》里的一句话，那便是：“我真傻，真的，我单单知道后端整天都是CRUD，我没想到前端整天都是Form表单”。这句话要从哪里说起呢？大概要从最近半个月的“全栈工程师”说起。项目上需要做一个城市配载的功能，顾名思义，就是通过框选和拖拽的方式在地图上完成配载。博主选择了前后端分离的方式，在这个过程中发现：首先，只要有依赖jQuery的组件，譬如Kendoui，即使使用了Vue，依然需要通过jQuery去操作DOM。其次，只有有通过Rozar生成的DOM，譬如HtmlHelper，Vue的双向绑定就突然变得尴尬起来，更不用说，Rozar中的@语法和Vue中的@指令相互冲突的问题，原本可以直接用v-for生成列表，因为使用了HtmlHelper，突然一下子变得厌恶起来，虽然Rozar语法非常强大，可我依然没有在JavaScript里写C#的热情，因为实在太痛苦啦Orz…… 所以，想做好前后端分离，首先需要分离出一套前端组件库，做不到这一点，前后端分离就无从谈起，就像我们公司的项目，即使框架切换到.NET Core，可是在很长的一段时间里，我们其实还是再写MVC，因为所有的组件都是后端提供的HtmlHelper/TagHelper这种形式。我这次做项目的过程中，其实是通过jQuery实现了一部分组件，正因为如此，一个在前后端不分离时非常容易实现的功能，在前后端分离以后发现缺好多东西，就比如最简单的表单验证功能，即便你是在做一个新项目，为了保证产品在外观上的一致性，你还是得依赖老项目的东西，所以，这篇博客主要想说说前后端分离以后，Vue的时代怎么去做表单的验证。因为我不想测试同事再给我提Bug，问我为什么只有来自后端接口的验证，而没有来自前端页面的验证。我希望，在写下这篇博客之前，我可以实现和老项目一模一样的表单验证。如同CRUD之于后端，80%的前端都是在写Form表单，所以，这个事情还是挺有意思的。 最简单的表单验证OK，作为国内最接“地气”的前端框架，Vue的文档可以说是相当地“亲民”啦！为什么这样说呢，因为其实在官方文档中，尤大已经提供了一个表单验证的示例，这个示例让我想起给某银行做自动化工具时的情景，因为这两者都是采用MVVM的思想，所以，理解起来是非常容易的，即：通过一个列表来存储错误信息，而这个错误信息会绑定到视图层，所以，验证的过程其实就是向这个列表里添加错误信息的过程。我们一起来看这个例子： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;div&gt; &lt;h2&gt;你好，请登录&lt;/h2&gt; &lt;div&gt; &lt;form id=\"loginFrom\"&gt; &lt;div&gt; &lt;label&gt;邮箱&lt;/label&gt; &lt;input type=\"text\" class=\"form-control\" id=\"inputEmail3\" placeholder=\"Email\" v-model=\"email\"&gt; &lt;/div&gt; &lt;/div&gt; &lt;div&gt; &lt;label&gt;密码&lt;/label&gt; &lt;input type=\"password\" class=\"form-control\" id=\"inputPassword3\" placeholder=\"Password\" v-model=\"password\"&gt; &lt;/div&gt; &lt;div&gt; &lt;button type=\"button\" class=\"btn btn-default login\" v-on:click=\"login()\"&gt;登录&lt;/button&gt; &lt;/div&gt; &lt;div v-if=\"errorList.length &gt; 0\"&gt; &lt;div class=\"alert alert-danger\" role=\"alert\"&gt;&#123;&#123;errorList.join(';')&#125;&#125;&lt;/div&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt;&lt;/div&gt;&lt;script&gt;var vm = new Vue(&#123; el: '#loginFrom', data: &#123; email: \"\", password: \"\", errorList: [] &#125;, methods: &#123; validate: function () &#123; this.errorList = [] if (this.email == '') &#123; this.errorList.push('请输入邮箱'); &#125; else &#123; var reg = /^([a-zA-Z]|[0-9])(\\w|\\-)+@[a-zA-Z0-9]+\\.([a-zA-Z]&#123;2,4&#125;)$/; if (!reg.test(this.email)) &#123; this.errorList.push('请输入有效的邮箱'); &#125; &#125; if (this.password == '') &#123; this.errorList.push('请输入密码'); &#125; else &#123; if (this.password.length &lt; 6) &#123; this.errorList.push('密码长度不得少于6位'); &#125; &#125; return this.errorList.length &lt;= 0; &#125;, login: function () &#123; if (this.validate()) &#123; alert('登录成功'); &#125; &#125; &#125;&#125;);&lt;/script&gt; 为了排除无关内容对大家的影响，写这个例子的时候，博主排除了一切复杂的HTML结构和CSS样式，经过简单润色以后，这个例子的效果展示如下，果然GUI满足了人们颜控的一面，可让这个世界高速运行的是CLI，Bootstrap是博主这种“全栈工程师”的最爱之一。这种验证方式简直是人类本能的反应，可这恰好是最糟糕的一个例子，因为这个代码完全没法复用，可以想象得到，如果再继续增加针对密码强度，譬如大小写、数字等等的验证，这个代码会混乱成什么样子，所以，这是最简单的表单验证，同样是最糟糕的表单验证。 第一个表单验证的例子 基于jQuery的表单验证其实，如果不是因为老项目依赖jQuery，而新项目在某些地方又需要和老项目保持一致，有谁会喜欢在Vue的世界里使用jQuery呢？因为数据驱动和事件驱动，真的是两种不同的思想，我就见过因为监听不到某个事件而花费一整天时间的人……所以，这里使用jQuery的表单验证插件jQuery Validation，目的只有一个，即实现博主对自己的承诺，做一个和老项目一模一样的表单验证。官方这个示例最大的问题是，它的检验逻辑扩展性比较差，后端同学对这个应该有所体会啦，譬如实际业务中常常有邮箱、手机号、非空、数字、正则等等的验证规则，而后端常常采用基于Attribute的验证或者是FluentValidation这样的库，所以，核心问题是，能不能定义相应的验证规则。接下来，我们通过jQuery的表单验证插件来实现验证。 通常情况下，jQuery Validation支持面向控件和面向代码两种验证方式。所谓面向控件，就是指在控件里添加类似required、email、range等等的扩展属性，jQuery Validation内置了十余种标准的验证规则，基本可以满足我们的日常使用。而面向代码，就是通过JavaScript来定义验证规则，这就非常符合Vue数据驱动的风格了，因为在JavaScript里一切皆是对象，而这些对象可以作为Vue中的数据来使用。自然而然地，在第一个示例的基础上，我们可以非常容易地扩展出基于jQuery的表单验证： 1234567891011121314151617181920212223242526272829303132var vm = new Vue(&#123; el:'#loginFrom', data:&#123; email:\"\", password:\"\", validators:&#123; rules: &#123; email: &#123; required: true, email: true &#125;, password: &#123; required: true, minlength: 6, &#125; &#125;, messages:&#123; email:&#123; required:\"请输入邮箱\", email:\"请输入有效的邮箱\" &#125;, password:&#123; required:\"请输入密码\", minlength:\"密码长度不得少于6位\" &#125; &#125; &#125; &#125;, mounted:function()&#123; $('#loginFrom').validate(this.validators); &#125;&#125;); 对于当前表单loginFrom，其验证规则为validators，它完全参照jQuery Validation的API文档而来，具体大家可以从jQuery Validation的文档来做进一步了解。这里唯一看起来不爽的就是#loginFrom，因为它和整个Vue看起来格格不入。不过，像博主目前项目的处境，如果老项目里使用jQuery来对表单进行验证，而使用Vue开发的新项目要兼容老项目的设计风格，使用jQuery有什么不可以呢？不得不说，Vue作为一个渐进式的开发框架，真正照顾了各个”年龄”段的前端工程师。使用jQuery Validation以后的表单验证效果如下： 基于jQuery的表单验证 通过jQuery Validation，我们或许能感觉到一点不一样的地方，那就是表单验证其实还是蛮有意思的哈。也许是因为我原本是一个无聊的人，所以看到一点新的东西就觉得有趣。就像我虽然在提交数据时在后端做了校验，可牺牲的其实是整个前端的使用体验。而如果在前端对数据进行校验，是在输入过程中校验还是在输入完成校验，是通过表单自带的提交功能还是自己发起一个AJAX请求，这里面的确是有非常多的细节支撑的。第一种方案不支持远程校验，这更加能说明校验本身要考虑的不单单只有前端了，同理，有了前端的校验，不代表后端可以不做校验。前端时间有人在知乎上提问，大意是说前端该不该完全信任后端返回的数据，严格来说，我们不应该信任任何人提供的数据，而这就是校验这件事情本身的意义。 基于Vue的表单验证OK，如果说前面的两种校验是因为我们有一点历史包袱，那么，接下来，我们将尝试采用更“现代化”的表单验证方式。通过Vue文档中关于数据校验这一节的内容，我们了解到官方推荐的两个表单验证插件是vuelidate和VeeValidate，而实际上这篇博客中的第一个例子，就是由文档中的例子演化而来。我个人比较喜欢后者，所以，下面我们将使用这个插件来完成第三个例子。首先 ，我们通过Vue-Cli创建一个Vue项目，然后安装下面vee-validate和vue-i18n两个插件： 12npm install vee-validate@2.0.0 --savenpm install vue-i18n 注意到这里指定了版本号，这是因为最新的3.x超出了我这个新人的接受范围，一句话，太难了！接下来，我们在入口文件main.js中添加下面的代码，目的是启用这两个插件： 12345678910111213141516171819import VueI18n from 'vue-i18n';import VeeValidate from 'vee-validate';import zh_CN from 'vee-validate/dist/locale/zh_CN'//启用Vue国际化插件Vue.use(VueI18n)//配置VeeValidateconst i18n = new VueI18n(&#123; locale: 'zh_CN',&#125;)Vue.use(VeeValidate, &#123; i18n, i18nRootKey: 'validation', dictionary: &#123; zh_CN &#125;&#125;); 接下来，编写一个单文件组件LoginForm.vue: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263&lt;!-- template of LoginForm --&gt;&lt;template&gt; &lt;div class=\"container\"&gt; &lt;h2 class=\"text-center\"&gt;你好，请登录&lt;/h2&gt; &lt;div class=\"row\"&gt; &lt;form class=\"form-horizontal col-md-offset-4 col-md-4\" id=\"loginFrom\"&gt; &lt;div class=\"form-group\"&gt; &lt;label for=\"inputEmail3\" class=\"col-sm-2 control-label\"&gt;邮箱&lt;/label&gt; &lt;div class=\"col-sm-10\"&gt; &lt;input type=\"text\" class=\"form-control\" id=\"email\" name=\"email\" placeholder=\"Email\" v-model=\"email\" v-validate=\"'required|email'\" data-vv-as=\"邮箱\"/&gt; &lt;p class=\"alert alert-danger\" role=\"alert\" v-show=\"errors.has('email')\"&gt;&#123;&#123; errors.first('email') &#125;&#125;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\" name=\"password\" rules=\"required\"&gt; &lt;label for=\"inputPassword3\" class=\"col-sm-2 control-label\"&gt;密码&lt;/label&gt; &lt;div class=\"col-sm-10\"&gt; &lt;input type=\"password\" class=\"form-control\" id=\"password\" name=\"password\" placeholder=\"Password\" v-model=\"password\" v-validate=\"'required|min:6'\" data-vv-as=\"密码\"/&gt; &lt;p class=\"alert alert-danger\" role=\"alert\" v-show=\"errors.has('password')\"&gt;&#123;&#123; errors.first('password') &#125;&#125;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;div class=\"col-sm-offset-2 col-sm-10\"&gt; &lt;div class=\"checkbox\"&gt; &lt;label&gt; &lt;input type=\"checkbox\" /&gt;记住密码 &lt;/label&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class=\"form-group\"&gt; &lt;div class=\"col-sm-offset-2 col-sm-10\"&gt; &lt;button type=\"button\" class=\"btn btn-default login\" v-on:click=\"login()\"&gt;登录&lt;/button&gt; &lt;/div&gt; &lt;/div&gt; &lt;/form&gt; &lt;/div&gt; &lt;/div&gt;&lt;/template&gt;&lt;!-- script of LoginForm --&gt;&lt;script&gt;export default &#123; name: \"LoginForm\", components: &#123;&#125;, data: () =&gt; (&#123; email: \"\", password: \"\" &#125;), methods: &#123; login: function() &#123; &#125; &#125;&#125;;&lt;/script&gt;&lt;!-- style of LoginForm --&gt;&lt;style scoped&gt;.login &#123; color: white; height: 38px; width: 300px; background-color: #2b669a;&#125;&lt;/style&gt; 可以看到，我们在关键的两个input控件上添加了v-validate和data-vv-as这两个属性。比如我们这里需要验证用户输入的邮箱是否合法、邮箱是否为空，那么我们就可以使用下面的语法： 12&lt;input type=\"text\" class=\"form-control\" id=\"email\" name=\"email\" placeholder=\"Email\" v-model=\"email\" v-validate=\"'required|email'\" data-vv-as=\"邮箱\"/&gt;&lt;p class=\"alert alert-danger\" role=\"alert\" v-show=\"errors.has('email')\"&gt;&#123;&#123; errors.first('email') &#125;&#125;&lt;/p&gt; 这些语法在Vue中被称为指令，而data-vv-as则是HTML5中的一个特性，用来给提示信息中的字段起一个别名。实际上，这个插件里同样内置了一批常见的校验规则。当控件中的值不满足校验条件时，就会在errors中产生错误信息，所以，我们根据错误信息中是否包含指定字段来决定要不要展示错误信息，这就是这个插件的作用。运行这个例子，我们会得到下面的结果。 基于Vue的表单校验 既然提到这类表单验证最难的地方在于扩展性，那么下面我们再来看看如何扩展一个新的校验规则，这里以最常见的手机号校验为例, 个人以为这是这个插件最为强大的地方： 12345678Validator.extend('isMobile', &#123; messages: &#123; zh_CN: field =&gt; field + '必须是11位手机号码' &#125;, validate: value =&gt; &#123; return value.length === 11 &amp;&amp; /^((13|14|15|17|18)[0-9]&#123;1&#125;\\d&#123;8&#125;)$/.test(value) &#125;&#125;) 相信通过今天这篇博客，大家应该对Vue里的表单验证有一点心得了。这类验证的库或者框架其实非常多，整合到Vue中要做的工作无外乎写一个插件，在控件触发相关事件或者表单提交的时候进行验证。作为一个Vue的新人，这个过程可谓是路漫漫其修远。你大概想不到，我是在凌晨加班加到凌晨两点半的情况下做完这几个示例的，最近这两三个月里加的班比我过去三年都多，这到底是好事还是坏事呢？有时候不知道自己还能不能坚持下去，往事已矣，人难免会感到迷茫的吧！ 本文小结这篇博客主要通过三个示例分享了Vue下表单校验的实现，而促使博主对这一切进行研究的原始动力，则是源于一个实际工作中通过Vue开发的新项目。前后端要不要分离、项目里要不要继续使用jQuery、该不该频繁地操作DOM，这其实是毫无关联地三件事情，而这种事情90%的人是完全不关心的，就像有一种看起来相当“成年人”的做法，出了事情第一时间不是去纠结谁的过错，而是问能不能马上解决以及解决问题需要多长时间。这看起来好像一点问题都没有，可不去在意事件本身对错的人，是因为这些问题不需要他去处理，利益相关和责任相关是完全不一样的，因为你不能一出问题全部都找到程序员这里，这项目又不是程序员一个人的。我关心这些无关紧要的问题，纯粹是因为我对自己做的东西有一种感情，我想做好它而已，我希望自己是个纯粹的人，而且可以一直纯粹下去，晚安！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"https://qinyuanpei.github.io/tags/Vue/"},{"name":"表单","slug":"表单","permalink":"https://qinyuanpei.github.io/tags/%E8%A1%A8%E5%8D%95/"},{"name":"验证","slug":"验证","permalink":"https://qinyuanpei.github.io/tags/%E9%AA%8C%E8%AF%81/"}]},{"title":"在WSL中使用Linux桌面环境的尝试与总结","date":"2019-08-17T21:09:46.000Z","path":"posts/3972610476/","text":"最近忙里偷闲的博主，再次迷恋上折腾Linux。话说自从微软推出WSL以后，我就彻底地停止了Windows + Linux 的双系统组合。回想起从前使用过的各种Linux发行版，基本上每隔一段时间就会崩溃一次，所以，面对WSL这种近乎应用级别的方案，我个人是非常愿意去接受的。因为一不小心玩坏了的话，可以直接对应用程序进行重置，或者重新从应用商店下载，相比重装系统，我觉得这种方式要更友好一点。虽然说Windows10是有史以来最好的Linux发行版:smile:，可面对只有命令行的Linux，果然还是有一丝丝的失望啊:beetle:。所以，在这篇博客里，主要想和大家分享下，关于在WSL下使用Linux桌面系统的一点点尝试和体会。虽然目前应用商店里已经提供了Ubuntu、Debian、Kail Linux、OpenSUSE这些常见的发行版，可当你熟悉了Linux的世界以后，就会明白这个世界对多元化的追求是永无止境的，我不想去Judge这些多元化间优劣，我只想自由地使用我喜欢的技术，比如Linux Deepin、Elementary OS。这是我想要使用Linux桌面环境的理由。 我们知道，目前应用商店里提供的Linux发行版都是&quot;命令行&quot;版本。因为Windows本身就提供了非常出色的桌面环境，虽然每一次设计都给人一种相当前卫的感觉。平时我们使用SSH登录远程服务器的时候，其实是使用它的终端环境即CLI。Linux和Windows最大的不同在于，Linux 的桌面环境并不是Linux本身的一部分，它和所有的Linux应用程序并没有什么区别，因为脱离桌面环境的Linux的单独运行，而脱离桌面环境的Windows则未必可以。那么，我们怎么样在Windows里使用Linux的桌面环境呢？常见的思路主要有XServer和远程桌面两种。这里我们主要介绍第一种方式，即XServer。什么是XServer呢？Linux的GUI架构其实是C/S模式的，其中XServer负责显示，XClient负责请求。所以，我们只要在宿主机上安装XServer就可以啦。在这里，常见的XServer主要有：VcXsrv、X410和MobaXterm。理论上，我们只需要在WSL里安装桌面环境，在Windows上安装XServer，然后通过命令行启动相应桌面环境即可。 作为一个最流行的Linux发行版，微软非常贴心地给出了16.04和18.04两个版本。不过随着博主不甘寂寞地一通升级以后，最终还是稳定在了18.04这个版本。既然选择从Ubuntu这个发行版开始折腾，不如从它默认的桌面环境Gnome开始折腾吧！虽然我个人一直不太喜欢这个风格，不然就不会有接下来针对Pantheon和Deepin两个桌面环境的作死啦。这个过程最有意思的事情，居然是发现了一个更轻量级的桌面环境，可能真的是&quot;无心插柳柳成荫&quot;吧。好了，关于如何开启WSL及安装Linux发行版的过程不再多说。首先，让我们把系统默认的源切换到阿里云，因为这样能节省博主和大家的时间。:slightly_smiling_face: 12sudo cp /etc/apt/sources.list /etc/apt/sources.list.2019016sudo vim /etc/apt/sources.list 接下来，我们使用下面的命令对文件内容进行替换, 或者你可以手动逐行去编辑。 12:%s/security.ubuntu/mirrors.aliyun/g:%s/archive.ubuntu/mirrors.aliyun/g 除此以外，还推荐大家使用以下国内的镜像源： 清华大学镜像源：https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ 网易开源镜像站：http://mirrors.163.com/.help/ubuntu.html 完成镜像源的切换以后，我们就可以愉快地使用apt-get update刷一波存在感啦，话说最近看到一条微博，建议给sudo起一个别名plz或者pls。除了调侃以外，可能更多是想把冰冷的命令行变得充满人情味吧。Windows下安装VcXsrv大家都轻车熟路啦，这个不再过多的说明。下面，我们来安装以下Ubuntu桌面环境： 12echo \"y\"|sudo apt-get install ubuntu-desktop unity compizconfig-settings-managersudo dpkg-reconfigure dbus &amp;&amp; service dbus restart 接下来配置XLaunch，这是我们安装完VcXsrv后自带一个应用程序： 配置XLaunch 按照默认配置直至完成后我，我们会发现桌面上出现了一个黑色的窗口，如下图所示： XLaunch经典黑屏 此时，我们在Ubuntu的Bash窗口中输入sudo compiz命令并切回XLaunch界面。接下来，就是见证奇迹的时刻： 经典的Ubuntu桌面 如你所见，这是Ubuntu默认的Unity桌面，博主一开始是在Ubuntu16.04上研(折)究(腾)的，当时安装完以后桌面其实是黑色的，因为当时并没有保留下这历史性的一刻，所以，从网上找了张图来这里充数啦，这张图片出自：Run any Desktop Environment in WSL。 OK，既然Ubuntu可以装桌面，那么，衍生自Ubuntu的Elementary OS和Linux Deepin应该同样可以吧，虽然目前应用商店里还有这两个发行版。本着不折腾就不会死的选择，先装个Elementary OS的桌面环境试试呗！我个人挺喜欢这个发行版的，理由是默认主题样式就很好看，同理，Linux Deepin除了好看以外，本身就带有大量优秀的软件。所以说，人类果然还是始于颜值的啊！Elementary OS使用的桌面环境是Pantheon，我们可以通过下面的命令行快速安装： 123sudo add-apt-repository ppa:elementary-os/stablesudo apt updatesudo apt install elementary-desktop 通常，每个桌面环境都会自带一部分“最佳”适配的应用程序，考虑到WSL并不是一个完整的Linux实现，我们在这里卸载掉一部分WSL下不支持的应用程序。而微软新推出的WSL2，则是基于VM的实现，两种方式完全没有可比性，这里不做无意义的争论： 123sudo apt purge gnome-screensaver \\switchboard-plug-power switchboard-plug-bluetooth switchboard-plug-networking \\wingpanel-indicator-bluetooth wingpanel 参考Installing Pantheon Desktop On Ubuntu这篇文章中的建议，为了启动Pantheon桌面环境，我们需要 gala、 plank和wingpanel三个软件，它们的作用有点像前面的compiz。而关于X410，你可以把它理解为和VcXsrv类似的软件，不同的是这是一个付费软件，作者写了一系列的博客来推广它。接下来，在安装gala的过程中，你大概会遇到这个错误： 123The following packages have unmet dependencies:gala : Depends: libmutter-2-0 (&gt;= 3.28.4-0ubuntu18.04.1+elementary4~ubuntu5.0.1) but 3.28.4-0ubuntu18.04.1 is to be installedE: Unable to correct problems, you have held broken packages. 我向作者发邮件寻求帮助，作者非常热心地回复了我三次邮件，对方表示应该是Elementary OS团队正在基于Ubuntu19.04开发新版本，所以可能没有意识到elementary-desktop这个包已经broken了，并且他们在18.04版本上复现了这个问题，建议我直接联系官方。好吧，博主的英语表示受宠若惊，邮件在此为证： 来自国外网友的热心指导 总而言之，博主试图在WSL上体验Elementary OS的想法彻底失败，既然这个最美的Linux发行版已失败告终，并不打算就此罢手的博主，决定继续在命令行终端里折腾Linux Deepin。这个发行版是我从大学时开始接触的Linux发行版，那时有个小学弟第一次给我介绍了Linux Mint，不过我对这个版本实在爱不起来，因为太像Windows了啊，可谁能想到若干年后，Windows反而变成了最好的Linux发行版呢(:smile:)，果真是“人生不相见，动如参与商”啊…… 好啦，继续敲命令。Linux Deepin的桌面环境是Deepin Desktop Environment，简称dde： 123sudo add-apt-repository ppa:leaeasy/ddesudo apt-get updatesudo apt install dde dde-file-manager Linux Deepin安装是非常顺畅的，但即便安装完这个桌面环境，博主还是不知道怎么启动这个环境，因为你常规使用Ubuntu的话，安装完切换桌面管理器就可以了，可当你用WSL这种方式使用Ubuntu的时候，可能你就会感到非常困惑。相比之下，xfce就让人感觉友好得多，因为它只有一个命令startxfce4，而安装只需要安装xfce4和xfce4-terminal就可以了。在对比了Gnome、KDE、Unity、Mint、xfce等等的桌面环境以后，我觉得Linux在桌面市场输给Windows是理所当然的，因为实在太混乱了，WSL下需要的应该是一个轻量级的桌面，因为越是华而不实东西，越会消耗大量资源。我最初想要折腾桌面环境，无非是为了下面这个结果，撒花完结，以上！ 简洁/简陋的xfce桌面","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://qinyuanpei.github.io/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"WSL","slug":"WSL","permalink":"https://qinyuanpei.github.io/tags/WSL/"},{"name":"Linux","slug":"Linux","permalink":"https://qinyuanpei.github.io/tags/Linux/"},{"name":"桌面","slug":"桌面","permalink":"https://qinyuanpei.github.io/tags/%E6%A1%8C%E9%9D%A2/"}]},{"title":"通过ApiExplorer为Swagger提供MVC扩展","date":"2019-08-06T23:02:05.000Z","path":"posts/4116164325/","text":"我一直想吐槽下运维同事提供的Jekins项目模板，因为它居然不支持含有多个项目的解决方案。作为一个有追求的程序员，每个解决方案下最少应该含有两个项目，即项目本身和项目对应的单元测试。可惜在这样一种情形下，我没法再去坚持这样的原则，而这真正让我感到难过的是，为了在编译环节向Jekins妥协，大家在一个项目里极尽所能，在这一个项目里居然混合了MVC、WebApi和WebService三种技术，甚至到最后连传统三层的界限都越来越模糊了。这让我意识到一件事情，工程上的妥协和技术选型一样，在某种意义上它们都不能被称之为科学，因为确实没什么道理，完全是运维为了方便而制造出的问题。在我们意识到文档的重要性以后，写文档就变成了日常工作。我一直坚持的原则是，文档能通过工具生成就坚决不要手写，所以，看到项目目录里充斥着各种各样的文档格式，譬如Word、Excel、Pdf、Viso等等的时候，我毅然决然地选择了Swagger。而今天这篇文章的原由，恰恰来自于这个”混搭”的项目。说到这里，你可能已经想到我想做什么了。不错，我们有部分WebApi是写在MVC的控制器里的，我希望使用者可以通过Swagger看到这部分接口的文档，这样我就有时间在这里写博客了。😄 故事缘起常规的Swagger的使用就不再说啦，因为基本上你通过Nuget安装完Swashbuckle以后，再配置下项目生成的XML注释文档就可以使用啦！不过，博主在这里遇到的第一个问题就是，按照常规套路配置好了以后，Swagger页面打开完全就是空白的啊，反复尝试直至怀疑人生后，我突然意识到，莫非是因为我这是一个MVC的项目？立马跑到官方的Issues下面逐个扫视，果不其然，大佬们一致给出了答案：Swagger是不支持MVC类型的项目的。这里补充说明，这里的MVC是指ASP.NET MVC。目前官方主推的ASP.NET Core是没有这种困惑的啦，因为微软在这个新版本中统一了MVC和WebApi。对于这种历史“遗留问题”，既然Swagger官方都不愿意提供支持，那么，博主只好勉为其难的提供一个实现，我不得不承认，带着历史包袱的ASP.NET在扩展性上的确不如全新的“Core”系列，因为单单是System.Web系列的动态链接库版本就令人痛苦不堪，因此，博主在写这个扩展的时候，全部升到了最新的5.2.7.0。 实现MvcApiExplorer好了，Swagger之所以能够生成友好、可交互的API文档，其核心依赖于IApiExplorer接口。这一点，我们可以通过Swashbuckle项目中的源代码来得到验证。其中，生成符合Swagger规范的JSON文档，是通过SwaggerGenerator这个类来实现的。而进一步研究这个类，我们就会发现它依赖IApiExplorer接口。这个接口位于System.Web.Http.Description命名空间下，而显然这是WebApi相关的命名空间，所以，对于一般的WebApi项目，因为微软已经帮我们实现了默认的ApiExplorer，所以，Swagger可以识别出项目中的Controller及其Action，并通过XML注释文档进一步填充接口相关的描述信息。一旦想到这一层，我们就会明白，为什么Swagger不支持MVC项目，因为MVC里压根就没有实现IApiExplorer接口啊！那么，怎么办呢？我们的想法是通过反射取出所有的MVC控制器及其Action，然后组织出这些接口的描述信息，再将它们添加到默认的IApiExplorer实现中去，这样MVC和WebApi都可以被Swagger识别，为此，我们继承默认的ApiExplorer，并实现我们自定义的MvcApiExplorer： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677public class MvcApiExplorer : ApiExplorer &#123; /// &lt;summary&gt; /// HttpConfiguration /// &lt;/summary&gt; private HttpConfiguration _configuration; public MvcApiExplorer (Assembly assembly, HttpConfiguration configuration) : base (configuration) &#123; _configuration = configuration; assembly.GetTypes () .Where (type =&gt; typeof (IController).IsAssignableFrom (type) &amp;&amp; type.Name != \"ErrorController\" &amp;&amp; type.BaseType != typeof (ApiController)) .ToList ().ForEach (controller =&gt; &#123; base.ApiDescriptions.AddRange (BuildControllerApiDescription (controller)); &#125;); &#125; /// &lt;summary&gt; /// ApiExolorer for Action is visible /// &lt;/summary&gt; /// &lt;param name=\"actionVariableValue\"&gt;&lt;/param&gt; /// &lt;param name=\"actionDescriptor\"&gt;&lt;/param&gt; /// &lt;param name=\"route\"&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public override bool ShouldExploreAction (string actionVariableValue, HttpActionDescriptor actionDescriptor, IHttpRoute route) =&gt; true; /// &lt;summary&gt; /// ApiExolorer for Controller is visible /// &lt;/summary&gt; /// &lt;param name=\"controllerVariableValue\"&gt;&lt;/param&gt; /// &lt;param name=\"controllerDescriptor\"&gt;&lt;/param&gt; /// &lt;param name=\"route\"&gt;&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public override bool ShouldExploreController (string controllerVariableValue, HttpControllerDescriptor controllerDescriptor, IHttpRoute route) =&gt; true; private List&lt;ApiDescription&gt; BuildControllerApiDescription (Type type) &#123; var controllerName = type.Name.Replace (\"Controller\", \"\"); var methods = type.GetMethods (System.Reflection.BindingFlags.Instance | System.Reflection.BindingFlags.Public | BindingFlags.DeclaredOnly) .Where (m =&gt; typeof (ActionResult).IsAssignableFrom (m.ReturnType)); var list = new List&lt;ApiDescription&gt; (); foreach (var method in methods) &#123; var apiDescription = new ApiDescription (); apiDescription.ActionDescriptor = new MvcHttpActionDescriptor (method); apiDescription.ActionDescriptor.ControllerDescriptor = new HttpControllerDescriptor (_configuration, controllerName, type); apiDescription.HttpMethod = HttpMethod.Post; apiDescription.Route = new HttpRoute (string.Format (\"&#123;0&#125;/&#123;1&#125;\", controllerName, method.Name)); apiDescription.RelativePath = string.Format (\"&#123;0&#125;/&#123;1&#125;\", controllerName, method.Name); apiDescription.Documentation = string.Empty; typeof (ApiDescription).GetProperty (\"ParameterDescriptions\").SetValue (apiDescription, BuildApiParameters (method)); typeof (ApiDescription).GetProperty (\"ResponseDescription\").SetValue (apiDescription, new ResponseDescription () &#123; ResponseType = method.ReturnType, DeclaredType = method.DeclaringType, Documentation = string.Empty &#125;); list.Add (apiDescription); &#125; return list; &#125; private Collection&lt;ApiParameterDescription&gt; BuildApiParameters (MethodInfo methodInfo) &#123; return new Collection&lt;ApiParameterDescription&gt; ( methodInfo.GetParameters ().Select (p =&gt; new ApiParameterDescription () &#123; Name = p.Name, Documentation = string.Empty, Source = ApiParameterSource.Unknown, ParameterDescriptor = new MvcHttpActionParameterDescriptor (p, new MvcHttpActionDescriptor (methodInfo)), &#125;).ToList ()); &#125;&#125; 通过代码可以看出，实现MvcApiExplorer的过程，其实就是向ApiDescriptions集合中添加元素的过程。为此，我们通过程序集去反射所有实现了IController接口，同时其父类不是ApiController，并且方法返回值类型为ActionResult的所有类型，通过这个类型信息，我们进一步反射每个方法以及方法的参数，并把这些参数转换为ApiDescription类型需要的参数类型。在组织信息的过程中，有一部分属性被微软设计为只读，故而不得不通过反射的方式来解决。我们知道，MVC里默认的路由模板是：{controller}/{action}，这是WebApi里的特性路由流行以前默认的、最基础的路由。我们这里基于沿用这个规则，所谓“约定大于配置”，这可以为我们节省不少时间。MVC里的HTTP动词我全部使用了POST，这是因为MVC里真正控制一个方法是GET还是POST请求，其实是JsonRequestBehavior这个参数，当它设置为AllowGet时，该方法可以同时支持这两种HTTP动词。同样，在模模型绑定阶段，我全部使用了Unknown，因为MVC会尝试通过Body或者Form的形式来接受一个参数，这两个地方完全是来自MVC本身机制的限制，如果大家有更好的思路，欢迎大家在博客里留言。 一旦实现了自定义的MvcApiExplorer，我们就可以尝试用它来替换微软默认的实现。在ASP.NET中，我们通过GlobalConfiguration.Configuration.Services.Replace()方法来实现服务的替换。其实，这种思路在ASP.NET Core里依然存在，比如我们在实现动态WebApi时采用的ControllerFeatureProvider都属于服务替换，所不同的时，ASP.NET时代是通过一个内置的IoC容器来实现服务替换，而ASP.NET Core时代，我们显然有了更多的选择，甚至依赖注入渗透到了整个.NET Core的方方面面，这的确是一种相当大的进步。曾几何时，Javaer嘲笑我们只会拖控件，可今天的我们，Java里有的概念我们都有对应的实现，反倒是Java开始从C#身上学习那些有点“甜”的语法糖啦！的确，我们写了这么多代码，其实最关键的就只有下面这一句，住口！这明明是三行： 12var assembly = typeof(DefaultMvcProject.MvcApplication).Assembly;var apiExplorer = new MvcApiExplorer(assembly, GlobalConfiguration.Configuration); GlobalConfiguration.Configuration.Services.Replace(typeof(IApiExplorer), apiExplorer); OK，接下来我们简单写几个MVC的控制器，来验证下我们为Swagger编写的MVC控制。在此之前，请确保完成了Swagger的两步常规配置，即为Swagger引入XML注释文档、在项目属性中勾选XML注释文档。这是使用Swagger的最小配置，相信大家一定都知道啦！ 12345678GlobalConfiguration.Configuration .EnableSwagger (c =&gt; &#123; c.SingleApiVersion (\"v1\", \"DefaultMvcProject\"); c.IncludeXmlComments ($\"&#123;System.AppDomain.CurrentDomain.BaseDirectory&#125;/bin/DefaultMvcProject.XML\"); &#125;) .EnableSwaggerUi (c =&gt; &#123; c.DocumentTitle (\"My Swagger UI\"); &#125;); 两个非常简单的Controller，这里就不再贴代码啦！ 非常简单的Controller 可以注意到，一切都工作的很好，我们在Swagger里可以看到我们编写的Api接口，并且可以直接对接口进行调试。因为MVC本身的原因，这些MVC控制器的注释都不会生成到XML注释文档里。所以，稍微有一点遗憾的地方就是，这些接口都没有对应注释。不过，这已经达到了本文最初的目的，至少我不用再去写文档，告诉使用者这个接口里有哪些参数，以及这个接口的地址是什么啦，说到底啊，懒惰是人类进步的阶梯。这篇博客里实现的扩展，我已经发布到Github上，并附带了一个简单的示例(不要想太多哦，就是这篇文章里的示例)，感兴趣的朋友可以自助研究，仓库地址为：https://github.com/qinyuanpei/Swashbuckle.Extension.Mvc 差一点就完美了 本文小结本文实现了一个针对MVC项目的Swagger扩展，它可以让你编写在MVC控制器里的API接口，像普通WebApi项目一样展示在Swagger里。其原理是继承并重写了ApiExplorer类，这是Swagger生成API文档的核心接口。好了，以上就是这篇文章的全部内容啦，写这种短小的文章没有那么累，希望大家读起来一样不会累吧，晚安，世界！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"WebApi","slug":"WebApi","permalink":"https://qinyuanpei.github.io/tags/WebApi/"},{"name":"Swagger","slug":"Swagger","permalink":"https://qinyuanpei.github.io/tags/Swagger/"},{"name":"MVC","slug":"MVC","permalink":"https://qinyuanpei.github.io/tags/MVC/"}]},{"title":".NET Core POCOController在动态Web API中的应用","date":"2019-08-01T16:44:59.000Z","path":"posts/116795088/","text":"Hi，大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是：https://blog.yuanpei.me。在上一篇文章中，我和大家分享了ASP.NET中动态Web API的实现，这种方案的现实意义是，它可以让我们把任意一个接口转换为Web API，所以，不单单局限在文章里提到的WCF迁移到Web API，任意领域驱动开发(DDD)中的服务层，甚至是更为普遍的传统三层，都可以通过这种方式快速构建前后端分离的应用。可能大家会觉得直接把Service层暴露为API，会引发一系列关于鉴权、参数设置(FromQuery/FromBody)等等的问题，甚至更极端的想法是，这样和手写的没什么区别，通过中间件反射能达到相同的目的，就像我们每天都在写各种接口，经常有人告诉我们说，不要在Controller层写太重的业务逻辑，所以，我们的做法就是不断地在Service层里增加新接口，然后再把Service层通过Controller层暴露出来，这样子真的是对的吗？ 可我个人相信，技术总是在不断向前发展的，大家觉得RESTful完全够用啦，结果GraphQL突然发现了。大家写了这么多年后端，其实一直都在绕着数据转，可如果数据库本身就支持RESTful风格的接口，或者是数据库本身就支持某种ORM，我们后端会立马变得无趣起来。其实，在ASP.NET Core中已经提供了这种特性，这就是我们今天要说的POCOController，所以，这也许是个正确的思路，对吧？为什么Service层本身不能就是Controller层呢？通过今天这篇文章，或许你会接受这种想法，因为POCOController，就是弱化Controller本身的特殊性，一个Controller未必需要继承自Controller，或者在名称中含有Controller相关的字眼，如果Controller同普通的类没有区别会怎么样呢？答案就是Service层和Controller层的界限越来越模糊。扪心自问，我们真的需要中间这一层封装吗？ 什么是POCOControllerPOCOController是ASP.NET Core中提供的一个新特性，按照约定大于配置的原则，在ASP.NET Core项目中，所有带有Controller后缀的类，或者是使用了[Controller]标记的类，即使它没有像模板中一样继承Controller类，ASP.NET Core依然会将其识别为Controller，并拥有和普通Controller一样的功能，说到这里，你是不是有点兴奋了呢，因为我们在ASP.NET里花了大力气去做类似的事情，因为ASP.NET里一个普通的类是没有办法成为Controller的，即使通过Castle的Dynamic Proxy黑科技，我们依然需要去Hack整个MVC框架创建、筛选Controller和Action的过程。可在ASP.NET Core里这一切居然变成了一个新的feature，所以，我预感到这篇文章应该不会像上一篇文章那么长，果然9102有9102的好处呢……好了，现在我们来写一个POCOController： 1234567public class MessageController&#123; public string Echo(string receiver) &#123; return $\"Hello, &#123;receiver&#125;\"; &#125;&#125; 接下来，我们通过浏览器访问：http://localhost:6363/Message/Echo?receiver=PayneQin，我们就会发现一件非常神奇的事情，那就是，我们并没有真的在写一个Controller，它没有继承Controller类，虽然它的名字里带着Controller的后缀，可它确实实现了一个Controller所具备的功能，因为它返回了我们期望的信息。 欢迎来到POCOController的世界 可以注意到，这个Controller使用起来和普通的Controller是没有任何区别的，这正是我们想要的结果。对于.NET Core而言，一个普通的类想要成为POCOController，只需要满足以下任意一个条件：第一，继承自Microsoft.AspNetCore.Mvc.Controller类，无论是否带有Controller后缀，都可以作为POCOController。第二，不继承自Microsoft.AspNetCore.Mvc.Controller类，同时引用了Microsoft.AspNetCore.Mvc相关的程序集。在这里，博主一开始就犯了这个错误，因为博主建的是一个Web API类型的项目。 ControllerFeatureProvider那么，为什么ASP.NET Core里可以实现如此炫酷的功能呢？这里要介绍到ControllerFeatureProvider。在.NET Core中，微软引入了应用程序部件的概念，顾名思义，它是对应用程序资源的一种抽象，通过这些应用程序部件， .NET Core提供了发现和加载MVC组件，如控制器、视图(View)、标记(TagHelper)、Razor等等的功能。在MVC中，这些功能由ApplicationPartManager对象来进行管理，它维护着一个叫做FeatureProviders的列表，以上这些功能分别对应一个Feature，所以，当我们希望引入一个新的功能的时候，只需要实现IApplicationFeatureProvider接口即可，而这里的ControllerFeatureProvider显然是提供“控制器”相关的Feature，它有一个最为关键的接口IsController(TypeInfo)。 回到一开始的话题，微软定义了一个类成为POCOController的规则，实际上我们同样可以定义自己的规则，譬如ABP框架中限定的接口约束是实现IAppService这个接口，那么我们就可以把一个程序集或者多个程序集里的类型识别为控制器，这就是POCOController的奥秘所在。在比如我们的项目中难免会有大量CRUD的垃圾需求，区别仅仅是它访问不同的仓储，我们可能会想写一个泛型的控制器来处理，可惜在过去的ASP.NET里，实现这一切并不太容易。为什么说不大容易呢？通过我们上一篇文章里动态路由的整个过程，大家就知道有多麻烦了啊，可在.NET Core里要实现一个泛型的控制器就非常容易了啊，因为我们只需要告诉ControllerFeatureProvider，这是一个控制器，并且控制器的类型就是这个泛型参数T，所以，综上所述，ControllerFeatureProvider主要做两个事情，第一，判定一个类型能不能算作Controller；第二，对程序集里的类型进行筛选和过滤。下面，我们顺着这个思路来实现我们自己的ControllerFeatureProvider。 123456789101112public class DynamicControllerFeatureProvider : ControllerFeatureProvider &#123; protected override bool IsController (TypeInfo typeInfo) &#123; var type = typeInfo.AsType (); if (!typeof (IDynamicController).IsAssignableFrom (type) || !typeInfo.IsPublic || typeInfo.IsAbstract || typeInfo.IsGenericType) &#123; return false; &#125; return true; &#125;&#125; 如你所见，我们采用了一种简单粗暴的方式，任何非Public、非抽象、非泛型并且实现了IDynamicController接口的类型，都可以被认为是一个Controller，原谅我起了这样一个直白而普通的接口名称，因为一开始做的时候，真的就是想延续动态Web Api这个想法而已，所以，大家明白就好了，不用太过纠结这个接口的名字，甚至你还可以通过Attribute来打上标记，反正都是为了辨别哪些类型可以被当做控制器。 IApplicationModelConventionOK，现在我们已经告诉.NET Core，怎么样去把一个类型识别为Controller。因为MVC中有一些所谓“约定大于配置”的东西，比如默认的路由规则是{area}/{controller}/{action}/{id}，相信从ASP.NET时代一起走过来的各位，对这个东西应该很熟悉啦，因为最早App_Start里会有RouteConfig和WebApiConfig这两个东西。我们在做ASP.NET版本的动态Web API的实现的时候，实际上就是配置了这样一个固定的路由，所以，理论上现在即使我们不讲下面这部分内容，现在我们已经实现了动态Controller。可如果我们希望对路由进行全局配置，我们就不得不关注这个接口。简而言之，通过这个接口，我们可以修改MVC里约定俗成的这套规则，譬如在路由中带个版本号前缀，或者根据命名空间去生成某种规则的路由，我们都可以考虑去实现这个接口。一般情况下，我们会通过重写Apply()方法来达到修改路由的目的。 在这篇文章里，我们希望在MVC这套默认路由的基础上，增加对特性路由的支持。说到这里，我们又会回到一个旧话题，即基于配置的路由和基于特性的路由这两种路由。前者是MVC里的路由设计的基础，而后者是Web API里提出并在RESTful风格API的设计中发扬光大。所以，我们希望在提供默认路由的基础上，使用者可以自由配置路由风格，所以，我们需要通过这个接口来构造路由信息，值得一提的是，我们可以在这个过程中设置ApiExplorer是否可见，为接口参数设置合适的绑定模型等等，所以，我们会使用HttpGet/HttpPost等来标记接口的调用方式，使用Route来标记用户自定义的路由信息，使用FromBody/FromQuery等来标记参数的绑定信息，有了这些配合Swagger简直是无往不胜，并非是开发人员不愿意写文档，而是因为文档的更新速度往往赶不上需求的变化速度，一旦文档落后于实际业务，这样的文档实际是没有意义的，我真的讨厌所有人都来找你问接口的地址、参数这些东西，如果你写完了一个Service，写好对应的方法注释，然后你就有了一个可用的Web API，和一个可用的在线文档，何乐而不为呢？ 下面，是博主实现的一个动态路由，它主要涉及到ConfigureApiExplorer()、ConfigureSelector()和ConfigureParameters()这三个部分的实现，我们一起来看下面的代码，ASP.NET Core版本相比ASP.NET版本，少了像Castle DynamicProxy这样的黑科技，因此它的实现会更加纯粹一点。 ConfigureApiExplorer()首先，是对ApiExplorer进行配置。通过ApiExplorer，我们可以控制Controller级别和Action级别的Web API的可见性。一般情况下的用法是在Controller或者Action上添加ApiExplorerSettings标记，而在这里，我们只需要给ControllerModel和ActionModel的ApiExplorer属性赋值即可。 12345678910111213141516private void ConfigureApiExplorer (ControllerModel controller) &#123; if (string.IsNullOrEmpty (controller.ApiExplorer.GroupName)) controller.ApiExplorer.GroupName = controller.ControllerName; if (controller.ApiExplorer.IsVisible == null) controller.ApiExplorer.IsVisible = true; controller.Actions.ToList ().ForEach (action =&gt; ConfigureApiExplorer (action));&#125;private void ConfigureApiExplorer (ActionModel action) &#123; if (action.ApiExplorer.IsVisible == null) action.ApiExplorer.IsVisible = true;&#125; ConfigureSelector()接下来，是对路由进行配置。这部分的核心其实就是根据AreaName、ControllerName、ActionName来生成路由信息，我们会为没有配置过特性路由的Action生成默认的路由，这其实就是MVC里约定大于配置的一种体现啦。在这里会涉及到对ControllerName和ActionName的优化调整，主要体现在两个方面，其一是对类似XXXService、XXXController等这样的后缀进行去除，使其构造出的Api路由更加短小精简；其二是对ActionName里的Get/Save/Update等动词进行替换，使其构造出的Api路由更加符合RESTful风格。 123456789101112131415161718192021222324252627282930313233343536373839private void ConfigureSelector (ControllerModel controller, DynamicControllerAttribute controllerAttribute) &#123; if (_dynamicControllerOptions.UseFriendlyControllerName) &#123; var suffixsToRemove = _dynamicControllerOptions.RemoveControllerSuffix; if (suffixsToRemove != null &amp;&amp; suffixsToRemove.Any ()) suffixsToRemove.ToList ().ForEach (suffix =&gt; controller.ControllerName = controller.ControllerName.Replace (suffix, \"\")); &#125; controller.Selectors.ToList ().RemoveAll (selector =&gt; selector.AttributeRouteModel == null &amp;&amp; (selector.ActionConstraints == null || !selector.ActionConstraints.Any ()) ); if (controller.Selectors.Any (selector =&gt; selector.AttributeRouteModel != null)) return; var areaName = string.Empty; if (controllerAttribute != null) areaName = controllerAttribute.AreaName; controller.Actions.ToList ().ForEach (action =&gt; ConfigureSelector (areaName, controller.ControllerName, action));&#125;private void ConfigureSelector (string areaName, string controllerName, ActionModel action) &#123; action.Selectors.ToList ().RemoveAll (selector =&gt; selector.AttributeRouteModel == null &amp;&amp; (selector.ActionConstraints == null || !selector.ActionConstraints.Any ()) ); if (!action.Selectors.Any ()) &#123; action.Selectors.Add (CreateActionSelector (areaName, controllerName, action)); &#125; else &#123; action.Selectors.ToList ().ForEach (selector =&gt; &#123; var routePath = $\"&#123;_dynamicControllerOptions.DefaultApiRoutePrefix&#125;/&#123;areaName&#125;/&#123;controllerName&#125;/&#123;action.ActionName&#125;\".Replace (\"//\", \"/\"); var routeModel = new AttributeRouteModel (new RouteAttribute (routePath)); if (selector.AttributeRouteModel == null || !_dynamicControllerOptions.UseCustomRouteFirst) selector.AttributeRouteModel = routeModel; &#125;); &#125;&#125; 我们知道，每个API接口都会有相对应的HTTP动词，譬如GET、POST、PUT等等，那么，我们在构造路由的时候，如何知道当前的Action应该使用什么HTTP动词呢？实际上，我们有两个来源来组织这些信息。第一个来源，是根据方法本身的名称，比如Get/Save/Update等等，我们通过对应关系将其转化为对应的HTTP动词。第二个来源是根据用户在接口中配置的路由信息，比如RouteAttribute、HttpMethod等等，将其转化为对应的HTTP动词。这个方法，其实我们在分享ASP.NET下的实现的时候，就已经用过一次啦，所谓“万变不离其宗”，大概就是如此： 12345678910111213141516171819202122232425262728293031323334353637383940private SelectorModel CreateActionSelector(string areaName, string controllerName, ActionModel action)&#123; var selectorModel = new SelectorModel(); var actionName = action.ActionName; var routeAttributes = action.ActionMethod.GetCustomAttributes(typeof(HttpMethodAttribute), false); if (routeAttributes != null &amp;&amp; routeAttributes.Any()) &#123; var httpVerbs = routeAttributes.SelectMany(s =&gt; (s as HttpMethodAttribute).HttpMethods).ToList().Distinct(); var routePath = $\"&#123;_dynamicControllerOptions.DefaultApiRoutePrefix&#125;/&#123;areaName&#125;/&#123;controllerName&#125;/&#123;action.ActionName&#125;\".Replace(\"//\", \"/\"); selectorModel.AttributeRouteModel = new AttributeRouteModel(new RouteAttribute(routePath)); selectorModel.ActionConstraints.Add(new HttpMethodActionConstraint(httpVerbs)); return selectorModel; &#125; else &#123; var httpVerb = string.Empty; var methodName = action.ActionMethod.Name.ToUpper(); if (methodName.StartsWith(\"GET\") || methodName.StartsWith(\"QUERY\")) &#123; httpVerb = \"GET\"; &#125; else if (methodName.StartsWith(\"SAVE\")) &#123; httpVerb = \"POST\"; &#125; else if (methodName.StartsWith(\"UPDATE\")) &#123; httpVerb = \"PUT\"; &#125; else if (methodName.StartsWith(\"DELETE\")) &#123; httpVerb = \"DELETE\"; &#125; var routePath = $\"api/&#123;areaName&#125;/&#123;controllerName&#125;/&#123;action.ActionName&#125;\".Replace(\"//\", \"/\"); selectorModel.AttributeRouteModel = new AttributeRouteModel(new RouteAttribute(routePath)); selectorModel.ActionConstraints.Add(new HttpMethodActionConstraint(new[] &#123; httpVerb &#125;)); return selectorModel; &#125;&#125; 由此可见，无论多么令人惊诧的黑科技，当我们一层层地拨开它的迷雾时，常常有种豁然开朗的感觉。当然，和那些令人看起来神清气爽的代码相比，博主远远达不到返璞归真的境界，因为这段代码怎么看都觉得丑陋。古美门律师告诉我们，要爱上丑陋，或许每个程序员都是从写烂代码开始的吧！ ConfigureParameters()接下来参数绑定相对简单，因为简单类型MVC自己就能完成绑定，所以，我们只需要关注复杂类型的绑定即可，最常见的一种绑定方式是FromBody： 123456789101112131415161718private void ConfigureActionParameters(ActionModel action)&#123; foreach (var parameter in action.Parameters) &#123; if (parameter.BindingInfo != null) continue; var type = parameter.ParameterInfo.ParameterType; if (type.IsPrimitive || type.IsEnum || (type.IsGenericType &amp;&amp; type.GetGenericTypeDefinition() == typeof(Nullable&lt;&gt;))) &#123; if (IsFromBodyEnable(action, parameter)) &#123; parameter.BindingInfo = BindingInfo.GetBindingInfo(new[] &#123; new FromBodyAttribute() &#125;); &#125; &#125; &#125;&#125; 通过以上三个关键步骤，我们就能实现本文一开始的效果，感觉无形中我们又复习了一篇MVC匹配路由的原理呢！ 集成Swagger和WebApiClient今天这篇文章，本质上依然是ABP框架中Dynamic WebAPI这一特性的延伸，无非是因为.NET Core中提供了更为友好的机制，可以让这一切实现起来更简单而已。还记得博主研究这个特性的“初心”是什么吗？因为我们在升级.NET Core的过程中打算抛弃WCF，我们需要一种方法，可以让现有的一个普通的Service变成一个Controller。固然，我们可以一个一个的去重新封装，可这真的是比较好的实践方式吗？从内部RPC逐渐转变为Web API调用，这种转变就像从Dubbo换成了Spring Cloud，可是Spring Cloud有注册中心啊，现在我们什么都没有，从RPC转变为Web API，会面临诸如接口授权、地址配置、不同上下文等等的问题。你经常需要告诉别人某个接口的地址是什么，不出意外地话，你至少会有三套环境的地址，别人还会问你各个参数的含义，甚至更懒的会要求你提供示例报文。所以，我觉得做微服务，尤其是全部采用Web API进行通信的微服务，提供实时更新、在线查看的文档真的非常重要，每次看到同事在Git里提交Word或者Excel，我就感到非常纠结，一来这种东西没法正常Merge(压缩包合并个鬼啊)，二来我必须下载下来看(君不见我下载目录里一堆重复文件)，所以，我更推荐努力维护好一家公司的API资产，在我们用JWT保护这些资产以前，至少要先了解它们吧！ 对于API文档，我个人推荐专门用一个站点来承载所有的Web API，比如我们最常用的Swagger，它在融合OAuth2以后可以更完美地去调试接口，了解每个接口的参数和返回值。尤其是在这篇博客的背景下，因为我们只需要把这些POCOController对应的注释文件(.XML)和程序集(.DLL)放到一起，同时把这些注释文件全部Include进来，Swagger就可以把它们展示出来。这里用到一个非常重要的特性就是IApiExploer接口，你可以把它理解为，它是一切文档展示的核心，每个接口及其参数、返回值的描述信息都是由它提供的。在没有Swagger之前，微软提供了一个叫做Web API HelpPage的组件，它和Swagger的原理无出其右。这里剧透下，稍后我会专门写一篇博客来扩展Swagger，目的是确保它可以为ASP.NET MVC提供文档支持。这里，我们使用Swagger来生成在线API文档，其核心配置如下： 123456789101112services.AddMvcCore ().AddApiExplorer ();services.AddSwaggerGen (swagger =&gt; &#123; swagger.SwaggerDoc (\"v1\", new Swashbuckle.AspNetCore.Swagger.Info () &#123; Title = \"DynamicController\", Version = \"1.0\", &#125;); swagger.DocInclusionPredicate ((docName, description) =&gt; true); var xmlFile = $\"&#123;Assembly.GetExecutingAssembly().GetName().Name&#125;.xml\"; var xmlPath = Path.Combine (AppContext.BaseDirectory, xmlFile); swagger.IncludeXmlComments (xmlPath);&#125;); 可以注意到，这篇文章里实现的动态Controller和默认的ValuesController都被展示了出来，两个字，完美，我们想要的就是这个效果。 通过Swagger生成的在线Api文档 说完了API文档的事情，我们再来说说调用Web API的问题。按理说，这应该没啥大问题，因为虽然我们会为HttpWebRequest、WebClient、HttpClient和RestSharp等等不同的API而感到纠结，可这丝毫不会影响我们调用Web API。那么，问题来了，当你面对数不胜数的API接口的时候，你打算如何考虑这些问题？我的API地址应该配置在哪里？是存到Web.Config里还是存到数据库里？我调用API的时候，Token应该从哪里获取？是每次都获取还是获取了缓存起来？如果Token过期了我又该怎么办？这几乎是所有全部采用Web API进行微服务设计时都会遇到的问题。 此时，我们需要一种更优雅的方式，即Retrofit，它能让我们像调用一个普通方法一样调用一个Web API，这样，我们在调用方式上其实不会有太大的改变，因为Web API本质上是一种特殊的RPC。在.NET的世界里，我们有WebApiClient和Refit这样的轮子，我之前还专门为大家介绍过WebApiClient。这里就不再展示它的具体细节了，所谓点到为止，希望大家可以自己去发现这种美，对博主而言，如果在定义Service的时候，就考虑到这一点，或许我们可以实现更理想的效果，即，服务端和客户端是一套代码，我们写完一个接口以后，它就是Web API，而通过动态代理，它本身又会是客户端，此中乐趣，则不足为外人道也！ 本文小结又是漫长的一个夏天，下雨并不能让这座城市温柔起来。这篇博客延续了上一篇博客中关于动态Controller的设想，而借助于.NET Core框架提供的良好特性，它以一种更为简洁的方式被实现了，核心的内容有两个点，其一是ControllerFeatureProvider，它能决定MVC会不会把一个普通的类当做控制器。其二是IApplicationModelConvention接口，它能对全局的路由规则进行修改，以满足我们特殊的定制化需要。再此基础上，继续引入Swagger和WebApiClient两个轮子，来解决微服务构建中的API文档和API调用问题。写博客真的是一件辛苦的事情诶，好啦，今天这篇博客就先写到这里，我们下一篇博客再见，晚安！本文中涉及到的代码可以通过：https://github.com/qinyuanpei/DynamicWCFProxy/tree/master/DynamicWebApi.Core来做进一步的了解，以上！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"技巧","slug":"技巧","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E5%B7%A7/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"API","slug":"API","permalink":"https://qinyuanpei.github.io/tags/API/"},{"name":"Web","slug":"Web","permalink":"https://qinyuanpei.github.io/tags/Web/"}]},{"title":"长安十二时辰随想","date":"2019-07-22T11:17:23.000Z","path":"posts/1540537013/","text":"年少时未见长安，难以想象万国来朝的盛唐气象，心中最为仰慕的人物，是那个“好剑术、喜任侠“、二十五岁“仗剑去国、辞亲远游”的李白。人在年少轻狂的时候，容易因为一个人的豪迈不羁，而选择性地模糊一个时代的印象。于是，长安就蓦地变成了李太白大放异彩的舞台。印象里的长安，是一个可以让人吟咏“安能摧眉折腰事权贵，使我不得开心颜”的地方，是一个可以让“贵妃捧墨、力士脱靴”的地方，是一个“绣口一吐，就是半个盛唐”的地方。自此，喜欢上“大道如青天，我独不得出”，喜欢上“古来圣贤皆寂寞，唯有饮者留其名”，喜欢上“天生我才必有用，千金散尽还复来”，仿佛李白就是盛唐，而盛唐就是长安，若非如此，杨玉环便不会在极乐之宴上称赞李白的才华。 可当历史脉络逐渐清晰起来的时候，我们突然发现，原本我们以为最为意气风发的李白，那一年(开元18年，即公元730年)李白已经30岁了，就在那一年李白谒见宰相张说及一干长安名流，均无结果，直到他结识贺知章并被对方称之为“谪仙”， 引出一段“金龟换酒”的传奇佳话。这位谪仙人曾两度离开长安，第一次是感慨“行路难，归去来”，那一年李白38岁；第二次是供奉翰林期间遭玄宗“贬谪”，那一年李白43岁。所以，年少时以为的李白，是否是真实的李白？年少时以为的长安，是否是真实的长安？李白生平豪放，有诗的地方必有酒、有剑，一首《侠客行》更是金庸武侠小说中接近玄学的存在，可李白生平最快乐的时候，或许只有白帝城两岸猿啼知道了。 人们喜欢选择性地美化回忆，就像迪士尼重制的《狮子王》，我们曾以为木法沙和辛巴是正义的化身，而弑兄上位的刀疤则是邪恶的代表，其实用成人的眼光来看待这部电影，我们还真的找不出木法沙和辛巴的统治会比刀疤的统治好到哪里去的证据，这大概就是记忆本身的滤镜作用，长大了发现小时候常吃的熊毅武方便面，居然是陕西省出产的，而中萃方便面，则是江苏省出产的。当你未来的时光，有一小部分是和这两个地方有关，你不能不说，记忆真的是个奇妙的东西。《妖猫传》里绮丽璀璨的幻术表演，极力展现长安奢华的一面，虽然这一切都是活在两位主角的想象中，因为它想表达的是一种美的消逝和幻灭，此时的长安，其伟大和无与伦比体现在这三个符号上——空海代表的真理密法、李白代表的艺术创作、杨贵妃代表的绝对的美。 正如我们已无从想象，当年矗立在兴庆宫的花萼相辉楼到底是什么样子，于是导演将其安排在一个看起来像是个洞穴的地方。我们更无从得知，那一年的白居易到底怀着什么样的抱负来到长安，当他从已为陈迹的花萼相辉楼里捡起李白用过的笔的时候，是否真的如他想说想要开创一个新的时代，谱写一曲荡气回肠的长恨歌。有人说，玄宗兴建花萼相辉楼的时候，在周遭兴建了五座宅邸供诸王居住，逢宴请娱游更是宴请诸位兄弟一同前去，一改盛唐自玄武门之变以来手足相残的情形。可正如《长安十二时辰》里战战兢兢的太子李亨一般，一个对兄弟手足颇具温情的帝王，为何又能冤杀三个皇子在前？我们不得不说，历史极具迷惑性。 《妖猫传》开篇由玄宗驾崩引出，在经历了安史之乱以后，通过一只猫的视角，我们看到了在极尽繁华后满目苍凉。有人问，李白为何在吟咏《清平调》的时候泪流满面？也许以李白经天纬地的才华，他早就洞悉了帝王之爱的虚伪，早就看出了盛世之下的危机重重，早就明白了身为御用文人的悲哀，所谓盛世，或许仅仅是帝王权术操纵下的一场表演。可即使如此，李白依然愿意在洞悉这一切后去讴歌这种美，不论美本身多么的脆弱，至少这一刻它是真实存在的，就像罗曼罗兰说的那样：“这世界上只有一种真正的英雄主义，就是在看清生活之后，依然热爱生活”。 今天在路上遇到一位外地来的游客，询问我关于陕博、大雁塔和兵马俑的种种，可其实我和他一样，都不过是这座城市的过客。我有时候会不由地起，一千多年前的长安，是否和今天一样向世界敞开大门？《妖猫传》里遣唐的日本僧人空海，今天依然可以在青龙寺的简介中找到姓名，而透过张天爱的胡旋舞，或许可以看到那个胡汉相融、开放包容的长安。《长安十二时辰》里，有突厥狼卫，有胡椒胡饼，有波斯王子，有圣拜火教，有粟特大秦，有拢右拨换……几乎可以媲美世界中心。而一千多年后的今天，各种商业中心不再局限于东西两市，而兴庆宫、曲江池不再是皇家宫殿园林，长安一百零八坊的格局依稀可见，皇城北侧空荡荡的大明宫遗址，是否会听到来自玄武门的阵阵杀伐之声？ 《长安十二时辰》里的主角张小敬，曾经是万年县不良帅，长安以朱雀大街为界，朱雀大街以西为长安县，朱雀大街以东为万年县，实则取“长安万年”之意。剧中靖安吏们聚集在一起八卦朝廷，有一个人说自古以来哪里有万年的江山。不管历史上的李亨是否提出过对赋税和藩镇进行改革的提议，我们都知道安史之乱是唐朝由盛转衰的开始。据说马亲王这本书的灵感来自“刺客信条”，我本人同样是这部游戏的忠实粉丝，可当你真正想在长安寻找鸟瞰点并进行同步的时候，你会发现小雁塔顶端早已残损，攀爬这样的建筑物简直就是在碰瓷儿，而大雁塔的高度早已被周遭的大悦城超越，按照书中的设定，只要在大悦城的天台上增设武侯，不要说同步鸟瞰点，分分钟就会被弓弩手射中失去同步，因为据说大雁塔下面只有音乐喷泉，并没有安置干草堆…… 对于《长安十二时辰》这部网剧而言，剧中的崔器或许是无数想留在长安的人的一个缩影，没有过人的背景，智力和胆识有限，因为担负着兄长的希望和光耀门楣的使命，渴望建功立业、想抓住一切能抓住的机会努力向上爬，在长安这座城市获得一种归属感。崔器的人设并不讨喜，甚至从一出场就在扮演猪队友的角色，属于那种有点蠢但本质不坏的人，靖安司一役被编剧写死完全是剧情需要，总体来说，这种小人物的设定，只要不是又蠢又坏，总能因为贴近底层而引起更多人的共鸣。《妖猫传》里的主角白乐天初到长安时，诗人顾况开他玩笑说：“居大不易”。同样地，在《长安十二时辰》里，有到长安来干谒的岑参，有出身贫寒的元载，各自的选择不同，最终的结果不同。虽然选择比努力更重要，可你的能力总要能配得上你的野心。每个时代都有每个时代的困境，今天在西安讨生活的你我，和一千多年前的这些前辈们有什么不同呢？你的选择又是什么呢？ 在浩如烟海的茫茫历史中，太多的人和事，最终都会变得像雪泥鸿爪一般无迹可寻。对史学家而言，那是震惊寰宇的历史发现，可对更多像你和我一样的普通人而言，那不过偶然想起的经年旧事。我们回头看这些历史的时候，一如空海和白居易回头瞥见八重樱下的杨玉环，所谓“一切有为法，皆化作泡影”。《长安十二时辰》中塑造了张小敬这样一个“刺客”形象，可历史不过是姚汝能笔下轻描淡写的一句话。安国柱，一个身在长安的粟特人，即使娶了美艳的长安女子做妻子，依然想着努力工作好配得上她；徐宾，一个身在长安的靖安司主事，为了让大家更好得整理案牍，积极改良造纸技术，甚至到生命的最后一刻还在保护案牍；焦遂，一个身在长安的布衣，悬挂金鱼袋只为进宫喝酒，一句“长安，焦遂”豪气干云……有这些可爱可敬的人，我愿意相信，这一切都曾在这个城市发生过，而一千多年后的今天，我在长安，可我见了长安，便懂了长安么？是少年豪气作祟的“赵客缦胡缨，吴钩霜雪明”，还是一个快三十岁的中年大叔“为赋新词强说愁”呢……","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://qinyuanpei.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"长安","slug":"长安","permalink":"https://qinyuanpei.github.io/tags/%E9%95%BF%E5%AE%89/"},{"name":"长安十二时辰","slug":"长安十二时辰","permalink":"https://qinyuanpei.github.io/tags/%E9%95%BF%E5%AE%89%E5%8D%81%E4%BA%8C%E6%97%B6%E8%BE%B0/"}]},{"title":"使用ASP.NET Core和Hangfire实现HTTP异步化方案","date":"2019-07-04T08:56:28.000Z","path":"posts/1071063696/","text":"Hi，大家好，我是Payne，欢迎大家一如既往地关注我的博客。今天这篇博客里的故事背景，来自我工作中的一次业务对接，因为客户方提供的是长达上百行的XML，所以一度让更喜欢使用JSON的博主感到沮丧，我这里不是想讨论XML和JSON彼此的优缺点，而是我不明白AJAX里的X现在基本都被JSON替代了，为什么还有这么多的人坚持使用并友好的XML作为数据的交换协议呢？也许你会说，因为有这样或者那样等等的理由，就像SOA、ESB、SAP等等类似的技术在企业级用户依然大量流行一样，而这些正是“消费”XML的主力军。我真正想说的是，在对接这类接口时，我们会遇到一个异步化的HTTP协议场景，这里的异步和多线程、async/await没有直接关系，因为它描述的实际上是业务流程上的一种“异步”。 引子-想对XML说不我们知道，HTTP协议是一个典型的请求-响应模型，由调用方(Client)调用服务提供者(Server)提供的接口，在理想状态下，后者在处理完请求后会直接返回结果。可是当后者面对的是一个“耗时”任务时，这种方式的问题就立马凸显出来，此时调用者有两个选择：一直等对方返回直至超时(同步)、隔一会儿就看看对方是否处理完了(轮询)。这两种方式，相信大家都非常熟悉了，如果继续延伸下去，我们会联想到长/短轮询、SignalR、WebSocket。其实，更好的方式是，我们接收到一个“耗时”任务时，立即返回表明我们接收了任务，等任务执行完以后再通知调用者，这就是我们今天要说的HTTP异步化方案。因为对接过程中，客户采用的就是这种方案，ESB这类消息总线本身就提供了这种功能，可作为调用方的博主就非常难受啦，因为明明能“同步”地处理完的事情，现在全部要变成“异步”处理，就像一个习惯了async/await语法糖的人，突然间就要重新开始写APM风格的代码，宝宝心里苦啊，“异步”处理就异步处理嘛，可要按人家要求去返回上百行的XML，博主表示想死的心都有了好嘛…… 好了，吐槽归吐槽，吐槽完我们继续梳理下HTTP异步化的方案，这种方式在现实生活中还是相当普遍的，毕竟人类都是“异步”做事，譬如“等你哪天有空一起吃个饭”，测试同事对我说得最多的话就是，“等你这个Bug改完了同我说一声”，更不用说，JavaScript里典型的异步单线程的应用等等……实现“异步”的思路其实是非常多的，比如同样在JavaScript里流行的回调函数，比如通过一张中间表存起来，比如推送消息到消息队列里。在面向数据库编程的时候，我听到最多的话就是，没有什么问题是不能用一张中间表来解决的，如果一张不行那就用两张。项目上我是用Quartz+中间表的方式实现的，因为这是最为普通的方式。这里，我想和大家分享下，关于使用Hangfire来实现类似Quartz定时任务的相关内容，果然，我这次又做了一次标题党呢，希望大家会对今天的内容感兴趣。简单来说，我们会提供一个接口，调用方提供参数和回调地址，调用后通过Hangfire创建后台任务，等任务处理结束后，再通过回调地址返回结果给调用方，这就是所谓的HTTP异步化。 开箱即用的Hangfire我们项目上是使用Quartz来实现后台任务的，因为它采用了反射的方式来调用具体的Job，因此，它的任务调度和任务实现是耦合在同一个项目里的，常常出现单个Job引发整个系统卡顿的情况，尤其是是它的触发器，常常导致一个Job停都停不下来，直到后来才渐渐开始通过Web API来分离这两个部分。Quartz几乎没有一个自己的可视化界面，我们为此专门为它开发了一套UI。我这里要介绍的Hangfire，可以说它刚好可以作为Quartz的替代品，它是一个开箱即用的、轻量级的、开源后台任务系统，想想以前为Windows开发定时任务，只能通过定时器(Timer)来实现，尚不知道CRON为何物，而且只能用命令行那种拙劣的方式来安装/卸载，我至今都记得，测试同事问我，能不能不要每次都弹个黑窗口出来，这一起想起来还真是让人感慨啊。好了，下面我们开始今天的实践吧！首先，第一步自然是安装Hangfire啦，这里我们新建一个ASP.NET Core的Web API项目就好，然后通过NuGet依次安装以下库： 12Install-Package HangFireInstall-Package Hangfire.MySql.Core 这里我们选择了MySQL来实现任务的持久化，从官方的流程图中可以了解到，Hangfire有服务端、持久化存储和客户端三大核心部件组成，而持久化存储这块儿，除了官方默认的SQLServer(可以集成MSMQ)以外，还支持Redis、MongoDB等，Hangfire使用起来是非常简单哒，首先在Startup类的ConfigureServices()方法中注入Hangfire相关的服务，然后在Configure()方法中使用HangfireServer和UseHangfireDashboard即可： 12345678910111213141516171819public void ConfigureServices (IServiceCollection services) &#123; //为了简化说明，已忽略该方法中无关的代码 services.AddHangfire (x =&gt; x.UseStorage (new MySqlStorage (Configuration.GetConnectionString (\"Hangfire\"))) .UseFilter (new HttpJobFilter ()) .UseSerilogLogProvider () );&#125;public void Configure (IApplicationBuilder app, IHostingEnvironment env) &#123; //为了简化说明，已忽略该方法中无关的代码 app.UseHangfireServer (new BackgroundJobServerOptions () &#123; Queues = new string[] &#123; \"default\" &#125;, WorkerCount = 5, ServerName = \"default\", &#125;); app.UseHangfireDashboard (); app.ApplicationServices.GetService&lt;ILoggerFactory&gt; ().AddSerilog ();&#125; 注意到在配置持久化的部分，我们使用了一个数据库连接字符串Hangfire，它需要我们在appsettings.json中配置ConnectionStrings部分。这里我们为Hangfire设置了默认队列default、默认服务器default、并发数目为5。与此同时，我们开启了Hangfire中自带的Dashboard，可以通过这个界面来监控后台任务的执行情况。此时运行项目，输入以下地址：http://locahost:/hangfire，就会看到下面的画面，这说明Hangfire配置成功： Hangfire Dashboard Hangfire中默认支持四种类型的后台任务，他们分别是Fire-and-forget jobs、Delayed jobs、Recurring jobs和Continuations。严格来说，Fire-and-forget jobs和Delayed jobs并不能算后台任务，因为它们在执行一次后就会从队列中移除，属于一次性“消费”的任务，这两者的不同在于Delayed jobs可以在设定的时间上延迟执行。而Recurring jobs和Continuations则是周期性任务，任务在入队后可以按照固定的时间间隔去执行，周期性任务都是支持CRON表达式的，Continuations类似于Task中的ContinueWith()方法，可以对多个任务进行组合，我们现在的项目中开发了大量基于Quartz的Job，可当你试图把这些Job相互组合起来的时候，你就会觉得相当尴尬，因为后台任务做所的事情往往都是大同小异的。从官方文档中 ，我们会发现Hangfire的关键代码只有下面这四行代码，可以说是相当简洁啦！ 123456789101112131415161718//Fire-and-forget jobsvar jobId = BackgroundJob.Enqueue( () =&gt; Console.WriteLine(\"Fire-and-forget!\"));//Delayed jobsvar jobId = BackgroundJob.Schedule( () =&gt; Console.WriteLine(\"Delayed!\"), TimeSpan.FromDays(7));//Recurring jobsRecurringJob.AddOrUpdate( () =&gt; Console.WriteLine(\"Recurring!\"), Cron.Daily);//ContinuationsBackgroundJob.ContinueWith( jobId, () =&gt; Console.WriteLine(\"Continuation!\")); Hangfire除了这种偏函数式风格的用法以外，同样提供了泛型版本的用法，简而言之，泛型版本是自带依赖注入的版本。众所周知，稍微复杂点的功能，常常会依赖多个服务，比如后台任务常常需要给相关人员发邮件或者是消息，此时，Job的实现就会依赖MailService和MessageService。Hangfire内置了基于Autofac的IoC容器，因此，当我们使用泛型版本时，它可以自动地从容器中Resolve相应的类型出来。事实上，我们可以通过重写JobActivator来实现自己的依赖注入，譬如博主就喜欢Castle。下面是一个简单的例子： 1234567891011121314151617//Define a class depends on IDbContext &amp; IEmailServicepublic class EmailSender&#123; private IDbContext _dbContext; private IEmailService _emailService; public EmailSender() &#123; _dbContext = new DbContext(); _emailService = new EmailService(); &#125; // ...&#125;//When it is registered in Ioc ContainerBackgroundJob.Enqueue&lt;EmailSender&gt;(x =&gt; x.Send(\"Joe\", \"Hello!\")); 可扩展的HangfireOK，在对Hangfire有了一个初步的了解以后，我们再回到本文的题目，我们希望实现一个基于HTTP方式调用的HttpJob。因为我们不希望任务调度和具体任务放在一起，我们项目上采用Quartz来开发后台任务，它要求我们实现一个特定接口IbaseJob，最终任务调度时会通过反射来创建Job，就在刚刚过去的这周里，测试同事向我反馈了一个Bug，而罪魁祸首居然是因为某个DLL没有分发，所以，我希望实现一个基于HTTP方式调用的HttpJob，这既是为了将任务调度和具体任务分离，同时为了满足这篇文章开头描述的场景，得益于Hnagfire良好的扩展性，我们提供了一组Web API，代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788/// &lt;summary&gt;/// 添加一个任务到队列并立即执行/// &lt;/summary&gt;/// &lt;param name=\"jobDescriptor\"&gt;&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpPost (\"AddEnqueue\")]public JsonResult Enqueue (HttpJobDescriptor jobDescriptor) &#123; try &#123; var jobId = string.Empty; jobId = BackgroundJob.Enqueue (() =&gt; HttpJobExecutor.DoRequest (jobDescriptor)); return new JsonResult (new &#123; Flag = true, Message = $\"Job:#&#123;jobId&#125;-&#123;jobDescriptor.JobName&#125;已加入队列\" &#125;); &#125; catch (Exception ex) &#123; return new JsonResult (new &#123; Flag = false, Message = ex.Message &#125;); &#125;&#125;/// &lt;summary&gt;/// 添加一个延迟任务到队列/// &lt;/summary&gt;/// &lt;param name=\"jobDescriptor\"&gt;&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpPost (\"AddSchedule\")]public JsonResult Schedule ([FromBody] HttpJobDescriptor jobDescriptor) &#123; try &#123; var jobId = string.Empty; jobId = BackgroundJob.Schedule (() =&gt; HttpJobExecutor.DoRequest (jobDescriptor), TimeSpan.FromMinutes ((double) jobDescriptor.DelayInMinute)); return new JsonResult (new &#123; Flag = true, Message = $\"Job:#&#123;jobId&#125;-&#123;jobDescriptor.JobName&#125;已加入队列\" &#125;); &#125; catch (Exception ex) &#123; return new JsonResult (new &#123; Flag = false, Message = ex.Message &#125;); &#125;&#125;/// &lt;summary&gt;/// 添加一个定时任务/// &lt;/summary&gt;/// &lt;param name=\"jobDestriptor\"&gt;&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpPost (\"AddRecurring\")]public JsonResult Recurring ([FromBody] HttpJobDescriptor jobDescriptor) &#123; try &#123; var jobId = string.Empty; RecurringJob.AddOrUpdate (jobDescriptor.JobName, () =&gt; HttpJobExecutor.DoRequest (jobDescriptor), jobDescriptor.Corn, TimeZoneInfo.Local); return new JsonResult (new &#123; Flag = true, Message = $\"Job:&#123;jobDescriptor.JobName&#125;已加入队列\" &#125;); &#125; catch (Exception ex) &#123; return new JsonResult (new &#123; Flag = false, Message = ex.Message &#125;); &#125;&#125;/// &lt;summary&gt;/// 删除一个定时任务/// &lt;/summary&gt;/// &lt;param name=\"jobName\"&gt;&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpDelete (\"DeleteRecurring\")]public JsonResult Delete (string jobName) &#123; try &#123; RecurringJob.RemoveIfExists (jobName); return new JsonResult (new &#123; Flag = true, Message = $\"Job:&#123;jobName&#125;已删除\" &#125;); &#125; catch (Exception ex) &#123; return new JsonResult (new &#123; Flag = false, Message = ex.Message &#125;); &#125;&#125;/// &lt;summary&gt;/// 触发一个定时任务/// &lt;/summary&gt;/// &lt;param name=\"jobName\"&gt;&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpGet (\"TriggerRecurring\")]public JsonResult Trigger (string jobName) &#123; try &#123; RecurringJob.Trigger (jobName); return new JsonResult (new &#123; Flag = true, Message = $\"Job:&#123;jobName&#125;已触发执行\" &#125;); &#125; catch (Exception ex) &#123; return new JsonResult (new &#123; Flag = false, Message = ex.Message &#125;); &#125;&#125;/// &lt;summary&gt;/// 健康检查/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;[HttpGet (\"HealthCheck\")]public IActionResult HealthCheck () &#123; var serviceUrl = Request.Host; return new JsonResult (new &#123; Flag = true, Message = \"All is Well!\", ServiceUrl = serviceUrl, CurrentTime = DateTime.Now &#125;);&#125; 你可以注意到，这里用到其实还是四种后台任务，在此基础上增加了删除Job和触发Job的接口，尤其是触发Job执行的接口，可以弥补Quartz的不足，很多时候，我们希望别人调了接口后触发后台任务，甚至希望在编写Job的过程中使用依赖注入，因为种种原因，实施起来总感觉有点碍手碍脚。这里我们定义了一个HttpJobExecutor的类，顾名思义，它是执行Http请求的一个类，说来惭愧，我写作这篇博客时，是一边看文档一边写代码的，所以，等我实现了这里的HttpJobExecutor的时候，我忽然发现文档中关于依赖注入的内容，简直相见恨晚啊。这里直接给出它的实现，我要再一次安利RestSharp这个库，比HttpWebRequest、HttpClient这两套官方的API要好用许多，可还是有人喜欢一遍又一遍地封装啊，话说自从我们把WCF换成Web API后，看着相关同事在Git上的折腾历史，果然还是回到了写Http Client的老路上来，话说在纠结是手写代理还是动态代理的时候，Retrofit了解下啊！ 123456789101112131415[HttpJobFilter]public static void DoRequest (HttpJobDescriptor jobDestriptor) &#123; var client = new RestClient (jobDestriptor.HttpUrl); var httpMethod = (object) Method.POST; if (!Enum.TryParse (typeof (Method), jobDestriptor.HttpMethod.ToUpper (), out httpMethod)) throw new Exception ($\"不支持的HTTP动词：&#123;jobDestriptor.HttpMethod&#125;\"); var request = new RestRequest ((Method) httpMethod); if (jobDestriptor.JobParameter != null) &#123; var json = JsonConvert.SerializeObject (jobDestriptor.JobParameter); request.AddParameter (\"application/json\", json, ParameterType.RequestBody); &#125; var response = client.Execute (request); if (response.StatusCode != HttpStatusCode.OK) throw new Exception ($\"调用接口&#123;jobDestriptor.HttpUrl&#125;失败，接口返回：&#123;response.Content&#125;\");&#125; 在这里，我们以HealthCheck这个接口为例，来展示HttpJob是如何工作的。顾名思义，这是一个负责健康检查的接口。我们现在通过Postman来触发健康检查这个后台任务。在这里，该接口是一个GET请求： 通过Postman创建后台任务 接下来，我们我们就会在Hangfire的Dashborad中找到对应的记录，因为这是一个Fire &amp; Forget类型的任务，因此我们几乎看不到中间的过程，它就已经执行结束啦。我们可以在Dashboard中找到对应的任务，然后了解它的具体执行情况。值得一提的是，Hangfire自带了重试机制，对于执行失败的任务，我们可以重试栏目下看到，这里是其中一条任务的执行记录。可以注意到，Hangfire会把每个Job的参数序列化为JSON并持久化起来，仔细对照的话，你会发现，它和我们在Postman中传入的参数是完全一样的！ Hangfire中Job执行详情查看 在执行Job的过程中，我们可能会希望记录Job执行过程中的日志。这个时候，Hangfire强大的扩展性再次我们提供了这种可能性。注意到在HttpJobExecutor类上有一个 [HttpJobFilter]的标记，显然这是由Hangfire提供的一个过滤器，博主在这个过滤器中对Job的ID、状态等做了记录，因为在整个项目中博主已经配置了Serilog作为Hangfire的LogProvider，所以，我们可以在过滤器中使用Serilog来记录日志，不过博主个人感觉这个Filtre稍显鸡肋，这里还是给出代码片段吧！ 123456789101112131415161718192021222324public class HttpJobFilter : JobFilterAttribute, IApplyStateFilter &#123; private static readonly ILog Logger = LogProvider.GetCurrentClassLogger (); public void OnStateApplied (ApplyStateContext context, IWriteOnlyTransaction transaction) &#123; if (context.NewState is FailedState) &#123; var failedState = context.NewState as FailedState; if (failedState != null) &#123; Logger.ErrorException ( String.Format (\"Background Job #&#123;0&#125; 执行失败。\", context.BackgroundJob.Id), failedState.Exception); &#125; &#125; else &#123; Logger.InfoFormat ( \"当前执行的Job为：#&#123;0&#125;, 状态为：&#123;1&#125;。\", context.BackgroundJob.Id, context.NewState.Name ); &#125; &#125; public void OnStateUnapplied (ApplyStateContext context, IWriteOnlyTransaction transaction) &#123; &#125;&#125; 为什么我说这个Filter有点鸡肋呢？因为你看下面的图就会明白了啊！ 使用Serilog记录日志 本文小结果然，我还是不得不承认，这又是一篇彻彻底底的”水文”啊,因为写着写着就发现自己变成了标题党。这篇文章总结下来其实只有两句话，一个不喜欢写XML报文的博主，如何与ERP、SAP、ESB里的XML报文斗智斗勇的故事，在这样一个背景下，为了满足对方的”异步”场景, 不得不引入一个后台任务系统来处理这些事情，其实，这个事情用消息队列、用Redis、甚至普通的中间表都能解决，可惜我写这篇文章的时候，是有一点个人化的情绪在里面的，这种情绪化导致的后果就是，可能我越来越难以控制一篇文章的写作走向啦，大概是写东西越来越困难，而又没有时间取吸收新的知识进来，这让我觉得自己的进步越来越少，Hangfire的有点说起来就是挺好用的，以上！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"Hangfire","slug":"Hangfire","permalink":"https://qinyuanpei.github.io/tags/Hangfire/"}]},{"title":"通过动态Controller实现从WCF到Web API的迁移.","date":"2019-06-08T13:48:41.000Z","path":"posts/4236649/","text":"在《又见AOP之基于RealProxy实现WCF动态代理》这篇文章中，我和大家分享了关于使用动态代理来简化WCF调用过程的相关内容，当时我试图解决的问题是，项目中大量通过T4生成甚至手动编写的“代理方法”。今天，我想和大家分享的是，如何通过动态的Controller来实现从WCF到Web API的迁移。为什么会有这个环节呢？因为我们希望把一个老项目逐步迁移到.NET Core上面，在这个过程中首当其冲的就是WCF，它在项目中主要承担着内部RPC的角色，因为.NET Core目前尚未提供针对WCF服务端的支持，因此面对项目中成百上千的WCF接口，我们必须通过Web API重新“包装”一次，区别于那些通过逐个API进行改造的方式，这里我们通过Castle动态生成Controller来实现从WCF到Web API的迁移。 如何对类和接口进行组合首先，我们来思考这样一个问题，假设现在有一个类BaseClass、一个接口IBaseService及其实现类BaseService，我们有没有什么办法，可以让这个类和接口组合起来呢？联系面向对象编程的相关知识，我们应该可以想到最常见的两种方式，即BaseService继承BaseClass(或者反过来)、BaseClass实现IBaseService接口。考虑到语言本身是否支持多继承的因素，第二种方式可能会更具有适用性。可如果这个问题，就仅仅到这种程度，我相信大家一定会感到失望，因为这的确没有什么好说的。现在的问题是，假如BaseClass类、BaseService类都已经存在了，我们有没有什么思路，可以把它们组合到一个类中呢？这又和我们今天要讨论的内容有什么关系呢？ 好了，不卖关子啦，下面隆重请出Castle中的Dynamic Proxy，我们曾经介绍过Castle中的动态代理，它可以为指定的类和接口创建对应的代理类，除此以外，它提供了一种称为AdditionalInterfaces的接口，这个接口可以在某个代理对象上“组合”一个或者多个接口，换句话说，代理对象本身包含被代理对象的全部功能，同时又可以包含某个接口的全部功能，这样就实现了一个类和一个接口的组合。为什么我们会需要这样一个功能呢？因为假如我们可以把一个ApiController类和指定的接口类如CalculatorService进行组合，在某种程度上，CalculatorService就变成了一个ApiController，这样就实现了我们的目标的第一步，即动态生成一个ApiController。与此同时，它会包含我们现有的全部功能，为了方便大家理解，我们从下面这个简单的例子开始： 12345678910111213141516171819202122232425262728293031323334353637383940414243/// &lt;summary&gt; /// IEchoService定义 /// &lt;/summary&gt; public interface IEchoService &#123; void Echo (string receiver); &#125; /// &lt;summary&gt; /// IEchoServicee实现 /// &lt;/summary&gt; public class EchoService : IEchoService &#123; public void Echo (string receiver) &#123; Console.WriteLine ($\"Hi，&#123;receiver&#125;\"); &#125; &#125; /// &lt;summary&gt; /// 空类EmptyClass /// &lt;/summary&gt; public class EmptyClass &#123; &#125; public class EchoInterceptor : IInterceptor &#123; private IEchoService _realObject; public EchoInterceptor (IEchoService realObject) &#123; _realObject = realObject; &#125; public void Intercept (IInvocation invocation) &#123; invocation.Method.Invoke (_realObject, invocation.Arguments); &#125; &#125; var container = new WindsorContainer (); container.Register ( Component.For&lt;EchoService, IEchoService&gt;(), Component.For (typeof (EchoInterceptor)).LifestyleTransient(), Component.For (typeof (EmptyClass)).Proxy.AdditionalInterfaces (typeof(IEchoService)) .Interceptors (typeof (EchoInterceptor)).LifestyleTransient() ); var emptyClass = container.Resolve&lt;EmptyClass&gt; (); var methodInfo = emptyClass.GetType().GetMethod (\"Echo\"); methodInfo.Invoke (emptyClass, new object[] &#123; \"Dynamic WebApi\" &#125;); 此时，我们会发现通过Castle动态生成的代理类，同时具备了类和接口的功能。 通过Castle实现类和接口的组合功能 重温ASP.NET MVC原理OK，通过第一个例子，我们已经达到了第一个目的。接下来，顺着这个思路，我们不妨想象一下，如果把这个BaseClass换成BaseController会怎么样呢？因为在一个OO的语言里，一切都是Class，所以，Web开发中的Controller同样不会脱离这个体系。不过，在这之前，我们需要复习下ASP.NET MVC的原理，为什么要说这个呢？因为接下来的内容，都和它有重大的关联，我们实际上是自己实现了ASP.NET MVC中几个关键的环节，所以，在博主看来，这部分内容是非常重要的，这几乎是这篇文章中实现的最细节部分，因为第一个目标，说句实话，Castle帮我们简化到了只有4行代码。 一张图了解MVC 通常来讲，当我们在MVC中接收到一个Url请求后，这个请求会被UrlRoutingModule拦截。此时，请求的上下文HttpContext会被封装到HttpContextWrapper对象中。而根据当前请求的HttpContext，则可以提取出符合当前Url的路由对象RouteData，它会被进一步封装为RequestContext对象。接下来，从RequestContext对象中获取RouteData，它对应一个RouteHandler，是IHttpHandler的一个实现类。对于MVC而言，则对应MvcHandler。通过调用MvcHandler，对应的Controller会被反射激活，进而调用具体的Action。以上就是整个MVC请求的过程描述，可以看出最关键的两个组件是UrlRoutingModule和MvcHandler，前者的作用是解析Controller和Action名称，后者的作用则是根据Controller名称去反射调用具体的Action，大家可以通过上面的图来理解这个过程。 在这里，其实我们只需要关注第二部分:-D，即MvcHandler，因为我们会在默认路由的基础上，增加一个自定义路由来“标记”这些动态的Controller，所以，我们集中关注MvcHandler这部分即可，虽然这里提到它会根据Controller的名称来反射激活相应的Controller实例、调用具体的Action，但这仅仅是宏观上的一种认识。我们来看一下，它具体是怎么反射出Controller以及调用Action的。 IControllerFactory接口第一个关键的组件是IControllerFactory接口，顾名思义，它是作用是创建Controller，可实际上，这个组件除了完成创建Controller的工作以外，还会涉及到Controller类型的解析、Controller实例激活、Controller实例释放、会话状态行为选项获取等多个功能。这里有一个激活的过程，我们可以将其理解为Controller的初始化，因为Controller在使用的过程中往往会通过IoC容器来注入相关服务，所以，你可以理解为在构造Controller的过程中，我们需要一个IoC容器来完成依赖注入相关的事情，微软默认提供了一个DefaultControllerFactory的实现，它内部是通过IHttpControllerActivator接口来完成依赖注入的，而这恰恰是我们要关注的第二个组件。 IHttpControllerActivator接口老实说，通过自定义IHttpControllerActivator的方式实现依赖注入的方式并不常见，因为更一般的情况是，大家在Global.asax里初始化像Unity、Autofac等等类似的容器，然后在Controller里通过容器去Resolve一个服务出来，对于IHttpControllerActivator接口而言，它只有一个Create()方法，在这篇文章中，我们是通过Castle这个容器来实现依赖注入的，所以，你大概可以想象出它的过程，首先把所有动态生成的Controller全部注入到Ioc容器中，然后再根据传入的类型获取对应Controller的实例。在本文中，我们重写了默认的HttpControllerActivator，这里主要指Create()方法，因为我们希望实现的效果是，动态的Controller全部从Castle容器中获取，而静态的Controller依然按照微软的设计来获取。 IHttpControllerSelector接口OK，现在有了Controller以后，我们怎么让MVC路由到正确的Controller上面去呢？这时候，必然需要有人来解析路由啊，这就是第三个组件——IHttpControllerSelector。这又是一个顾名思义的接口，充分说明命名是件多么重要的事情。在这里我们重写了SelectController()方法，当路由信息中存在ServiceName和ActionName时，就去检查容器中是否存在对应的Controller，如果存在就返回一个HttpControllerDescriptor，这是一个用以描述控制器上下文信息的类型。反之，会调用默认的base.SelectController()方法，这样做还是为了兼容微软原来的设计，因为我们不希望在引入动态Controller后，导致普通的Controller无法正常工作。 IhttpActionSelector接口同理，我们还需要告诉MvcHandler，它应该调用哪个方法，这时候我们需要IHttpActionSelector，因为从路由信息中我们可以提取到ActionName参数，因此，通过通过typeof(Controller).GetMethod(ActionName)，就可以获得对应ActionName对应的方法，熟悉反射的朋友应该都知道，它会返回MethodInfo这个类型，实际上IHttpActionSelector所做的事情，就是把MethodInfo传给MvcHandler，因为此时只要通过反射调用这个方法即可，Controller的实例在上一步就创建好了，而调用方法所需要的参数，则被存储在当前请求的上下文HttpContext里面，至此万事具备！我们要做的，就是顺着这些思路去实现以上组件。 关键组件的自定义实现OK，下面我们来看看如何针对这些组件， 来分别实现我们的自定义组件，实现这些自定义组件并对MVC中的默认组件进行替换，这就是我们这篇文章中实现动态Controller的一个基本原理。 DynamicControllerActivatorDynamicControllerActivator 实现了IHttpControllerActivator接口，这里我们通过单例模式获得了DynamicHttpControllerManager对象的一个实例，其内部封装了Castle的容器接口IWindsorContainer，所以，在这里我们直接通过controllerType从容器中Resolve对应的Controller即可，而默认情况下，所有的Controller都实现了IHttpController接口，所以，这一步我们需要做一个显示的类型转换，后面我们会通过它替换微软默认的实现，这样，当一个请求被发送过来的时候，我们实际上是从这个自定义容器中获取对应Controller的实例。 1234567public class DynamicHttpControllerActivtor : IHttpControllerActivator&#123; public IHttpController Create(HttpRequestMessage request, HttpControllerDescriptor controllerDescriptor, Type controllerType) &#123; return (IHttpController)DynamicHttpControllerManager.GetInstance().Resolve(controllerType); &#125;&#125; DynamicHttpControllerSelector如果说DynamicControllerActivator 是真正实现控制器的“激活”部分，那么在此之前，我们需要实现控制器的“筛选”部分，换言之，一个请求被发送过来的时候，到底应该用哪一个Controller去处理这个请求呢？所以，我们来看看DynamicHttpControllerSelector这个组件是如何实现的，这里我们重写SelectController()这个方法来完成控制器的“筛选”部分的工作。可以注意到，我们首先会判断路由信息中是否存在ServiceName和ActionName这两个值，因为对于动态的Controller，我们默认使用的路由模板是services/{ServiceName}/{ActionName}，这里使用services前缀是为了区别于微软默认的api前缀，当然，强迫症的你同样可以使用相同的前缀。 接下来，我们会判断ServiceName是否在容器中注册过，如果注册了就从容器里取出对应的服务，并构造DynamicHttpControllerDescriptor对象，否则调用父类方法按微软默认实现去处理。那么，这个DynamicHttpControllerDescriptor对象，又是何方神圣呢？从名称上我们大概可以了解，这应该是一个对控制器相关信息进行描述的类型，它继承了HttpControllerDescriptor这个父类，目前没有任何扩展性的实现。对于DynamicHttpControllerDescriptor，它最重要的参数是构造函数中第三个参数，即 controllerType，因为DynamicControllerActivator 实际上就是根据它来工作的。 123456789101112131415161718192021222324252627282930313233343536373839404142public class DynamicHttpControllerSelector: DefaultHttpControllerSelector&#123; private HttpConfiguration _configuration; /// &lt;summary&gt; /// 构造函数 /// &lt;/summary&gt; /// &lt;param name=\"configuration\"&gt;&lt;/param&gt; public DynamicHttpControllerSelector(HttpConfiguration configuration) : base(configuration) &#123; _configuration = configuration; &#125; public override HttpControllerDescriptor SelectController(HttpRequestMessage request) &#123; var routeData = request.GetRouteData().Values; if (routeData.ContainsKey(\"ServiceName\") &amp;&amp; routeData.ContainsKey(\"ActionName\")) &#123; var serviceName = routeData[\"ServiceName\"].ToString(); var actionName = routeData[\"ActionName\"].ToString(); if (DynamicHttpControllerManager.GetInstance().ContainsService(serviceName)) &#123; var controllerInfo = DynamicHttpControllerManager.GetInstance().GetControllerInfo(serviceName); var controller = DynamicHttpControllerManager.GetInstance().Resolve(serviceName); if (controller == null) return base.SelectController(request); var controllerDescriptor = new DynamicHttpControllerDescriptor(_configuration, serviceName, controllerInfo.ControllerType); controllerDescriptor.Properties[\"ServiceName\"] = serviceName; controllerDescriptor.Properties[\"ActionName\"] = actionName; controllerDescriptor.Properties[\"IsDynamicController\"] = true; controllerDescriptor.Properties[\"ServiceType\"] = controllerInfo.ServiceType; controllerDescriptor.Properties[\"ControllerType\"] = controller.GetType(); return controllerDescriptor; &#125; &#125; return base.SelectController(request); &#125;&#125; DynamicHttpActionSelector既然通过路由中的ServiceName可以对Controller进行“筛选”，那么，我们自然可以通过路由中的ActionName来对Action进行筛选”。Action是控制器中的概念，对应一般的接口或者类，我们称之为方法，因此，DynamicHttpActionSelector在这里实现针对Action的筛选，它继承ApiControllerActionSelector类并重写了SelectAction()方法，下面给出具体的实现： 12345678910111213141516171819202122public class DynamicHttpActionSelector : ApiControllerActionSelector&#123; public override HttpActionDescriptor SelectAction(HttpControllerContext controllerContext) &#123; var isDynamicController = controllerContext.ControllerDescriptor.Properties.ContainsKey(\"IsDynamicController\"); if (isDynamicController) &#123; var controllerType = new object(); if (controllerContext.ControllerDescriptor.Properties.TryGetValue(\"ControllerType\", out controllerType)) &#123; var actionName = controllerContext.ControllerDescriptor.Properties[\"ActionName\"].ToString(); var methodInfo = ((Type)controllerType).GetMethod(actionName); if (methodInfo == null) return base.SelectAction(controllerContext); return new DynamicHttpActionDescriptor(controllerContext.ControllerDescriptor, methodInfo); &#125; &#125; return base.SelectAction(controllerContext); &#125;&#125; 和筛选Controller的过程类似，首先我们会判断这是不是一个动态的Controller，请注意在DynamicHttpControllerSelector中，我们为ControllerDescriptor添加了大量的Properties，这些Properties可以在这里继续使用。显然，我们只需要关注动态的Controller即可，如果可以通过ActionName找到对应的MethodInfo，那就说明当前Controller中存在指定的Action，反之则需要调用父类方法按微软默认的实现去处理。其实，这里不好的一点就是，我们的通过反射获取MethodInfo时，需要传入ActionName即方法的名字，而方法的名字是区分大小写的，这会导致我们的URL必须区分大小写，这不太符合RESTful API风格。同样额，这里定义了一个类型DynamicHttpActionDescriptor，它继承自ReflectedHttpActionDescriptor，它需要传入MethodInfo，这样MVC就知道应该去调用控制器的哪一个方法了。 容器注册及服务替换在我们实际的业务系统中，存在着大量的WCF接口，它们都是通过ServiceHost这种方式来托管，然后在调用端通过代理类的方式来相互调用，因此把WCF迁移到Web API上，被抛弃的仅仅是这些.svc的文件，而这些WCF接口依然可以继续使用。在之前的文章中，我们用Castle的Dynamic Proxy来代替各种手写的代理类，在这篇文章中我们继续沿用ICalculator这个接口示例，它包含着最为简单加减乘除四个方法，那么，我们应该怎样把这个接口变成一个Web API呢？这就是所谓的容器注册和服务替换啦！首先我们来注册ICalculator这个服务，它的代码只有一行： 1DynamicHttpControllerManager.GetInstance().RegisterType&lt;CalculatorService, ICalculator&gt;(); 这是一个典型的依赖注入，其中CalculatorService是ICalculator的实现类，它到底做了什么呢？我们来看看本质： 123456789101112131415public void RegisterType&lt;TImplement, TInterface&gt;(string serviceName = \"\")&#123; if (string.IsNullOrEmpty(serviceName)) serviceName = GetServiceName&lt;TImplement&gt;(); _container.Register( Component.For(typeof(TImplement), typeof(TInterface)), Component.For&lt;DynamicApiInterceptor&lt;TInterface&gt;&gt;().LifestyleTransient(), Component.For&lt;BaseController&lt;TInterface&gt;&gt;().Proxy.AdditionalInterfaces(typeof(TInterface)) .Interceptors&lt;DynamicApiInterceptor&lt;TInterface&gt;&gt;().LifestyleTransient() .Named(serviceName) ); _controllerInfoList.Add(serviceName, new DynamicControllerInfo(typeof(TInterface)));&#125; 有没有觉得这段代码非常熟悉，实际上这就是我们这篇文章最开始提出的问题：怎么样对一个类和接口进行租户。一开始我们是用一个最普通的类、一个最普通的接口来演示这种可能性，而这里我们不过将其推广到一个特殊的场景，如果这个类是一个继承了ApiController的BaseController呢？这是一个由一般到特殊的过程。如你所见，内部的确使用了Castle的容器来处理依赖注入，而_controllerInfoList则存储了Controller相关的信息，方便我们在整个流程中随时获取这些信息。完成容器注册以后，我们就可以着手对MVC中的默认组件进行替换工作啦，我个人建议，替换工作放在整个Global.asax的最前面： 1234567var configuration = GlobalConfiguration.Configuration;var dynamicControllerSelector = new DynamicHttpControllerSelector(configuration);var dynamicHttpControllerActivtor = new DynamicHttpControllerActivtor();var dynamicActionSelector = new DynamicHttpActionSelector();GlobalConfiguration.Configuration.Services.Replace(typeof(IHttpControllerSelector), dynamicControllerSelector);GlobalConfiguration.Configuration.Services.Replace(typeof(IHttpActionSelector), dynamicActionSelector);GlobalConfiguration.Configuration.Services.Replace(typeof(IHttpControllerActivator), dynamicHttpControllerActivtor); 假设现在我希望调用ICalcultor接口中的Add方法，理论上它的URL应该是http://localhost/Service/Calculator/Add，因为截至到目前为止，所有的接口默认都是通过Get来访问的，下面是整个流程第一次跑通时的截图： 迁移后的ICalculator接口 接口迁移后的二三事现在，我们完成了ICalculator接口的改造，它从一个WCF服务变成了一个Web API，而在这个过程中，我们发现一点点问题。首先，Web API中的URL是不区分大小写的，而我们这里的ServiceName、ActionName都是严格区分大小写的。其次，接口方法中的out、ref、params等关键字不适用于Web API语境，需要进一步对接口进行改造。再者，Web API需要区分GET、POST、PUT、DELETE等动词，返回值需要统一调整为JSON格式。最后，完成改造的动态API需要通过RestSharp或者HttpClient等HTTP客户端来调用，以替换原有的WCF代理方法。这里简单对后面这两个问题做下说明，因为前两个问题，都是历史遗留问题啦，哈哈😄。 HTTP动词支持为了让接口支持不同的HTTP动词，我们需要对整个设计进行进一步优化。为什么我会把这件事情看得如此重要呢？因为在我看来，RESTful风格的API大概会有这样几种级别，第一种级别指仅仅使用了HTTP协议来设计API，第二种级别是在API设计中引入资源的概念，第三种级别是合理地使用HTTP动词如GET、POST、PUT等，第四种级别是使用HATEOSA来返回用户接下来可能的意图。可惜在实际的应用种，能做到第二种级别的都相当不容易啦。比如某接口不支持GET操作，原因是它需要附加token在Body中，因此在改造接口的过程中，哪怕参数是最简单的值类型，它还是必须要用POST方式来请求。可其实这种问题，如果把token附加在HTTP首部中，或者干脆就使用标准的Authorizatin字段完全就能解决啊。为了让这个方案更完美一点，我们对DynamicHttpActionDescriptor进行改造，重写它的SupportedHttpMethods属性： 1234567891011121314151617181920212223var isDynamicController = controllerDescriptor.Properties.ContainsKey(\"IsDynamicController\");if (isDynamicController)&#123; var serviceType = controllerDescriptor.Properties[\"ServiceType\"]; var httpVerbAttributes = ((Type)serviceType).GetMethod(methodInfo.Name).GetCustomAttributes&lt;Attribute&gt;() .Where(t =&gt; typeof(IActionHttpMethodProvider).IsAssignableFrom(t.GetType())) .ToList(); if (httpVerbAttributes.Any()) &#123; //根据路由来获取Http动词 if (httpVerbAttributes.Count &gt; 1) throw new Exception($\"Multiple http verb matched in method &#123;methodInfo.Name&#125; of &#123;((Type)serviceType).Name&#125;\"); _httpVerbs = GetHttpVerbByRoute(httpVerbAttributes); &#125; else &#123; //根据方法名称获取Http动词 _httpVerbs = GetHttpVerbByMethod(methodInfo); &#125; &#125;&#125; 其原理说起来并不复杂，检查方法上是否有HTTPGet、HttpPost、HttpPut等标签，如果存在，则添加相应的HTTP动词到_httpVerbs集合中；如果不存在，则根据方法的名字来构建相应的HTTP动词。譬如以Add、Create等开头的方法对应POST请求，以Get开头的方法对应GET请求，以Update开头的方法对应PUT请求，以Delete开头的方法对应DELETE请求等。最终，我们只需要把_httpVerbs作为SupportedHttpMethods属性的返回值即可。 接口返回值优化通常在编写控制器的时候，我们会使用JSON作为接口的返回值，这是因为JSON在信息冗余度上相比XML更低，而且JSON和JavaScript有着密不可分的联系，所以使用JSON作为返回值会流行起来一点都不奇怪。我们知道，WCF是可以实现Web Service这种所谓的SOAP架构的，而WebService本质上是使用XML进行通信的HTTP，在调用WCF接口的时候，接口的参数、返回值都会被序列化为XML。平时我们手写Controller的时候，通常是在Controller层调用一层薄薄的Service层，然后对结果进行封装，使其成为对前端更友好的数据类型，可当我们调用动态的Controller时，其接口的返回值是在接口中定义好的，我们不可能去修改已经在使用中的Service定义。 虽然微软的Web API中可以自动对返回值进行序列化，参考最经典的ValuesController，它是微软对RESTful风格的一种标准实现，具体表现为Get()、Post()、Put()、Delete()四个方法，分别对应GTE、POST()、PUT()、DELETE(四个HTTP动词，这就是所谓的约定大于配置，并且这些方法的返回值都不是ActionResult或者IHttpActionResult，但整个框架依然可以帮我们将其序列化为JSON，这一切是为什么呢？其实，我们只需要重写DynamicHttpActionDescriptor的ReturnType属性，同时重写DynamicHttpActionDescriptor的ExecuteAsync()方法就可以达到这一目的： 123456789101112131415161718192021222324252627282930313233public override Type ReturnType&#123; get &#123; return typeof(DynamicApiResult); &#125;&#125;public override Task&lt;object&gt; ExecuteAsync(HttpControllerContext controllerContext, IDictionary&lt;string, object&gt; arguments, CancellationToken cancellationToken)&#123; return base.ExecuteAsync(controllerContext, arguments, cancellationToken) .ContinueWith(task =&gt; &#123; try &#123; if (task.Result == null) &#123; return new DynamicApiResult() &#123; Flag = true &#125;; &#125; if (task.Result is DynamicApiResult) &#123; return task.Result; &#125; return new DynamicApiResult() &#123; Flag = true, Result = task.Result &#125;; &#125; catch (AggregateException ex) &#123; throw ex; &#125; &#125;);&#125; 从代码中大家大致可以猜出DynamicApiResult的结构了，它包含三个属性：Flag、Msg、Result。这是一个最常见的Web API的返回值封装，即通过Flag判断方法是否调用成功，通过Msg来返回异常信息，通过Result来返回具体的返回值。最近对接某公司的API接口的时候，发现一个非常奇葩的现象，一般没有返回值可以返回null或者空字符串，可这家公司居然返回的是”无数据”，你以为这是放在Msg里的吗？不，人家是放在Result里的。对此，我只能说，互联网发展到2019年了，那些年野蛮生长留下的坑却还一直都在。好了，现在我们来看看接口调用的结果，喏，这次是不是感觉顺眼多啦！ 优化后的ICalculator接口返回值 POCOController其实，这篇文章写到这里就已经结束啦，因为对于一般的ASP.NET项目，这篇文章里所分享这些内容，基本上可以实现我们最初的目标，即把老系统中的WCF接口迁移到Web API上，从长远的角度来看，这是为了后续迁移到.NET Core上做准备，其实不单单是WCF，任何的接口、服务都可以顺着这种思路去做扩展，手写Controller虽然是最容易上手的实践方式，可随着业务的不断推进，无一例外地出现接口爆炸的现象，在没有注册中心的情况下，业务系统间互相调对方的Web API简直叫一个混乱，你能想象一家公司里的不同业务系统，居然没有通用的网关去做接口的授权吗？反正我最近是见识到了某友的混乱。这篇文章中的思路，其实是参考了Abp这个框架中的DynamicApiController这一功能，可我们大多数人都没怎么好好用过这项技术，.NET Core就来了，Abp官方着手开发的Abp vNext就是基于.NET Core的下一代Abp框架，不知道届时会不会有这个功能。 既然说到了,NET Core，那么就不可避免地要说到.NET Core里的POCOController。因为ASP.NET与ASP.NET Core的机制完全不同，所以，我们在这篇文章里的实现是无法直接用到ASP,NET Core里的，这听起来有点遗憾是不是，就在我写这篇博客的前几天，我看到有人把Abp的DynamicApiController移植到了.NET Core下面，还是熟悉的味道，但内部的原理已然大为不同。具体来讲, .NET Core下的POCOController特性会让这一切更简单。所谓POCOController，就是指任意一个类都可以是Controller。我们都知道在ASP.NET下，要写一个Web API必须继承ApiController，就是说这个类必须实现了IHttpController接口，就是因为有这个限制，所以，我们不得不通过Castle来动态生成一个Controller，既然现在ASP.NET Core里可以打破这一限制，那么实现起来自然会非常简单。限于这篇文章的篇幅(截至到这里已经将近6000余字)，我将在下一篇文章中和大家分享这一特性的相关内容。 本文小结在传统的ASP.NET项目向ASP.NET Core迁移的过程中，我们遇到的第一个阻力就是作为内部RPC使用的WCF。因此，收到上一篇文章基于Castle动态代理这一思路的影响，参考Abp框架中的DynamicApiController功能，我们分享了一种可以为任意接口动态生成Controller的思路，其核心原理是通过Castle中的AdditionalInterfaces功能，将指定接口和ApiController进行组合，使得一个普通的接口可以像Controller一样被调用。在这个过程中，我们回顾了ASP.NET MVC的基本原理，了解了MVC是如何根据路由筛选Controller、激活Controller和筛选Action，在此基础上，我们对微软的MVC进行了一次Hack，使用我们自定义的组件替换了微软的默认实现，从而可以让原来托管在ServiceHost上的接口，通过Web API来访问和调用。当然，这篇文章里没有实现自定义的路由、过滤器的支持，所谓抛砖引玉，Abp的代码本身在Github上就可以找到，大家如何对此感兴趣的话，可以做进一步的研究和扩展。我们实现了服务端的切换，这意味着在客户端同样需要一次切换，预知后事如何，请大家关注我的下一篇博客，以上就是我这篇博客的全部内容了，谢谢大家！ 参考文章 Castle中AdditionalInterfaces用法介绍 ABP源码分析三十五：ABP中动态WebAPI原理解析 https://github.com/FJQBT/ABP","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"RESTful","slug":"RESTful","permalink":"https://qinyuanpei.github.io/tags/RESTful/"},{"name":"WebApi","slug":"WebApi","permalink":"https://qinyuanpei.github.io/tags/WebApi/"},{"name":"动态代理","slug":"动态代理","permalink":"https://qinyuanpei.github.io/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"}]},{"title":"《Web API 的设计与开发》读书笔记","date":"2019-05-28T12:00:53.000Z","path":"posts/3677280829/","text":"设计优美的Web API：易于使用、便于更改、健壮性好、不怕公开 REST的两层含义： 指符合Fielding的REST架构风格的Web服务系统 指使用符合RPC风格的XML或JSON + HTTP接口的系统(不使用SOAP) 端点的基本设计： 短小便于输入的URI- 人可以读懂的URI 没有大小写混用的URI 修改方便的URI 不暴露服务端架构的URI 规则统一的URI HTTP方法和端点： GET获取资源 POST新增资源 PUT更新已有资源 DELETE删除资源 PATCH更新部分资源 查询参数和路径的使用区别 表示唯一资源时，放在路径中 当参数可以忽略时，放在查询参数中RESTful的设计级别 使用HTTP 引入资源的概念 引入HTTP动词 引入HATEOAS如何指定数据格式？ 查询参数：url?format=xml 扩展名：/url.json Accept头部字段让用户决定响应的内容 GraphQL通过状态码表示错误信息1xx：消息2xx：成功3xx：重定向4xx：客户端原因造成的错误5xx：服务端原因造成的错误缓存与HTTP协议规范RFC7234：过期模型/验证模型过期模型：Cache-Control/Expires验证模型：Last-Modified/ETagVary首部：指定缓存单位Conent-Type/Accept：指定媒体类型 API版本控制 在URI中嵌入版本号 在查询字符串中加入版本信息 通过媒体类型指定版本API安全问题 推荐使用HTTPS XSS/XSRF注入漏洞 返回正确的数据格式 使用安全相关首部 采用KVS实现访问限制提供API文档 API Blueprint API Console/Apigee 提供SDK","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://qinyuanpei.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Web API","slug":"Web-API","permalink":"https://qinyuanpei.github.io/tags/Web-API/"},{"name":"RSETful","slug":"RSETful","permalink":"https://qinyuanpei.github.io/tags/RSETful/"},{"name":"提纲","slug":"提纲","permalink":"https://qinyuanpei.github.io/tags/%E6%8F%90%E7%BA%B2/"}]},{"title":"又见AOP之基于RealProxy实现WCF动态代理","date":"2019-05-10T16:27:50.000Z","path":"posts/2954591764/","text":"最近一直在研究Mongodb和ElasticSearch之间同步数据的问题，苦于到目前为止，并没有取得任何实质性的进展。偶尔“趁得浮生半日闲暇”，看一看Web API设计方面的书籍，和前辈交流下项目中的历史遗留问题，最为直观的感受就是，这个世界上任何方案的最终落地，都经过理想和现实的无数次挣扎，比如我们希望迁移项目到.NET Core平台上，初步分析大概有将近1000多个无法兼容的地方，维持现状固然可以保证整个项目的稳定，可如果真到了不得不升级的地步，面临的问题可能会越来越多，所谓“凡事预则立，不预则废”，早一点准备总是好的。既然说到里历史问题，那么，今天这篇文章就来说一说，基于RealProxy实现WCF动态代理。 故事背景在我们的业务系统中，对内是使用WCF来进行相互通信的，而对外则是使用Web API来进行数据交换。关于RPC还是REST的争论由来已有，严格地来说，两者没有绝对的高下之分，从风格上而言，RPC倾向于让接口映射到一个方法上，而REST则倾向于让接口映射到一个资源上。从我们实际的使用情况来看，REST在系统中应用得并不是很完美，因为大多数情况下，我们实现的仅仅是HTTP+JSON这样一种协议组合，因此业务系统中存在着大量的WCF接口供系统内部调用。 内部服务调用示意图 最早的时候，是通过T4模板来生成针对某个接口的代理类，而代理类中通常封装了ChannelFactory的创建、释放等等WCF相关的代码，实际应用中还会对WCF接口的异常进行捕获、记录日志、统计调用时间等，因此早期的T4模板实际上承担了生成代理类的职责。虽然业务的不断推进，接口中加入的新方法越来越多，导致具体业务类中的代码越来越多，动辄出现单个文件中代码行数达3000行以上，与此同时，每当WCF接口中增加了新方法，就不得不在其相关的代理类中增加代理方法。坦白地讲，就是增加一个看起来差不多的方法，因为你依然要处理ChannelFactory的创建、释放、异常处理、日志记录等等的工作。 其实，WCF可以直接生成客户端代码，因为每个WCF的服务都可以以WebService服务的形式暴露出来，而只要是WebService，总可以通过WSDL生成一个代理类。不过这显然不利于团队间的协作，更不利于服务终结点配置的集中化，更失去了异常处理、日志记录等等这些“通用”工作的可能性。T4应该可以基于“工作”，可显然大家觉得手写比生成要来得更容易些，所以，这个故事最终演变成这样一个局面，我们不得不通过局部类(Partial Class)的方式来开辟新的类文件。 系统中充斥着大量类似的代码 那么，说了这么多，从一个历史遗留问题入手，它真正的痛点在哪里呢？在我看来，主要有两点：第一，是手写代理类的“此恨绵绵无绝期”，明明就是对接口的简单封装，看起来是增加一个代理方法，其实最多就是复制黏贴，因为代理方法的核心代码就是调用接口，而剩下的都是重复的“服务型”代码；第二，是异常处理、日志记录的“哀鸿遍野”，同核心代码交织在一起，一遍又一遍的“重复”，为什么不考虑让它统一地去处理呢？难道每个人都抄着同一段代码，这样就实现了某种意义上的复用吗？ RealProxy介绍既然像我这样懒惰的人，不愿意像别人一样手写代理类，那么我的思路又是什么呢？显然，从这篇文章的题目，你就可以看出，我这里要说的是动态代理，原来的代理类同样属于代理，它是在编译时期间生成了一个代理类，我们以为在调用这个代理类，可其实真正去工作的是ChannelFactory，这种方式称之为“静态代理”。如果你了解过设计模式，应该会知道相对应的代理模式，这里不再展开开来讲这这个设计模式，可以明确的是，动态代理就是在运行时期间动态创建一个代理对象的实例，它可以完全模拟被代理对象的行为，而我们的目的，就是要和手写的代理类永远地说再见！ 好了，下面隆重介绍本文的主角——RealProxy。相信大家一定听说过AOP，即所谓的面向切面编程。它可以让我们在某一个所针对的横切面编程，并讲这种功能应用到所有相同的横切面上。譬如对方法级别的横切面增加拦截器，那么所有的方法都可以在执行前后具备相同的逻辑，典型的如日志记录、指定操作前的检验等等。而RealProxy 类恰恰提供最基本的代理功能，它是一个抽象类，必须通过重写其 Invoke()方法并添加新功能来继承，该类位于System.Runtime.Remoting.Proxies 命名空间中，通过重写Invoke()方法，我们就可以在被代理对象调用前后插入相关逻辑，而通过GetTransparentProxy()方法，则可以返回实际的代理对象。所以，通过这个原理，我们就可以在运行时期间，动态创建出指定类型的实例。这里，我们从一个简单的例子来开始，以帮助大家更好的理解RealProxy。 123456789101112131415161718192021222324252627282930public interface ICalculator&#123; double Add(double n1, double n2); double Subtract(double n1, double n2); double Multiply(double n1, double n2); double Divide(double n1, double n2);&#125;public class CalculatorService : ICalculator&#123; public double Add(double n1, double n2) &#123; return n1 + n2; &#125; public double Subtract(double n1, double n2) &#123; return n1 - n2; &#125; public double Multiply(double n1, double n2) &#123; return n1 * n2; &#125; public double Divide(double n1, double n2) &#123; return n1 / n2; &#125;&#125; 首先，我们定义一个简单的接口ICalculator，它含有加、减、乘、除四种基本运算，我们希望记录每个方法调用的参数、结果和执行时间，因此通过RealProxy对现有类型CalculatorService进行代理，并动态地创建代理对象来供调用方使用，下面给出关键代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public class CalculatorServiceProxy : RealProxy &#123; private Server.Service.ICalculator _calculator; public CalculatorServiceProxy(Server.Service.ICalculator calculator) : base(typeof(Server.Service.ICalculator)) &#123; _calculator = calculator; &#125; public override IMessage Invoke(IMessage message) &#123; var methodCall = message as IMethodCallMessage; var methodInfo = methodCall.MethodBase as MethodInfo; var startTime = DateTime.Now; var serviceName = _calculator.GetType().Name; var methodName = methodInfo.Name; try &#123; Console.WriteLine(\"调用&#123;0&#125;服务的&#123;1&#125;方法开始...\", serviceName, methodName); var argsInfo = new Dictionary&lt;string, object&gt;(); for (int i = 0; i &lt; methodCall.ArgCount; i++) &#123; argsInfo.Add(methodCall.GetArgName(i), methodCall.Args[i]); &#125; Console.WriteLine(\"当前传入参数:&#123;0&#125;\", JsonConvert.SerializeObject(argsInfo)); var result = methodInfo.Invoke(_calculator, methodCall.InArgs); if (result != null) Console.WriteLine(\"当前返回值:&#123;0&#125;\", JsonConvert.SerializeObject(result)); return new ReturnMessage(result, null, 0, methodCall.LogicalCallContext, methodCall); &#125; catch (Exception ex) &#123; Console.WriteLine( \"调用&#123;0&#125;服务的&#123;1&#125;方法失败,失败原因：&#123;2&#125;\", serviceName, methodName, ex.Message ); throw ex; &#125; finally &#123; Console.WriteLine( \"调用&#123;0&#125;服务的&#123;1&#125;方法结束,共耗时&#123;2&#125;秒\", serviceName, methodName, DateTime.Now.Subtract(startTime).TotalSeconds ); Console.WriteLine(\"----------------------------------\"); &#125; &#125; &#125; 可以注意到，最核心的代码是在Invoke()方法中，在这里我们增加了我们想要的功能，但这些功能丝毫不会影响到CalculatorService，当我们通过构造函数给RealProxy传入被代理对象后，它就会对被代理对象的特定方法进行拦截，这里实际上就是加、减、乘、除四个方法。OK，到现在为止，这些都是我们的想像而已，具体我们实现执行结果来看。 123456var serviceProxy = new CalculatorServiceProxy(new CalculatorService());var calculator = (ICalculator)serviceProxy.GetTransparentProxy();calculator.Add(12, 24);calculator.Subtract(36, 10);calculator.Multiply(12, 35);calculator.Divide(36, 12); 现在，我们可以说，刚刚所说的一切都是真的，因为我们真的创建了一个ICalculator接口的实例，它真的记录了每个方法调用的参数、结果和执行时间。 RealPrxoy牛刀小试 WCF动态代理现在，我们来考虑WCF，WCF需要通过ChannelFactory来创建和释放，而这恰恰是代理类所做的事情，就像下面的代码一样，我们通常会把所有的WCF集中配置在一个地方，并通过构造Binding和终结点地址来创建一个WCF服务，在调用服务的过程中，会对调用时间、异常信息等进行记录，这其实和我举的第一个例子完全一致，那么我们能不能用RealProxy来实现这些功能呢？ 1234567891011121314151617181920212223242526public class ServiceInfo&lt;TService&gt;&#123; private readonly ChannelFactory _channelFactory; public ServiceInfo(ChannelFactory channelFactory) &#123; _channelFactory = channelFactory; &#125; public TService Service &#123; get; set; &#125; public void Close() &#123; if (_channelFactory != null) _channelFactory.Close(); &#125; &#125;private ServiceInfo&lt;TService&gt; FindService()&#123; ChannelFactory&lt;TService&gt; channelFactory = new ChannelFactory&lt;TService&gt;(_binding, _endpointAddress); var serviceInfo = new ServiceInfo&lt;TService&gt;(channelFactory); serviceInfo.Service = channelFactory.CreateChannel(); return serviceInfo;&#125; 顺着这样的思路，如果我们可以把ChannelFactory注入到RealProxy中，就可以在接口调用过程中记录相关信息，这样我们就可以关注调用本身，因为所有的我们不想写的代码，现在全部都由代理类接管了，更重要的是，所有通过这种方式调用的WCF服务，都可以以一种统一而简洁的方式去处理，永远不用担心因为某个人忘记写代理方法而出现问题，下面给出整个实现的关键代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960public class DynamicServiceProxy&lt;TService&gt; : RealProxy&#123; private readonly Binding _binding; private readonly EndpointAddress _endpointAddress; public DynamicServiceProxy(Binding binding, EndpointAddress endpointAddress) : base(typeof(TService)) &#123; _binding = binding; _endpointAddress = endpointAddress; &#125; public DynamicServiceProxy(Binding binding, string serviceUrl) : this(binding, new EndpointAddress(serviceUrl)) &#123; &#125; public override IMessage Invoke(IMessage message) &#123; var serviceInfo = FindService(); var methodCall = message as IMethodCallMessage; var methodInfo = methodCall.MethodBase as MethodInfo; var startTime = DateTime.Now; var serviceName = serviceInfo.Service.GetType().Name; var methodName = methodInfo.Name; try &#123; Console.WriteLine(\"RealProxy调用&#123;0&#125;服务&#123;1&#125;方法开始...\", serviceName, methodName); var argsInfo = new Dictionary&lt;string, object&gt;(); for (int i = 0; i &lt; methodCall.ArgCount; i++) &#123; argsInfo.Add(methodCall.GetArgName(i), methodCall.Args[i]); &#125; Console.WriteLine(\"RealProxy当前传入参数:&#123;0&#125;\", JsonConvert.SerializeObject(argsInfo)); var result = methodInfo.Invoke(serviceInfo.Service, methodCall.InArgs); if (result != null) Console.WriteLine(\"RealProxy当前返回值:&#123;0&#125;\", JsonConvert.SerializeObject(result)); return new ReturnMessage(result, null, 0, methodCall.LogicalCallContext, methodCall); &#125; catch (Exception ex) &#123; Console.WriteLine( \"RealProxy调用&#123;0&#125;服务&#123;1&#125;方法失败,失败原因：&#123;2&#125;\", serviceName, methodName, ex.Message ); throw ex; &#125; finally &#123; serviceInfo.Close(); Console.WriteLine( \"调用&#123;0&#125;服务&#123;1&#125;方法结束,共耗时&#123;2&#125;秒\", serviceName, methodName, DateTime.Now.Subtract(startTime).TotalSeconds ); Console.WriteLine(\"----------------------------------\"); &#125; &#125;&#125; 对于WCF服务端的实现，我们依然使用ICalculator这个接口，需要注意的是为其添加[ServiceContract]和[OperationContract]标签，在这个例子中，我们共有CalculatorService和MessageService两个服务，为了简化这个实例，我们采用BasicHttpBinding的方式进行绑定，并为其指定各自的终结点地址。可以注意到，现在我们的动态代理实现了和原来代理类一样的效果。 123var binding = new BasicHttpBinding();var serviceUrl = \"http://localhost:8502/Calculator.svc\";var calculator = ServiceProxyFactory.CreatePorxy&lt;Server.Service.ICalculator&gt;(binding, serviceUrl); 通过RealPrxoy动态代理WCF服务 在调用WCF的时候，因为超时、网络等原因造成的调用异常，此时，我们可以为WCF添加异常处理相关的标签，而相应地，我们可以在异常中对异常的种类进行判断和处理，以便于及时地关闭ChannelFactory，因为如果它不能正确地关闭，会导致后续的通信出现问题，而这恰好是当初的代理类想要解决的问题，考虑到创建ChannelFactory是需要付出一定的性能代价的，因此，可以适当地考虑对ChannelFactory进行缓存，而这恰好是原来业务中的一个盲点。 Castle.DynamicProxy通过RealProxy，我们已经实现了WCF服务的动态代理，这里介绍第二种方式，即Castle.DynamicProxy，Castle和AspectCore、Unity等项目一样，提供了AOP相关的能力，可以让我们对接口、虚方法、类等进行拦截。Castle中的动态代理使用的是透明代理，而.NET Remoting的动态代理必须继承自MarshalByRefObject。博主暂时没有搞清楚，这两种是否属于同一种技术上的实现，作为延伸，我们来一起看看如何使用Castle中的DynamicProxy实现类似的功能，首先我们定义一个拦截器，它需要实现IInterceptor接口中的Intercept()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142public void Intercept(IInvocation invocation)&#123; var serviceInfo = FindService(); var methodInfo = invocation.Method; var startTime = DateTime.Now; var serviceName = serviceInfo.Service.GetType().Name; var methodName = methodInfo.Name; try &#123; Console.WriteLine(\"CastleProxy调用&#123;0&#125;服务&#123;1&#125;方法开始...\", serviceName, methodName); var argsInfo = new Dictionary&lt;string, object&gt;(); var parameters = methodInfo.GetParameters(); for (int i = 0; i &lt; invocation.Arguments.Length; i++) &#123; argsInfo.Add(parameters[i].Name, invocation.Arguments[i]); &#125; Console.WriteLine(\"当前传入参数:&#123;0&#125;\", JsonConvert.SerializeObject(argsInfo)); var result = methodInfo.Invoke(serviceInfo.Service, invocation.Arguments); if (result != null) &#123; Console.WriteLine(\"当前返回值:&#123;0&#125;\", JsonConvert.SerializeObject(result)); invocation.ReturnValue = result; &#125; &#125; catch (Exception ex) &#123; Console.WriteLine( \"CastleProxy调用&#123;0&#125;服务&#123;1&#125;方法失败,失败原因：&#123;2&#125;\", serviceName, methodName, ex.Message ); throw ex; &#125; finally &#123; serviceInfo.Close(); Console.WriteLine( \"CastleProxy调用&#123;0&#125;服务&#123;1&#125;方法结束,共耗时&#123;2&#125;秒\", serviceName, methodName, DateTime.Now.Subtract(startTime).TotalSeconds ); Console.WriteLine(\"----------------------------------\"); &#125;&#125; 接下来，我们通过ProxyGenerator来生成新的代理类，我们需要告诉ProxyGenerator要创建的类型是什么，是一个接口还是类，以及要应用哪一个拦截器。这里我们用到的方法是CreateInterfaceWithoutTarget()，它在这里的作用就是动态创建ICalculator接口的代理类。而通过查看Castle的API，我们会发现它可以在以下几种情况下创建某个类型的实例。首先是CreateInterfaceWithoutTarget()这个方法，当你希望创建一个接口的代理而又不想提供具体的实现时可以使用。其次是CreateInterfaceProxyWithTarget()这个方法，当你希望创建一个接口的代理同时又有提供具体实现时使用可以使用。接下来，是CreateInterfaceProxyWithTargetInterface()这个方法，它的命名看起来让人感到迷惑，甚至在某种角度来看，它和CreateInterfaceProxyWithTarget()这个方法还有点相似，其实。这两者最大的不同就是：后者允许你将调用目标替换为目标接口的不同实现。这种在实际场景中使用得不多，从Castle官方的使用场景来看，唯一用到这种技术的是Castle.Facilities，它可以和Windsor 这样的容器整合在一起使用，这个时候调用者就可以把WCF服务当作一个普通接口来使用，果然，大家都想到这一点，英雄所见略同啊，哈哈。好了，下面我们来看具体的代码实现： 123ProxyGenerator generator = new ProxyGenerator();var interceptor = new CastleServicePorxy&lt;ICalculator&gt;(binding, serviceUrl);var calculator = (ICalculator)generator.CreateInterfaceProxyWithoutTarget(typeof(ICalculator),interceptor); 迁移至.NET Core其实，我对WCF是不太感冒的，因为第一个字母W表明，它是一个只能运行在Windows平台的产物，现在依然有大量的Web Service存在，如果可以让我像使用普通接口一样使用WCF接口，我还是非常愿意去使用它的，毕竟系统中有大量依赖WCF的东西。可话又说回来，现在到.NET Core这个版本，微软并没有把WCF的服务端移植到.NET Core上，仅仅是提供了客户端调用的支持，或许还是因为WCF里有太多平台相关的东西吧！如果希望自己的.NET应用可以跨平台，越早摆脱这些Windows平台东西越好，譬如IIS、SQLServer等等。不过我这里想说的是，RealProxy在.NET Core中有类似的实现，我们可以用下面这种方式来进行迁移，当然，如果你直接Castle就更没有问题啦！ 123456789101112131415161718192021public class InvokeSerice&#123; public static T Proxy&lt;T&gt;() &#123; return DispatchProxy.Create&lt;T, InvokeProxy&lt;T&gt;&gt;(); &#125;&#125;public class InvokeProxy&lt;T&gt; : DispatchProxy&#123; private Type type = null; public InvokeProxy() &#123; type = typeof(T); &#125; protected override object Invoke(MethodInfo targetMethod, object[] args) &#123; //TODO: 在这里实现拦截逻辑 &#125;&#125; 本文小结这篇博客再次让大家领略了AOP的魅力，通过动态代理来创建相关的服务接口，让我们逐渐摆脱了手写代理类的深渊。本文主要分享了两种动态代理的实现方式，一种是基于.NET Remoting的RealProxy，一种是基于Castle的DynamicProxy。两种方式在使用上是非常相近的，通过这种方式。我们实现了WCF服务创建细节的隐藏，调用者不再需要去关心ChannelFactory相关的底层细节，可以像使用普通接口一样调用WCF服务，并且可以用一种统一的方式去记录调用相关的细节、对异常进行处理等等。早期的T4模板本质上是一种静态代理的方式，其缺点是难以适应快速迭代的变化，必须人手编写代理方法，而通过动态代理，这一切只需要写一次就好了，从而做到了真正意义上的“一次编写，到处运行”，这就是所谓的面向横切面编程的思路。关于Castle动态代理更多的应用场景，以及Castle.Facilities相关的内容，大家可以从各自的文档中去了解，以上就是这篇博客的全部内容了。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://qinyuanpei.github.io/tags/AOP/"},{"name":"Castle","slug":"Castle","permalink":"https://qinyuanpei.github.io/tags/Castle/"},{"name":"Dynamic Proxy","slug":"Dynamic-Proxy","permalink":"https://qinyuanpei.github.io/tags/Dynamic-Proxy/"}]},{"title":"WSL下Docker使用踩坑小记","date":"2019-04-22T22:13:36.000Z","path":"posts/4159187524/","text":"众所周知，Win10中开始提供Linux子系统，即Windows Subsystem for Linux，简称WSL，它可以让我们在Windows系统使用Linux系统，自从有了这个新功能以后，博主果断地放弃双系统的方案，因为折腾起来实在花费时间。关于如何使用WSL，网上有非常多的文章可以参考，这里不再赘述。今天想说的是，WSL下使用Docker遇到的各种坑。 装完WSL以后，对各种编译环境的使用相当满意，最近在研究日志可视化平台ELK，其中需要使用Docker来搭建环境，一顿sudo操作猛如虎，快速安装完Docker环境，结果发现熟悉的命令行居然无法正常工作，是可忍孰不可忍。 123456789101112131415sudo apt-get updatesudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-commoncurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add -sudo apt-key fingerprint 0EBFCD88sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\"sudo apt-get updatesudo apt-get install docker-ce docker-ce-cli containerd.io 第一个错误是，你按照官方文档安装完Docker，输入docker -v，一切显示正常的时候，此时，如果会执行docker run hello-world命令，会出现以下错误： 1$ docker run hello-world docker: Cannot connect to the Docker daemon at unix:///var/run/docker.sock. Is the docker daemon running?. See 'docker run --help'. 此时，你可能会尝试通过执行systemctl start docker命令来启动Docker服务，因为错误信息告诉我们，Docker的守护进程没有启动，可你会发现这样依然报错。可是为什么呢？明明Docker都在WSL里安装成功了啊，事实上除了docker -v不需要依赖守护进程，其余的命令都需要依赖守护进程，而WSL恰恰是不支持docker-engine的，所以，一种曲线救国的思路就是，让WSL去连接宿主机上的docker engine。果然，还是要安装Docker for Windows啊！那么，剩下的事情变得就非常简单啦，确保系统开启Hyper-V，然后安装Docker for Windows，并打开对宿主机Docker的监听，这些相信玩过Docker的人都会啦！ 暴露宿主机器Docker端口 接下来，我们给WSL中的Docker设置宿主机的地址，在终端中输入下列命令即可： 1export DOCKER_HOST=tcp://localhost:2375 此时，我们执行docker run hello-world命令，如果不出意外的话，我们会看到下面的画面，这说明我们的Docker环境已经正常工作啦： WSL中完美运行的Docker 博主按捺不住内心的激动，果断安装ELK全家桶，体验了下Kibana的可视化界面，开始思考：如何把存储在Mongodb中的日志数据放到ElasticSearch中。当然，这都是后话啦，因为博主马上发现了WSL中Docker的第二个坑，那就是终端关闭以后，针对宿主机的Docker连接就结束了。 ELK全家桶 OK，为了解决这个问题，我们继续在终端中输入以下命令： 1echo \"export DOCKER_HOST=tcp://localhost:2375\" &gt;&gt; ~/.bashrc &amp;&amp; source ~/.bashrc 在使用Docker的过程中，最令人困惑的部分当属分区的挂载，因为你时刻要搞清楚，它到底表示的是容器内部的分区，还是宿主机上的分区。对于运行在WSL中的Docker而言，它会采用类似/mnt/c/Users/Payne/这样的更符合Linux习惯的路径，而Docker for Windows则会使用类似/c/Users/Payne/这样更符合Windows习惯的路径。因此，如果你在使用Docker的过程中，需要处理分区挂载相关的东西，一个比较好的建议是修改WSL的配置文件(如果不存在需要自行创建)： 1234sudo nano /etc/wsl.conf[automount]root = /options = \"metadata\" 好了，以上就是在使用WSL中的Docker搭建ELK全家桶过程中遇到的问题的梳理，从体验上来讲，我个人会把Linux平台相关的工作渐渐转移到WSL上，因为安装双系统总会分散你的精力去处理维护相关的事情，虽然装系统对程序员来说都不算是个事儿，可我内心依旧排斥自己被贴上“修电脑”的标签。我会在后续的博客中分享.NET Core下日志分析平台构建相关内容，希望大家可以继续关注我的博客，这篇文章到此结束，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"WSL","slug":"WSL","permalink":"https://qinyuanpei.github.io/tags/WSL/"},{"name":"Docker","slug":"Docker","permalink":"https://qinyuanpei.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://qinyuanpei.github.io/tags/Linux/"}]},{"title":"由DBeaver与PL/SQL引发的数据库吐槽","date":"2019-04-19T12:52:10.000Z","path":"posts/337943766/","text":"因为工作中需要同时面向MySQL、Oracle和SQLServer三种数据库进行开发，所以，大概从去年国庆节开始，我开始使用一个开源的数据库管理工具——DBeaver。 使用这个工具的初衷，是因为我不想在同一台电脑上安装三个客户端工具，尤其是Oracle和SQLServer这种令人恐惧的、动辄需要重装系统的应用程序。我不想再使用类似Navicat这样的软件，因为它的画风像是上个世纪VB6.0的产品一样，同理，我不喜欢用PL/SQL，因为我每次都要瞪大眼睛，在它狭窄而拥挤的画面上找表、找视图，更有甚者，有时要去找触发器、找存储过程。直到我同事给我发了一个几十M的文档，我突然间意识到，这货居然还要安装Oracle的客户端，配置数据库连接要手动去改配置文件，我一点都不喜欢PL/SQL。 除了这三种经典的关系型数据库，我们还会用Memcache和Redis这样的内存数据库，Mongodb这样的非关系型数据库，所以，我希望有一个统一的入口来管理这些连接，毕竟我身边的同事会使用三种以上的工具，譬如Sqlyog、PL/SQL、SQLServer等来处理这些工作，恰好DBeaver可以满足我80%的工作需要。目前，DBeaver企业版支持关系型数据库和非关系型数据库，而社区版仅支持关系型数据库。 可最近在写Oracle环境的触发器(存储过程和触发器都是万恶之源)时，我发现DBeaver和PL/SQL在面对同一段SQL脚本时，居然因为一点点语法上的差异而不兼容，这让我内心深处不由得想对Oracle吐槽一番。这是一个什么样的SQL脚本呢？我们一起来看下面的例子： 12345678910111213141516CREATE OR REPLACE TRIGGER \"TRI_SYNC_ITEM_VALUE\" BEFORE DELETE ON \"or_line\" FOR EACH ROWDECLARE v_item_value NUMBER(18,6);BEGIN SELECT ITEM_VALUE INTO v_item_value FROM \"order_info\" WHERE ORDER_GID = :OLD.ORDER_GID; v_item_value := v_item_value - :OLD.PACKAGE_COUNT * NVL(to_number(:OLD.OL_UDF7),0); IF v_item_value &lt; 0 THEN v_item_value:= 0; END IF; UPDATE \"order_info\" SET ITEM_VALUE = v_item_value WHERE ORDER_GID = :OLD.ORDER_GID;END \"TRI_SYNC_ITEM_VALUE\";INSERT INTO \"sys_upgrade_history\"(UPGRADE_TYPE,VERSION_NO,UPDATE_DATE,REMARK) VALUES('版本更新','10005',SYSDATE,'Normal'); 这是实际业务中编写的一个简单触发器脚本，我们通常的编写习惯是，在写完触发器或者存储过程以及函数后，会在升级历史中插入一天新纪录，所以，这个脚本实际上由两部分组成。如果这段脚本分两次执行，那么在DBeaver和PL/SQL中效果是一样的。可如果我们希望一次执行整个脚本，根据PL/SQL的规范，一个PL/SQL脚本由如下结构组成： 123456DECLARE [声明部分]BEGIN [过程部分]END;/ 这个时候，我们就要在这两部分脚本间增加一个分隔符——/。可尴尬的是，这种写法在DBeaver中是无法编译执行的，因为它认为/是个无效的SQL关键字。我一直疑心这是个Bug，因为Github上曾有人提过类似的Issue，作者回复说，DBeaver并没有完全实现PL/SQL语法的解析，而最近更新的6.0版本中提到：对Oracle环境的存储过程编译进行了强化。博主尝试升级到最新版本，发现这个问题依然存在，哪怕用Ctrl+Enter来执行一样会报错，于是我想从这件事吐槽下某数据库，从哪里说起呢，就从PL/SQL说起吧！ 标准与私货我想一开始学习SQL语法的时候，大家绝对不会想到，看起来和谐而统一的结构化查询语言，其实是貌合神离。为什么这样说呢？因为我真的不知道，一个时间函数居然可以有SYSDATE、NOW()和GETDATE()三种写法，我更不知道，有一天会因为不知道ROWNUM而被面试官鄙视，更不必说每种数据库都会定义一两种不一样的数据类型，这东西号称是有一个标准吗？比如SQL92/99这个标准定义了DML(数据操作语言)、DDL(数据定义语言)、DCL(数据控制语言)和TCL(事务控制语言)四种分类，所以，SQL的定位其实更接近于交互式命令行，它是命令式的查询语言，而非过程式的声明语言。 可在标准化进程缓慢的大背景下，每一家数据库厂商都在往自家产品里夹藏私货，以甲骨文为首的Oracle发展出了PL/SQL、以微软为首的SQLServer发展出了T-SQL。其实，我很能理解这种标准跟不上时代发展需要的阵痛，就像我们的Web领域直到10年前后才提出了HTML5标准，在此之前，我们为不同的浏览器的兼容性煞费苦心，兼容IE8与否甚至成为了评价技术好坏的一个隐性标准，可说句实话，浏览器的Bug难道不应该让浏览器厂商来修复吗？关前端工程师什么事？同样的，数据库间的差异，让我们的脚本失去了可移植性，触发器、存储过程这种严重依赖数据库的东西，一旦更换了数据库，基本等于要重头再写一遍，如今的小程序让Web变成信息孤岛，甚至Chrome正在变成下一个IE，这就是所谓“屠龙少年战胜恶龙，自身亦化为恶龙吗”？ 这种不统一带来的弊端就是，我们永远写出可以完美“跨”数据库的SQL，现在跨平台基本成为了大家的共识，因为操作系统间的差异越来越小，以我个人为例，我使用的大多数软件都可以找到对应的Linux版本，这样做的好处是，我可以在无差别地从Windows切换到Linux。可现在，我们必须在MySQL里使用VARCHAR、而在Oracle里使用NVARCHAR，而在SQLServer里又要使用NVARCHAR2，可明明它们都是表示一样的东西啊，类似的还有MediumText和CLOB，是不是起一个不一样的名字会显得与众不同呢？更不必说在DDL中表约束相关的语法存在差别了。我被告知Oracle脚本中表名要用双引号括起来，理由是Oracle区分大小写，加上双引号就可以让它忽略大小写，忽略大小写不应该给Oracle一个设置吗？为什么要让我再写个多余的双引号呢？诸如此类，举不胜举。 SQL是个好DSL吗？SQL标准定义的SQL，就是一个以集合论为基础的结构化查询语言，它天生适合的场景就是，你在命令行中输入SQL语句，然后它去执行你输入的SQL语句，它就像我们大多数情况下使用的交互式命令行，不然，为什么MySQL要提供命令行版本，主流的数据库管理工具都提供了输入SQL语句的窗口。可我们同样能意识到，SQL的表达能力有限，它无法表达顺序、条件、循环这种基本的程序结构，所以，数据库厂商几乎都对SQL标准进行了扩展，像PL/SQL和T-SQL中都提供了这些语法，进而催生出函数、触发器、存储过程一系列“万恶之源”，可从编程语言的角度来看，SQL算是个好DSL吗？ SQL试图从编程语言中获得“灵感”的思路是正确的，但总给人一种买椟还珠的感觉，譬如使用大量的英文关键字来作为保留关键字，可你很难想象，像GROUP BY和ORDER BY这样的关键字，居然可以保留中间一个甚至多个空格，既然是关键字，为什么不选择一个单词，而选择一个组合词呢？这个世界上用Begin和End的编程语言，我使用过的有Pascal和Basic，但现在我几乎不会再用它们，为什么呢？因为使用花括号({})更符合这个世界的发展趋势，你看Python居然用缩进代替花括号，是打算时刻用游标卡尺写代码吗？ 全世界都默认用分号作为一个语句的结束，那么，当多个语句放在一起的时候，直接相互间用分号隔开，编译器或者解释器都能识别，就算不喜欢写分号的JavaScript，最新的标准提案里不还是建议要写吗？可为什么到了PL/SQL这里，明明已经用分号作为结束符了，偏偏还要再用一个/作为分隔符。我们都知道/会被当做是注释的开始，那么如果我在PL/SQL里恰好在End;后写上一句/，你告诉我，这到底代表什么意思？明明像&amp;&amp;、||、^等这样的运算符，都是有固定含义，并且大家所有编程需要都默认了这个原则，可偏偏有人用||来连接字符串，你告诉我，用+不好吗？就像从小到大，÷都会被认为表示一个除法运算，结果突然有一天，有人用这个符号来表示加法运算，你说你是不是有种被当做傻子的感觉。全世界都用=表示赋值运算，结果PL/SQL自作聪明地搞了个:=，我想说，你真的考虑过使用者的体验吗？ 你甚至连分页、排序、分组这种事情，都无法在不同的数据库上获得一致的书写体验，读取指定数目的数据库记录，居然要纠结用到底用Limit还是Top，像Select Into这样把指定列存储到指定变量中的操作，居然要求使用者来限制结果集的数目，从函数的角度来看，返回的必然是结果集中的一个元素，只有这样才可以赋值给指定的变量，可问题是存在多条记录的时候，你必须用游标去循环读取，而不能像大多数编程语言一样，直接Map()到一个类型上然后ToList()，可能是我对SQL的要求太高了吧，毕竟它就是个面向过程的语言，OO不OO的没那么重要，可明明你可以抛出异常啊，可以对字符串做截取啊正则啊，可以在控制台里输出日志啊，可以调用各种有的没的的内部函数啊，elsif可能是因为e不发音，就像usr绝对不是拼写错误…… Python的缩进虽然为人所不齿，但它至少和大部分编程语言一样，单独一行的程序语句和由多行程序组成的程序块之间，并不需要明显的分割符号。可MySQL需要用DELIMITER $$这种奇怪的符号，PL/SQL需要用/这种奇怪的符号，SQLServer需要用@这种奇怪的符号，还有大名鼎鼎的虚拟表DUAL。也许这些东西写多了就可以记住，就像我现在可以分清SYSDATE、NOW()和GETDATE()，可它带来的问题是什么呢，大多数的触发器、存储过程、函数都是没有移植性可言的，很多年前，我们讲设计模式，最喜欢觉的例子就是，如果项目发生变动，需要更换数据库，我们要怎么设计能不改动代码，现在看起来，当时还是太天真了，真要换了数据库，估计就是重新做了，敢把全部业务写到数据库里，Web就做一个展示层的项目，有生之年应该是不会换数据库啦！ 多元与统一这个世界的离奇之处在于，人们一边渴望在标准的庇护下幸福生活，又一边渴望可以超脱标准去发展独立的个性，如你我所见，多元与统一，构成了这个世界永恒的旋律，或许是因为那句名言——没有永远的敌人，只有永远的利益。可对比Web的标准化与SQL的标准化，我们却看到了截然不同的场景，虽然Chrome浏览器市场份额的不断提高，加上微软、Mozilla等“浏览器巨头”一起推动，HTML5和CSS4，让大量的工作得到了简化，尤其像WebSocket、Drag&amp;drop、Canvas等API的推出，这带来的好处是什么呢？大家不再去重点关注浏览器的兼容性问题，各种天花乱坠的炫酷特效不再通过JavaScript去控制。一个标准的API + 一个支持降级的profily，基本就可以覆盖到主流的浏览器，就算有小程序这种偏离标准的解决方案，回顾近几年整个前端领域的趋势，可以说，一切都在向着好的方向发展。 可数据库领域发生了什么，依稀记得甲骨文和Google因为Android使用了Java而官司连连，Google不得不推出一种新的基于JVM的语言——Kotlin；依稀记得甲骨文在开源社区的强烈反对下收购了MySQL，社区不得不继续维护MySQL的开源分支——MariaDB。从这两件事情，我完全提不起对甲骨文这家公司的好感，虽然大家都说Oracle品质卓越，可实际使用下来，经常出问题的Oracle。从LAMP时代开始，MySQL就以其免费、轻量的特点广泛应用在互联网产品中，直至今天有大量的云产品使用着MySQL，而Oracle和SQLServer则被更多地使用在私有部署的场景中。虽然，我承认把数据掌握在自己手里会放心些，可当你没有能力去维护这些东西时，付出的时间和精力远远要比这多。甲骨文收购了那么多公司的产品，时至今日，对整个行业的标准化有什么推动呢？Oracle数据库依然难装、难用，PL/SQL同样难用得要命，可我们这世界一直都很奇怪，最流行的偏偏未必是最好的，据说Oracle的代码写得非常差，开发人员表示不会在为它继续开发新功能。 可能有时候，我们完全说不出来，一件东西是好还是坏，就像JavaScript能在前端开发流行，是因为没有其它的选择，你说这门语言没有缺点吗？当然有，JavaScript里各种“骚操作”和“黑科技”，甚至吐槽三天三夜都说不完。同样，还有Python这门语言，大家都觉得它的解释器慢腾腾的，动态语言遇上大型项目简直就是火葬场，还有神来之笔—— 通过缩进来代替花括号。我最终还是在PL/SQL里执行了我的脚本，只要我在使用DBeaver 的时候，人肉地区分/前后的SQL语句就可以了。果然，我骨子里还是一个不喜欢写SQL脚本的人，因为我认为这么别扭的东西简直不能称之为脚本，你看看Lua，再看看Python，有哪一门脚本语言有SQL脚本这样别扭呢？数据库对我而言，就是一个存取数据的“潘多拉魔盒”，索引啊，触发器啊，数据库任务啊，执行计划啊，存储过程啊，难道不属于暴露了太多细节给用户吗？我天天用这个数据库，我每天用哪些表，我每天用哪些字段，你作为一个成熟的数据库了，居然不能自己去解决这些问题，我对你很失望啊，请记住，程序员比任何人都喜欢偷懒。","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"DBeaver","slug":"DBeaver","permalink":"https://qinyuanpei.github.io/tags/DBeaver/"},{"name":"PL/SQL","slug":"PL-SQL","permalink":"https://qinyuanpei.github.io/tags/PL-SQL/"},{"name":"Oracle","slug":"Oracle","permalink":"https://qinyuanpei.github.io/tags/Oracle/"}]},{"title":"zTree删除/拖拽子节点保留父节点分组样式","date":"2019-04-12T12:37:10.000Z","path":"posts/1397717193/","text":"最近需要在项目中实现报表的自定义设置功能，即用户可以针对报表新建自定义分组，分组间可以互相嵌套，分组及分组内的报表需要支持拖拽排序、编辑、删除……相信听到这里，你大概明白我要实现一个什么样的功能了。不错，我要实现一个集美观、功能于一身的树形菜单。本着“不要重复制造轮子”的原则，我在考察了JQuery EasyUI、layui、Bootstrap、Kendo UI等不同框架提供的“树形菜单”组件以后，最终选择了zTree这样一个插件，虽然这个官网看上去相当复古，虽然最终的成品依然被同事吐槽丑，可它的确完美得实现了我想要的功能，是当之无愧的“树形菜单”王者。 zTree的API相当复杂，尤其是属性和事件的种类，简直叫一个繁杂，这是大部分基于jQuery插件的一个特点。不过zTree的使用还是比较简单的，我们只需要提供一个DOM节点，一份JSON数据，zTree就可以帮我们在界面上渲染出一个完整的树形菜单： 123var data = res.Data;var zNodes = JSON.parse(data.TreeData);$.fn.zTree.init($(\"#reportTree\"), setting, zNodes); zTree的节点是由JSON结构来定义的，其基本结构是{name:”节点名称”,children:[]}，父子节点采用相同的结构相互嵌套。例如，下面是博主所使用的数据结构： 123456789101112131415161718192021222324252627282930313233343536[ &#123; \"id\": null, \"name\": \"全部报表\", \"url\": null, \"pId\": null, \"viewUrl\": null, \"children\": [ &#123; \"id\": null, \"name\": \"示例报表A\", \"url\": null, \"pId\": null, \"viewUrl\": null, \"children\": [ &#123; \"id\": null, \"name\": \"示例报表B\", \"url\": null, \"pId\": null, \"viewUrl\": \"/MyReport/List?menuid=38c0e1ce7442419f9e3305a03b819128\", \"children\": null &#125;, &#123; \"id\": null, \"name\": \"示例报表C\", \"url\": null, \"pId\": null, \"viewUrl\": \"/MyReport/List?menuid=e88ae4a5c07445a59c2f04ec405e6158\", \"children\": null &#125; ] &#125; ] &#125;] 参考官网上的DEMO，我们基本上就可以快速上手zTree，博主这里就是结合了节点的编辑、拖拽这两个功能。不过，按照官网上的DEMO会存在两个Bug，与我们实际的期望有所不同，其一，是当一个分组下的子节点被全部删除后，这个分组的图标会变成一个子节点的图标；其二，是当个一个分组下的节点被全部拖拽到分组以外的地方，这个分组的图标会变成一个子节点的图标。这两个Bug是由测试小姐姐们发现的，zTree是我引入到项目中来的，这个Bug哪怕跪着都要改完，说多了都是泪啊，下面给出解决方案： 12345678910111213141516171819202122232425262728293031323334353637function onRemove(e, treeId, treeNode) &#123; var zTree = $.fn.zTree.getZTreeObj(reportTreeId); var root = zTree.getNodes()[0]; if (treeNode.isParent) &#123; reports = GetReportsByNode(treeNode) var parentNode = treeNode.getParentNode(); if (parentNode != null &amp;&amp; (parentNode.children == null || parentNode.children.length == 0)) &#123; parentNode.isParent = true; parentNode.isOpen = true; zTree.updateNode(parentNode); &#125; &#125;&#125;var emptyNode;function beforeDrop(treeId, treeNodes, targetNode, moveType, isCopy) &#123; var zTree = $.fn.zTree.getZTreeObj(reportTreeId); for (var i = 0; i &lt; treeNodes.length; i++) &#123; var treeNode = treeNodes[i]; var parentNode = treeNode.getParentNode(); if (parentNode != null &amp;&amp; (parentNode.children == null || parentNode.children.filter(function (s) &#123; return s.name != treeNode.name; &#125;).length == 0)) &#123; emptyNode = parentNode; break; &#125; &#125; return true;&#125;function onDrop(event, treeId, treeNodes, targetNode, moveType, isCopy) &#123; var zTree = $.fn.zTree.getZTreeObj(reportTreeId); if (emptyNode != null) &#123; emptyNode.isOpen = true; emptyNode.isParent = true; zTree.updateNode(emptyNode); emptyNode = null; &#125;&#125; OK，实际项目中可能需要存储这个树形结构，因为你能想象，用户编辑完这样一个“个性化”的设置以后，我们还要根据这个设置来加载树形菜单，以达到个性化的目的。那么，怎么获得这个树形结构呢，理论上我们只需要通过zTree.getNodes()方法获得整个树的节点信息，然后将其序列化为JSON即可，可实际上zTree会在树上附加“冗余”信息，所以，博主的做法是，通过递归来遍历整个树的节点，获取其中的关键信息，这里以name字段为例： 123456789101112131415161718function GetTreeData(zTree) &#123; var data = []; for (var i = 0; i &lt; zTree.length; i++) &#123; var treeNode = zTree[i]; if (!treeNode.isParent) &#123; var obj = new Object(); obj.name = treeNode.name; data.push(obj) &#125; else &#123; var obj = new Object(); obj.name = treeNode.name; obj.children = GetTreeData(treeNode.children) data.push(obj) &#125; &#125; return data;&#125; 好了，最近接触到都是些零碎的东西，大家都讲究着看看吧，可以说没有什么干货。折腾前端最大的感悟就是，做一个页面其实并不难，真正难的是集成到一个系统里，像iframe和tab这种“垃圾”的东西，集成到一起就像猜地雷，你永远不知道别人埋了什么坑在里面，以上就是这篇博客啦，晚安！","categories":[{"name":"前端开发","slug":"前端开发","permalink":"https://qinyuanpei.github.io/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://qinyuanpei.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"JavaScript","slug":"JavaScript","permalink":"https://qinyuanpei.github.io/tags/JavaScript/"},{"name":"zTree","slug":"zTree","permalink":"https://qinyuanpei.github.io/tags/zTree/"}]},{"title":"分享两种实现前端拖拽排序的方案","date":"2019-03-31T12:49:37.000Z","path":"posts/2436573863/","text":"Hi，大家好，在经历了两周多的“写Bug”、“改Bug”死循环后，又一个迭代终于在习以为常的加班生活中结束啦！联想到最近在Github上发起的“996.icu”事件，不禁令人由衷地感慨生活不易，所谓”起风了，唯有努力生存“。其实，我反对是加班常态化所导致的无效加班，既然努力工作是为了更好的生活，可如果因此而模糊了工作和生活的界限，这到底是一件好事还是一件坏事呢？想想每个周末被工作群里消息支配的失落感，我希望我有可以自由支配的时间，即使我看起来比别人年轻，即使我下班后依旧孤身一人，因为用时间来换钱这件事情，着实是件性价比不高的事情，货币会一天天地贬值直至我们老去，可那些失去的时间就永远地失去了。好了，”业精于勤荒于嬉“，今天我们来说前端中实现拖拽排序这件事情。 其实，这件事情说起来挺尴尬的，我们曾经为用户提供过某种”智能“的体验，我们通过对用户的行为进行分析，为其推荐了个性化的菜单项，甚至根据用户的使用频率对菜单进行了排序。可事实上用户的反响并不是非常强烈，在经过一段时间的使用后，用户依然觉得这个功能相当地”鸡肋“，这件事情告诉我们一个真相，即无论是产品设计还是需求研讨，最好不要轻易地代入用户的角色。最终的结果是我们打算为用户提供自定义的功能，考虑到操作的便利性问题，我们放弃了那种通过上下箭头按钮进行排序的方案，这样就回到了本文的主题，如何在前端中对一组列表进行拖拽排序，最终我们选定了两组方案，它们分别是Nestable和Sortable。 Nestable方案Nestable是一个基于jQuery的插件，是一个在Github上开源的项目，据作者声称，这是一个”拖放具有鼠标和触摸兼容性的分层列表”的方案。这里针对触摸兼容性的支持可以忽略不计，因为如今都9012年了，博主依然在做传统前端页面的开发，这里博主最感兴趣的一点是，它可以支持分层列表，换言之，我们的列表元素是可以有层级关系、是可以嵌套的，唯一令人有点不爽的就是它依赖jQuery了，在这样一个连Github和Bootstrap都在努力移除jQuery的时代，没有jQuery的历史包袱，意味着我们可以大胆地去做现代前端应该做的事情。好了，我们来看看Nestable具体是怎么使用的吧！首先，我们定义一个简单的HTML结构： 123456789101112131415161718192021&lt;div class=\"dd\"&gt; &lt;ol class=\"dd-list\"&gt; &lt;li class=\"dd-item\" data-id=\"1\"&gt; &lt;div class=\"dd-handle\"&gt;Item 1&lt;/div&gt; &lt;/li&gt; &lt;li class=\"dd-item\" data-id=\"2\"&gt; &lt;div class=\"dd-handle\"&gt;Item 2&lt;/div&gt; &lt;/li&gt; &lt;li class=\"dd-item\" data-id=\"3\"&gt; &lt;div class=\"dd-handle\"&gt;Item 3&lt;/div&gt; &lt;ol class=\"dd-list\"&gt; &lt;li class=\"dd-item\" data-id=\"4\"&gt; &lt;div class=\"dd-handle\"&gt;Item 4&lt;/div&gt; &lt;/li&gt; &lt;li class=\"dd-item\" data-id=\"5\"&gt; &lt;div class=\"dd-handle\"&gt;Item 5&lt;/div&gt; &lt;/li&gt; &lt;/ol&gt; &lt;/li&gt; &lt;/ol&gt;&lt;/div&gt; 接下来，我们可以使用如下的JavaScript代码来初始化整个列表，果然，一股jQuery风扑面而来： 123$('.dd').nestable(&#123; /* config options */&#125;); 然后，我们就可以看到下面的效果： nestablejs-demo 怎么样？看起来效果还不错吧！不过博主在前期调研的过程中发现，它对于复杂的层级关系就无能为力啦，可能是博主打开的姿势不对吧！如果希望对列表做更深层次的定制，它需要配置的属性会非常非常的多，而且它有一套内在约束在里面，譬如className、nodeName等等，虽然这些都可以去配置，但要想像作者一样运用得好，依然是需要花费大量时间来学习它的API。 说到这里，对于Nestable，我唯二喜欢的一个feature是，它可以实时地获取到排序后的节点信息，而且是序列化后的JSON格式哦，因为当我们要保存用户的排序结果时，有这样一个接口简直太棒啦有木有！这里需要说明的是，所有具备类似data-属性的节点都可以被序列化，熟悉前端的朋友一定知道，这是一个HTML5中的扩展功能，可以让我们在节点上附带更多的数据信息，在Bootstrap中经常需要用到这一特性。 1$('.dd').nestable('serialize'); 继续以这个例子为例，我们将会得到下面的JSON信息： 1[&#123;\"id\":1&#125;,&#123;\"id\":2&#125;,&#123;\"id\":3,\"children\":[&#123;\"id\":4&#125;,&#123;\"id\":5&#125;]&#125;] 不过，遗憾的是，貌似作者已经不打算维护这个项目啦，最后一次维护时间已经是6年前，毕竟属于jQuery的辉煌时代都已经过去，何况是基于jQuery的一个插件呢？可这种频繁修改DOM结构引发浏览器重绘的操作，在大前端时代会消失吗？或许并不会。关于这个项目更多的使用细节，大家可以到它的Github主页去了解。 Sortable方案Sortable相比Nestable好的一点就是，它对自己的定位是“一个用于可重新排序的拖放列表的JavaScript库”。它不再局限于jQuery这样一个方案上，事实上它支持Vue、React、Angualr、Knockout等将近7个框架，除了支持常规的列表以外，还支持Grid中元素的拖拽，文档相比Nestable要更为完善一点，所以要在项目中使用的话，我个人更推荐Sortable。我们一起来看看如何使用Sortable吧，这里我们选择Bootstrap作为基础样式。首先，我们写一个简单的“列表组”： 1234567891011121314&lt;ul class=\"list-group\" id=\"items\"&gt; &lt;li class=\"list-group-item\" data-id=\"0\"&gt; Menu1 &lt;/li&gt; &lt;li class=\"list-group-item\" data-id=\"1\"&gt; Menu2 &lt;/li&gt; &lt;li class=\"list-group-item\" data-id=\"2\"&gt; Menu3 &lt;/li&gt; &lt;li class=\"list-group-item\" data-id=\"3\"&gt; Menu4 &lt;/li&gt;&lt;/ul&gt; 接下来，我们通过JavaScript来给这个列表“施加”魔法——巴拉能量： 12var ele = document.getElementById('items');var sortable = Sortable.create(ele); 然后我们就可以发现，这个基于Bootstrap的列表居然可以拖拽啦！ sortablejs-demo-1 OK，我们继续给这个例子来点魔法，可以让列表元素在拖动的时候高亮显示： 1234var sortable = Sortable.create(ele, &#123; animation: 150, ghostClass: 'blue-backgroun-class'&#125;); 可以注意到，拖拽时动画会变得更流畅，被拖拽的元素会以蓝底白字高亮显示： sortablejs-demo-2 和Nestable类似，我们可以指定一个回调函数来获得排序后的结果，注意到我们这里指定一个dataIdAttr，它告诉Sortable我们将用哪一个值作为数据的主键，从data-text这个命名就可以看出，它的数据是维护在类似data-的属性上的，假设我们这里希望获得排序后的菜单，那么，它的打开方式是这样的： 12345678910111213var ele = document.getElementById('items');var result = document.getElementById('result');var sortable = Sortable.create(ele, &#123; animation: 150, dataIdAttr: 'data-text', onUpdate: onUpdate, ghostClass: 'blue-backgroun-class'&#125;);function onUpdate(evt)&#123; var data = sortable.toArray(); result.innerText = \"当前排序结果为：\" + JSON.stringify(data);&#125; 好了，现在可以看到，随着我们对列表进行拖拽，每次都会获得更新以后的列表数据，显然，我们可以将这个结果存到任何地方，这样就可以按用户定义的方式去加载一个列表。 sortablejs-demo-3 以上就是Soratble的基本用法，关于更多的使用细节，官方文档了解一下。 HTML5原生方案OK，说完了Nestable和Sortable这两个第三方的解决方案，下面我们来说说基于HTML5的原生方案。HTML5标准问世以来，有很多有意思的东西被吸收到标准之中，拖放(drag &amp; drop)就是其中之一。在此之前，我们需要写大量的JavaScript代码来实现这个功能。现在，HTML5中原生支持拖放API，我们不妨考虑通过它来实现一个可拖拽的列表，这里我们继续沿用基于Bootstrap的例子。 12345678910111213141516171819202122232425var dragElement = null;var source = document.querySelectorAll('.list-group-item');for(var i = 0; i &lt; source.length; i++)&#123; source[i].addEventListener('dragstart',function(ev)&#123; dragElement = this; &#125;,false); source[i].addEventListener('dragenter', function(ev)&#123; if(dragElement != this)&#123; this.parentNode.insertBefore(dragElement,this); &#125; &#125;, false) source[i].addEventListener('dragleave', function(ev)&#123; if(dragElement != this)&#123; if(this == this.parentNode.lastElementChild || this == this.parentNode.lastChild)&#123; this.parentNode.appendChild(dragElement); &#125; &#125; &#125;, false)&#125;;document.ondragover = function(e)&#123;e.preventDefault();&#125;document.ondrop = function(e)&#123;e.preventDefault();&#125; 这里唯一需要注意的地方，就是要给每一个className为list-group-item的元素添加draggable属性，并设置该属性为true，这是使用HTML5拖放API的一个前提，换言之，只有draggable的元素才可以被拖拽。那么，HTML5中针对拖放的API有哪些呢？针对拖放事件，我们可以抽象出三种角色，它们分别是： 源对象：即对拖拽的对象。它有dragstart、drag和dragend三个事件。 过程对象：即被拖拽的对象，在拖拽过程中经过的中间对象，它有dragenter、dragover和dragleave三个事件。 目标对象：即被拖拽的对象，最终所放置的对象，它只有一个drop事件。 而在所有的拖拽事件中，都提供了一个数据传递对象dataTransfer，用于在源对象和目标对象间传递数据。例如，我们可以通过setData()来向dataTransfer存入数据，通过getData()来从dataTransfer读取数据，通过clearData()来清理dataTransfer中的数据。此外，还可以通过setDragImage()、effectAllowed属性 和 dropEffect 属性来设置拖拽过程中的图标、拖放的视觉效果等。这里需要注意的是，IE浏览器不支持dataTransfer对象。了解了这下，我们就可以做出一个”简陋“的拖拽排序功能： sortablejs-demo-4 本文小结这篇文章主要分享了三种实现列表拖拽排序的方案，在技术选型阶段，主要选择Nestable和Sortable这两种方案，前者对层级节点提供的序列化支持非常好，但经过一番折腾后，发现要想像作者一样用好这个插件，着实是件困难的事情，而且貌似作者已经不再维护这个项目了，最近的代码提交历史大概是6年前，毕竟属于jQuery的辉煌时代已经过去，何况是一个基于jQuery的插件呢？所以，个人不建议在正式项目中使用Nestable。相比之下，Sortable的定位要更高一点，它不再局限于某个UI框架上，理论上任何前端项目都可以使用，从文档的完整性和易用性上，都要比Nestable要更胜一筹。原本一开始打算写这两种方案的，后来觉得HTML5中提供了拖拽相关的API接口，这种方式不失为一种解决方案。虽然提到HTML5就让人联想到兼容性，可都2019年了，连浓眉大眼的微软(巨硬)都开始在Edge里使用Chrome内核了，兼容性问题还算是个问题吗？所以，这篇文章实际上介绍了三种解决方案，具体使用哪一种，大家可以根据实际情况来决定，好啦，这篇博客就写到这里，谢谢大家，晚安！","categories":[{"name":"前端开发","slug":"前端开发","permalink":"https://qinyuanpei.github.io/categories/%E5%89%8D%E7%AB%AF%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://qinyuanpei.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"HTML5","slug":"HTML5","permalink":"https://qinyuanpei.github.io/tags/HTML5/"},{"name":"拖拽","slug":"拖拽","permalink":"https://qinyuanpei.github.io/tags/%E6%8B%96%E6%8B%BD/"}]},{"title":"《阿里巴巴Java开发手册》读书笔记","date":"2019-03-20T12:49:37.000Z","path":"posts/1122710277/","text":"最近利用闲暇时间从图书馆借了两三本书来“充电”，因为如果不及时摄取新的营养，感觉会越来越难有新的想法输出出来，尤其是像ServerLess、组件化、分布式等等这样的场景慢慢开始接触，就势必无法再用从前的眼光去看待。大概去年的时候，阿里巴巴发布了「阿里巴巴开发手册」这本小册子，大概不到100页的样子，这次我就挑选了我觉得还不错的关键点，和大家简单分享一下，所以，这是一篇“典型”的读书笔记，下面的编号代表的是指定章节下的第几条规范，例如，1.1.2表示的是第一章第一节中的第二条规范，欢迎大家一起讨论。 编程规范 1.1.2 代码中的命名严禁使用拼音与英文混合的方式，不允许直接使用中文的方式，纯拼音命名方式更要避免采用。 说明：英文不好可以去查，禁止使用纯拼音或者拼音缩写的命名方式，除了不能“望文生义”以外，对导致别人在调用接口的时候，向这种“丧心病狂”的编码风格妥协，这里不点名批评某SAP提供的OA接口，除了超级难用以外，每次都要花大量时间去对字段。 1.4.3 相同参数类型，相同业务含义，才可以使用Java的可变参数，避免使用Object，可变参数必须放置在参数列表最后。 说明：例如一个接口同时支持单条更新或者批量更新，此时，完全就可以使用param关键字来声明相同的参数类型，而无须定义InsertOne和InsertMany两个方法。 1.4.4 对外部正在使用或者二方库依赖的接口，不允许修改方法签名，以避免对接口调用方产生影响。若接口过时，必须加@Deprecated注解，并清晰地说明采用的新接口或者新服务是什么。 说明：对于过期的接口可以通过Obsolete特性来声明过期，这样在编译时期间可以告知使用者该接口已过期。对于WebAPI接口，除非有版本控制机制，否则一律不允许修改已上线的接口签名、参数和返回值。 1.4.17 在循环体内，字符串的连接方式使用StringBuilder的append方法进行扩展。 说明：这一点，在C#中同样适用，因为字符串类型是Immutable的，对字符串进行拼接会产生大量的临时对象。 1.5.7 不要在foreach循环内进行元素的remove/add操作。remove元素请使用Iterator方式，如果并发操作，需要对Iterator对象加锁。 说明：因为foreach是基于迭代器(IEnumerator)的，在foreach循环内部修改集合，会导致Current和MoveNext()发生混乱，早期的集合使用SynRoot来解决线程安全(内部原理是使用了Interlocked锁)，现在我们使用CurrentBag等线程安全的集合。 1.6.1 获取单例对象需要保证线程安全，其中的方法同样要保证线程安全。 说明：只要类型中有静态成员存在，就要考虑线程安全，因为静态成员隶属于类型而非类型的实例。 1.6.5 SimpleDataFormat是线程不安全的类，一般不要定义为static变量，如果定义为static，必须加锁，或者使用DateUntils工具类。 说明：无论所声明的静态成员是否线程安全，都应该考虑到在竞态条件下，可能会出现多个线程同时修改静态成员的风险，此时最好对其进行加锁。 1.6.8 在并发修改同一条记录时，为避免更新丢失，需要加锁。要么在应用层加锁，要么在缓存层加锁，要么在数据库层使用乐观锁，使用version作为更新依据。 说明：所谓“悲观锁”，是指认为数据一定会被篡改，此时，在一个作用域结束前对其进行加锁，典型的如lock关键字。而所谓“乐观锁”，是认为数据不一定会被篡改，此时，通过一个version来作为更新的依据。 1.6.12 在并发场景下，通过双重检查锁(double-checkedlocking)实现延迟初始化的优化问题隐患，推荐解决方案中较为简单的一种(JDK5及以上版本)，即目标属性声明为volatile型。 1.7.4 在表达异常的分支时，尽量少用if-else方式。如果不得不使用if…elseif…else方式，请勿超过3层。 说明：当条件不满足时可以直接return，或者先判断不满足的条件，则剩余逻辑默认就是满足条件的分支，尽量避免使用if…elseif…else方式，同时保证分支里的代码足够简单，复杂的逻辑应考虑封装或者用switch…case甚至多态来重构。 1.7.8 循环体的语句要考量性能，以下操作请尽量移至循环体外处理，如定义对象或变量、获取数据库连接，避免进行不必要的try…catch操作。 说明：抛出一个异常是非常简单的，然而捕获一个异常需要付出一定的性能代价，因为它需要捕捉程序异常时的上下文信息，建议在进入循环内部合理检验，覆盖到每一种考虑到的情况，考虑不到的请让它向上抛出。 2.1.2 对大段代码进行try-catch，使得程序无法根据不同的异常做出正确的应激反应，不利于定位问题，这是一种不负责任的表现。 说明：对大段代码进行try-catch，或许可以保证应用程序不崩溃，但在程序异常的一瞬间，可能业务数据已经出错，此时再让程序继续运行下去，不仅无法快速定位出错原因，而且会对下一流程的业务产生“污染”。 异常日志 2.1.2 捕捉异常是为了处理它，不要捕捉了却什么都不处理而抛弃之，如果不想处理它，请将该异常抛给它的调用者，然后由调用者在最外层业务中处理异常，并将其转化为用户可以理解的内容。 说明：捕捉了异常一定要去处理它，如果单单是为了记录个错误日志，完全可以通过AOP来记录，底层抛出的异常不允许被“吞掉”，必须将其抛给它的调用者，异常最终需要转化为友好的界面提示。 2.2.5 finally块必须对资源对象、流对象进行关闭操作，如果有异常同样要做try-catch操作(JDK7及以上版本可以使用try-with-resource方式) 说明：因为finally块一定会在return前执行，所以，无论程序是否发生了异常，我们都可以在finally块中对资源对象、流对象、数据库连接等进行关闭或者释放，using其实是try…finally的语法糖，它会自动地在finally块里调用Dispose方法(因为它要实现IDispose接口)。 2.2.7 不能在finally块中使用return。 说明：这里涉及到一个return和finally，尽管return可以提前“跳出”，但对finally来说，不管是否发生异常，它都会执行，在此之前return会把返回值写入内存，等finally块执行结束后，return再“跳出”。C#中finally块中不允许写return，否则会导致编译错误。通常，finally块用来做清理相关的工作。 数据库 5.1.1 表达是否的概念时，必须使用is_xxx的命名方式，数据类型是unsigned tinyint。其中，1表示是，0表示否。 说明：表达是否最好用0和1来表示，我们用Y和N时经常会出现，开发人员忘记给模型赋值，导致进入到数据库里的数据出现错误数据，而领域模型里又不建议给字段默认值，可如果使用unsigned tinyint类型，它本身就自带默认值0，这样就可以避免这种问题的出现。 5.1.2 表名、字段名必须使用小写字母或数字，禁止出现数字开头，禁止两个下画线中间只出现数字。 说明：建议全部使用小写，因为主流SQL教程的里关键字都采用大写，但在PLSQL/SQLyog里编写SQL语句时，字段会自动地变成小写，而且不区分大小写，为了避免人格分裂，建议所有字段都用小写。我们表名用小写，表字段用大写，输出的SQL语句看起来特别奇怪。 5.1.13 字段允许适当冗余，以提高查询性能，但必须考虑数据一致。冗余字段应遵循： 不是频繁修改的字段 不是varchar超长字段，更不能是text字段。 说明：冗余字段是个好东西，但主表和扩展表间的一致性保证需要经过良好的设计，那种把相关表都放在一个事务里处理的做法，都声称是为了保证数据的一致性，可实际过程中依然会存在数据不一致的情况。 5.1.15 当单表行数超过500万行活着单表容量超过2G时，才推荐进行分库分表。 说明：多租户架构下，不同租户采用不同的库，是最简单的数据隔离方案，但缺点是增加了维护多个库的成本。如果要分库分表，最好从框架层面来“切库”，而不要让开发人员自行维护数据库的连接字符串。 5.2.1 业务上具有唯一特性的字段，即使是多个字段的组合，也必须建成唯一索引。根据墨菲定律，只要没有唯一索引，必然会有脏数据产生，即使在应用层做了非常完善的检验控制。 5.2.2 超过三个表禁止join，需要join的字段，类型必须绝对一致；当多表关联查询时，保证被关联的字段需要有索引。 说明：关系型数据库最值得炫耀的地方就是表多，超过三张表禁止join，实际中根本不现实，所以，建议以业务场景为准，我就曾经join了5张表，大概客户就喜欢看这些东西吧！ 5.3.7 禁止使用存储过程，存储过程难以调试和扩展，更没有移植性。 说明：存储过程和触发器是万恶之源，不同数据库下的SQL语句千姿百态，同样的业务逻辑，Oracle、MySQL和SQLServer基本上是三种语法，更不用说$$、/和@这种奇葩的东西了，查询语言就老老实实写查询，写业务了逻辑，SQL真的不行，太垃圾，虽然做权限划分非常容易…… 5.3.9 in操作能避免则避免，如实在避免不了，需要仔细评估in后面的集合元素数量，最好控制在1000之内。 说明：这一点表示认同，我们经常遇到这样的情况，先筛选出A表符合条件的所有记录，然后根据A表中某一列(通常是外键)，通过IN操作来筛选出B表中符合条件的所有记录，这个时候，应该注意控制IN后面集合内元素的数目，总之不要太大……","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://qinyuanpei.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"阿里","slug":"阿里","permalink":"https://qinyuanpei.github.io/tags/%E9%98%BF%E9%87%8C/"},{"name":"Java","slug":"Java","permalink":"https://qinyuanpei.github.io/tags/Java/"}]},{"title":"聊聊前端跨域的爱恨情仇","date":"2019-02-26T15:03:35.000Z","path":"posts/3846545990/","text":"今天是过完春节以后的第二周啦，而我好像终于回到正常工作的状态了呢，因为突然间就对工作产生了厌倦的情绪，Bug就像无底洞一样吞噬着我的脑细胞。人类就像一颗螺丝钉一样被固定在整部社会机器上，除了要让自己看起来像个正常人一样，还要拼命地让所有人都像个正常人一样。过年刚经历过被催婚的我，面对全人类近乎标准的“幸福”定义，大概就是我此刻这种状态。其实，除了想自己定义“幸福”以外，我还想自己定义“问题”，因为，这样就不会再有“Bug”了。言归正传，今天我想说的是前端跨域这个话题，相信读完这篇文章，你就会明白，这个世界上太多太多的问题，都和你毫无瓜葛。 故事缘起年前被安排去做一个GPS相关的需求，需要通过百度地图API来计算预计到达时间，这并不是一个有难点的需求，对吧？就在博主为此而幸灾乐祸的时候，一个非常醒目的错误出现在Chrome的控制台中，相信大家都见过无数次啦，大概是说我们的请求受到浏览器的同源策略的限制。那么，第一个问题，什么是同源策略呢？我们知道，一个URL通常有以下几部分组成，即协议、域名、端口和请求资源。由此我们就可以引申出同源的概念，当协议、域名和端口都相同时，就认为它们是在同一个域下，即它们同源。相反地，当协议、域名和端口中任意一个都不相同时，就认为它们在不同域下，此时就发生了跨域。按照排列组合，我们可以有以下常见的跨域场景： URL 说明 是否允许跨域 www.abc.com/a.js vs www.abc.com/b.js 相同域名下的不同资源 允许 www.abc.com/1/a.js vs www.abc.com/2/b.js 相同域名下的不同路径 允许 www.abc.com:8080/a.js vs www.abc.com:8081/b.js 相同域名下的不同端口 不允许 http://www.abc.com vs https://www.abc.com 相同域名采用不同协议 不允许 http://www.abc.com vs http://wtf.abc.com 相同域名下的不同子域 不允许 http://www.abc.com vs http://www.xyz.com 两个完全不同的域名 不允许 http://192.168.100.101 va http://www.wtf.com 域名及其对应的IP地址 不允许 那么，我们就不仅要问啦，现在微服务啊、RESTful啊这些概念非常流行，在我们实际的工作中，调用第三方的WebAPI甚至WebService，这难道不是非常合理的场景吗？前端的Ajax，即XMLHttpRequest，和我们平时用到的RestSharp、HttpClient、OkHttp等类似，都可以发起一个Http请求，怎么在客户端里用的好好的东西，到了前端这里就突然出来一个“跨域”的概念呢？这是因为从原理上来说，这些客户端都是受信的“用户”(好吧，假装是被信任的)，而浏览器的环境则是一个“开放”的环境。 URI_Syntax_Diagram 举一个例子，你在家的时候，可以随意地把手插进自己的口袋，因为这是你的私有环境。可是当你在公共环境中时，你是不允许把手插进别人口袋的。所以，浏览器有“跨域”限制，本质上是为了保护用户的数据安全，避免危险地跨域行为。试想，没有跨域的话，我们带上Cookie就可以为所欲为了，不是吗？实际上，同源限制和JavaScript没有一丁点关系，因为它是W3C中的内容，是浏览器厂商要这样做的，我们的请求其实是被发出去了，而它的响应则被浏览器给拦截了，所以我们在控制台中看到“同源策略限制”的错误。 喜闻乐见的跨域拦截 十八般武艺好了，既然现在浏览器有这个限制，那为了客户着想，我们还是要去解决这个问题(对吧？)，虽然我至今想不明白，适配浏览器为什么会成为我们的工作之一[doge]。打开Google搜索“前端跨域”，于是发现了解决跨域问题的各种方案，这里选取最具代表性的JSONP和CORS。 JSONP首先，我们来说说JSONP，什么是JSONP呢？我们知道，通常RESTful接口返回的都是JSON，而JSONP返回的是一段可以执行的JavaScript代码，我们所需要的数据就被“包裹”在这段代码中，这就是JSONP，即JSON Padding的得名由来。在实际应用中，服务的提供方会根据调用方传入的回调函数(callback)来组织返回数据，譬如callback({“name”:”tom”,“gender”:”male”})。这就说到一个点，并不是所有的API接口在调用的时候出现跨域问题，都可以通过JSONP的方式来解决，因为它需要后端来配合组织返回数据。这里我们以“不蒜子”这个静态博客中使用最多的访问量统计工具为例，通过查看页面源代码，我们了解到它是通过JSONP来返回数据的。为什么它要用这种方式来返回数据呢？其实，我们仔细想想就能明白其中的缘由，因为像Hexo、Jekyll这种静态博客大多都是没有后端服务支持的，所以，它要访问“不蒜子”的统计服务，就必然会存在跨域的问题啊！那怎么解决这个问题呢？当然是选择JSONP啦！这里我们以Postman调用不蒜子接口为例，可以发现它的返回值是下面这个样子： 在Postman中调用不蒜子接口 博主计划在接下来的时间里，迁移不蒜子的统计数据到LeanCloud上，届时博主会使用最喜欢的Python，来抓取这些访问量数据，因为JSONP返回的都不是JSON数据，因此再处理这些数据的时候，需要用正则来匹配这些结果。为什么在前端领域没有这些问题呢，因为JSONP返回的是世界上最“任性”的语言——JavaScript，当然，这些会是下一篇甚至下下一篇里的内容啦。 CORS好了，下面我们说说CORS这种方案。CORS，即跨域资源共享，是一种利用HTTP头部信息访问不同域下的资源的机制。我们在前面提到过，发生跨域访问时，其实请求已经发出去了，但响应则被浏览器给拦截住了。那么，CORS说白了就是它可以通过HTTP头部信息，告诉浏览器来自哪些域的请求可以被允许，来自哪些域的请求应该被禁止。如果说JSONP多少带着点“hack”的意味儿，那么CORS就可以说是被官方认可的跨域解决方案啦！这种方案需要启用新的HTTP头部字段，具体可以参考这里。 按照定义，浏览器会将CORS请求分为简单请求和非简单请求两类。对于简单请求，浏览器会对请求的头部进行“魔改”，即增加一个Origin字段，这样只要后端接口支持CORS跨域，就可以接收这些跨域请求，并做出回应，即在响应的头部信息中返回Access-Control-Allow-Origin等字段。而对于非简单请求，通常会先发出一个OPTIONS的“预检请求”，只有这个验证过程通过以后，主请求才会被发起。那么浏览器是怎么验证请求是否通过的呢？答案就是：检查Origin字段是否包含在Access-Control-Allow-Origin中。当验证不通过时，浏览器就会输出同源策略限制的错误。这就是CORS，浏览器和服务端分别通过响应、请求的HTTP头部信息来“商量”要不要跨域。 没有银弹说了这么多关于“跨域”的话题，其实博主想说的是，没有银弹。这是一位前辈高人，曾经对博主反复说过的话。现在我们来看JSONP，会发现它本质上是利用了浏览器的“漏洞”。为什么这样说呢？因为在浏览器中，所有具备src属性的HTML都是可以跨域的，譬如script、img、iframe、link这四个标签，我们赖以生存的CDN加速、图床、插件等等都是基于这一“漏洞”的产物。所以，很多人问为什么$.ajax可以跨域，但原生的XMLHttpRequest则不可以呢？因为jQuery实际上把JSONP做成了一种语法糖，这就就会给人一种ajax可以跨域的错觉。 JSONP？其实就是JSJSONP实际上返回的是可以执行的JavaScript，即text/javascript，它和我们所使用的大多数JavaScript并无区别，所以，你可以想到，当我们把一个远程地址赋值给script标签的src属性时，它和我们引用CDN上的医院文件并无区别，这正是JSONP的秘密所在，显然它只支持Get方式，当我们想要支持更多方式的时候，我们需要的是CORS，一起来看下面这段代码，我们首先来写一个简单的API接口： 12345678910111213141516171819// GET api/user/5?callback=[HttpGet(\"&#123;id&#125;\")]public IActionResult Get(string id, string callback)&#123; var userInfo = UserInfoService.Find(x =&gt; x.UserId == id); if (userInfo == null) return NotFound(); if (string.IsNullOrEmpty(callback)) &#123; //返回JSON Response.ContentType = \"application/json\"; return Json(userInfo); &#125; else &#123; //返回JSPNP Response.ContentType = \"application/javascript\"; return Content($\"&#123;callback&#125;(&#123;JsonConvert.SerializeObject(userInfo)&#125;)\"); &#125;&#125; OK，写完这个接口以后，我们首先来尝试在前端页面中调用这个接口，为了尽可能地减少依赖，我们这里用最新Fetch API来代替$.ajax()，毕竟现在都是2019年了呢，Github和Bootstrap相继宣布从代码中移除jQuery。大家都知道，原生的xhr和Date对象一样，简直难用得要命，而这一切在新的Fetch API下，会变得非常简单： 12345678910//基于Fecth API调用JSONPshowUserByFetch:function()&#123; fetch(\"https://localhost:5001/api/user/1\") .then(function(response) &#123; return response.json(); &#125;) .then(function(user) &#123; showUser(user); &#125;);&#125; 果然，就算使用最新的Fetch API，浏览器还是会因为同源限制策略而拦截我们的请求 浏览器中再次出现同源限制错误 那么，试试用JSONP的思路来解决这个问题。注意到，为了兼容JSONP方式调用，我们在API接口中增加了一个callback参数，这个参数实际上就是预先在客户端中定义好的方法的名字啦！既然JSONP返回的是可执行的JavaScript，那么我们在页面里增加一个Script标签好了： 1&lt;script src=\"https://localhost:5001/api/user/1?callback=showUser\"&gt;&lt;/script&gt; 其中，showUser是一个预先定义好的JS函数，其作用是输出用户信息到页面上： 12345//展示用户信息function showUser(user)&#123; var result = document.getElementById('jsonp-result'); result.innerText = '用户ID：' + user.uid + \", 姓名：\" + user.name + ', 性别：' + user.gender;&#125; 现在，我们可以注意到，在控制台中输出了我们期望的结果，这说明页面中定义的showUser()方法确实被执行了，所以，到这里我们可以对JSONP做一个简单总结：JSONP是一种利用script标签实现跨域的方案，它需要对后端接口进行适当改造以返回可以执行的JavaScript，客户端需要事先定义好接收数据的方法，两者通过callback参数建立起联系，返回类似callback({“name”:”tom”,“gender”:”male”})结构的数据，因此JSONP请求必然且只能是一个GET请求。 通过Script标签调用JSONP 既然通过Script标签可以调用一个JSONP接口，那么我们不妨试试动态创建Script标签，然后你就会发现这两种方式的效果是一样的，都可以调用一个JSONP接口，前提是JS中已经存在showUser()方法： 1234567//动态创建scipt调用JSONPshowUserByDynamic:function()&#123; var self = this; var script = document.createElement(\"script\"); script.src = \"https://localhost:5001/api/user/1?callback=showUser\"; document.body.appendChild(script); &#125;, 事实上，jQuery中针对JSONP的支持正是基于这种原理，虽然jQuery的时代终将过去，可我相信这些背后的原理永远不会过时。顺着这个思路，我们不妨来看看jQuery中是如何实现JSONP的，以下代码可以在这里找到： 12345678910111213141516171819202122232425262728293031// Bind script tag hack transportjQuery.ajaxTransport(\"script\",function(s) &#123; // This transport only deals with cross domain or forced-by-attrs requests if (s.crossDomain || s.scriptAttrs) &#123; var script, callback; return &#123; send: function(_, complete) &#123; script = jQuery(\"&lt;script&gt;\").attr(s.scriptAttrs || &#123;&#125;).prop(&#123; charset: s.scriptCharset, src: s.url &#125;).on(\"load error\", callback = function(evt) &#123; script.remove(); callback = null; if (evt) &#123; complete(evt.type === \"error\" ? 404 : 200, evt.type); &#125; &#125;); // Use native DOM manipulation to avoid our domManip AJAX trickery document.head.appendChild(script[0]); &#125;, abort: function() &#123; if (callback) &#123; callback(); &#125; &#125; &#125;; &#125;&#125;); 可以注意到，它和我们这里的思路一致，即动态创建一个script标签，然后设置其src属性为目标地址，当其加载完成或者加载失败时，就会从页面的DOM节点中删除该标签，因为数据已经通过指定的callback处理过了。jQuery甚至可以替我们生成对应的callback函数，例如，在这里我们可以这样使用jQuery来实现JSONP跨域，具体使用细节这里不再深究： 12345678910111213//基于$.ajax()调用JSONPshowUserByAjax:function()&#123; $.ajax(&#123; type: \"get\", url: \"http://localhost:5000/api/user/1\", dataType: \"jsonp\", jsonp: \"callback\", data: \"\", success: function (user) &#123; showUser(user); &#125; &#125;);&#125;, CORS，跨域新标准？相对JSONP来说，CORS实现起来就非常简单啦，因为主流的Web框架中几乎都提供了CORS的支持，因为CORS可以实现除了GET以外的譬如POST、PUT等请求，所以，它比JSONP这种”Hack“的方式有更为广阔的适用性，而且随着Web标准化的不断推荐，目前CORS可以说是官方主推的跨域方案。这里我们以.NET Core为例来讲解CORS跨域。 CORS，即同源资源共享，其实早在ASP.NET时代，这一机制就已经得到了支持，现在我们以.NET Core来讲，无非是希望大家放下历史包袱，在跨平台的新道路上轻装上阵。好了，在.NET Core中我们有两种CORS方案，一种是在Startup类中以全局配置的方式注入到整个中间件管道中，一种是以特性的方式在更小的粒度上控制CORS。这其实和之前配置路由的思路相近，即我们可以配置全局的路由模板，同样可以在Controller和Action级别上定义路由。在这里，我们先定义两种CORS策略，AllowAll和AllowOne，并以此来测试CORS实际的使用效果。 12345678910111213141516171819//CORS策略：简单粗暴一刀流 services.AddCors(opt=&gt;&#123; opt.AddPolicy(\"AllowAll\", builder =&gt; &#123; builder.AllowAnyOrigin(); builder.AllowAnyHeader(); builder.AllowAnyMethod(); &#125;); &#125;);//CORS策略：允许指定域services.AddCors(opt=&gt;&#123; opt.AddPolicy(\"AllowOne\", builder =&gt; &#123; builder.WithOrigins(\"http://localhost:8888\") .AllowAnyHeader() .AllowAnyMethod() .WithExposedHeaders(\"X-ASP-NET-Core\",\"X-UserName\") .AllowCredentials(); &#125;);&#125;); 可以注意到，在全局范围内应用AllowAll以后，我们的后端接口将支持来自任意域/端口的跨域访问，这意味着我们之前必须使用JSONP来跨域的地方，现在都可以直接发起跨域请求。到底是不是和我们想得一样呢？答案啊，那必须是肯定的啊！ 1234567[EnableCors(\"AllowOne\")][Route(\"api/[controller]\")][ApiController]public class UserController:Controller&#123; //...&#125; 好了，现在我们来测试在UserController上应用局部的CORS请求，在这个实例中，我们指定只有来自localhost:8888的请求可以跨域，为此博主这里用Python临时开了一个服务器，本文中的前端页面，实际上就是运行在这个服务器上的。你知道我想说什么，“人生苦短，我用Python”。因为我们这里返回的是application/json，所以它是一个非简单请求，这里复习一下简单请求与非简单请求。 简单请求根据MDN中关于CORS的定义，若请求满足所有下述条件，则该请求可视为“简单请求”，简单请求意味着不会触发CORS 预检请求： 使用下列方法之一：GET、HEAD、POST。 Fetch 规范定义了对 CORS 安全的首部字段集合，不得人为设置该集合之外的其他首部字段。该集合为：Accept、Accept-Language、Content-Language、Content-Type (需要注意额外的限制)、DPR、Downlink、Save-Data、Viewport-Width、Width。 Content-Type 的值仅限于下列三者之一：text/plain、multipart/form-data、application/x-www-form-urlencoded。 MDN中对简单请求的图解 非简单请求非简单请求和简单请求相反，即不满足简单请求中任一条件的请求都被成为非简单请求。非简单请求，相对简单请求多了一次CORS 预检请求。其过程是，首先由浏览器自动发起一个OPTION请求，该请求中携带HTTP头部字段Origin。在本例中，前端页面部署在http://localhost:8888服务器上，所以，它的Origin字段即为http://localhost:8888。接下来，服务端会返回Access-Control-Allow-Origin/Access-Control-Allow-Headers/Access-Control-Allow-Methods等字段，它对应我们后端定义的AllowOne，注意到这里我们有两个自定义字段X-ASP-NET-Core和X-UserName。在通过预检以后，我们在发起正式请求(本例中为GET请求)的时候，设置后端允许的源，即http://localhost:8888，这样就可以实现基于CORS的跨域请求啦！ MDN中对非简单请求的图解 所以，我们可以注意到，这里会有一个OPTION请求，即“预检请求”。对于AllowOne这个CORS策略而言，它允许来自localhost:8888的跨域请求，允许的请求方法有GET、PUT、POST和OPTION，客户端必须携带一个自定义HTTP头：X-ASP-NET-Core。当这三个条件满足时，即表示通过“预检”。此时，服务端会返回Access-Control-Allow-Origin/Access-Control-Allow-Methods/Access-Control-Allow-Headers等字段。接下来，浏览器发起的正式请求会带上这些字段，并返回我们所需要的JSON数据，这就是CORS跨域的实际过程。 OPTION预检请求 本文小结这篇文章主要梳理了目前前端跨域的两种主流方案(事实上，在奇葩的前端领域里，最不缺的就是解决方案)，即JSONP和CORS。其中，JSONP本质上是返回可以执行的JS，其基本套路是callback({“foo”:”bar”})，利用了HTML中含src的属性天生具备跨域能力的“漏洞”，是一种相对”hack”的方案，要求预先定义好callback，需要改造后端接口，仅支持最简单的GET请求。而CORS，是比较“官方”的跨域解决方案，其原理是利用HTTP头部字段对请求的来源进行检验，CORS支持除GET以外的请求动词，在使用中间件的情况下，无需修改后端接口，可以在全局或者局部配置CORS跨域策略，对后端开发相对友好。自从接触前端领域，对这个领域里的“黑科技”、“骚操作”吐槽无数次了，不过，前后端分离过程中这些事情还是挺有意思的，对吧？好了，以上就是这篇博客里的全部内容了，欢迎大家吐槽！本文中的示例请从：https://github.com/qinyuanpei/dotnet-sse/blob/master/server/index.html这里来获取，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"跨域","slug":"跨域","permalink":"https://qinyuanpei.github.io/tags/%E8%B7%A8%E5%9F%9F/"},{"name":"CORS","slug":"CORS","permalink":"https://qinyuanpei.github.io/tags/CORS/"},{"name":"JSONP","slug":"JSONP","permalink":"https://qinyuanpei.github.io/tags/JSONP/"}]},{"title":"基于Server-Sent Events实现服务端消息推送","date":"2019-01-18T13:46:44.000Z","path":"posts/3175881014/","text":"前段时间，为客户定制了一个类似看板的东西，用户可以通过看板了解任务的处理情况，通过APP扫面页面上的二维码就可以领取任务，而当任务被领取以后需要通知当前页面刷新。原本这是一个相对简单的需求，可是因为APP端和PC端是两个不同的Team在维护，换句话说，两个Team各自有一套自己的API接口，前端页面永远无法知道APP到底什么时候扫描了二维码，为此前端页面不得不通过轮询的方式去判断状态是否发生了变化。这种方式会发送大量无用的HTTP请求，因此在最初的版本里，无论是效率还是性能都不能满足业务要求，最终博主采用一种称为服务器推送事件(Server-Sent Events)的技术，所以，在今天这篇文章里，博主相和大家分享下关于服务器推送事件(Server-Sent Events)相关的内容。 什么是Server-Sent Events我们知道，严格地来讲，HTTP协议是无法做到服务端主动推送消息的，因为HTTP协议是一种请求-响应模型，这意味着在服务器返回响应信息以后，本次请求就已经结束了。可是，我们有一种变通的做法，即首先是服务器端向客户端声明，然后接下来发送的是流信息。换句话说，此时发送的不是一个一次性的数据包，而是以数据流的形式不断地发送过来，在这种情况下，客户端不会关闭连接，会一直等着服务器端发送新的数据过来，一个非常相似而直观的例子是视频播放，它其实就是在利用流信息完成一次长时间的下载。那么，Server-Sent Events(以下简称SSE)，就是利用这种机制，使用流信息像客户端推送信息。 说到这里，可能大家会感到疑惑：WebSocket不是同样可以实现服务端向客户端推送信息吗？那么这两种技术有什么不一样呢？首先，WebSocket和SSE都是在建立一种浏览器与服务器间的通信通道，然后由服务器向浏览器推送信息。两者最为不同的地方在于，WebSocket建立的是一个全双工通道，而SSE建立的是一个单工通道。所谓单工和双工，是指数据流动的方向上的不同，对WebSocket而言，客户端和服务端都可以发送信息，所以它是双向通信；而对于SSE而言，只有服务端可以发送消息，故而它是单向通信。从下面的图中我们可以看得更为直观，在WebSocket中数据”有来有往”，客户端既可以接受信息亦可发送信息，而在SSE中数据是单向的，客户端只能被动地接收来自服务器的信息。所以，这两者在通信机制上不同到这里已经非常清晰啦！ WebSocket与SSE对比 SSE服务端下面我们来看看SSE是如何通信的，因为它是一个单工通道的协议，所以协议定义的都是在服务端完成的，我们就从服务端开始吧！协议规定，服务器向客户端发送的消息，必须是UTF-8编码的，并且提供如下的HTTP头部信息： 123Content-Type: text/event-streamCache-Control: no-cacheConnection: keep-alive 这里出现了一个一种新的MIME类型，text/event-stream。协议规定，第一行的Content-Type必须是text/event-stream，这表示服务端的数据是以信息流的方式返回的，Cache-Control和Connection两个字段和常规的HTTP一致，这里就不再展开说啦！OK，现在客户端知道这是一个SSE信息流啦，那么客户端怎么知道服务端发送了什么消息呢？这就要说到SSE的消息格式，在SSE中消息的基本格式是： 1[field]: value\\n 其中，field可以取四个值，它们分别是：data、event、id、retry，我们来一起看看它们的用法。 data字段表示数据内容，下面的例子展示SSE中的一行和多行数据，可以注意到，当数据有多行时，可以用\\n作为每一行的结尾，只要保证最后一行以\\n\\n结尾即可。 1234567：这是一行数据内容data: SSE给你发了一行消息\\n\\n：这是多行数据内容data: &#123;\\ndata: \"foo\": \"foolish\",\\ndata: \"bar\", 2333\\ndata: &#125;\\n\\n event字段表示自定义事件，默认为message，在浏览器中我们可以用addEventListener()来监听响应的事件，这正是为什么SSE被称为服务器推送事件，因为我们在这里既可以发送消息，同样可以发送事件。 123456789: GameStart事件event: GameStart\\ndata: 敌军还有30秒到达战场\\n\\ndata: Double Kill\\n\\n: GameOver事件event: GaneOver\\ndata: You Win！\\n\\n *id *字段是一个数据标识符，相当于我们可以给每一条消息一个编号。 123456id: 1\\ndata: 敌军还有30秒到达战场\\n\\nid: 2\\ndata: Double Kill\\n\\nid: 3\\ndata: You Win！\\n\\n retry字段可以指定浏览器重新发起连接的时间间隔，所以，SSE天生就支持断线重连机制。 1retry: 10000\\n SSE客户端SSE目前是HTML5标准之一，所以，目前主流的浏览器(除了IE和Edge以外)都天然支持这一特性，这意味着我们不需要依赖前端娱乐圈推崇的各种工具链，就可以快速地使用SSE来投入开发。这里需要使用地是EventSource对象，我们从下面这个例子开始了解： 123456789101112131415161718192021222324252627if ('EventSource' in window) &#123; var source = new EventSource(url, &#123; withCredentials: true &#125;); /* open事件回调函数 */ source.onopen = function()&#123; console.log('SSE通道已建立...'); &#125;; /* message事件回调函数 */ source.onmessage = function(evt)&#123; console.log(evt.data); &#125; /* error事件回调函数 */ source.onerror = function(evt)&#123; console.log('SSE通道发生错误'); &#125; /* 自定义事件回调 */ source.addEventListener('foo', function (event) &#123; var data = event.data; // handle message &#125;,false); /* 关闭SSE */ source.close()&#125; 和各种各样的HTML5接口一样，我们需要判断当前的浏览器环境是否支持SSE。建立SSE只需要后端提供一个Url即可，当存在跨域时，我们可以打开第二个参数：withCredentials，这样SSE会在建立通道时携带Cookie。我们通过实例化后的source对象来判断通道是否建立，该对象有一个重要的属性：readyState。当它的取值为0时，表示连接还未建立，或者断线正在重连；当它的取值为1时，表示连接已经建立，可以接受数据；当它的取值为2时，表示连接已断，且不会重连。 好了，当SSE被成功建立以后，首先会触发open事件。这里介绍下SSE中的关键事件，即open、message和error，我们可以分别通过onopen、onmessage和onerror这三个回调函数来监听相应的事件。对于SSE而言，它是一个单工通道，客户端不能主动向服务端发送信息，所以，一旦建立了SSE通道，客户端唯一需要关注的地方就是onmessage这个回调函数，因为客户端只需要负责处理消息即可，甚至我们可以连onerror都不用关注，因为SSE自带断线重连机制，当然你可以选择在发生错误的时候关掉连接，此时你需要close()方法。 我们在上面提到，SSE在服务端可以定义自定义事件，那么，在浏览器中我们该如何接收这些自定义事件呢？这当然要提到无所不能的addEventListener，在人肉操作DOM的jQuery时代，jQuery中提供的大量API在协调不同浏览器间差异的同时，让我们离这些底层的知识越来越远，时至今日，当erySelector/querySelectorAll完全可以替换jQuery的选择器的时候，我们是不是可以考虑重新把某些东西捡起来呢？言归正传，在SSE中，我们只需要像注册普通事件一样，就可以完成对自定义事件的监听，只要客户端和服务端定好消息的协议即可。 在.NET中集成Server-Sent EventsOK，说了这么多，大家一定感觉有一个鲜活的例子会比较好一点，奈何官方提供的示例都是PHP的，难道官方默认PHP是世界上最好的编程语言了吗？所谓万变不离其宗”，下面我们以.NET为例来快速集成Server-Sent Events，这里需要说明的是，博主下面的例子采用ASP.NET Core 2.0版本编写，首先，我们建一个名为SSEController的控制器，在默认的Index()方法中，按照SSE规范，我们首先组织HTTP响应头，然后发送了一个名为SSE_Start的自定义事件，接下来，我们每隔10秒钟给客户端发送一条消息，请原谅我如此敷衍的Sleep()： 12345678910111213141516171819202122232425[Route(\"api/[controller]\")][ApiController]public class SSEController : Controller&#123; [HttpGet] public IActionResult Index() &#123; //组织HTTP响应头 Response.Headers.Add(\"Connection\", \"keep-alive\"); Response.Headers.Add(\"Cache-Control\", \"no-cache\"); Response.Headers.Add(\"Content-Type\", \"text/event-stream\"); //发送自定义事件 var message = BuildSSE(new &#123; Content = \"SSE开始发送消息\", Time = DateTime.Now &#125;, \"SSE_Start\"); Response.Body.Write(message, 0, message.Length); //每隔10秒钟向客户端发送一条消息 while (true) &#123; message = BuildSSE(new &#123; Content = $\"当前时间为&#123;DateTime.Now&#125;\" &#125;); Response.Body.Write(message, 0, message.Length); Thread.Sleep(10000); &#125; &#125;&#125; 我们提到，SSE的数据是按照一定的格式，由id、event、data和retry四个字段构成的，那么，织消息格式的代码我们放在了BuildSSE()方法中，我们来一起看看它的实现： 12345678910private byte[] BuildSSE&lt;TMessage&gt;(TMessage message, string eventName = null, int retry = 30000)&#123; var builder = new StringBuilder(); builder.Append($\"id:&#123;Guid.NewGuid().ToString(\"N\")&#125;\\n\"); if (!string.IsNullOrEmpty(eventName)) builder.Append($\"event:&#123;eventName&#125;\\n\"); builder.Append($\"retry:&#123;retry&#125;\\n\"); builder.Append($\"data:&#123;JsonConvert.SerializeObject(message)&#125;\\n\\n\"); return Encoding.UTF8.GetBytes(builder.ToString());&#125; 可以看到，完全按照SSE规范来定义的，这里每次生成一个新的GUID来作为消息的ID，客户端断线后重连的间隔为30秒，默认发送的是“消息”，当指定eventName参数时，它就表示一个自定义事件，这里我们使用JSON格式来传递信息。好了，这样我们就完成了服务端的开发，怎么样，是不是感觉非常简单呢？我们先让它跑起来，下面着手来编写客户端，这个就非常简单啦！ 1234567891011121314151617181920212223242526272829303132&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;body&gt;&lt;h1&gt;DotNet-SSE&lt;/h1&gt;&lt;div id=\"result\"&gt;&lt;/div&gt;&lt;script&gt;if ('EventSource' in window) &#123; var source = new EventSource('http://localhost:5000/api/SSE/'); /* open事件回调函数 */ source.onopen = function()&#123; document.getElementById(\"result\").innerHTML+= \"SSE通道已建立...&lt;br/&gt;\"; &#125;; /* message事件回调函数 */ source.onmessage = function(evt)&#123; document.getElementById(\"result\").innerHTML+= \"Message: \" + event.data + \"&lt;br/&gt;\"; &#125; /* error事件回调函数 */ source.onerror = function(evt)&#123; document.getElementById(\"result\").innerHTML+= \"SSE通道发生错误&lt;br/&gt;\"; &#125; /* SSE_Start事件回调 */ source.addEventListener('SSE_Start', function (event) &#123; document.getElementById(\"result\").innerHTML += \"SSE_Start: \" + event.data + \"&lt;br/&gt;\"; &#125;,false);&#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 此时，不需要任何现代前端方面的技术，我们直接打开浏览器，就可以看到： SSEDemo 更为直观的，我们可以通过Chrome开发者工具观察到实际的请求情况，相比普通的HTTP请求，SSE会出现一个名为EventStream的选项卡，这是因为我们在服务端设置的Content-Type为text/event-stream的缘故，可以注意到，我们定义的id(GUID)会在这里显示出来： 有点与众不同的SSE 同类技术优劣对比OK，这篇文章写到这里，相信大家已经对SSE有了一个比较具体的概念，那么，我们不妨来梳理下相关的同类技术。一路走过来，我们大体上经历了(短)轮询、长轮询/Comet、SSE和WebSocket。 (短)轮询这个比较容易理解了，它从本质上来讲，就是由客户端定时去发起一个HTTP请求，这种方式是一种相对尴尬的方式，为什么这样说呢？因为时间间隔过长则无法保证数据的时效性，而时间间隔过短则会发送大量无用的请求，尤其是当客户端数量比较多的时候，这种方式很容易耗尽服务器的连接数。 而长轮询则是(短)轮询的一个变种，它和(短)轮询最大的不同在于，服务端在接收到请求以后，并非立即进行响应，而是先将这个请求挂起，直到服务器端数据发生变化时再进行响应。所以，一个明显的优势是，它相对地减少了大量不必要的HTTP请求，那么，它是不是就完美无暇了呢？当然不是，因为服务端会将客户端发来的请求挂起，因此在挂起的那些时间里，服务器的资源实际上是被浪费啦！ 严格地说，SSE并不是一门新技术，为什么这样说呢？因为它和我们基于HTTP长连接的Push非常相似。这里又提到一个新概念，HTTP长连接，其实，这个说法病逝非常严谨，因为我们知道HTTP最早就是一个请求-响应模型，直到HTTP1.1中增加了持久连接，即Connection:keep-alive的支持。所以，我们这里说的长连接、短链接实际上都是指TCP的长连接还是短连接，换句话说，它和客户端没有关系，只要服务端支持长连接，那么在某个时间段内的TCP连接实际上复用的，进而就能提高HTTP请求性能，曾经我们不是还用iframe做过长连接吗？ WebSocket作为构建实时交互应用的首选技术，博主曾经在《基于WebSocket和Redis实现Bilibili弹幕效果》一文中有所提及，WebSocket相比前面这些技术，最大的不同在于它拥有专属的通信通道，一旦这个通道建立，客户端和服务端就可以互相发送消息，它沿用了我们传统的Socket通讯的概念和原理，变被动为主动，无论是客户端还是服务端，都不必再被动地去“拉”或者“推”。在这个过程中，出现了像SignalR/SocketIO等等的库，它们主打的兼容性和降级策略，曾经一度让我们感到亲切，不过随着WebSocket标准化的推进，相信这些最终都会被原生API所替代吧，也许是有生之年呢？谁知道未来是什么样子呢？ 下面给出针对以上内容的“简洁”版本： （短)轮询 长轮询/Comet SSE WebSocket 浏览器支持 全部 全部 除IE/Edge 现代浏览器 是否独立协议 HTTP HTTP HTTP WS 是否轻量 是 否 是 否 断线重连 否 否 是 否 负载压力 占用内存/请求数 同（短)轮询 一般 同SSE 数据延迟 取决于请求间隔 同（短)轮询 实时 实时 本文小结正如本文一开始所写，博主使用SSE是因为业务上的需要，在经历了轮询带来的性能问题以后，博主需要一款类似WebSocket的东西，来实现服务端主动向客户端推送消息，究其原因，是因为浏览器永远都不知道，App到底什么时候会扫描二维码，所以，从一开始我们试图让网页去轮询的做法，本身就是不太合理的。那么，为什么没有用WebSocket呢？因为WebSocket需要一点点框架层面的支持，所以，我选择了更为轻量级的SSE，毕竟，这比让其它Team的同事去调整他们的后端接口要简单的多。我之前参与过一部分WebSocket相关的项目，我深切地感受到，除了在浏览器的兼容性问题以外，因为WebSocket使用的是独有的WS协议，所以，我们常规的API网关其实在这方面支持的都不是很好，更不用说鉴权、加密等等一系列的问题啦，而SSE本身是基于HTTP协议的，我们目前针对HTTP的各种基础设施，都可以直接拿过来用，这应该是我最大的一点感悟了吧，好了，这篇文章就是这样啦，谢谢大家，新的一年注定要重新开始的呢…… 参考文章 IBM - Comet：基于 HTTP 长连接的“服务器推”技术 Mozilla - 使用服务器发送事件 阮一峰 - Server-Sent Events 教程 呆呆_小茗 - Ajax轮询，Ajax长轮询和Websocket(详细使用) hrhguanli - HTTP长连接和短连接","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"WebSocket","slug":"WebSocket","permalink":"https://qinyuanpei.github.io/tags/WebSocket/"},{"name":"SSE","slug":"SSE","permalink":"https://qinyuanpei.github.io/tags/SSE/"},{"name":"后端","slug":"后端","permalink":"https://qinyuanpei.github.io/tags/%E5%90%8E%E7%AB%AF/"}]},{"title":"博客图片迁移折腾记","date":"2019-01-18T09:27:35.000Z","path":"posts/3444626340/","text":"&emsp;&emsp;去年国庆的时候，七牛官方开始回收测试域名，这直接导致博客中大量图片出现无法访问的情况，虽然博主第一时间启用了新的域名：https://blog.yuanpei.me，可是因为七牛官方要求域名必须备案，所以，这件事情一直耽搁着没有往下进行。至于为什么会一直拖到2019年，我想大家都能猜到一二，没错，我就是懒得去弄域名备案这些事情:joy:。最近花了点时间，把博客里的图片从七牛和CSDN迁移了出来，所以，今天这篇博客，主要想和大家分享下这个折腾的过程，如果能帮助到和我一样，因为七牛官方回收了域名而无法导出图片的朋友，在下开心之至。虽然今天没有回望过去，没有给新的一年立flag，就如此平淡地过渡到了2019年，可或许这才是生活本来的样子吧！ &emsp;&emsp;七牛的测试域名被官方回收了以后，我们有两种思路去导出这些图片，其一，是临时像官方提工单申请一个测试域名，这样在测试域名被回收前，我们可以直接使用官方提供的qrsctl或者qshell工具进行批量导出，因为此时我们可以直接在配置文件里配置测试域名，具体可以参考这篇文章：跑路之后七牛图片如何导出备份至本地，甚至你可以直接到七牛的管理控制台手动下载，可这样就一点都不极客了对吗？我们是一生追求做极客的人好伐。其二，同样是借助官方提供的qshell工具，因为没有域名，我们没有办法批量导出，可是工具中提供了两个非常有用的命令，它们分别是：qshell listbucket、qshell get。通过这两个命令，我们就可以列举出指定bucket中的文件以及下载指定文件，所以，这就是我们的第一步，首先把图片从七牛那里导出到本地。以博主的blogspace为例： 12qshell account &lt;ak&gt; &lt;sk&gt; 'qinyuanpei@163.com' /* 请使用你的ak/sk，谢谢 */qshell listbucket blogspace 使用listbucket列举指定bucket内文件 &emsp;&emsp;事实上，通过第一列的Key，即文件名，我们就可以下载该资源到本地，因为七牛实际上是采用对象存储的方式来组织资源的，这里我们以第一张图片05549344-BF85-4e8c-BCBC-1F63DFE80E43.png为例： 1qshell get blogspace 05549344-BF85-4e8c-BCBC-1F63DFE80E43.png &emsp;&emsp;默认情况下，该图片会下载到当前目录下，本地文件和远程文件名保持一致。当然，我们还可以通过-o参数来指定输出文件： 使用get命令下载指定文件 &emsp;&emsp;好了，有了这个基础，我们就可以着手博客图片的迁移啦。博主最初的想法是，先获取到指定bucket下的全部文件，然后再对结果进行拆分，循环执行qshell get命令，可惜再PowerShell下并没有类似grep的命令，所以，这个想法放弃。其实，你仔细观察七牛图片外链的格式就会发现，除了域名部分以外，剩下的就是该文件在bucket里对应的key啦，所以，博主的想法开始从Markdown文件入手，最终我们的思路是，解析博客对应的Markdown文件，通过正则匹配所有的图片链接，截取出图片的文件名并通过qshell下载到本地。人生苦短，我用Python。具体写出来，大概是下面这个样子： 123456789101112131415161718192021222324252627def sync(root,ak,sk,account,bucket): files = [] children = os.listdir(root) for child in children: path = os.path.join(root,child) if os.path.isfile(path): files.append(path) for file in files: links = [] newContent = '' with open(file,'rt',encoding='utf-8') as fp: content = fp.read() matches = re.compile('!\\\\[.*?\\\\]\\\\((.*?)\\\\)').findall(content) if(len(matches)&gt;0): links.extend(matches) for link in links: fileKey = link.split('/')[-1] if('http://img.blog.csdn.net' in link): newLink = sync_csdn(link) newContent = content.replace(link,newLink) elif('clouddn.com' in link): newLink = sync_qiniu(ak,sk,account,bucket,fileKey) newContent = content.replace(link,newLink) if(newContent != '' and len(links) &gt; 0): with open(file,'wt',encoding='utf-8') as fp: fp.write(newContent) print('已自动完成对&#123;0&#125;中图片链接的自动更新'.format(file)) &emsp;&emsp;因为博主的博客，在此之前(指2012年~2018年，暴露年龄啦ORZ)，主要都在：https://blog.csdn.net/qinyuanpei这里维护，所以，这次就一并通过脚本处理啦。这部分我们这里不用太关注，对于托管在七牛上的图片资源，我们通过sync_qiniu方法来完成同步： 123456789101112def sync_qiniu(ak,sk,account,bucket,fileKey): os.system('qshell account &#123;0&#125; &#123;1&#125; &#123;2&#125; -w'.format(ak,sk,account)) outfile = root + \"\\\\download\\\\blogspace\\\\\" + fileKey outfile = outfile.replace('\\\\','/') if(os.path.exists(outfile)): os.remove(outfile) os.system('qshell get &#123;0&#125; &#123;1&#125; -o &#123;2&#125;'.format(bucket,fileKey,outfile)) print(\"同步七牛图片&#123;0&#125;完成\".format(fileKey)) pid = upload(outfile) if(pid != None): print('同步后的图片链接为:' + upload(outfile)) return pid &emsp;&emsp;博客中的图片导出到本地以后，我们就要开始考虑第二个问题，这些图片要放到哪里去，直接和博客放在一起，估计早晚会突破Github单个仓库1G的限制。七牛增加域名备案的限制以后，像又拍云这种同类产品必须会跟进这个feature，原因嘛，我想大家都知道不必多说。大概考虑了像阿里云和腾讯云的OSS类产品，因为我司的产品最近正在着手从自有的FTP上切换到阿里云的OSS上，主要是考虑服务器的维护成本，但对博主这样的个人用户而言，这类OSS产品实在太贵了，最终，博主选择国内某知名社交平台提供的“图床服务”。参考这篇文章：PHP上传图片到微博图床，最终实现了一个简洁(陋)的版本： 123456789101112131415161718def upload(src_file): url = \"http://picupload.service.weibo.com/interface/pic_upload.php\" fileExt = src_file.split('.')[-1] if(fileExt == 'png'): fileExt = 'jpg' timestamp = str(int(time.time())) mimes = &#123;\"gif\":'image%2Fgif','jpg':'image%2Fjpeg','jpeg':'image%2Fjpeg'&#125; querystring = &#123;\"mime\":mimes[fileExt],\"data\":\"base64\",\"url\":\"0\",\"markpos\":\"1\",\"logo\":\"\",\"nick\":\"0\",\"marks\":\"1\",\"app\":\"miniblog\",\"cb\":\"http://weibo.com/aj/static/upimgback.html?_wv=5\",\"callback\":\"STK_ijax_\" + timestamp&#125; headers = &#123; 'Cookie': \"在这里填入Cookie\", &#125; files = &#123;'pic1':open(src_file,'rb').read()&#125; response = requests.request(\"POST\", url, headers=headers, params=querystring,files=files) if(response.status_code == 200): result = re.sub(r\"&lt;meta.*&lt;/script&gt;\", \"\", response.text, flags=re.S) image_result = json.loads(result) image_id = image_result.get('data').get('pics').get('pic_1').get('pid') return 'https://ww1.sinaimg.cn/large/&#123;0&#125;.&#123;1&#125;'.format(image_id,fileExt) &emsp;&emsp;如果你现在访问我的博客，大概就会发现，之前那些无法显示的图片，现在基本上都可以显示啦，而我所做的事情，就是执行这些Python脚本，让它帮我完成从图片下载、上传再到替换链接的所有事情。感觉配合Typora在插入图片时可以拷贝到指定目录的功能，完全可以支持本地图片链接自动替换的功能，这样子以后写博客的时候，只要插入准备后的本地图片就好了，真是想想都觉得美好呢？我和一位朋友分享了这个想法，他觉得“微博图床”并不靠谱，这样说起来，它最不好的地方大概就是没有办法保留原有的文件名，所以，万一将来有一天它挂了，你要恢复这些图片会比较麻烦，一个好的建议是维护一个数据库，譬如SQLite足矣，把本地文件名和远程文件名对应起来，甚至你可以把图片的Base64编码存储到数据库里呢，对吧？ &emsp;&emsp;好了，以上就这2019年第一篇碎碎念啦，为了证明我的思维的确是跳跃的，最后的最后，强烈地向大家安利两个图床工具：WeiBox、PicGo，它们都支持微博图床，所以，你猜我是用哪个工具上传这篇文章里地图片的呢？当然是脚本啊，那样不就不那么极客了嘛，我们是一生追求做极客的人好伐！:v:","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"七牛","slug":"七牛","permalink":"https://qinyuanpei.github.io/tags/%E4%B8%83%E7%89%9B/"},{"name":"图床","slug":"图床","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%BE%E5%BA%8A/"}]},{"title":"基于EF的数据库主从复制、读写分离实现","date":"2018-10-18T08:41:08.000Z","path":"posts/2418566449/","text":"&emsp;&emsp;各位朋友，大家好，欢迎大家关注我的博客，我是Psyne，我的博客地址是https://blog.yuanpei.me。在上一篇博客中，我们提到了通过DbCommandInterceptor来实现EF中SQL针对SQL的“日志”功能。我们注意到，在这个拦截器中，我们可以获得当前数据库的上下文，可以获得SQL语句中的参数，更一般地，它具备“AOP”特性的扩展能力，可以在执行SQL的前后插入相应的动作，这就有点类似数据库中触发器的概念了。今天，我们主要来说一说，基于EF实现数据库主从复制和读写分离，希望这个内容对大家有所帮助。 主从复制 ＆ 读写分离&emsp;&emsp;首先，我们先来了解一个概念：主从复制。那么，什么是主从复制呢？通常，在只有一个数据库的情况下，这个数据库会被称为主数据库。所以，当有多个数据库存在的时候，数据库之间就会有主从之分，而那些和主数据库完全一样的数据库就被称为从数据库，所以，主从复制其实就是指建立一个和主库完全一样的数据库环境。 &emsp;&emsp;那么，我们为什么需要主从复制这种设计呢？我们知道，主数据库一般用来存储实时的业务数据，因此如果主数据库服务器发生故障，从数据库可以继续提供数据服务，这就是主从复制的优势之一，即作为数据提供灾备能力。其次，从业务扩展性上来讲，互联网应用的业务增长速度普遍较高，随着业务量越来越大，I/O的访问频率越来越高，在单机磁盘无法满足性能要求的情况下，通过设置多个从数据库服务器，可以降低磁盘的I/O访问频率，进而提高单机磁盘的读写性能。从业务场景上来讲，数据库的性能瓶颈主要在读即查询上，因此将读和写分离，能够让数据库支持更大的并发，这对优化前端用户体验很有意义。 &emsp;&emsp;通常来讲，不同的数据库都在数据库层面上实现了主从复制，各自的实现细节上可能会存在差异，譬如SQLServer中可以通过“发布订阅”来配置主从复制的策略，而Oracle中可以通过DataGurd来实现主从复制，甚至你可以直接把主库Dump出来再导入到从库。博主没有能力详细地向大家介绍它们的相关细节，可博主相信“万变不离其宗”的道理，这里我们以MySQL为例，因为它在互联网应用中更为普遍，虽然坑会相应地多一点:)…… &emsp;&emsp;MySQL中有一种最为重要的日志binlog，即二进制日志，它记录了所有的DDL和DML(除查询以外)语句，通过这些日志，不仅可以作为灾备时的数据恢复，同样可以传递给从数据库来达到数据一致的目的。具体来讲，对于每一个主从复制的连接，都有三个线程，即拥有多个从库的主库为每一个从库创建的binlog输出线程，从库自身的IO线程和SQL线程： 当从库连接到主库时，主库就会创建一个线程然后把binlog发送到从库，这是binlog输出线程。 当从库执行START SLAVER以后，从库会创建一个I/O线程，该线程连接到主库并请求主库发送binlog里面的更新记录到从库上。从库I/O线程读取主库的binlog输出线程发送的更新并拷贝这些更新到本地文件(其中包括relay log文件)。 从库创建一个SQL线程，这个线程读取从库I/O线程写到relay log的更新事件并执行。 EF中主从复制的实现&emsp;&emsp;虽然从数据库层面上做主从复制会更简单一点，可在很多时候，这些东西其实更贴近DBA的工作，而且不同数据库在操作流程上还都不一样，搞这种东西注定不能成为“通用”的知识领悟。对开发人员来说，EF和Dapper这样的ORM更友好一点，如果可以在ORM层面上做触发器和存储过程，可能SQL看起来就没有那么讨厌了吧！博主的公司因为要兼顾主流的数据库，所以，不可能在数据库层面上去做主从复制，最终我们是通过EF来实现主从复制。 &emsp;&emsp;其实，讲了这么多主从复制的原理，对我们来说，这篇文章的实现则是非常简单的。因为通过DbCommandInterceptor我们能拦截到SQL命令，所以，只要是Select命令全部走从库，Insert/Update/Delete全部走主库，这样就实现了读写分离。怎么样，是不是感觉相当简单啊！当然，前提是要准备好主从库的屋里环境，这些就让DBA去折腾吧(逃。好了，下面一起来看具体代码，首先我们定义一个主从库管理类MasterSlaveManager： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public static class MasterSlaveManager&#123; private static MasterSalveConfig _config =&gt; LoadConfig(); /// &lt;summary&gt; /// 加载主从配置 /// &lt;/summary&gt; /// &lt;param name=\"fileName\"&gt;配置文件&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public static MasterSalveConfig LoadConfig(string fileName = \"masterslave.config.json\") &#123; if (!File.Exists(fileName)) throw new Exception(string.Format(\"配置文件&#123;0&#125;不存在\", fileName)); return JsonConvert.DeserializeObject&lt;MasterSalveConfig&gt;(File.ReadAllText(fileName)); &#125; /// &lt;summary&gt; /// 切换到主库 /// &lt;/summary&gt; /// &lt;param name=\"command\"&gt;DbCommand&lt;/param&gt; public static void SwitchToMaster(DbCommand command, string serverName = \"\") &#123; var masterServer = string.IsNullOrEmpty(serverName) ? _config.Masters.FirstOrDefault() : _config.Masters.FirstOrDefault(e =&gt; e.ServerName == serverName); if (masterServer == null) throw new Exception(\"未配置主库服务器或者服务器名称不正确\"); //切换数据库连接 ChangeDbConnection(command, masterServer); &#125; /// &lt;summary&gt; /// 切换到从库 /// &lt;/summary&gt; /// &lt;param name=\"command\"&gt;DbCommand&lt;/param&gt; public static void SwitchToSlave(DbCommand command, string serverName = \"\") &#123; var salveServer = string.IsNullOrEmpty(serverName) ? _config.Slaves.FirstOrDefault() : _config.Slaves.FirstOrDefault(e =&gt; e.ServerName == serverName); if (salveServer == null) throw new Exception(\"未配置从库服务器或者服务器名称不正确\"); //切换数据库连接 ChangeDbConnection(command, salveServer); &#125; /// &lt;summary&gt; /// 切换数据库连接 /// &lt;/summary&gt; /// &lt;param name=\"command\"&gt;&lt;/param&gt; /// &lt;param name=\"dbServer\"&gt;&lt;/param&gt; private static void ChangeDbConnection(DbCommand command, DbServer dbServer) &#123; var conn = command.Connection; if (conn.State == System.Data.ConnectionState.Open) conn.Close(); conn.ConnectionString = dbServer.ConnectionString; conn.Open(); &#125;&#125; 接下来，和之前关于EF中的SQL拦截器类似，我们定义一个名为MasterSlaveDbInterceptor的拦截器： 123456789101112131415161718192021222324252627public class MasterSlaveDbInterceptor : DbCommandInterceptor&#123; public override void NonQueryExecuting(DbCommand command, DbCommandInterceptionContext&lt;int&gt; interceptionContext) &#123; //Insert/Update(写操作)走主库 MasterSlaveManager.SwitchToMaster(command); base.NonQueryExecuting(command, interceptionContext); &#125; public override void ScalarExecuting(DbCommand command, DbCommandInterceptionContext&lt;object&gt; interceptionContext) &#123; //Select(读操作)走从库 var sqlText = command.CommandText; if (!sqlText.ToUpper().StartsWith(\"INSERT\") || !sqlText.ToUpper().StartsWith(\"UPDATE\")) MasterSlaveManager.SwitchToSlave(command); base.ScalarExecuting(command, interceptionContext); &#125; public override void ReaderExecuting(DbCommand command, DbCommandInterceptionContext&lt;DbDataReader&gt; interceptionContext) &#123; //Select(读操作)走从库 var sqlText = command.CommandText; if (!sqlText.ToUpper().StartsWith(\"INSERT\") || !sqlText.ToUpper().StartsWith(\"UPDATE\")) MasterSlaveManager.SwitchToSlave(command); base.ReaderExecuting(command, interceptionContext); &#125;&#125; 至此，我们就实现了基于EF的数据库主从复制、读写分离。其实，更严谨的说法是，主从复制是在数据层面上完成的，而读写分离则是在代码层面上完成。当然，实际应用中需要考虑事务、数据库连接等因素，这里我们仅仅提供一种思路。这里我们的配置文件中，对主、从数据库进行了简单配置，即一主一从。在实际应用中，可能我们会遇到一注多从的情况，在这个基础上，我们又可以延申出新的话题，譬如在存在多个从库的情况下，通过心跳检测来检查从库服务器的健康状态，以及如何为不同的从库服务器设置权重，实现多个从库服务器的负载均衡等等。我们在微服务中提出的“健康检查”和“负载均衡”等概念，其实都可以映射到这里来，我想这是真正值得我们去深入研究的地方。 本文小结&emsp;&emsp;并没有，いじょう","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"EF","slug":"EF","permalink":"https://qinyuanpei.github.io/tags/EF/"},{"name":"读写分离","slug":"读写分离","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/"},{"name":"主从复制","slug":"主从复制","permalink":"https://qinyuanpei.github.io/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/"}]},{"title":"戏里戏外的一出好戏","date":"2018-10-11T09:02:05.000Z","path":"posts/1127467740/","text":"&emsp;&emsp;上周国庆节放假，在家里看了黄渤的导演处女座《一出好戏》，虽然网上对它的评价还不错，可当我真正看完了这部电影，我反而觉得它更适合一个人的时候去看，因为在“演而优则导”的大趋势下，越来越多的人都在尝试“触电”，前有角逐奥斯卡的《逐梦演艺圈》，后有倒卖情怀的《爱情公寓》大电影，在这样一个充斥着“浮躁”的娱乐时代，有这样一类充满哲学意味的电影，可以说这是中国电影里的“净土”。不知道是不是因为年龄大了的缘故，对打打杀杀的动作戏显得视觉疲劳，有时候更愿意看点安静平淡的东西，这部电影所吸引我的，是某个镜头里无比空旷而迷离的故事和人们。 &emsp;&emsp;“一出好戏”这四个字一出，陡然间有种开了上帝视角的感觉。其实，我们总以为在看戏里的别人，我们又何尝不是这戏里的人？就像人们觉得大街上耍猴有意思，人们看着被驯化的猴子，遵从人们的指令做出各种动作，人们瞬间有了种睥睨众生的感觉，可明明人类就是由猿猴进化而来，想到这一点，你忽然觉得人类世界的奇妙之处，即人类以自身有限的认知，所勾勒和描绘出的这个世界，其实永远都是冰山一角，在某种情况下，这种体系的崩塌，我让我们不得不重新审视自我的合理性，所谓“你站在桥上看风景，看风景的人在楼上看你 。明月装饰了你的窗子，你装饰了别人的梦”。 &emsp;&emsp;整个故事架设在一个现代文明被摧毁的世界里，因为天外陨石落入海洋引发巨大海啸，男主马进及公司参与团建的众人，被困在一个与世隔绝的孤单上面。故事从男主颇具“屌丝”气质的自嘲开始，男主名叫马进，是一个在公司里基本没有存在感的人，连想给心仪的女生买饮料都要拐弯抹角，渴望通过买彩票实现一夜暴富的理想。这的确是一个普通社会阶层的真实写照，如男主所言，即便陨石真的落到地球上，像男主这样一穷二白的人，真的是穷到无所畏惧，可转眼间发现自己中了6000万彩票，同时流落到一个荒无人烟的孤单，如此喜剧性的一幕，无非是在质问我们，如果整个世界都遭遇崩塌，我们所在乎的这些，又到底该算作什么呢？ &emsp;&emsp;我们不妨看看众人的反应，面对这样一个突如其来的灾难，首先被诘难的是史教授，它代表的是某种社会权威。接下来，被诘难的是张总，它代表是组织权威。这其实可以理解为一个群体引发的信任危机，史教授作为这个集体中的高端人才，他必须在抚慰群众人情绪和顾及自身尊严这两点上找到一个平衡，所以，他的做法是向大家“部分地”承认错误。而张总从一开始的认为“有钱可以搞到船”，到最后在岛上绝望地散尽“千金”，这同样是因为群体性的信任危机，所以，第一个点是，群体性的“信任危机”往往代表着某种体系崩溃的开始。马进身上的矛盾恰恰就在于此，他带着一个可能已经崩塌的世界里的产物——彩票，来到了一个全新的世界里，而在这个世界里，彩票是undefined，彩票映射的是作为一般等价物的货币，同样，货币在这个世界里是undefined。 &emsp;&emsp;所以，电影所描绘的，其实更像是人类从无到有的演化过程。在众人缺乏食物和淡水的情况下，因为服过兵役而具备野外生存能力的小王，第一次成为了这个群体中的领袖。这象征的是人类历史上，以“体力”作为主要角逐指标的蛮荒时代。这里想吐槽下编剧的恶趣味，王根基这个名字实在是一言难尽。小王的策略是“想吃就自己干”，这其实是人类早期以采集狩猎为主的生活场景的反映，在这个阶段，对体力的重视超过对智力的重视，所以，史教授作为知识分子的身份第一次遭遇解离。人们普遍尊重劳动的价值，所以，两位没有参与劳动的“老总”，作为职场上司的身份遭遇第一次解离。同样，集体中身材最好的女性Lucy，被老潘一把推给“王”，这是早期推崇“体力”的体系中，对性资源的一种绝对占有。 &emsp;&emsp;那么，在推崇“体力”的体系中，满足了人们的口腹之欲后，人们很快厌倦了这种满足感。以张总为代表的“智力”派，开始向着推崇“智力”的文明时代演变。在这个过程中，主要有两点，第一，是通过“期权”和“蓝图”发展出第一批员工。第二，是以扑克牌的形式定义了货币体系。这两点是整个社会转变的重要历程，第一点张总可以和“王”分庭抗礼的基础，而第二点则使得人们告别了“以物易物”的时代。张总利用马进想要离开孤单的心理，拉拢了岛上半数左右的人，可实际上他从未想过要带大家离开，这像不像现代职场里给期权的画饼方式？第二点，货币的出现让整个岛上的物品出现了流通。电影里有个人问，一张扑克牌能换多少鱼，张总回答说，这是有它的价值来决定的，这可以理解为经济学中的一个理论，即价格是由供需关系来决定的，故事到这里，我们已然看到了人类经济社会的雏形。 &emsp;&emsp;如果说在“体力”时代，人们角逐方式就是争斗，小到人与人之间的决斗，大到部落与部落间的战争，那么，到了“智力”时代，人们开始追求更高阶的竞争。或许竞争是万物的天性，所谓“物竞天择，适者生存”，从小就被教育这套弱肉强食的丛林法则，更是在宫斗、商斗等一众“争斗”里不亦乐乎，当真是“与天奋斗，其乐无穷；与地奋斗，其乐无穷；与人奋斗，其乐无穷”啊……那么，当岛上两拨人为了食物而大打出手的时候，到底是生存更重要还是道德更重要？为什么进化到“智力”时代的人们，依然要面对像强盗一样的“体力”时代的人们？人类历史上有多少自诩正义的行为，其实带来的都是流血和牺牲？所谓“鹬蚌相争，渔翁得利”，最终是马进在这场争斗中获利。 &emsp;&emsp;回头来看马进的行为，其实是群体中对优质资源的逐步占有的过程。如马进所言，只要是岛上生产不出的东西，都是宝贝。这里有两层意思，第一，物以稀为贵。第二，社会中的原始资源是有限的，只有不断创造新资源，整个社会的资源才能得以流通。虽然在电影中马小兴修坏了小王的水陆两用车，但其实电影想说的是，马小兴是所有人里唯一一个懂得现代科技的人，所以，马小兴的黑化，其实是马进人性中的阴暗面而已，当你真的拥有了摆布他人的能力，你是否又能守住道德的底线。 &emsp;&emsp;马进成为取代“王”和张总，成为新的领袖，从故事上来说，多少有点宗教的意味。首先，在光影的掩映下以高姿态俯视众人，这是神化的过程，马进从一个不被人待见的无名之辈，瞬间转变为充满神性的人，神到了什么地步呢？甚至连女神珊珊都开始主动向他求爱。众人穿着白色竖纹衣服的那一幕真的很美好，就连Lucy跳绳的镜头我都看了好几遍😉。有没有觉得马进一手持书的样子像极了耶稣，如果说耶稣通过圣经来向世人传道，那么马进对着黑暗中众人的一番演讲，是否具有类似的教化的作用，马进再一次“刷新”了活着的定义，引导人们去重见光明、寻找新大陆和重建家园，至此，我们仿佛过渡到了追求精神文明的阶段。 &emsp;&emsp;如果说，故事永远按照现在的方向去发展，那么或许在某个时刻人们就会回到“新大陆”，重新经历一次体系的重建。可生活从来都不是童话，导演用马小兴的黑化，完美地打破了这种想当然。或许有人会说，这是人类演化的必然，因为集体主义消亡以后，必然会导致精致的利己主义的产生，可即便如此，人们依然怀念着那个“罗曼蒂克”的时代，不是因为人们想要这样对别人，仅仅是希望别人这样对待自己而已。在张总主导的这个阶段，马进曾因为张总不愿意带大家离开，而被张总手下一通暴打，可其实他同样迷失在这份“岁月静好”中，所以，他不愿意让大家相信真的有大船经过，而这种内心的纠结，则完全交由马小兴来完成，主要事件有两个，其一是勒索张总资产，其二是小王“被得精神病”。电影快结束的时候，马进一直在重复“真的”还是“假的”，当一个人认识到这个社会的复杂性，当一个人在真真假假中来回穿梭的时候，或许他就会和马进一样，真的就分不出“真假”，可让马进走上神坛的电灯，和让小王变成“精神病”的电，难道不是一样的吗？ &emsp;&emsp;在圣经故事里，耶稣最后被他的门徒犹大背叛，最终被人们钉上十字架，这是不是和马进被马小兴背叛特别相似？最后，岛上只有马进和珊珊的那一幕，我个人更倾向于理解为，这是马进内心的真实写照，他愿意和珊珊一起在这个岛上生活，可他并不愿意让其他人永远困在这个岛上，所以，这是他心中的一种美好的想象，真实的结局是大家一起乘船离开了荒岛，可据说船上放烟花，据说是泰坦尼克号事件以后的一种约定成俗，意思是一种求救信号，所以，这艘大船并不存在？结尾，众人一起到医院看马小兴，马小兴暂时失忆，大概导演是不想他想起那些“阴暗”的记忆，可如果这是暂时失忆，就是说终究会再想起来的，那么，结合马小兴的经历，或许马小兴内心深处就是这样的？众人惊愕地停在一圈儿精神病人面前，大概每个人面对荒诞的时候，都不能确定自己这算不算荒诞吧，可谁叫这就是个反乌托邦的荒诞故事呢？你说，这故事在那只蜥蜴的眼睛里又会是什么样子呢？","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"影评","slug":"影评","permalink":"https://qinyuanpei.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"一出好戏","slug":"一出好戏","permalink":"https://qinyuanpei.github.io/tags/%E4%B8%80%E5%87%BA%E5%A5%BD%E6%88%8F/"}]},{"title":"使用VSCode作为SourceTree的Diff和Merge工具","date":"2018-09-30T08:43:44.000Z","path":"posts/3222622531/","text":"&emsp;&emsp;使用SourceTree有一段时间啦，从界面舒适度和易用性两个方面来看，的确要比小乌龟更好一点，日常配合命令行来使用，基本能覆盖到各种使用场景，譬如分支、版本、变基、合并等等。我本人在工作中接触到的Git工作流，大体上可以分为两类，从最早是官方所推崇的5个分支的Git Workflow，到如今在Github上更为流行的PR(Pull Request)。这两种方式，实际使用中各有优劣吧，而且这个话题似乎更适合专门写一篇文章来说。 &emsp;我真正想说的是，我需要一个优雅的Diff和Merge工具。虽然，对一个使用命令行的人来说，使用git diff来展示差异对比已经完全足够啦，可在某些需要解决冲突的场合，命令行就显得有点力不从心。我个人一直不习惯小乌龟的合并工具，因为使用起来总觉得相当别扭。直到我发现，VSCode可以在打开冲突文件的时候，自动提示解决冲突的选项，我觉得我开始喜欢上这个工具啦。所以，平时我解决冲突的做法是，在命令行里找到冲突的文件，然后逐一用VSCode打开来解决冲突。 &emsp;现在，使用SourceTree的时候，周围同事大部分都习惯GUI操作，所以，就想能不能把SourceTree和VSCode结合着来用，因为我发现SourceTree可以支持外部的Diff和Merge工具。其实，小乌龟一样是支持的，关键是配置太难用啦！SourceTree支持的Merge工具里有鼎鼎大名的P4Merge，不过我发现一来官网完全打不开(需要翻墙)，二来界面相当复古我不喜欢，而SourceTree默认的Merge工具其实就是小乌龟里的，所以，请允许我如此任性的折腾吧！ &emsp;首先，确保你安装了VSCode，这显然是一句废话，可对于博主来说，这是唯一可以替代Sublime Text的代码编辑器，想想可以写Markdown、写Python、写JS、写.NET Core，简直不能更美好了好嘛？然后，我们在SourceTree里做如下配置，这里我们直接让VSCode作为我们的Diff和Merge工具，具体参数如图所示： SourceTree配置图示 &emsp;好了，现在我们就可以在SourceTree里愉快地使用VSCode啦，感受一下这如德芙一般的纵想丝毫，从现在开始，彻底忘掉小乌龟那丑陋的合并工具吧！ VSCode解决冲突 VSCode差异比较 &emsp;既然，作为Git可视化工具的SourceTree可以使用VSCode作为Diff和Merge的工具，那么，我们干脆一鼓作气，将VSCode作为Git默认的Diff和Merge的工具吧！熟悉Git命令行的朋友一定遇到过这样的场景，有时候，我们执行完git merge以后，命令行会采用Vim的方式来进行交互，这是因为Git默认的编辑器就是Vim，为什么是Vim呢？因为Git和Linux一样，都出自Linus大神之手啊！所以，这句话的意思是，我们可以给Git配置外部工具，譬如小乌龟、P4Merge等等，这里直接给出相关命令： 12345678910111213//Merge时不创建备份文件git config --global al mergetool.keepBackup fap false//配置Diff工具git config --global al diff.tool cod codegit config --global al difftool.prompt mpt falsegit config --global al difftool.code.cmd '\"C '\"C:\\Program Files\\Microsoft VS Code\\de\\Code.exe\" \"-\" \"--wait --diff\" \"$LOCAL\" \"$REMOTE\"'//配置Merge工具git config --global al merge.tool cod codegit config --global al mergetool.prompt mpt falsegit config --global al mergetool.code.cmd '\"C '\"C:\\Program Files\\Microsoft VS Code\\de\\Code.exe\" \"-\" \"--wait\" \"$MERGED\"'git config --global al mergetool.code.trustexitcodecode true &emsp;OK，配置完Git以后，遇到用到需要Diff的场景，我们只需要执行git difftool；而需要用到Merge的场景，我们只需要执行git mergetool。直接合理搭配工具，Git一样可以变得非常可爱，而不是一堆枯燥乏味的命令行，好啦，Enjoy it，难得写一篇不那么技术向的博客，以后记得早点睡觉~zZ，晚安！","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://qinyuanpei.github.io/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://qinyuanpei.github.io/tags/Git/"},{"name":"VSCode","slug":"VSCode","permalink":"https://qinyuanpei.github.io/tags/VSCode/"},{"name":"SourceTree","slug":"SourceTree","permalink":"https://qinyuanpei.github.io/tags/SourceTree/"}]},{"title":"记通过EF生成不同数据库SQL脚本的一次尝试","date":"2018-09-17T09:42:23.000Z","path":"posts/795474045/","text":"&emsp;&emsp;接触新项目有段时间了，如果让我用一句话来形容此刻的感受，大概就是“痛并快乐着”。痛苦之一是面对TFS，因为它的分支管理实在是一言难尽，无时无刻不在体验着人肉合代码的“趣味”。而痛苦之二是同时维护三套数据库的脚本，这让我想到一个梗，在讲到设计模式的时候，一个常常被提到的场景是，怎么样从设计上支持不同数据库的切换。我想，这个问题是非常容易回答的，真正的问题是我们真的需要切换数据库吗？原谅我的年少无知，我们的产品因为要同时支持公有云和私有化部署，所以在数据库的选择上，覆盖到了主流MySQL、Oracle和SQL Server，这直接导致我们要维护三套数据库的脚本，你说这样子能不痛苦吗？而快乐的地方在于，终于有机会在一个有一定用户体量的产品上参与研发，以及从下周开始我们将从TFS切换到Git。好了，今天这篇文章的主题是，通过EF来生成不同数据库的SQL脚本，这是痛苦中的一次尝试，所谓“痛并快乐着”。 基本原理&emsp;&emsp;我们知道数据库和面向对象这两者间存在着天然阻抗，这是因为两者在事物的认知上存在差异，数据库关注的是二维表、是集合间的关系，而面向对象关注的是封装、是细节的隐藏，所以，不管到什么时候，这两者都只能以某种尴尬的方式共存，SQL执行效率高，这是以牺牲可读性为代价的； ORM迎合了面向对象，这是以牺牲性能为代价的，所以，即使到了今天，关于SQL和ORM的争论从来没有停止过，甚至写SQL的人不知不觉间“造”出了ORM，而使用ORM的人有时需要SQL。所以，面对这样一个需要同时维护三套数据库脚本的工作，我个人倾向于用工具去生成，或许是出于程序员对“懒”这种美德的极致追求，或许是出于我对SQL这种“方言”天生的排斥，总而言之，我不是很喜欢手写SQL除非特别必要，因为它和正则一样，只有写得人懂它真正的含义。 &emsp;&emsp;那么，说到这里，我们就知道了一件事情，ORM可以帮助我们生成SQL，所以，我们为什么不让它帮我们生成不同数据库的SQL脚本呢？虽然ORM的性能总是为人所诟病，因为它严格遵循某种规则，所以注定做不到像人类一样“灵活”。我们始终认为不“灵活”的就是“笨拙”的，可即便如此ORM生成的SQL依然比人类写得要好看。故而，我们的思路是，在ORM生成SQL语句的时候将其记录下来，然后按照一定规则生成不同数据库的脚本。毕竟SQL语言更接近“方言”，每一种数据库的SQL脚本都存在着细微的差别。所以，后来人们不得不发明T-SQL，可任何东西归根结底不都是权力和利益带来的附属品吗？人类为了互相竞争而形成差异化，可当一切差异都不甚明显时，最终又不得不花费精力来解决这些差异。可一个只有垄断存在的世界，除了让人想起1984里的Big Brother以外，还能想起什么呢？ 尝试过程&emsp;&emsp;好了，顺着这个思路，我们就会想到在ORM中添加拦截器或者是日志的方式，来获得由ORM生成的SQL语句，这里我们以Entity Framework(以下简称EF)为例，这是.NET中最常见的ORM，因为目前官方的Web开发框架有ASP.NET和ASP.NET Core两个版本，所以这里我们分别以ASP.NET和ASP.NET Core为例来说明具体的实现过程，相应地，我们分别使用了EF6和EF Core 作为各自的ORM。 EF6&emsp;&emsp;对于EF6，我们可以通过继承DbCommandInterecptor类来编写一个拦截器。而在拦截器中重写相应的方法，就可以对数据库中的常见操作(CURD)进行拦截。所以，根据这个思路，我们会联想到，通常数据库迁移都是针对“写”这个操作，因此，我们的想法是记录INSERT和UPDATE两种SQL语句。这里我们通过下面的示例来验证这个想法，需要说明的是，本文中所有数据库相关的示例，均采用Code First的方式来创建。 12345678910111213141516171819202122232425262728293031public class SQLGenInterceptor : DbCommandInterceptor&#123; public override void NonQueryExecuting(DbCommand command, DbCommandInterceptionContext&lt;int&gt; interceptionContext) &#123; var sqlText = FormatSQL(command); Log.Info(sqlText); &#125; public override void ReaderExecuting(DbCommand command, DbCommandInterceptionContext&lt;DbDataReader&gt; interceptionContext) &#123; var sqlText = FormatSQL(command); Log.Info(sqlText); &#125; public override void ScalarExecuting(DbCommand command, DbCommandInterceptionContext&lt;object&gt; interceptionContext) &#123; var sqlText = FormatSQL(command); Log.Info(sqlText); &#125; private string FormatSQL(DbCommand command) &#123; var sqlText = command.CommandText; foreach (DbParameter sqlParam in command.Parameters) &#123; sqlText = sqlText.Replace(sqlParam.ParameterName, sqlParam.Value.ToString()); &#125; return sqlText; &#125;&#125; &emsp;&emsp;在这个示例中，我们使用NLog来记录由EF生成的SQL语句，可以注意到它比我们想象中的要稍微复杂些，所以，人们说ORM性能差并不是没有道理。可当你见过那些由人手写出的天书一般的SQL语句后，也许两者在可读性上来说不过是五十步笑百步。实际上EF生成的SQL是一种叫做T-SQL的东西，你可以把它理解为一种标准的SQL语言。譬如在PowerBuilder这个数据库建模软件中，我们可以通过T-SQL转换出主流数据库的SQL语句。博主在工作中需要维护三套SQL脚本，而这些脚本间细小的语法差异，就变成了这个过程中最难忘的记忆，这里我们不考虑去做语法转换的事情，因为实际上通过传入不同的连接字符串，我们就能得到不同数据库的SQL脚本，所以接下来的工作就交给各位了(逃…… 123456789101112//注入SQLGen拦截器DbInterception.Add(new SQLGenInterceptor());using (var context = new DataContext())&#123; context.Users.Add(new User() &#123; UserName = \"PayneQin\", UserRole = \"Administrator\" &#125;); context.SaveChanges();&#125; &emsp;&emsp;现在，我们需要将这个拦截器注册到EF中，注册过程非常简单，一旦拦截器注册完成，当我们在EF中执行相应操作的时候，就可以在日志中看到相对应的SQ语句了，这样我们就达到了用EF生成SQL语句的目的，虽然说这样可能还没手写来快，可它至少让你知道了，这个世界上有一种不需要手写SQL的可能性啊，你说对吗？ EF生成SQL语句比想象中更为复杂 EF Core&emsp;&emsp;对于EF Core来说，它并没有提供像EF6那样的拦截器，虽然官方曾经说过后续会做这方面的工作[摊手]……不过办法终究是人想出来的，对于EF Core我们可以通过注入日志的方式来实现。我们知道，微软在.NET Core中大力地发展了依赖注入、中间件等一系列特性，所以，这对于我们这种喜欢搞事情的人来说，简直太方便了有木有啊！.NET Core中日志注入主要集中在ILogger、ILoggerFactory和ILoggerProvider三个接口，简单来说，ILoggerFactory是日志工厂，负责返回具体的Logger；而ILoggerProvider，则决定在什么情况下应该提供什么样的Logger。最常见的两种LoggerProvider是Console和Debug，它们分别通过AddConsole()和AddDebug()来注入。具体到这里，我们通过下面的方式实现： 1234567891011public class SQLGenLogger : ILogger&#123; private readonly string categoryName; public SQLGenLogger(string categoryName) =&gt; this.categoryName = categoryName; public IDisposable BeginScope&lt;TState&gt;(TState state) =&gt; null; public bool IsEnabled(LogLevel logLevel) =&gt; true; public void Log&lt;TState&gt;(LogLevel logLevel, EventId eventId, TState state, Exception exception, Func&lt;TState, Exception, string&gt; formatter) &#123; Log.Info(state) &#125;&#125; &emsp;&emsp;首先定义SQLGenLogger，顾名思义，它是用来记录生成的SQL语句的，同样，我们选择了NLog。这里有一点要说明，平时我们在控制器中使用ILogger的时候，通常会在控制器的构造函数中注入ILogger，一旦我们使用泛型的ILogger接口，Log()方法中的参数state实际上就是当前类型，这里和SQL语句相关的类型DbCommandData，实际上是博主试出来的，因为如果不限定ILogger中的参数T，我们将得到所有的执行日志，显然，这不是我们想要的结果。 1234567891011121314public class SQLGenLoggerProvider : ILoggerProvider&#123; public ILogger CreateLogger(string categoryName) &#123; if(categoryName == \"Microsoft.EntityFrameworkCore.Database.Command\") return new SQLGenLogger(categoryName); return NullLogger.Instance; &#125; public void Dispose() &#123; &#125;&#125; &emsp;&emsp;接下来来看，ILoggerProvider接口的实现。我们说过，ILoggerProvider接口决定在什么情况下应该提供什么样的Logger，我们注意到它提供了一个CreateLogger()的方法，它会根据categoryName来返回不同的Logger，而参数categoryName实际上等价与nameof(FooController)，所以，到这里我们就会明白，为什么这里要判断categoryName了，它实际上起一个过滤的作用，因为我们只需要SQL相关的日志，它和SQLGenLogger中的state相对应，我们已经说过，这是博主试出来的。 12345678910111213141516171819public class DataContext : DbContext&#123; public virtual DbSet&lt;User&gt; Users &#123; get; set; &#125; protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) &#123; var loggerFactory = new LoggerFactory(); loggerFactory.AddProvider(new SQLGenLoggerProvider()); //在这里注入日志工厂 optionsBuilder.UseLoggerFactory(loggerFactory) .EnableSensitiveDataLogging() .UseSqlServer(@\"Data Source=(LocalDb)\\MSSQLLocalDB;Initial Catalog=SQLGen.DataContext;Integrated Security=True;MultipleActiveResultSets=True;App=EntityFramework\"); &#125; protected override void OnModelCreating(ModelBuilder modelBuilder) &#123; modelBuilder.ApplyConfiguration(new UserTypeMap()); modelBuilder.Entity&lt;User&gt;().ToTable(\"Users\"); &#125;&#125; &emsp;&emsp;好啦，接下来就非常简单啦，我们在DbContext里对EF的Logger进行配置，把我们定义的SQLGenLoggerProvider注入到EF里，可以注意到，它可以如我们期望得那样，输出由EF生成的SQL脚本，这实在是有趣，Ok，打完收工！ 通过注入日志获取EF生成的SQL 本文小结&emsp;&emsp;我一直相信，懒惰是工程师的一种美德，因为为了让自己有机会懒惰，你就必须要先让自己勤奋起来。我一直怕自己在舒适区里温水煮青蛙，明明一直在重复做一件事情，还要安慰自己说：“做好这一件事情一样是成功“，有时候，一味地重复自己并不见得会有太多收获，所以，就像这篇文章一样，我本来像偷懒少写一点SQL，结果意外地发现了给数据库记录日志的方法。当有了意外收获以后，曾经的初衷到底是什么可能就没那么重要了，如“雨血”中左殇所说，当你赢了的时候，你说曾经有十成把握亦不为过。 &emsp;&emsp;这篇文章主要介绍如何利用EF来生成不同数据库的SQL脚本，对EF6来说，需要继承DbCommandInterecptor类编写拦截器；对于EF Core来说，需要注入ILogger来记录日志。本文的延伸之一是记录SQL执行日志，这一点在本文已经有所体现。本文更深层次的延伸是，在这个基础上实现数据库的主从复制、读写分离，这一点我会在下一篇博客中讲解，欢迎大家继续关注我的博客，好啦，以上就是这篇文章的全部内容啦，晚安！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"EF","slug":"EF","permalink":"https://qinyuanpei.github.io/tags/EF/"},{"name":"Logger","slug":"Logger","permalink":"https://qinyuanpei.github.io/tags/Logger/"}]},{"title":"漫谈前端进化史之从Form表单到文件上传","date":"2018-09-05T12:57:36.000Z","path":"posts/2463121881/","text":"&emsp;&emsp;Hi，大家好，欢迎大家关注我的博客，我是Payne，我的博客地址是https://qinyuanpei.github.io。今天这篇博客，我们来说说文件上传相关的内容。看到这里，大家一定觉得博主在技术上越来越没追求了吧，文件上传这种再简单不过的东西，真的值得博主你专门写篇博客吗？在介绍声明式RESTful客户端WebApiClient的这篇文章中，博主曾经提到，HTTP协议中对文件上传的支持，主要是通过multipart/form-data来实现。因为这种方式是将文件视为一种特殊的键值对，所以对这种方式我本人不太喜欢。可作为标准的意义就是要忽略个人的情感因素，所以，在今天这篇文章中，博主更多的是想从HTTP协议(RFC2388)的角度来看待这个问题，即为什么它选择了multipart/form-data来实现上传，以及伴随着前端技术的发展它经历了哪些变化。 从Form表单说起&emsp;&emsp;圣经上开篇就点明主旨，“起初神创造天地。地是空虚混沌。渊面黑暗”。一切的一切，都要从神创造天地开始，神说，要有光，这世上便有了光。那么，对于HTTP协议我们要从哪里开始说起呢。HTTP的全称是超文本传输协议，所以，它设计的初衷是传输超文本类型的数据。什么是超文本类型的数据呢？从现代网页的组成，我们就可以知道，它不单单是指文本类信息，同时指图片、音频、视频等等一切可能的信息形式。可神奇的地方就在于，HTTP协议是基于文本的协议，这意味着我们在网页中的信息交换，是借助某种文本类型的通信协议。顺着这个思路，最早我们在网页中交换信息的方式是什么呢？我认为是Form表单。想想看，我们在Form表单中输入信息，然后通过一个按钮将数据提交到服务器，服务器会对我们的请求做出响应。事实上，直到今天，我们的前端依然在采用这一机制。所不同的是，我们今天用各种组件替代了Form表单。 &emsp;&emsp;如果我们讲各种语言的”打印”理解为Hello World，那么对前端而言最浅显的Hello World是什么呢？我个人以为是登录，想象一下，这是任何一个Web应用里都有的功能，我们输入用户名和密码以后，点击“登录”按钮就可以登录到系统。虽然，此时此刻的你我，都知道这是一个简单的POST请求，甚至对于用户名和密码这两个字段，我们有多种方法可以将其传递到服务器上。那么，各位是否知道，我们通过Form表单来登录时，这个过程中到底发生了什么呢？既然提到了登录，那么我们这里通过下面的例子来分析。 &emsp;&emsp;如你所见，这是一个相当“简陋”的Web页面。对一名后端开发人员而言，精致的Web页面就是一段被套在华丽外壳里的代码(不知道这样会不会被前端网红们打死)。所以，排除了样式相关的CSS，可以让我们更加专注于核心原理。同样地，我们编写了一个简单的Web API，来处理前端发送来的HTTP请求，这不是本文的重点，我们假设它存在且可以工作就好。 HTML结构/界面 &emsp;&emsp;这里已经说过，比起炫酷的Web页面和后端接口，我们这里更关心的是，登录时到底发生了什么。所以，大家都猜对了，通过Chrome自带的开发人员工具，我们可以捕捉到点击“登录”按钮时发出的HTTP请求，我们一起来看看它的报文内容是什么吧，相信大家都会有一种恍然大悟的感觉，让我们拭目以待吧！ encrypt为x-www-form-urlencode时的请求报文 &emsp;&emsp;通过这个报文内容，我们可以发现，“登录”实际上是一个POST请求，这是因为我们在HTML结构中声明了，Form表单用什么样的方式去提交数据。而实际上呢，Form表单默认的行为是GET。我们同样会注意到报文中的Content-Type为application/x-www-form-urlencode，它的特点是采用类似key1=value1&amp;key2=value2……的形式来提交数据，并且每一个value都会被编码。这样，我们就不得不提到Form表单的encrypt属性，它有三种基本取值：text/plain、application/x-www-form-urlencode和multipart/form-data。其中，text/plain这种不必再说，因为它传递的是纯文本数据。而对于multipart/form-data来说，它的特点是采用一系列的boundary来分割不同的值，如果我们将示例中Form表单的encrypt属性设为multipart/form-data，就会得到下面的报文内容，可以注意到，它和我们预期是一致的。 encrypt为multipart/form-data时的请求报文 &emsp;&emsp;或许大家会说，现在我们用AJAX来请求RESTful风格的API时，不都是用JSON作为数据交换的格式吗？对于这一点，或许我们可以理解为，Form表单是封装了有限的3种Content-Type的XHR对象，所以，Form表单足以让我们一窥AJAX最初的样子。虽然，我们今天已经不再主张使用jQuery，但是熟悉jQuery的朋友一定知道这一点，即jQuery中默认的Content-Type示例上是application/x-www-form-urlencoded。所以，即使我们今天有了全新的Fetch API，可它依然脱离不了HTTP协议的范畴。可或许正因为如此，HTTP中的文件上传多少像是某种妥协的产物。 神奇的Input控件&emsp;&emsp;OK，在本文的第一节，我们使用的是最简单的Input控件，即它的type属性为“text”。事实上，Input控件是一个神奇的控件，因为不同的type会有不同的作用。例如，type为password对应密码域；type为checkbox对应复选；type为radio对应单选域；type为button对应按钮域等等……有很多朋友可能会问，你说的这个和这篇文章有什么关系吗？我想说的是，当然有关系而且关系密切，因为我们下面要提到的这种Input控件，和本文想要说明的HTTP上传，在本质上有着千丝万缕的联系。具体是什么样的联系呢？我们来一起看下面的这个例子。 HTTP_Upload_06 HTTP_Upload_05 &emsp;&emsp;通过这个例子，我们很容易发现的一点是，当我们采用type为file的Input控件上传一个文件时，它会采用multipart/form-data来传递数据，报文中使用了和第二个示例类似的结构，即第一部分负责描述文件信息，譬如文件的名称、扩展名类型等等；第二部分表示文件数据流，可以理解为二进制形式的内容。既然它采用multipart/form-data来传递数据，那么这是否意味着，我们可以在这个结构中携带更多的信息呢？譬如，有时候我们需要将文件和用户提交的信息关联起来，这个时候就需要将这些信息一切提交到服务器端，如果我们将其拆分为两个API来实现，那么就需要去花精力维护这个关联的id啦。答案自然是可以的，只要把文件视为一种特殊的键值对即可。 HTTP与文件上传&emsp;&emsp;好了，说了这多么内容，是时候来说说HTTP与文件上传啦！现在大家都知道了，HTTP上传实际上是在multipart/form-data基础上扩展而来的。早期人们在制定HTTP协议的时候，并没有想到用它来作为文件上传的协议，因为事实上TPC/IP或者FTP都可以提供更好的上传支持。当我们回顾Form表单中关于HTTP的部分，我们就会发现，HTTP中具备上传文件可能性的方式只有两种，即multipart/form-data和x-www-form-urlencode。这里为什么不考虑text/plain呢？尽管从理论上来讲，它可以作为文件上传的一种方式，此时，它相当于把整个文件的内容全部放在请求体(body)中。从实用性角度来讲，text/pain在实际应用中并不多见，因为采用纯文本意味着客户端与服务端必须按照某种规则去解析报文。而从功能性角度来讲，把整个文件的内容全部放在请求体中，则会造成文件信息的不完整，因为此时文件名等信息是没有办法传输到服务器端的，所以，这样综合下来再看的话，HTTP协议本身留给我们的选择的空间并不大，我们能够选择的就只有multipart/form-data和x-www-form-urlencode这两种啦，下面着重来分析下这种数据加密方式。 HTTP_Upload_07 &emsp;&emsp;对于Content-Type为multipart/form-data而言，首先，它会在请求头部的Content-Type字段中，声明当前的内容类型为multipart/form-data，并指定一个名为boundary的随机字符串，它的含义是说，从现在开始，请求中的每一个“字段”都会用这个名为boundary的随机字符串进行分割。而对于每一个“字段”而言，它可以拥有部分子头部字段，一个最为常见的头部字段是Content-Disposition，其取值为form-data。除此之外，每一个“字段”可以在Content-Disposition: form-data;后追加若干个字段，譬如name、filename以及用以指定文件类型的Content-Type(假如这个“字段”是一个文件的话)。HTTP协议中还规定这里可以支持扩展字段。我们通过type为file 的Input控件进行上传时，默认的name为multipartfile，当服务器端接受到类似的字段时，就会根据报文对文件进行拼接，所以，对于HTTP上传来说，它可以支持多个文件并发上传，但并不直接支持断点续传。注意这里我说的是，不直接支持断点续传，实际上它可以通过请求头部中的Range字段来实现，当然这已经超出了这篇文章的范畴。 HTTP_Upload_08 &emsp;&emsp;对于Content-Type为x-www-form-urlencode而言，它会将请求中的每一个字段以key1=value1&amp;key2=value2……的形式串联起来，并对每一个value进行编程，这种传值方式我们一般称为QueryString，而更为一般的场景是，我们在通过GET方式请求数据的时候，QueryString是唯一的传参方式，不同之处是GET请求的参数是附加在URL上，而POST请求的参数是附加在body里。如果我们用这种方式来上传文件会怎么样呢？答案是，当我们试图将一个文件以x-www-form-urlencode方式进行传输时，文件流会被彻底忽略，它实际传输的是对应文件的名称。所以，从这个角度来讲，它不能用于文件的上传。事实上，它是被设计用来传输非二进制数据的，那么可能有人要问啦，那我如果有JSON来传输文件可不可以呢？理论上应该没有问题，曾经我们在一个项目中用JSON描述图片，当然这是经过Base64编码以后的图片。回过头来看text/plain，我们把JSON字符串直接放到body里可不可以呢？当然没有问题，因为问题全部转移到服务器端。所以，官方建议用它来作为调试的一种选择。 &emsp;&emsp;现在，我们可以来总结下Form表单和HTTP协议间的关系啦！首先，Form表单可以提交非二进制数据和二进制数据。非二进制数据，比如一般表单中提交的各种文本信息，用户名、密码这一类等等。二进制数据，主要指各种不同类型的文件等等。对于非二进制数据，可以通过x-www-form-urlencode或者multipart/form-data两种编码方式来提交。对于二进制数据，只能通过multipart/form-data这种方式来提交。所以，当我们需要混合提交二进制数据和非二进制数据的时候，我们就只有multipart/form-data这一种选择啦！更一般的结论是，只要我们的Form表单里有一个type为file的Input控件，对应POST请求的Content-Type就会变为multipart/form-data。我不喜欢这种方式的原因之一，就是构造它的HTTP报文非常难受。如果用HttpClient，痛苦会降低很多；而如果用HttpWebRequest，我会感到绝望。当然，你此时已明白了这个原理，相信Postman可以帮到你的忙。 Form表单消失以后&emsp;&emsp;熟悉前端演变历程的朋友，应该对我下面要说的历史表示怀念。在很久很久以前，我们的网页三剑客分别是Dreamwave、Fireworks和Flash。那个时候我们用Dreamwave制作的网页充斥着大量的Form表单，通过JS实现对数据的校验，就像这篇文章里描述的一样，我们做几个type为submit的按钮，就可以把数据提交到服务器端。按理说，这样子很没完美啊，我们可以提交用户输入的信息，可以上传用户选择的文件，何乐而不为呢？为什么大家要用Div + CSS淘汰Form表单呢？我认为主要有两点，传统的基于表格的布局无法满足现代Web程序的布局要求，RESTful风格Web API的出现让开发者希望前后端交互可控。换言之，开发者希望通过FormData这样的对象，精细地控制整个请求的细节，而不是交给一个由浏览器发出的POST请求。所以，我们看到了前端文件上传的新思路。 &emsp;&emsp;首先，最常见的方式，是通过监听Input控件的onchange方法，通过files属性即可获得当前用户选择的文件。我们知道，在大多数情况下，前端是无法和本地文件系统进行交互的。因此通过这种方式获得文件路径，实际上是一个指向本地数据的blob，前端将文件相关的type和size组织到一个FormData对象的实际中，即可完成对文件的上传。其次，可以利用HTML5中的“拖拽”和“粘贴”，其核心依然是监听相关的事件，然后从中获取File对象或者blob对象的实例，一旦获得了这些实例，就可以将其添加到FormData中。到了这一步，接下来的就和第一种方法完全一样啦！最后，是类似百度出品的WebUploader这类HTML5和Flash混合的插件，主打兼容性，不过随着大家对IE8以下版本兼容问题的逐步放弃，这类产品的使用场景会越来越少，我们大概知道就可以啦！归根到底一句话，Form表单和FormData对象，其实是可以相互转化的，Form表单里每一个Input控件的name，其实就是FormData里的key啦，到了这一步，我想HTTP上传就没有什么好神秘了的吧！ 本文小结&emsp;&emsp;本文从Form表单说起，首先探讨了Form表单和HTTP之间的关系，即Form表单在提交数据的时候，背后的本质其实是一条HTTP请求，相对应地，Form表单默认的请求方式是GET，在第一个示例中，我们分别展示了使用x-www-form-urlencode和multipart/form-data时请求报文实际的内容。接下来，我们提到了HTML中的Input控件，它可以通过指定不同的type达到不同的效果，作为第一个示例的延伸，我们尝试通过Form表单上传文件并重点关注其报文的结构。接下来，我们从协议的角度分析了为什么要选用multipart/form-data来上传文件以及它的原理是什么。最后，我们从前端常见的文件上传方式入手，简要分析了Form表单和FormData对象间的内在联系，即Form表单和FormData对象，其实是可以相互转化的，Form表单里每一个Input控件的name，其实就是FormData里的key。好啦，又是一个难以入眠的夜晚，这篇博客先写到这里，大家晚安！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"Form","slug":"Form","permalink":"https://qinyuanpei.github.io/tags/Form/"},{"name":"RFC","slug":"RFC","permalink":"https://qinyuanpei.github.io/tags/RFC/"}]},{"title":"基于WebSocket和Redis实现Bilibili弹幕效果","date":"2018-08-22T14:07:23.000Z","path":"posts/3269605707/","text":"&emsp;&emsp;嗨，大家好，欢迎大家关注我的博客，我是Payne，我的博客地址是https://qinyuanpei.github.io。在上一篇博客中，我们使用了.NET Core和Vue搭建了一个基于WebSocket的聊天室。在今天这篇文章中，我们会继续深入这个话题。博主研究WebSocket的初衷是，我们的项目上有需要实时去推送数据来完成图表展示的业务，而博主本人对这个内容比较感兴趣，因为博主有对爬虫抓取的内容进行数据可视化(ECharts)的想法。可遗憾的是，这些数据量都不算太大，因为难以支持实时推送这个想法，当然更遗憾的是，我无法在项目中验证以上脑洞，所以，最终退而求其次，博主打算用Redis和WebSocket做一个弹幕的Demo，之所以用Redis，是因为博主懒到不想折腾RabbitMQ。的确，这世界上有很多事情都是没有道理的啊…… &emsp;&emsp;其实，作为一个业余的数据分析爱好者，我是非常乐意看到炫酷的ECharts图表呈现在我的面前的，可当你无法从一个项目中收获到什么的时候，你唯一的选择就是项目以外的地方啦，所以，在今天这样一个精细化分工的时代，即使你没有机会独立地完成一个项目，我依然鼓励大家去了解项目的“上下文”，因为单单了解一个点并不足以了解事物的全貌。好了，下面我们来简单说明下这个Demo整体的设计思路，即我们通过Redis来“模拟”一个简单的消息队列，客户端发送的弹幕会被推送到消息队列中。当WebSocket完成握手以后，我们定时从消息队列中取出弹幕，并推送到所有客户端。当客户端接收到服务端推送的消息后，我们通过Canvas API完成对弹幕的绘制，这样就可以实现一个基本的弹幕系统啦！ 编写消息推送中间件&emsp;&emsp;首先，我们来实现服务端的消息推送，其基本原理是：在客户端和服务端完成“握手”后，我们循环地从消息队列中取出消息，并将消息群发至每一个客户端，这样就完成了消息的推送。同上一篇文章一样，我们继续基于“中间件”的形式，来编写消息推送相关的服务。这样，两个WebSocket服务可以独立运行而不受到相互的干扰，因为我们将采用两个不同的路由。在上一篇文章中，我们给“聊天”中间件WebSocketChat配置的路由为/wsws。这里，我们将“消息推送”中间件WebSocketPush配置的路由为/push。这块儿我们做了简化，不再对所有WebSocket的连接状态进行维护，因为对一个弹幕系统而言，它不需要让别人了解某个用户的状态是否发生了变化。所以，这里我们给出关键的代码。 123456789101112131415161718192021public async Task Invoke(HttpContext context)&#123; if (!IsWebSocket(context)) &#123; await _next.Invoke(context); return; &#125; var webSocket = await context.WebSockets.AcceptWebSocketAsync(); _socketList.Add(webSocket); while (webSocket.State == WebSocketState.Open) &#123; var message = _messageQueue.Pull(\"barrage\",TimeSpan.FromMilliseconds(2)); foreach(var socket in _socketList) &#123; await SendMessage(socket,message); &#125; &#125; await webSocket.CloseAsync(WebSocketCloseStatus.NormalClosure, \"Close\", default(CancellationToken));&#125; 同样地，我们需要在Startup类中添加WebSocketPush中间件。按照ASP.NET Core中的惯例，我们为IAppBuilder接口增加一个名为UseWebSocketPush的扩展方法。这样，可以让我们直接使用该方法完成中间件的注册。 1234public static void UseWebSocketPush(this IApplicationBuilder app)&#123; app.UseMiddleware&lt;WebSocketPush&gt;();&#125; Redis打造的消息队列&emsp;&emsp;OK，在编写“消息推送”中间件的时候，我们会注意到，我们使用了一个名为SimpleMessageQueue的类来取得消息，而服务端会负责将该消息群发到所有的客户端。这个其实就是博主写的一个简单的消息队列啦，如此简洁直白的命名证明它的确非常简单。有多简单呢？我想一会儿大家就会找到答案。在此之前，我想和大家讨论这样一个问题。其实，聊天室和弹幕挺像的吧，理论上服务端接收到客户端发的消息，就可以直接群发过去啊，为什么要搞一个消息队列在这里呢？而且更扯的一点是，既然博主你选择用Redis啦，你难道不知道Redis天生就支持发布订阅(Pub-Sub)吗？为什么要搞一个消息队列在这里呢？ &emsp;&emsp;对这个问题，我的想法其实是这样的，我最初想做的是：后端定期推送数据到前端，再由前端通过这些数据来绘制图表。此时，无论后端还是前端，其实都是数据的消费者，这些数据当然不能一股脑儿全给它们啊，这吃撑着了可怎么办，所以，为了避免它们消化不良，我得有一个东西帮助它维持秩序啊，这就是消息队列啊。简单来说，如果数据量超过程序的处理能力，这个时候我们就需要消息队列在前面帮忙“挡”一下。想象一下，如果去银行办理业务的人，都不排队一股脑儿涌向柜台，银行柜员大概会感到崩溃。我们的程序模拟的是现实生活，所以，我们需要消息队列。 为什么需要消息队列 &emsp;&emsp;那么，有朋友要问啦，就算你要用消息队列，那博主你为什么不用RabbitMQ，再不济可以考虑微软自带的MQ啊，为什么要用Redis做一个MQ呢？就算你坚持要用Redis做MQ，为什么不考虑用的Redis的发布-订阅(Pub-Sub)呢？对于第一个问题，你可以理解为我穷或者懒(穷个什么鬼啊，你特么就是懒(:з」∠))。我就是懒得去搞RabbitMQ，谁让我电脑C盘都快爆炸了呢，自从我把玩了几次Docker for Windows以后，而且我们项目上还真有不被允许用MQ的情况。所以，基于以上原因，我选择了Redis。 Redis中的Pub-Sub &emsp;&emsp;那么，为什么不用发布-订阅(Pub-Sub)呢，因为观察者模式的一个前提是，订阅者和主题必须在同一个上下文，即消息的发送方和接受方都必须同时“在线”。可Bilibili的弹幕和用户的在线与否无关，这意味着发弹幕与接收弹幕可以不在同一个时刻，所以，在设计上我们是提供了一个API接口来发送弹幕，而不是直接通过WebSocket来发送。否则，消息都到达服务端了，再通过一个消息队列来取消息，这就真的有点奇怪了不是吗？ &emsp;&emsp;下面给出这个消息队列的实现，原理上是这样的，每一个消息所在的Channel，实际上都是一个列表，我们使用Channel的名称作为这个列表的键。接下来，ServiceStack提供的Redis客户端中，提供了名为BlockingListItem()的方法，它可以提供类似消息队列的功能，我们在这个基础上实现了一个简单的消息队列。 12345678910111213141516171819202122232425262728293031323334public class SimpleMessageQueue&#123; private string _connectionString; private readonly BasicRedisClientManager _clientManager; public SimpleMessageQueue(string connectionString) &#123; _connectionString = connectionString; _clientManager = new BasicRedisClientManager(_connectionString); &#125; public void Push(string channel, string messsage) &#123; using (var client = _clientManager.GetClient()) &#123; client.PushItemToList(channel, messsage); &#125; &#125; public void Push(string channel, IEnumerable&lt;string&gt; messages) &#123; using (var client = _clientManager.GetClient()) &#123; client.AddRangeToList(channel, messages.ToList()); &#125; &#125; public string Pull(string channel,TimeSpan interval) &#123; using (var client = _clientManager.GetClient()) &#123; return client.BlockingDequeueItemFromList(channel,interval); &#125; &#125;&#125; 相应地，在WebSocketPush中间件中，我们通过Pull()方法来取得消息，时间间隔为2s。在MessageController中，我们提供了用以发送弹幕的API接口，它实际上调用了Push()方法，这个非常简单啦，我们不再做详细说明。 123456789101112[HttpPost][Route(\"/api/message/publish/barrage\")]public IActionResult Publish()&#123; Stream stream = HttpContext.Request.Body; byte[] buffer = new byte[HttpContext.Request.ContentLength.Value]; stream.Read(buffer, 0, buffer.Length); string message = System.Text.Encoding.UTF8.GetString(buffer); _redisPublisher.Push(\"barrage\", message); Response.Headers.Add(\"Access-Control-Allow-Origin\", \"*\"); return Ok();&#125; 使用Canvas绘制弹幕&emsp;&emsp;好啦，截止到目前为止，我们所有后端的开发已基本就绪。现在，我们来关注下前端的实现。关于WebSocket原生API的使用，在上一篇文章中，我们已经讲过啦，这里我们重点放在客户端提交弹幕以及绘制弹幕。 &emsp;&emsp;首先来说，客户端提交弹幕到服务器，因为我们已经编写了相应的Web API，所以这里我们简单调用下它就好。和上一篇文章一样，我们继续使用Vue作为我们的前端框架，这对一个不会写ES6和CSS的伪前端来说，是非常友好的一种体验。因为现在是2018年，所以，我们要坚决地放弃jQuery，虽然它的ajax的确很好用，可这里我们还是要使用Axios： 12345678910axios.post(\"http://localhost:8002/api/message/publish/barrage\",&#123; value: self.value, color: self.color, time: self.video.currentTime&#125;).then(function (response) &#123; console.log(response);&#125;).catch(function (error) &#123; console.log(error);&#125;); &emsp;&emsp;接下来，说说弹幕绘制。我们知道，HTML5中提供了基于Canvas的绘图API，所以，我们这里可以用它来完成弹幕的绘制。基本思路是：根据video标签计算出弹幕出现的范围，然后让弹幕从右侧向左逐渐移动，而弹幕的垂直位置则可以是顶部/底部/随机，当弹幕移动到屏幕左侧时，我们从弹幕集合中移除掉这个元素即可。下面给出基本代码，绘图相关的接口可以参考这里，弹幕相关参考了这篇文章： 12345678910var context = canvas.getContext('2d');context.shadowColor = 'rgba(0,0,0,' + this.opacity + ')';context.shadowBlur = 2;context.font = this.fontSize + 'px \"microsoft yahei\", sans-serif';if (/rgb\\(/.test(this.color)) &#123; context.fillStyle = 'rgba(' + this.color.split('(')[1].split(')')[0] + ',' + this.opacity + ')';&#125; else &#123; context.fillStyle = this.color;&#125;context.fillText(this.value, this.x, this.y); 翻滚吧，弹幕！&emsp;&emsp;OK，现在我们来一起看看最终的效果，如你所见，在视频播放过程中，我们可以通过视频下方的输入框发送弹幕，弹幕会首先经由Redis缓存起来，当到达一定的时间间隔以后，我们就会将消息推送到客户端，这样所有的客户端都会看到这条弹幕，而对于客户端来说，它在和服务端建立WebSocket连接以后，唯一要做的事情就是在onmessage回调中取得弹幕数据，并将其追加到弹幕数组中，关于弹幕绘制的细节，我们在本文的第三节已经做了相关说明，在此不再赘述。 弹幕效果展示 &emsp;&emsp;这里，我们采用了前后端分离的设计，即使我们没有并使用主流的ES6去实现客户端。因此，这是客户端实际上是一个静态页面，在本地开发阶段，我们可以通过打开多个浏览器窗口来模拟多用户。那么，如果我们希望让更多人来访问这个页面该怎么做呢？这就要说到ASP.NET Core中的静态文件中间件。无论是IIS还是Apache，对静态页面进行展示，是一个Web服务器最基本的能力。在ASP.NET Core中，我们是通过静态文件中间件来实现这个功能，简而言之，通过这个功能，我们就可以让别人通过IP或者域名来访问wwwroot目录下的内容。具体代码如下： 12app.UseDirectoryBrowser();app.UseStaticFiles(); &emsp;&emsp;当然，这里有一个细节是为了让别人可以通过IP或者域名来访问你的服务，你需要修改下WebHostBuilder中URL。此外，因为我们在前端界面中使用了绝对的URL去访问WebAPI，因此，当前端页面和WebAPI不在一个域中时，就会出现所谓垮域的问题，这方面的内容非常丰富，因为这是一个再常见不过的问题，身处在这个时代，80%的问题都已经被解决过了，这到底是我们的幸运还是不幸呢？ 123WebHost.CreateDefaultBuilder(args) .UseStartup&lt;Startup&gt;() .UseUrls(\"http://*:8002\"); 本文小结&emsp;&emsp;本文在上一篇的基础上，借助Redis和WebSocket实现了一个简单的弹幕系统。博主的初衷是想一个数据可视化的小项目，可以通过WebSocket实时地刷新图表，因为在博主看来，数据分析同样是有趣的事情。这篇文章选取博主在工作中遇到的实际场景作为切入点，试图发掘出WebSocket在实时应用方面更多的可能性。 &emsp;&emsp;首先，我们编写了“消息推送”中间件，并通过不同的路由来处理各自的业务，实现了模块间的相互独立。接下来，我们讨论了Redis作为消息队列的可行性，并基于Redis编写了一个简单的消息队列。最终，通Canvas API完成客户端弹幕的绘制，实现了从后端到前端的方案整合。藉由这个小项目，可以引出ASP.NET Core相关的话题，譬如静态文件中间件、部署、跨域等等的话题，感兴趣的朋友可以自己去做进一步的了解，以上就是这篇博客的全部内容啦，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"Redis","slug":"Redis","permalink":"https://qinyuanpei.github.io/tags/Redis/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://qinyuanpei.github.io/tags/WebSocket/"}]},{"title":"长安不见使人愁","date":"2018-08-10T20:42:23.000Z","path":"posts/3417652955/","text":"&emsp;&emsp;“大道如青天，我独不得出”。这是唐朝大诗人李白在《行路难》(其二)中的感慨，相比“长风破浪直济沧海”的豪迈，这首诗反而显得矫情啦，仿佛生活就应该陪着大家一起笑，我这种神经兮兮的文艺Boy，就只有这片手机屏幕大小的地方，来说些不合时宜的冷笑话。这大概是博客能让我坚持写下去的理由，因为它的的确确是属于你的，那么请原谅我，因为我要在这里写点矫情的话。 &emsp;&emsp;上周一个人独自从公司办理完离职手续，原来那天下午是可以不用下班打卡的，这种感觉就好像是，你坚持并且在乎了很久的一件事情，在某一瞬间突然变得不再重要。我突然意识到，我居然已经在这个城市里生活了两年多。两年多是种什么体验呢？或许是曾经说过再见的朋友再没有见过面，又或许是曾经拒绝过你的女孩子终于结了婚，又或许是青龙寺里的樱花们开了一年又一年，又或许是遗址公园里石榴又从青色变成了红色……你脑海中的记忆越来越浅，而额头上的皱纹越来越深，记忆果真都被时间从额头上凿了去吗？ &emsp;&emsp;和朋友们聊天的时候，他们一如既往地感慨着自己婚后的月光生活，一如既往地羡慕着我接近他们三倍的高薪工资，总要在聊天快要结束时侯，一如既往地问我：真的不打算回来了吗？也许，等到银西高铁通车的时候，我终于不用再坐将近12个小时的火车回家。“鸟倦飞而知还”，可我是否是《阿飞正传》里的那一只，那只没有脚的鸟，它只能够一直飞呀飞呀，飞累了就在风里睡觉。我认识的人里，有从大学时代就在这个城市驻足的人，有远离故乡在这个城市扎根的人，无一例外的是，我们都离故乡越来越远，交通的便利和发达，并不足以弥补这种心灵上的距离，就像你从地图上看各个省份好像都离得不远。可没法在一起的人们啊，连最后一步都会觉得遥远啊！我不得不承认，没有人天生会是一个无忧无虑的漂泊者，无论是洛阳还是长安，对我而言都不是故乡。 &emsp;&emsp;早已忘记是从什么时候开始不吃辣的，真正令我感到神奇的，是这种习惯终于让我带去到不同的城市，就像你很难说清楚，喜欢一个人有多少是来自喜欢，又有多少是来自习惯。周末基本固定的去书店看书，看书的同时亦看匆匆的行人。小寨和钟楼永远不乏光鲜亮丽的男男女女，俨然是这个城市里最繁华的地带，人们的自拍无一不透露着时尚与精致，在某一瞬间，让我这个来自三四线小城市的人，相形见绌到沉默不言。想象下大唐盛世里的长安城，最繁华的市集无外东西两市，马亲王的《长安十二时辰》所展现的盛唐风物，对真实的历史而言，不过是雪泥鸿爪、惊鸿一瞥。如今西市为商业街所包围，一座大唐西市博物馆悄立其中，其形堪称寂寥否？西安遍地都是商场、购物中心，其盛堪比大唐否？ &emsp;&emsp;我曾经开玩笑地和朋友说，我现在喜欢观察路上行人们的穿搭，仿佛这样能让我喜欢的女孩子愿意看我一眼，朋友不无嘲讽地说，“你这是在东施效颦啊”，就连我喜欢的女孩子都说，“每个人都会有自己喜欢的风格啊”。可其实，我只有一点能确定，我明确知道我不喜欢那种风格，倘若真要问我喜欢什么，我真的不知道啊！不要以为只有女孩子，会在面对琳琅满目的商品时选择困难，在这个选择多样化的时代，明确知道自己想要什么，对每一个人而言，反倒是一种相当稀缺的品质。就像人只有长大了以后才会明白，做一个优秀的男人是多么困难的事情，做学生的时候比的是学习成绩，做男人的时候则是比社会化综合测评。初到长安“居之不易”的白居易，和此时的你我是何其相似，彼时长安是大唐的首都，此时西安是新新一线城市，历史啊，果然都是相似的嘛，所不同的只是当事人。 &emsp;&emsp;朋友们都希望我可以“自信”点，可终于有这样一天，你做到了曾经想做而不敢做的事情，这一切又是否真的会如你所愿。人啊，总是情愿活在借口里。我有位朋友常常“一语惊人”，简直就是“语不惊人死不休”的典型代表，他说，“不管男人的话还是女人的话，都不要相信”。大意就是说，人家就是那么随口一说，你这还当真了不是。姜文《让子弹飞》里有一个情节，小六子被诬陷吃了两碗凉粉却给了一碗凉粉钱，百口莫辩的小六子，不得已剖开肚子来自证清白。其实，世上好多事情都是没有道理的，你证明了你可以做到某一件事情又能怎么样呢？时过境迁，当一切都重新归于平静，也许人家就是那么随口一说，也许人家早都忘记了说过这句话，而你却守着这个可笑的执念等到花儿都谢了。人呐，偶尔狠下心来，是因为这样很爽吗？就像人们喜欢暴力一样。其实，真正的自信应该是温柔的，很多时候你以为的自信，无非是任性罢了。一个小孩子，会因为你帮他捡起掉在地上的扇子，而对你微笑，即使他还不会说话。 &emsp;&emsp;有时候，我会想人们对于一件事物的评价标准为何会存在差异，这是否是因为我们根本不了解自己。人类其实和猴子差不了多少，对这个世界总是充满好奇，似乎什么都想要去尝试。喜欢吃喝玩乐会被认为是懂得享受生活，而喜欢独处内省则会被认为是乏味无趣，可其实大家都是第一次做人，都是第一次面对这个存活了上亿年的星球。当北极圈里开始出现30度的高温，大概在这个世界上并不存在绝对的事情。当所有的标准都被满足，这是否意味着无论对方是谁都可以，我们明明都在执着于找寻唯一的东西，却为何选择了原本和唯一无关的标准。因为但凡有标准存在的地方，它们就注定难以成为独一无二的东西。就像《小偷家族》里的“父亲”，自认为什么都不会除了盗窃，却教会了祥太关于青春期的一切。很多时候爱不像我们想象地拥有一个标准模板，就像这个并不“标准”的家庭，却拥有足以打动我们的情感一样。或许，追求“标准”本来就是件愚蠢的事情，我们自以为个性独立，实际上永远被各种“虚拟”的东西束缚着，正如卢梭所言：“人生而自由，而无往不在枷锁之中”。 &emsp;&emsp;我想，李白抒发“不见长安”的愁绪时，大抵不会想到日后遇赦时的快意，更不会想到被玄宗逐出长安时的失意。可当你真的了解了你所要面对的人生，是否还有勇气会像现在这样选择。对于我的人生，我不知道今后会是什么样子，我唯一能做的，就是接受我已经失去的一切，长安并不足以安，你会有一个可以令你心安的人出现吗？长安不见，你愿意让我见到你吗？","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"西安","slug":"西安","permalink":"https://qinyuanpei.github.io/tags/%E8%A5%BF%E5%AE%89/"},{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"},{"name":"矫情","slug":"矫情","permalink":"https://qinyuanpei.github.io/tags/%E7%9F%AB%E6%83%85/"}]},{"title":"使用.NET Core和Vue搭建WebSocket聊天室","date":"2018-08-01T15:42:23.000Z","path":"posts/1989654282/","text":"&emsp;&emsp;Hi，大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是：https://qinyuanpei.github.io。今天这篇博客，我们来说说WebSocket。各位可能会疑惑，为什么我会突然间对WebSocket感兴趣，这是因为最近接触到了部分“实时”的业务场景，譬如：用户希望在远程视频通话过程中，实时地监控接入方的通话状态，实时地将接入方的响应时间、通话时长以及接通率等信息推送到后台。与此同时，用户可以通过监控平台看到实时变化着的图表。坦白地讲，这种业务场景陌生吗？不，每一年的双11，都能见到小伙伴们实时地“剁手”。所以，在今天这篇文章中，我们会以WebSocket聊天室为例，来讲解如何基于WebSocket构建实时应用。 WebSocket概述&emsp;&emsp;WebSocket是HTML5标准中的一部分，从Socket这个字眼我们就可以知道，这是一种网络通信协议。WebSocket是为了弥补HTTP协议的不足而产生的，我们知道，HTTP协议有一个重要的缺陷，即：请求只能由客户端发起。这是因为HTTP协议采用了经典的请求-响应模型，这就限制了服务端主动向客户端推送消息的可能。与此同时，HTTP协议是无状态的，这意味着连接在请求得到响应以后就关闭了，所以，每次请求都是独立的、上下文无关的请求。这种单向请求的特点，注定了客户端无法实时地获取服务端的状态变化，如果服务端的状态发生连续地变化，客户端就不得不通过“轮询”的方式来获知这种变化。毫无疑问，轮询的方式不仅效率低下，而且浪费网络资源，在这种背景下，WebSocket应运而生。 &emsp;&emsp;WebSocket协议最早于2008年被提出，并于2011年成为国际标准。目前，主流的浏览器都已经提供了对WebSocket的支持。在WebSocket协议中，客户端和服务器之间只需要做一次握手操作，就可以在客户端和服务器之间实现双向通信，所以，WebSocket可以作为服务器推送的实现技术之一。因为它本身以HTTP协议为基础，所以对HTTP协议有着更好的兼容性，无论是通信效率还是传输的安全性都能得到保证。WebSocket没有同源限制，客户端可以和任意服务器端进行通信，因此具备通过一个单一连接来支持上下游通信的能力。从本质上来讲，WebSocket是一个在握手阶段使用HTTP协议的TCP/IP协议，换句话说，一旦握手成功，WebSocket就和HTTP协议再无瓜葛，下图展示了它与HTTP协议的区别： HTTP与WebSocket的区别 构建一个聊天室&emsp;&emsp;OK，在对WebSocket有了一个基本的认识以后，接下来，我们以一个最简单的场景来体验下WebSocket。这个场景是什么呢？你已经知道了，答案就是网络聊天室。这是一个非常典型的实时场景。这里我们分为服务端实现和客户端实现，其中：服务端实现自豪地采用.NET Core，而客户端实现采用Vue的双向绑定特性。现在是公元2018年了，当jQuery已成往事，操作DOM这种事情交给框架去做就好，而且我本人很喜欢MVVM这种模式，Vue的渐进式框架，非常适合我这种不会写ES6的伪前端。 .NET Core与中间件&emsp;&emsp;关于.NET Core中对WebSocket的支持，这里主要参考了官方文档，在这篇文档中，演示了一个最基本的Echo示例，即服务端如何接收客户端消息并返回消息给客户端。这里，我们首先需要安装Microsoft.AspNetCore.WebSockets这个库，直接通过Visual Studio Code内置的终端安装即可。接下来，我们需要在Startup类的Configure方法中添加WebSocket中间件： 1app.UseWebSockets() 更一般地，我们可以配置以下两个配置，其中，KeepAliveInterval表示向客户端发送Ping帧的时间间隔；ReceiveBufferSize表示接收数据的缓冲区大小： 123456var webSocketOptions = new WebSocketOptions()&#123; KeepAliveInterval = TimeSpan.FromSeconds(120), ReceiveBufferSize = 4 * 1024&#125;;app.UseWebSockets(webSocketOptions); &emsp;&emsp;好了，那么怎么接收一个来自客户端的请求呢？这里以官方文档中的示例代码为例来说明。首先，我们需要判断下请求的地址，这是客户端和服务端约定好的地址，默认为/，这里我们以/ws为例；接下来，我们需要判断当前的请求上下文是否为WebSocket请求，通过context.WebSockets.IsWebSocketRequest来判断。当这两个条件同时满足时，我们就可以通过context.WebSockets.AcceptWebSocketAsync()方法来得到WebSocket对象，这样就表示“握手”完成，这样我们就可以开始接收或者发送消息啦。 12345678if (context.Request.Path == \"/ws\")&#123; if (context.WebSockets.IsWebSocketRequest) &#123; WebSocket webSocket = await context.WebSockets.AcceptWebSocketAsync(); //TODO &#125;&#125;); &emsp;&emsp;一旦建立了Socket连接，客户端和服务端之间就可以开始通信，这是我们从Socket中收获的经验，这个经验同样适用于WebSocket。这里分别给出WebSocket发送和接收消息的实现，并针对代码做简单的分析。 123456789101112private async Task SendMessage&lt;TEntity&gt;(WebSocket webSocket, TEntity entity)&#123; var Json = JsonConvert.SerializeObject(entity); var bytes = Encoding.UTF8.GetBytes(Json); await webSocket.SendAsync( new ArraySegment&lt;byte&gt;(bytes), WebSocketMessageType.Text, true, CancellationToken.None );&#125; &emsp;&emsp;这里我们提供一个泛型方法，它负责对消息进行序列化并转化为byte[]，最终调用SendAsync()方法发送消息。与之相对应地，客户端会在onmessage()回调中就会接受到消息，这一点我们放在后面再说。WebSocket接收消息的方式，和传统的Socket非常相似，我们需要将字节流循环读取到一个缓存区里，直至所有数据都被接收完。下面给出基本的代码示例： 12345678910111213var buffer = new ArraySegment&lt;byte&gt;(new byte[bufferSize]);var result = await webSocket.ReceiveAsync(buffer, CancellationToken.None);while (!result.EndOfMessage)&#123; result = await webSocket.ReceiveAsync(buffer, default(CancellationToken));&#125;var json = Encoding.UTF8.GetString(buffer.Array);json = json.Replace(\"\\0\", \"\").Trim();return JsonConvert.DeserializeObject&lt;TEntity&gt;(json, new JsonSerializerSettings()&#123; DateTimeZoneHandling = DateTimeZoneHandling.Local&#125;); &emsp;&emsp;虽然不大清楚，为什么这里反序列化后的内容中会有大量的\\0，以及这个全新的类型ArraySegment到底是个什么鬼，不过程序员的一生无非都在纠结这样两个问题，“it works” 和 “it doesn’t works”，就像人生里会让你纠结的无非是”她喜欢你“和”她不喜欢我“这样的问题。有时候，这样的问题简直就是玄学，五柳先生好读书而不求甚解，我想这个道理在这里同样适用，截止到我写这篇博客前，这个代码一直工作得很好，所以，这两个问题我们可以暂时先放在一边，因为眼下还有比这更为重要的事情。 &emsp;&emsp;通过这篇文档，我们可以非常容易地构建出一个”实时应用“，可是它离我们这篇文章中的目标依然有点距离，如果各位足够细心的话，就会发现这样一个问题，即示例中的代码都是写在app.Use()方法中的，这样会使我们的Startup类显得臃肿，而熟悉OWIN或者ASP.NET Core的朋友，就会知道Startup类是一个非常重要的东西，我们通常会在这里配置相关的组件。在ASP.NET Core中，我们可以通过Configure()方法来为IApplicationBuilder增加相关组件，这种组件通常被称为中间件。那么，什么是中间件呢？ 中间件示意图 &emsp;&emsp;从这张图中可以看出，中间件实际上是指在HTTP请求管道中处理请求和响应的组件，每个组件都可以决定是否要将请求传递给下一个组件，比如身份认证、日志记录就是最为常见的中间件。在ASP.NET Core中，我们通过app.Use()方法来定义一个Func&lt;RequestDelegate,RequestDelegate&gt;类型的参数，所以，我们可以简单地认为，在ASP.NET Core中，Func&lt;RequestDelegate,RequestDelegate&gt;就是一个中间件，而通过app.Use()方法，这些中间件会根据注册的先后顺序组成一个链表，每一个中间件的输入是上一个中间件的输出，每一个中间件的输出则会成为下一个中间件的输入。简而言之，每一个RequestDelegate对象不仅包含了自身对请求的处理，而且包含了后续中间件对请求的处理，我们来看一个简单的例子： 1234567891011121314151617app.Use(async (context,next)=&gt;&#123; await context.Response.WriteAsync(\"这是第一个中间件\\r\\n\"); await next();&#125;);app.Use(async (context,next)=&gt;&#123; await context.Response.WriteAsync(\"这是第二个中间件\\r\\n\"); await next();&#125;);app.Use(async (context,next)=&gt;&#123; await context.Response.WriteAsync(\"这是第三个中间件\\r\\n\"); await next();&#125;); &emsp;&emsp;通过Postman或者任意客户端发起请求，我们就可以得到下面的结果，现在想象一下，如果我们在第一种中间件中不调用next()会怎么样呢？答案是中间件之间的链路会被打断，这意味着后续的第二个、第三个中间件都不会被执行。什么时候我们会遇到这种场景呢？当我们的认证中间件认为一个请求非法的时候，此时我们不应该让用户访问后续的资源，所以直接返回403对该请求进行拦截。在大多数情况下，我们需要让请求随着中间件的链路传播下去，所以，对于每一个中间件来说，除了完成自身的处理逻辑以外，还至少需要调用一次next()，以保证下一个中间件会被调用，这其实和职责链模式非常相近，可以让数据在不同的处理管道中进行传播。 ASP.NET Core中间件示例 &emsp;&emsp;OK，这里我们继续遵从这个约定，将整个聊天室相关的逻辑写到一个中间件里，这样做的好处是，我们可以将不同的WebSocket互相隔离开，同时可以为我们的Startup类”减负“。事实证明，这是一个正确的决定，在开发基于WebSocket的弹幕功能时，我们就是用这种方式开发了新的中间件。这里，我们给出的是WebSocketChat中间件中最为关键的部分，详细的代码我已经放在Github上啦，大家可以参考WebSocketChat类，其基本原理是：使用一个字典来存储每一个聊天室中的会话(Socket)，当用户打开或者关闭一个WebSocket连接时，会向服务器端发送一个事件(Event)，这样客户端中持有的用户列表将被更新，而根据发送的消息，可以决定这条消息是被发给指定联系人还是群发： 1234567891011121314151617181920212223242526public async Task Invoke(HttpContext context)&#123; if (!IsWebSocket(context)) &#123; await _next.Invoke(context); return; &#125; var userName = context.Request.Query[\"username\"].ToArray()[0]; var webSocket = await context.WebSockets.AcceptWebSocketAsync(); while (webSocket.State == WebSocketState.Open) &#123; var entity = await Receiveentity&lt;MessageEntity&gt;(webSocket); switch (entity.Type) &#123; case MessageType.Chat: await HandleChat(webSocket, entity); break; case MessageType.Event: await HandleEvent(webSocket, entity); break; &#125; &#125; await webSocket.CloseAsync(WebSocketCloseStatus.NormalClosure, \"Close\", default(CancellationToken));&#125; &emsp;&emsp;其中，HandleEvent负责对事件进行处理，HandleChat负责对消息进行处理。当有用户加入聊天室的时候，首先会向所有客户端广播一条消息，告诉大家有新用户加入了聊天室，与此同时，为了让大家可以和新用户进行通信，必须将新的用户列表推送到客户端。同理，当有用户离开聊天室的时候，服务器端会有类似的事件推送到客户端。事件同样是基于消息来实现的，不过这两种采用的数据结构不同，具体大家可以通过源代码来了解。发送消息就非常简单啦，给指定用户发送消息是通过用户名来找WebSocket对象，而群发消息就是遍历字典中的所有WebSocket对象，这一点我们不再详细说啦！ Vue驱动的客户端&emsp;&emsp;在实现服务端的WebSocket以后，我们就可以着手客户端的开发啦！这里我们采用原生的WebSocket API来开发相关功能。具体来讲，我们只需要实例化一个WebSocket类，并设置相应地回调函数就可以了，我们一起来看下面的例子： 12var username = \"PayneQin\"var websocket = new WebSocket(\"ws://localhost:8002/ws?username=\" + username); &emsp;&emsp;这里我们使用/s这个路由来访问WebSocket，相应地，在服务端代码中我们需要判断context.Request.Path，WebSocket在握手阶段是基于HTTP协议的，所以我们可以以QueryString的形式给后端传递一个参数，这里我们需要一个用户名，它将作为服务端存储WebSocket时的一个键。一旦建立了WebSocket，我们就可以通过回调函数来监听服务器端的响应，或者是发送消息给服务器端。主要的回调函数有onopen、onmessage、onerror和onclose四个，基本使用方法如下： 123456789101112131415websocket.onopen = function () &#123; console.log(\"WebSocket连接成功\");&#125;;websocket.onmessage = function (event) &#123; console.log(\"接收到服务端消息：\" + event.data)&#125;;websocket.onerror = function () &#123; console.log(\"WebSocket连接发生错误\");&#125;;websocket.onclose = function () &#123;console.log(\"WebSocket连接关闭\");&#125;; &emsp;&emsp;原生的WebSocket API只有两个方法，即send()和close()，这两个方法非常的简单，我们这里不再说明。需要说明的是，客户端使用了Vue来做界面相关的绑定，作为一个不会写CSS、不会写ES6的伪前端，我做了一个相当简洁(简陋)的前端页面，下面给出主要的页面结构，ViewModel层的代码比较多，大家可以参考这里： 12345678910111213141516171819&lt;div id=\"app\"&gt; Hi，&#123;&#123; username &#125;&#125;。欢迎来到WebSocket聊天室！ &lt;hr/&gt; 发送给： &lt;select v-model=\"sendTo\"&gt; &lt;option value=\"All\"&gt;全部&lt;/option&gt; &lt;option v-for=\"user in userList\" :value=\"user\"&gt;&#123;&#123;user&#125;&#125;&lt;/option&gt; &lt;/select&gt; &lt;hr/&gt; &lt;input id=\"text\" type=\"text\" v-model=\"message\" /&gt; &lt;button v-on:click=\"sendMessage\"&gt;发送消息&lt;/button&gt; &lt;hr/&gt; &lt;button v-on:click=\"openWebSocket\"&gt;打开WebSocket连接&lt;/button&gt; &lt;button v-on:click=\"closeWebSocket\"&gt;关闭WebSocket连接&lt;/button&gt; &lt;button v-on:click=\"clearMessageList\"&gt;清空聊天记录&lt;/button&gt; &lt;hr/&gt; &lt;div id=\"messageList\" v-html=\"messageList\"&gt; &#123;&#123; messageList &#125;&#125; &lt;/div&gt;&lt;/div&gt; &emsp;&emsp;下面是实际的运行效果，果然是非常简洁呢，哈哈:laughing: WebSocket聊天室展示 再看Websocket&emsp;&emsp;好了，我们花了如此大的篇幅来讲WebSocket，那么你对WebSocket了解了多少呢？或许通过这个聊天室的实例，我们对WebSocket有了一个相对直观的认识，可你是否想过换一个角度来认识它呢？我们说过，WebSocket是以HTTP协议为基础的，那么至少可以在握手阶段捕获到相关请求吧！果断在Chrome中打开”开发者工具“，在面板上选择监听”WebSocket”，然后我们就会得到下面的内容。 WebSocket的秘密-请求 &emsp;&emsp;相比HTTP协议，WebSocket在握手阶段的请求有所变化，主要体现在Upgrade、Connection这两个字段，以及Sec-WebSocket系列的这些字段。下面来分别解释下这些字段的含义，Upgrade和Connection这两个字段，是最为关键的两个字段，它的目的是告诉Apache、Nginx这些服务器，这是一个WebSocket请求。接下来，是Sec-WebSocket-Key、Sec-WebSocket-Protocol和Sec-WebSocket-Version这三个字段，其中Sec-WebSocket-Key是一个由浏览器采用Base64算法随机生成的字符串，目的是验证服务器是否真的支持WebSocket；Sec-WebSocket-Protocol则是一个由用户指定的字符串，目的是区分同一URL下，不同服务所需要的协议；Sec-WebSocket-Version是告诉服务器浏览器支持的WebSocket版本，标准规定9-12的版本号是保留字段，所以在这里我们看到的版本号是13. WebSocket的秘密-响应 &emsp;&emsp;那么，对于这个浏览器发起的这个请求，服务端是如何做出响应的呢？这就要来看看服务端返回的内容。 和客户端发起的请求类似，服务端返回的内容中依然会有Upgrade和Connection这两个字段，它们和请求中的含义是完全一致的。这里需要说明的是Sec-WebSocket-Accept这个字段，我们前面提到，浏览器会通过WebSocket-Key检验服务器是否真的支持WebSocket，具体怎么检验呢？是通过下面的算法。除此之外，一个特殊的地方是这个Response的状态码是101，这表示服务端说：下面我们就按照WebSocket协议来通信吧！当然，一个更为残酷的现实是，从这里开始，就不再是HTTP协议的势力范围了啊： 1sec-websocket-accept = base64(hsa1(sec-websocket-key + 258EAFA5-E914-47DA-95CA-C5AB0DC85B11)) 本文小结&emsp;&emsp;这篇文章选取了“实时应用”这样一个业务场景作为切入点，引出了本文的主题——WebSocket。WebSocket是一种建立在HTTP协议基础上的双向通信协议，它弥补了以“请求-响应”模型为基础的HTTP协议先天上的不足，客户端无需再通过“轮询”这种方式来获取服务端的状态变化。WebSocket在完成“握手”后，即可以长连接的方式在客户端和服务端间构建双向通道，因而WebSocket可以在实时应用场景下，作为服务器推送技术的一种方案选择。本文以一个WebSocket聊天室的案例，来讲解WebSocket在实际项目中的应用，在这里我们使用ASP.NET Core来完成服务端WebSocket的实现，而客户端选用原生WebSocket API和Vue来实现，在此基础上，我们讲解了ASP.NET Core下中间件的概念，并将服务器端WebSocket以中间件的形式实现。在下一篇文章中，我们将偏重于服务器端的数据推送，客户端将作为数据展现层而存在。好了，以上就是这篇文章的全部内容啦，谢谢大家，让我们一起期待下一篇文章吧！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Vue","slug":"Vue","permalink":"https://qinyuanpei.github.io/tags/Vue/"},{"name":".NET Core","slug":"NET-Core","permalink":"https://qinyuanpei.github.io/tags/NET-Core/"},{"name":"WebSocket","slug":"WebSocket","permalink":"https://qinyuanpei.github.io/tags/WebSocket/"}]},{"title":"草食系程序员的穿搭指南","date":"2018-07-25T10:11:35.000Z","path":"posts/94443781/","text":"&emsp;&emsp;最近一直在看《逃避虽可耻但有用》(逃げるは恥だが役に立つ)这部日剧，当我们感慨各种脑洞都满足不了人类的好奇心时，日剧依然在老老实实地讲述着故事，即使这个故事离普通人依旧很遥远。可我认为，这是一部以轻喜剧为载体的温情剧，不管你是单身、恋爱中还是已婚，你都能从这部剧中找到自己对应的部分。所以，对于这部日剧而言，我个人是推荐大家去看一看的。原谅我不肯用我贫乏的语言去评价这部电视剧，因为我相信“此中不足为外人道也”。所谓“如人饮水，冷暖自知”，感情这件事情，懂的人自然会懂，不懂的人假装懂。 &emsp;&emsp;剧中男主津崎平匡是一个“典型”的程序员，因为外表无攻击性，一脸的人畜无害，而被女主森山实栗称为“草食系”男人。男主的长相在主流审美中或许谈不上帅，因为这个世界更欣赏的，是风见君这样帅气的男人。程序员群体木讷而内向的性格，其实都是大众给贴上去的标签。人们不喜欢被贴上各种标签，可人们喜欢给别人贴各种标签，因为这样子区分不同的人最省事儿。我们无法指责这个世界用五官和三观来割裂地看待一个人，我们唯一能做的，就是去改变留在人们心中的刻板印象。剧中男主在很多方面是比我们优秀的，向他学习不能保证我们会娶到Gakki，可能让我们变得更优秀。 &emsp;&emsp;好了，下面就由我带大家一起来盘点男主在剧中的穿搭，所以，这是一篇总结向的草食系程序员穿搭指南。考虑到这部剧中室内场景比室外场景更多，季节主要集中在秋冬季，所以，我们将从环境、季节、种类等多个维度，对男主在剧中的穿搭进行盘点。活在一个看脸的时代最大的悲哀就是，那些长得比你好看，明明可以靠颜值，非要靠才华的人，永远都比你更努力。虽然津崎先生经常被人说“低情商”和“屌丝”，可我相信他比我们大多数“屌丝”要优秀得多。当然，这些优点需要大家在剧中去发掘。我只是希望，通过这种方式来提升自我。面对来自这个世界的恶意，争辩是没有意义的，你只能努力去纠正这种偏见。 室内篇 20180724012456548-101-2018725 1、深蓝色衬衣 + 深绿色休闲裤。作为职场日常穿搭，在第一集中出现，中年已婚男士池日在男主津崎面前炫耀“爱妻便当”，高情商的田沼先生替男主解围，安慰男主要好好吃饭。建议搭配：休闲皮鞋 + 一条优质皮带。同样地，我想说的是，一个人更要好好吃饭。 20180724012544572102-2018725 2、蓝色衬衣 + 西裤，俨然是雇主与雇员的上下级关系。女主森山实栗通过试用期考核，指令清晰、有条不紊给女主留下良好印象。作为职场常规搭配，搭配黑框眼睛，给人一种斯文儒雅的感觉，建议根据个人肤色，选择合适的颜色，具体来讲，如果你皮肤较白，建议选择明亮的色彩；如果你皮肤较黑，建议选择中性的色彩。 20180724012633880103-2018725 3、因为业务需求发生变更，男主被公司安排加班，在大家的共同努力下，项目终于按时完成，男主小心翼翼地在同事面前测试程序，衬衣领口的双色纹路，避免了视觉上的枯燥感，同事们在身后欢呼，男主深藏功与名，穿一件白衬衣，幻想自己是阿泰尔，千军万马避白袍，写程序没有Bug。 20180724012656554104-2018725 4、每个程序员都会有一件格子衬衫，仙剑之父姚壮宪更是穿了一辈子格子衬衫。讲道理，男主穿格子衬衫难看吗？为什么程序员穿格子衬衫和特步鞋就要被黑到异次元呢？其实，只要不是浮夸的大格子衬衫，穿起来一样萌萌哒，关键是合体！当然，只要一胖就完啦。所以，穿搭是技巧，健身是根本啊。 20180724012839470105-2018725 5、女人变美只需要一只口红，而男人变帅只需要一条领带。男女主决定协议结婚后，召集双方父母商议结婚事宜。一套贴合肩线的西装，搭配一件白色衬衫，视觉上给人成熟稳重的感觉，男主虽然在剧中表现得很“怂”，可这并不影响他的“帅”啊，这套衣服最多算彩排，真正的新郎礼服请关注第11集……(嗯，这是最后一集，日剧追起来很快呦) 20180724012746230106-2018725 6、简洁到不能再简洁的短袖衬衣 + 牛仔裤。前一秒的踌躇满志，同下一秒的惊慌失措，莫名地戳中萌点，明明同事就在眼前，非要学人家卷福发短信。请女生们不要再吐槽男生穿衣服“土”，你告诉我，除了长裤和短裤我们还有什么？对了，短裤是不能穿的哦……，尤其是花花绿绿的那种🙃 20180724012906742107-2018725 7、蓝白相间的衬衣，相比普通蓝色衬衣，平添了一种活泼的感觉，就连工牌卡的绳子都来凑热闹。你知道怎么快速从人群中识别一名程序员吗？牛仔裤 + 双肩包 + 工牌卡。不，我拒绝这种符号化的穿搭，大隐隐于市，忘了这套新手村装备吧……当然，如果你包里还是各种数据线……好像换汤不换药啊(逃 20180724013156508108-2018725 8、任何领域都会鄙视链的存在，像津崎先生这样优秀的工程师，自然远非某某培训班的学生们。如何做一名优雅的学院派呢？你需要一件毛衣或者是一件马甲，而且一定要套在衬衣上。你问我为什么这么穿，因为通常教授们都这样穿，请参考卷福主演的电影《模仿游戏》，负责破译德军恩尼格码密码机的专家们，都是这样的穿着，同样的，还有《万物李军》里剑桥的教授们…… 20180724013332938109-2018725 9、同样是毛衣和衬衣的搭配，圆领和V领是一种风格，是否翻出衬衣领又是一种风格。而我们的男主，显然可以同时驾驭这两种风格，再搭配一件休闲外套，试问还有谁？风见君帅是帅了，不过他的衣服好像永远都是针织衫啊，难道说有钱人都喜欢买一堆一样的衣服？恩，我说的就是老乔和小扎这种有钱人…… 20180724013332940110-2018725 10、果然，有圆领就会有V领，强迫症对工牌卡挂绳莫名地充满好感，这个“V”字完美地贴合衣领。针织衫和衬衣，需要有一定的层次感，比如备受我们嫌弃的格子衬衫，如果搭配针织衫效果还是非常不错的，唯一的要求或许是肩膀不能过宽，因为这样会显得整体线条僵硬。我有一个问题，像女主这样宽肩膀的女生，穿一字肩真的不怕滑下来吗？😂 20180724013332943111-2018725 11、这种“假领”的毛衣，穿出来同样好看，我严重怀疑，这个创意是来自上海静安区同福里的老马。如果你的脖子比较长，可以考虑尝试下高领毛衣，请注意，我不是在教你，去做一名女装大佬。话说回来，衬衣上套毛衣最大的缺点是，需要挤上衬衣最上面的扣子，所以买衬衣时，请确保可以放入两根手指，这样子不会像《杀破狼2》里的张晋一样被“帅”死。 20180724013332944112-1-2018725 20180724013332946112-2-2018725 12、这里分别是针织衫和毛背心搭配格子衬衫的正确示例，简而言之，衣服的搭配上需要体现出层次感，切忌选择色调过于接近的颜色，衬衣一定要修身，否则搭配毛衣会让你显得臃肿不堪。我要立一个flag，等我瘦到120斤，我就奖励自己一件针织衫。 20180724013332949113-1-2018725 20180724013332951113-2-2018725 13、毛衣和针织衫真的是搭配率超级高的优质单品，穿出来真的非常好看。我知圆领T恤是夏天最常见的穿搭，可如果你想尝试下不同的风格，我建议你买一件衬衣或者是Polo衫或者是针织衫，这些都能带给你不一样的感觉。我一直想尝试皮夹克或者是牛仔外套，可我自我感觉不适合这样硬朗的风格，谁让我是一个温柔的蓝孩纸呢…… 室外篇 20180724013619267201-2018725 1、这种材质的衣服应该很容易脏，而且大概率会让你显得臃肿(胖)，可不得不说，这一身和女主站一起挺搭的，我们学习穿搭只有两个目的，找到女朋友和不给女朋友丢脸(🙃)。作为围巾控，这身搭配我觉得可以尝试一下。 20180724013619269202-2018725 2、一个男人，只要有一件合身的西装，就已经在变帅的路上迈出一大步。这一款的话，毛衣黑白两种颜色，和衬衣蓝灰白的色调蛮接近的，所以基本上看不出层次感来。其实一直不明白男主为什么如此沉闷的颜色，难道是因为向女主表白以后变成熟了吗？😂 20180724013619273203-2018725 3、你看，这件衣服再次发挥了格子衬衫的伟大魅力，而在这件蓝色的针织衫的衬托下，可以明显地感觉到男主变“白”了，当90后们开始步入中年职场，不妨尝试穿一点靓丽的颜色，因为我们还可以再年轻一下。池日先生又讲了一句“名言”，你看津崎先生这震惊的小眼神。 20180724013619275204-1-2018725 20180724013619277204-2-2018725 4、这一次，男女主在众人“陪伴”下开展了一次小旅行，男主所穿的这件短袖衬衣真的是最普通的衣服，目测在某澜之家就可以找到同款，搭配这斜挎的帆布包简直是减龄神器，我真心羡慕那些三十多岁还会被认成学生的“大叔”们，在下高中刚毕业就被叫叔叔到现在，人家明明想被叫做“哥哥”😓 20180724013619279205-1-2018725 20180724013619281205-2-2018725 20180724013619283205-3-2018725 5、为什么这三件毛衣给人越来越帅的感觉？因为你发现它的颜色越来越纯粹，纯粹到最后就剩下一种颜色，所以，人家建议衣服上不要有Logo不无道理啊，在下有一位朋友，喜欢穿各种印有二次元图案的T恤，30多岁了永远都给人萌萌哒的感觉，你说到底听谁的好呢？总之，我计划今天买一件纯色毛衣，你呢？ 20180724013619285206-2018725 6、呃……这件应该被称为棒球衫还是夹克呢？我个人不太喜欢这种拼接的样式，我更喜欢那种纯色的简洁的夹克。说起这一集，男主因为错过女主的生日而自责，独自到商城里为女主挑选礼物，面对琳琅满目的商品，男主一脸茫然……有时，女生会嫌弃男生分不清口红色号什么的，并送给男生一个“直男”称号，其实，面对不熟悉的领域，谦虚而大方的承认就好了，我们当然是直的，难道你们喜欢弯的吗？ 20180724013619286207-2018725 7、你一定觉得像男主这样西装革履的高薪人士，每天都是坐在电脑前喝喝咖啡写写代码。其实，我们是一群连星巴克都不舍得去的人，每一次紧急加班，都是咖啡因转换为二进制代码的过程。我们并不是不会花钱，我们在数码产品、电子设备等方面的投入，完全不亚于你们买衣服、做美甲等等。有判词云：钱多、话少、死得快 20180724013619288208-2018725 8、嗯，这件怎么评价呢？中规中矩的秋冬款外套。我一直有一个愿望，等瘦下来以后买件卫衣穿，因为我实在怀疑自己，穿任何套头的衣服都会显得胖。不过好在这是秋冬季节，大家一起胖呀，这种衣服应该会比较容易脏，因为在下就有一件差不多的，果然直男审美啊，呵呵🙃 20180724013619290209-2018725 9、这个世界对长得高的人相当宽容，即使他们长得并不好看，可他们长得高穿衣服好看啊。从此刻开始，我希望你打破这种认知，谁说矮个子男生不能穿长款的衣服，男主这就是活生生的例子啊，我知道女生都喜欢175+的男生，可我希望你能找到我除了不能举高高以外的优点，女主到菜场就买了棵葱回来，男主赶紧接过来拎在手里，真是适合过日子的人啊 20180724233648400210-2018725 10、这是整部剧出镜率最高的一套衣服。什么？你问我这是哪一集？话说，你们都不看片尾曲的吗？由男主演唱的单曲《恋》，着实为抖音贡献了大量流量，这舞蹈难道不可爱吗？这衣服难道不好看吗？我说过了，衬衣 + 背心是学院派的典型穿法，男主果然是个文艺的男孩子，他的帅你Get到了吗？ 本文小结&emsp;&emsp;这或许是我写过的最“八卦”的一篇博客啦，有时候，越是轻松的东西越容易被人接受。程序员，他们并不是情商低，并不是内向，并不是不会撩妹，仅仅是因为这个世界不单单需要娱乐精神，同样需要严谨和专注。搅动一个人的情绪，无非是分泌出某种荷尔蒙；而真正驱动这个世界的，是严格甚至苛刻的规则。面对不熟悉的领域，应该保持敬畏心，而非以标签化的定义以讹传讹；如果靠贴标签就可以给人分类，那么谁是好人谁又是坏人？谁代表了正义谁又代表了邪恶？哦哦，对了，我们不会修电脑以及做任何你认为简单的事情……","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"程序员","slug":"程序员","permalink":"https://qinyuanpei.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"},{"name":"日剧","slug":"日剧","permalink":"https://qinyuanpei.github.io/tags/%E6%97%A5%E5%89%A7/"},{"name":"穿搭","slug":"穿搭","permalink":"https://qinyuanpei.github.io/tags/%E7%A9%BF%E6%90%AD/"}]},{"title":"邪不压正：本我的发现之旅","date":"2018-07-23T10:48:48.000Z","path":"posts/1099762326/","text":"&emsp;&emsp;一直想约朋友去看场电影，可是要找一部两个人都喜欢看的电影，当真是一件非常困难的事情。直到遇上了姜文的新片《邪不压正》，愿望终于在这个周末达成。说到姜文的电影，总是不可避免地提到“政治隐喻”这个词汇，所以，对这部电影而言，导演自成一体的独特风格，让其在与普通商业片拉开差距的同时，更将观众推向了一个略显尴尬的境地，以至于散场时朋友的第一反应是：好像完全没有看懂。 &emsp;&emsp;电影一开始，茫茫雪地里闪现出两个模糊的背影，向着雪地深处无限地延伸。而此时此刻，在火红的灯笼的映衬下，屋内一众人正忙着为师父庆贺寿辰，两位不速之客的到访，让一切瞬间化为烈焰中的修罗场。可以说，开篇这一场极具暴力美学的戏份，的确是可以吸引人眼球的戏份。姜文电影里有一种与生俱来的英雄主义，所谓的硬汉精神，于是你看到了身负东西方文化的李天然，是握着一把武士刀参与刺杀任务，而信奉武士道精神的根本一郎，果真是单刀赴会，说让三刀就是三刀。可这位武术名家，甚至连出手的机会都没有，就被手枪击中了头颅，武术在坚船利炮前又算得了什么呢？ &emsp;&emsp;不知道大家有没有注意到这样一个细节，朱潜龙和根本一郎闯到师父家里时，师父说了句：没听到狗叫，这是否是因为，在向师父祝寿时，跪拜的声音掩盖了炸弹的声音。联想到《让子弹飞》里，张牧之到鹅城上任，对老百姓说，“不许跪，皇帝都没有了，没有人值得你们跪……”。同样地，朱潜龙在师父面前，一样跪得可谓是以头抢地，可下一秒子弹就在师父脑袋上留下弹孔……其实，人蠢一点没有关系，毕竟都跪了几千年，可偏偏人还有点儿坏。师父问朱潜龙为什么日本人不在日本种植鸦片，朱潜龙说日本是文明的国家。 &emsp;&emsp;日本从明治维新以后，自上而下全面效仿西方国家，因为他们看到曾经最为强大的中华帝国，在鸦片和战争的侵蚀下早已满目疮痍。日本大河剧《坂上之云》里有一个片段，男主秋山真之在东京街头看到英国人欺负日本人，他愤怒地质问老师，为什么英国人在这里不讲绅士文化，他的老师不无遗憾地说，唯有强者有资格讲绅士文化。当时的日本不见得有多么文明，但那种全民参与到战争中的举动，在当时的世界格局里无出其右者，譬如日本曾担心和美国发生战争，起初民众讨论的是如何避免这场战争，后来则变成能否打赢这场战争，最后则变为如何打赢这场战争。 廖凡饰演的朱潜龙 &emsp;&emsp;朱潜龙在影片中是一个典型的汉奸，他帮日本人种鸦片，是希望在日本人的扶持下做个傀儡皇帝。在七七事变前，日本人借助麻姑囤事件，杀死了不愿意合作的张作霖，而朱潜龙自认为是大明后裔，一心想着要反清复明，可讽刺的是，溥仪在日本人的扶持下建立了伪满洲国政权，他居然天真地相信，日本人会允许两个傀儡政权同时存在。于是，在裁缝铺里李天然看到“龙袍”，导演不无幽默地说，这是准备去参加巴黎时装周的，仔细想起来，这是否是在讽刺某位穿着“龙袍”去参加电影节的演员呢？可朕的大清都灭亡了，你反什么清复什么明嘛，真有种《天龙八部》里慕容世家妄图兴复一个灭亡100余年的大燕国的痴狂劲儿。 姜文镜头下的北平城 &emsp;&emsp;姜文一心想要还原一个老北京的全貌，可我感觉在这部电影里看到的北京整体偏“白”一点，印象最深刻的地方是，老亨得利带着儿子从火车站回来，镜头里的北京好像刚下过雪一样。可或许是我们本不了解北京，故宫那种红墙青瓦的印象是从新中国成立以后的啦。梁思诚夫妇当年在战争中保护下来的古建筑群，或许本来就是这个样子的。于是，在姜文导演的镜头里，我们看到带着京味儿的北京胡同，看到了发生过无数故事的东交民巷，看到了曲折蜿蜒的八达岭长城，看到了古香古色的钟楼牌坊。李天然在屋顶跟踪朱潜龙的汽车时，我开玩笑地对朋友说，“以后刺客信条要出中国近代史系列游戏，完全可以参考李天然这个设定”。 姜文饰演的蓝青峰 &emsp;&emsp;这一次姜文饰演的蓝青峰，这个角色在我看来相当复杂：想要除掉朱潜龙和根本一郎，但私底下跟这两个人都有来往；和老亨得利有25年的交情，因为李天然身份暴露对其痛下杀手；被朱潜龙禁锢在家中无法自救，个人实力强弱被敌人查探地一清二楚；作为参加过辛亥革命的前辈，有且只有李天然一个下级……凡次种种，不一而足。从他的名字，我联想到“青出于蓝而胜于蓝”以及“青峰侠”，电影里李天然的英文名字叫做布鲁斯，他和师兄比武时致敬了李小龙的《龙争虎斗》，黑色的中国传统服饰，李小龙标志性的步法动作。可其实说到底，蓝青峰在精神上是懦弱的，因为他完全不清楚自己要做什么，那时国内外形势风起云涌，可他到底能真正地依赖谁，或许连他自己都不知道，他觉得李天然对他有用，就花了十余年时间去布局，李天然不过是他的一枚棋子…… &emsp;&emsp;蓝青峰的计划是让朱潜龙和根本一郎产生矛盾，朱潜龙杀死根本一郎后，再用李天然做交换。按照这个计划，李天然回国的确是来送死的，除非他可以在交换后杀死朱潜龙。蓝青峰害怕杀死根本一郎会引发战争，可从电影中来看，根本一郎并不是日军的高级军官。或许很多时候，人们都相信刺杀一两个人就可以让战争结束。全智贤在《暗杀》里说过这样一句话，“刺杀一两个日本人，能不能结束一场战争，我是不知道的，但我总要告诉人们，我们一直在战斗”。所以，即使李天然终于手刃仇人，卢沟桥的炮火依旧会在这个城市轰鸣。李天然凭借一腔热血，毫无来由地杀死了几个日本人，固然会让人激昂澎湃，可真的就是邪不压正吗？李天然的复仇，在我看来，是杀死懦弱的“自我”的过程，因为无父无母，李天然其实一直生活在“我是谁”、“我要去哪里”、“我要做什么”的自我怀疑之中， 许晴饰演的唐凤仪 &emsp;&emsp;唐凤仪，一个愿意陪着朱潜龙做皇帝梦的女人，习惯了被男人驱使和奴役，可被李天然恶作剧般在屁股上以后，她终于明白，自己在朱潜龙心中不过是一个玩物，尤其是六国饭店里的那场戏，看似不露痕迹地打朱潜龙耳光，实则这个敢爱敢恨的女人形象立了起来，回敬李天然的“凤仪之宝”，通过关巧红给李天然通风报信，日军进城时城墙上的一跃，都是这个角色留给人的深刻印象。所谓“商女不知亡国恨，隔江犹唱后庭花”，风尘女子的这种刻板印象，在姜文的电影里是不存在的，她们不单有性感的身姿，更有热血的灵魂。侵略者端坐在石狮子上准备拍照，被从城墙上一跃而下的唐凤仪撞倒在地上，当时电影院里发出一阵笑声，可这无非是一个女子的反抗而已。 姜文对老婆是真爱 &emsp;&emsp;与之相对的关巧红，她美好得宛如江南恬静的女子，她同样是一种独特的美感，和唐凤仪这种艳丽的画风不同，她是像迷一样的女子，背后有太多故事没有说完，看似惊鸿一瞥地讲了放脚、开裁缝铺这些琐碎的事情，但永远给人一种“这个女人不简单”的感觉，她好像无论什么时候，都能找得到李天然；她好像对李天然有种莫名的情愫，可又清楚地知道自己想要做什么……喜欢上这样的女人，就像喜欢上一朵云，你看云时很近，而云看你时很远。即使到了故事的结尾，她依然像阵风飘然远去，留下原地惆怅的李天然，明明李天然爬屋顶比她要好，可要寻找她时，又要去哪里寻找呢？有时候，这像是朴树的《那些花儿》散落天涯，有时候，又像是泰戈尔的“生如夏花般灿烂，死如秋叶般静美”…… &emsp;&emsp;说实话，这一次彭于晏的角色设定让人很出戏，因为这个角色本身的真实感并不强，即使他可以飞檐走壁，即使他可以躲开子弹。究其本质，是因为李天然身上有着勇敢而又懦弱的矛盾性格，未回国时，他一心想杀根本一郎和朱潜龙报仇；等回国后，他突然像被定住一般不知所措。第一次莽撞间接造成老亨得利被杀害，第二次莽撞直接导致蓝青峰被软禁。彭于晏一直都是一个“孤儿”，无论是师父、老亨得利还是蓝青峰，其实都不见得有多爱他。一个心中带着复仇愿望的人，一旦真正地手刃了仇人，他存在的意义又会是什么呢？所以，他怕自己因为复仇而变得迷茫，李天然看似身负正义之名，可对于师门武学的传承并无实际意义，相反，是那个杀死师父的朱潜龙，为师父塑像扬名，让师父成为大家所称赞的武术名家，到底谁是正？谁是邪？当周围人都是在利用你，杀了朱潜龙，李天然将失去存在感；而杀了李天然，日本人可以随时除掉朱潜龙。跪在岳飞目前的秦桧夫妇，和被塑成一条狗跪在武术名家塑像前，是否具有异曲同工之妙？普通人会在乎真相到底是什么样子的吗？ &emsp;&emsp;一个再简单不过的寻找“爸爸”的故事，对于那时的中国，是否就像年轻而莽撞的李天然，在探索着“我是谁”、“我要去哪里”、“我要做什么”的终极哲学命题。亨得利父子出城遇见正在演习的日本军官，对方声称亨得利父子的驴子挡住了坦克，破坏了军方的演戏计划。亨得利父子以美国护照作为挡箭牌，日本军官不得不去找这两头驴子的晦气。多年以后，吴京在《战狼》系列里重复着美国护照和海军陆战队的老梗，只是此时的中国早已不再是那个家国积弱的中国。日本军官质问李天然为什么穿着日本和服，可彼时彼刻，根本一郎自作聪明地曲解论语中的含义，又是否是在告诉我们，从外表上模仿何其容易，可一旦要张嘴说话，就很容易被人识破。曾经日本在全面欧化的过程中，被西方人讥讽为穿着衣服的猴子，我们都曾经模仿过他人，一如今天“韩式审美”在中国流行。这是一个时代里的众生相，愿每个人都能找到“真我”，不再犹豫，不再怯懦，勇敢地面对自己，发现自己。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"影评","slug":"影评","permalink":"https://qinyuanpei.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"邪不压正","slug":"邪不压正","permalink":"https://qinyuanpei.github.io/tags/%E9%82%AA%E4%B8%8D%E5%8E%8B%E6%AD%A3/"}]},{"title":"声明式RESTful客户端WebApiClient在项目中的应用","date":"2018-07-16T09:02:35.000Z","path":"posts/380519286/","text":"&emsp;&emsp;自从项目上采用敏捷开发的流程以后，我们的开发任务中出现了不少“联调”的任务，而所谓的“联调”任务，完全是拜前后端分离所赐。通常来讲，按照前后端分离的思想，我们的团队会被分成前端和后端两个组，前端负责页面内数据的展示，后端负责提供相关服务的接口。这样听起来非常合理，对吧？可问题在于，后端常常在等前端联调这些接口，因为后端不知道具体有哪些异常需要处理；同样，前端常常在等后端接口稳定，因为一旦出现问题，就会导致接口发生变更。虽然在此之前，我们早已花了一周左右的时间去讨论接口，接口文档早已伴随着API部署到线上，可我们依然需要大量的时间去沟通每个接口的细节。用一种什么样的语言来描述这种状态呢？大概就是人们并不是真的需要接口文档，因为真的不会有人去看这东西。 从敏捷开发到产品架构&emsp;&emsp;为什么会出现这种情况呢？我想，可以从三个方面来考虑，即设计不当、进度不一、沟通不畅。有时候集思广益去讨论一个接口，可能并不是一件好事，因为考虑的因素越多，问题就会变得越复杂，相应地妥协的地方就会越多。我并非不懂得做人需要适当妥协，事实是从妥协的那一刻起，我们的麻烦越来越多。有人问怎么能消灭Bug，我说消灭需求就可以了。现代人被各种各样的社交网络包围着，以至于隐私都被赤裸裸地暴露在空气中，可你很难想象人与人之间的沟通会越来越困难，难道是因为社交网络加剧了人类本身的孤独？没有人是一座孤岛，可前后端分离好像加剧了这种界限。现在动辄讲究全栈，可当你把精力都耗费在这些联系上去，你如何去追求全栈？相反，我们像电话接线员一样，在不停地切换上下文，因为我们要“敏捷”起来，可作为工程师就会知道，切换上下文需要付出相应的代价。 &emsp;&emsp;我之所以提到这样一个场景，是出于对当前项目的一种整体回顾。我们的项目是一个客户端产品，但是它依然体现了前后端分离的思想。受业务背景限制，这个客户端采用了Native + Web的技术架构。如果你了解整个互联网产品形态的演变历程，就会对这种技术架构非常的了解，从曾经的Native和Web之争，到所谓的Hybrid App，再到如今的React Native及小程序，这种技术架构其实一直都存在，譬如Electron、Atom、Node-Webkit、Cordova、Ionic、VSCode等等，其实都是非常相近的技术。对应到我们的项目，我们提供了一个JSBridge来完成Native层和Web层之间的通信，而客户端的渲染实际上是由前端来完成的，所以你可以想到，我们通过一个WebView来加载页面，而平台相关的交互由C++/C#来完成，所以，理论上客户端是是一个和Electron类似的壳子(Shell)，它可以展示来自任何页面的内容。 以JSBridge为核心的系统架构图 &emsp;&emsp;从客户端的角度来讲，它是Native层接口的提供者，连接着平台相关的API，并集成了第三方的硬件设备，所以，理论上它是和具体业务无关的。可实际上，因为Web层不能直接和文件系统交互，所以，像上传、下载这样本该由前端调用的接口，部分地转移到了客户端这边，所以，客户端无可避免地受到后端API变化的影响，因为业务上需求存在差异，上传接口前后共发生了三次变化，所以，客户端中存在三个版本的上传，当然，我相信这是一个设计上的问题，通过改进设计可以得到完美的解决。关于上传为什么会这么复杂，感兴趣的朋友可以通过留言来一起交流。这里我想说的是什么呢？因为客户端希望与具体业务无关，所以，客户端注定是以功能来划分服务，然后通过JSBridge暴露给Web层。可是对后端的微服务架构而言，它的服务是以业务为主导的，它的一个业务就是一个接口。由此导致一个问题，后端接口的数量不断增加，客户端面临频繁地改动。 不做平庸的ApiCaller&emsp;&emsp;有很多人说，今天的编程工作变得越来越简单，对于这一点我非常认同。因为，无论是无论是语言、工具、生态、平台，都获得空前的繁荣，所以，我们大多数人的工作，可能就是调用现成的API，而少数人的工作，可能就是提供友好的API，甚至连代码你都可以在Google上找到，你唯一要做的就是Ctrl + C &amp; Ctrl + V。当初想要改变世界的你我，突然有一天就变成了ApiCaller，甚至大多数的框架，你连底层细节都无从得知。可你真的打算做一个平庸的ApiCaller吗？至少我是不愿意的，因为在我看来，调用后端提供的API，大多数情况下都是换个URL，或者换个参数，这样的代码你写一次以后，剩下的基本就是复制和粘贴了，你可能会非常鄙视我的这种行为，可事实就是这样的，不单单我在复制，连我身边的同事都在复制。可这能怎么办啊，只要后端提供了新接口，或者是对接口进行了调整，而这些接口必须由客户端封装，我们的工作就永远不会停止，可这不过调用后端的API 而已啊！ &emsp;&emsp;有时候，我们会说工作经验和工作时间未必是正相关的，因为如果我们十年都在做一件事情，那么其实和一年是没有区别的。为了避免成为一个平庸的ApiCaller，你必须思考那些真正重要的事情。怎么能降低后端API变化对客户端的影响呢？降低耦合度。怎么降低耦合度呢？依赖抽象而非依赖具体。想想WebService，它通过WSDL来对服务进行描述，而通过WSDL就可以在客户端创建代理类，一旦WebService发生变更，重新生成代理类就好。再回想一下，调用后端API会遇到那些问题？设置Header、设置Cookie 、拼接URL、拼接参数、URLEncode、SSL、JSON序列化、FormData、上传文件、编码/解码等等，是不是每一次都在处理这些问题？看到项目里用HttpWebRequest去构造Mulitpartfile结构，我忽然间觉得绝望。既然每次都是翻来覆去这些东西，为什么要用手来写？API文档构建工具可以帮助用户生成curl以及常见语言对应的代码，所以，我有理由相信，我们需要一个东西来帮助我们完成这个工作，就像WebService生成代理类一样。那么，有没有这样一个东西呢？这就是本文的主角——基于声明式的RESTful风格的客户端：WebApiClient。 .NET下的Retrofit：WebApiClient&emsp;&emsp;WebApiClient是.NET平台下的Retrofit。要理解这句话，首先要理解Retrofit。什么是Retrofit呢？Retrofit是一个Android/Java下的网络通信库，其本身基于okHttp，熟悉Android开发的朋友，对这个库应该不会感到陌生。Retrofit帮助我们解决了上文中提到的，在请求一个Web API时会遇到的问题，并通过注解这种技术，以一种声明式的方式来定义接口。简单来说，所有你想要调用Web API都是接口中的一个方法，你通过注解来告诉Retrofit，该方法会请求哪一个Web API，参数会以什么样的形式传递过去，结果会以什么样的形式返回回来，你完全不必去写那些底层HTTP通信相关的东西，因为Retrofit会帮你在运行时实现这个接口。所以，我们说Retrofit是一种声明式的HTTP客户端。声明式我们见过相当多啦，Java里的注解，C#里的Attribute、Python里的装饰器、JavaScript里的修饰器，以及如今各种各样的双向绑定框架。下面，我们来一起看看WebApiClient这个库。 &emsp;&emsp;现在，我假设你手里已经有可供调用的Web API，并且你真实地了解这些Web API是如何工作的。至此，我们需要完成的工作主要都集中在客户端，这里我们编写一个控制台应用来完成这一工作。首先，需要在项目中引入WebApiClient这个库，我们直接通过Nuget来完成安装即可(注：这里共有Laojiu.WebApiClient、WebApiClient.JIT和WebApiClient.AOT三个版本，博主使用的是Laojiu.WebApiClient)。使用WebApiClient的基本流程是：首先，定义一个继承自IHttpApiClient的接口并在接口中声明相关方法；其次，通过Attribute对接口中的方法和参数进行修饰以完成和Web API的绑定；最后，通过WebApiClient生成该接口的一个实例，而通过调用相应的实例方法就可以得到结果。这是不是和代理类的感觉非常像呢？像博主这样懒惰的人，或许连接口都不愿意亲自去写，因为我相信越是严谨的规则，就越是适合应用到自动化上面去。这样说可能无法让大家形成对WebApiClient的直观印象，那么让我们从一个简单的例子开始吧！ Get请求接口12345678910111213[HttpHost(\"http://localhost:8000\")]public interface IValuesApiCaller : IHttpApiClient&#123; //GET http://localhost:8000/values1 [HttpGet(\"/values1\")] [OAuth2Filter] ITask&lt;string&gt; GetValues(); //GET http://localhost:8000/values1/&#123;id&#125; [HttpGet(\"/values1/&#123;id&#125;\")] [OAuth2Filter] ITask&lt;string&gt; GetValue(int id);&#125; &emsp;&emsp;在这个示例中，我们展示了WebApiClient是如何处理带参数以及不带参数的Get请求的。通过HttpGet特性，我们分别为GetValues()和GetValue()两个方法指定了请求的URL。虽然在这里我们指定一个完整的URL，可是考虑到我们Web API通常都是分布在不同的域名下，所以我们可以通过HttpHost特性来配置一个BaseURL。接口的返回值为ITask，我们可以通过我们的需要指定相应的类型，在这里我们以ITask为例，特别说明的是，如果服务器返回的是标准的JSON格式，那么我们可以将其映射为相应的实体结构，这就需要使用JsonReturn标特性对方法进行修饰。我们知道Get请求可以通过QueryString形式来进行传参，那么这一点在WebApiClient中如何实现呢？这就用到所谓的“平铺参数”，即我们在方法中声明的参数会被WebApiClient自动地追加到URL上面去，再不需要去手动地拼接这些参数；同理，这些参数可以用一个包装类封装起来，具体大家参考官方文档。 &emsp;&emsp;OK，现在来看看如何调用IValuesApiCaller这个接口。我们在前面说过，WebApiClient会帮助我们生成一个IValuesApiCaller的实例，所以我们调用一个Web API的时候，关注点已然从之前的过程实现转变为接口实现，这正是我们渴望看到的局面。一个非常简洁的调用示例： 123456789//调用Values Serviceusing (var client = HttpApiClient.Create&lt;IValuesApiCaller&gt;())&#123; Console.WriteLine(\"-----Invoke Values Service-----\"); var results = await client.GetValues().InvokeAsync(); Console.WriteLine($\"results is &#123;results&#125;\"); var result = await client.GetValue(10).InvokeAsync(); Console.WriteLine($\"result is &#123;result&#125;\");&#125; Post请求接口&emsp;&emsp;接下来，我们再来说说Post请求接口。同样的，这里我们使用博主编写好的一个Service，我们称之为Student Service。它使用了EF Core来完成数据库的读写，它提供了一组和Student实体相关的API，这里我们使用它来作为Post请求接口的示例实现。因此，我们首先定义一个接口IStudentApiCaller： 123456789101112131415[HttpHost(\"http://localhost:8000\")]public interface IStudentApiCaller : IHttpApiClient&#123; //GET http://localhost:8000/student [HttpGet(\"/student\")] [OAuth2Filter] [JsonReturn] ITask&lt;List&lt;Student&gt;&gt; GetAllStudents(); //POST http://localhost:8000/student [HttpPost(\"/student\")] [OAuth2Filter] ITask&lt;string&gt; NewStudent([JsonContent] Student student);&#125; &emsp;&emsp;这里重点关注接口中的第二个方法。首先，它是一个Post请求；其次，它接受一个JSON格式的文本作为它的请求体，所以我们这里使用了JsonContent特性。前面我们提到过，接口返回类型ITask，可以映射为对应的实体结构。注意到GetAllStudtents()这个方法中绑定的API，它负责从数据库中查询所有的Student信息并以JSON形式返回，所以这里我们将其映射为List。与此同时，你会注意到JsonReturn特性，这是在告诉WebApiClient，你希望将返回的结果映射为强类型的模型；同理，你可以使用XmlReturn特性来处理返回值为Xml的情形。除此之外，你还可以使用FormContent特性来修饰方法参数，其作用是将模型参数以key1=value1&amp;key2=value2……的形式写入请求体中，对应于x-www-form-urlencode；更一般地，你可以使用FormField特性修饰方法参数，以form-data的形式写入请求体中。Mulitpart是博主最为讨厌的一种数据格式，请大家自己去看官方文档。 过滤器与OAuth2&emsp;&emsp;无论如何，请允许我说，这是我最喜欢的一个特性。大家会注意到，在我的示例代码中，有一个东西一直没有去说，这就是OAuth2Filter，这其实是博主自己扩展的一个特性，这意味着在请求该API前，需要通过OAuth2授权以获得身份令牌。对于这一点，我想大家都是清楚的，因为在微服务架构中，Web API是作为一种受保护的资源而存在的，所以鉴权和授权是非常重要的点。以博主的项目组为例，我们做到第三个项目的时候，整个后端的OAuth2认证服务终于实现了统一，可即使如此，每一次这种基础设施都需要联调，都要考虑到底使用哪一种授权模式。譬如，客户端是考虑把token存放在全局静态类里，而前端是考虑把token存放在Cookie里，甚至在此之前，我们连refresh_token都没有，客户端在调用Web API时天天担心token过期，于是在调用Web API时主动去刷新一次token。你问我为什么不判断一下token有没有过期，因为后端没有提供这个接口呀。其实，我想说的只有一句话，基础设施请交给框架去处理。 &emsp;&emsp;WebApiClient提供了用于请求管道中的过滤器，可以让我们在请求前、请求后搞点事情。譬如，我们这里希望在请求前获取token，并将其追加到当前请求的Header里，或者是在请求前判断下token是否过期(假如后端愿意开发这个接口的话)，如果过期了就自动刷新下token，该怎么做呢？首先，我们定义一个IAuthApiCaller的接口，它负责从认证服务器上获取token，这里选择客户端模式： 123456[HttpHost(\"http://localhost:28203\")]public interface IAuthApiCaller : IHttpApiClient&#123; [HttpPost(\"/oauth2/token\")] ITask&lt;string&gt; GetToken([FormField] string client_id,[FormField] string client_secret,[FormField] string grant_type = \"client_credentials\");&#125; &emsp;&emsp;接下来，我们继承ApiActionFilterAttribute来编写OAuth2FilterAttribute，显然，它会在请求前调用IAuthApiCaller接口实例，这里我们将client_id和client_secret硬编码到代码里，单单是为了演示如何去印证这个想法，实际项目中大家可以考虑通过配置或者是传参来实现： 1234567891011121314151617[AttributeUsage(AttributeTargets.Method)]public class OAuth2FilterAttribute : ApiActionFilterAttribute&#123; public override Task OnBeginRequestAsync(ApiActionContext context) &#123; using (var client = HttpApiClient.Create&lt;IAuthApiCaller&gt;()) &#123; var client_id = \"578c06935d7f4c9897316ed50b00c19d\"; var client_secret = \"d851c10e1897482eb6f476e359984b27\"; var result = client.GetToken(client_id, client_secret).InvokeAsync().Result; var json = JObject.Parse(result); var token = json[\"access_token\"].Value&lt;string&gt;(); context.RequestMessage.Headers.Authorization = new AuthenticationHeaderValue(\"Bearer\",token); return base.OnBeginRequestAsync(context); &#125; &#125;&#125; &emsp;&emsp;至此，我们只需要给需要需要授权的API添加OAuth2Filter特性即可，全然不需要考虑这个token如何储存的问题。我对静态类和静态方法没有误解，仅仅是因为它是反模式的，任何全局内可以修改的成员，不管有没有人会去修改，它始终都是不安全的。在此我要表扬一下前端的同事，他们通过扩展ajax方法原型，实现了和这里类似的东西。所以说，你要多尝试去看看不同领域里的东西，抓住那些相同或者相似的本质，而不是被那些“旧酒换新瓶”的概念所迷惑，技术圈子的热闹有两种，一种是发明新的技术，一种是发明新的概念，我本人更喜欢第一种，你呢？ 上传与下载&emsp;&emsp;其实，上传应该是Post请求的一种类型，可是考虑到下载的时候，接口的返回类型应该是数据流，所以我决定将这两个内容一起来讲。这里我们就考虑单纯的上传，不考虑由文件和键值对混合组成的MulitpartFormDataContent，因为这种结构让我觉得厌恶。这里，我们直接通过ASP.NET Core编写了一个文件上传/下载的Service，同样地，我们首先定义IFilesApiCaller接口： 123456789101112131415[HttpHost(\"http://localhost:8000\")]public interface IFilesApiCaller : IHttpApiClient&#123; //Post http://localhost:8000/files/upload [HttpPost(\"/files/upload\")] [OAuth2Filter] [JsonReturn] ITask&lt;string&gt; Upload([HttpContent]List&lt;MulitpartFile&gt; files); //Get http://localhost:8000/files/download/&#123;fileId&#125; [HttpGet(\"/files/download/&#123;fileId&#125;\")] [OAuth2Filter] ITask&lt;HttpResponseMessage&gt; Download(string fileId);&#125; &emsp;&emsp;在这里，上传我使用了ASP.NET Core中的IFormFile接口，并且在Postman测试通过，可是在网页上用type为file的input标签进行测试时，发现页面一直无法正常响应，不知道具体是什么原因(后来发现它完全和Postman中的请求体一样，好吧😬)，我一直不太理解ajax上传和表单上传的区别，曾经项目上用HttpWebRequest去做文件的上传，里面需要大量的字符串拼接动作去构造MulitpartFormData，只要后端上传的API发生变更，这段代码几乎就会变成不可维护的代码，幸运的是，在经过几次迭代以后，他们终于意识到了这个问题，在我的建议下，他们使用HttpClient重构了代码。在这里你会看到Download()方法的返回值类型为ITask，这是HttpClient中使用的数据结构。为什么我推荐大家使用这套API，因为它和ASP.NET中的数据结构是一致的，而事实是上，WebApiClient正是在HttpClient的基础上完成的，所以这里你能够想到，我将通过HttpResponseMessage来获取返回的数据流，进而完成文件的下载。一起来看下面的示例： 12345678910111213141516171819202122232425//调用Files Serviceusing (var client = HttpApiClient.Create&lt;IFilesApiCaller&gt;())&#123; Console.WriteLine(\"-----Invoke File Service-----\"); var files = new string[] &#123; @\"C:\\Users\\PayneQin\\Videos\\Rec 0001.mp4\", @\"C:\\Users\\PayneQin\\Videos\\Rec 0002.mp4\", &#125; .Select(f=&gt;new MulitpartFile(f)) .ToList(); var result = await client.Upload(files).InvokeAsync(); Console.WriteLine(result); var json = JArray.Parse(result); var fileId = ((JObject)json.First)[\"fileId\"].Value&lt;string&gt;(); var fileName = Path.Combine(Environment.CurrentDirectory, \"Output/Video001.mp4\"); var filePath = Path.GetDirectoryName(fileName); if (!Directory.Exists(filePath)) Directory.CreateDirectory(filePath); using (var fileStram = new FileStream(fileName, FileMode.Create)) &#123; var stream = await client.Download(fileId).InvokeAsync(); stream.Content.ReadAsStreamAsync().Result.CopyToAsync(fileStram); &#125;&#125; &emsp;&emsp;这里说明的是，非常遗憾，这里的上传接口并没有被成功调用，可能我还是被MulitpartFormDataContent这种东西所困惑着，尽管我使用了WebApiClient中提供的MulitpartFile类，并且使用HttpContent特性对参数进行了修饰。(后来发现是因为我使用JsonReturn特性，可我的Action的确是返回了JSON啊，所以，我不暂时理解不了这一点😬)。我了解到的一点信息是，Spring Cloud中的Feign，一个和Retrofit极其相似的HTTP客户端，其本身并没有实现文件上传的功能，需要借助插件来实现相关功能，所以，这是否说明HTTP协议中的上传实现本身就是一个错误，因为它和form-data搅和在一起，试图用键值对的形式去描述一个文件，我们的业务中需要给文件增加备注关联相关信息，坦白讲，这种数据结构令人非常痛苦，所以，上传这块会有三个不同的版本，我一直希望上传可以和具体的业务解耦，即使需要给文件增加备注或者是关联相关信息，应该交给新的Service去做这件事情啊，这简直教人头疼啊。 可配置与动态化&emsp;&emsp;我知道许多人对特性这种”配置“方式并不感冒，因为他们觉得通过配置文件就可以做到不修改代码。我曾经帮助组里写了一个非常简洁的配置方案，后来这个方案在Code Review的时候被拒绝，因为我和别人写得不一样。直到前几天我看到ASP.NET Core里全新的配置方式，我瞬间意识到这种配置方式和我之前的想法不谋而合，这个世界上聪明的人的想法总是如此一致。我相信人们看到这篇文章里出现的各种特性，都会认为像Host、URL等等这些东西都被硬编码了，说得好像你们的代码不需要随着配置文件变化而变化似的，说得好像你们的代码每次都不需要重新编译似的。我曾经考虑到这一点，在开发一个库的时候，充分考虑到了可配置化，事实是大家都不喜欢写配置文件，从那以后，我就变成了坚定的“约定大于配置“主义。 &emsp;&emsp;回到WebApiClient这个话题，如果你不喜欢这种基于特性的配置方式，那么你可以通过HttpApiConfig这个类，动态地对诸如Host、URL等参数进行配置，并在WebApiClient创建接口实例的时候传入这些配置。下面是一个简单的示例： 123456789101112131415//手动创建配置var config = new HttpApiConfig()&#123; HttpHost = new Uri(\"http://www.yourdomain.com\"),&#125;;//调用Values Serviceusing (var client = HttpApiClient.Create&lt;IValuesApiCaller&gt;(config))&#123; Console.WriteLine(\"-----Invoke Values Service-----\"); var results = await client.GetValues().InvokeAsync(); Console.WriteLine($\"results is &#123;results&#125;\"); var result = await client.GetValue(10).InvokeAsync(); Console.WriteLine($\"result is &#123;result&#125;\");&#125; &emsp;&emsp;我知道杠精们绝对还有话要说，如果我连请求的URL都是动态地该怎么办呢？此时，你总不能让我再让我去配置URL了吧！对于这个问题，WebApiClient提供了Url特性，该特性可以修饰参数，表明这是一个URL，需要注意的是，该参数必须放在第一位，具体可以参考官方文档。 12[HttpGet]ITask&lt;string&gt; Login([Url] string url, string username, string password); 本文小结&emsp;&emsp;有时候，我会一直在想，前后端分离到底分离的是什么？在我看来，找出这种界限是最重要的，即前端与后端各自的职责是什么。我们想分离的其实是职责，可惜这种想法极其容易演变为前后端人员的分离。而这种人员上的分离，则让接口的设计和沟通充满了坎坷。前后端分离不在于项目是否由两个或者更多的人完成，而在于你是否可以意识到前后端代码里的界限。在这种前提下，博主通过项目上前后端分离的实践经验，配合产品本身的技术架构体系，引申出一个话题，即前端/客户端如何应对后端API快速扩增带来的影响，并由此提出，通过代理类来调用后端API的想法，这一想法借鉴了WebService。接下来，我们介绍了.NET平台下的Retrofit：WebApiClient，它可以让我们以一种“契约式”思想来声明接口，而不必关心这个接口该如何去实现，因为WebApiClient会帮助你实现具体功能。更改接口的代价永远比实现接口要小，所以，我相信这种声明式的HTTP客户端，可以让你更快速地应对来自后端的影响。在Java的世界里有Retrofit、有Feign，为了不被超越 太多，我们只能迎头赶上。谢谢大家，本篇到此结束，周末愉快！😬","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"RESTful","slug":"RESTful","permalink":"https://qinyuanpei.github.io/tags/RESTful/"},{"name":"WebApi","slug":"WebApi","permalink":"https://qinyuanpei.github.io/tags/WebApi/"},{"name":"HttpClient","slug":"HttpClient","permalink":"https://qinyuanpei.github.io/tags/HttpClient/"}]},{"title":"米花之味：永远相信美好的事情","date":"2018-07-02T09:50:17.000Z","path":"posts/2941880815/","text":"&emsp;&emsp;一如往常地坐公交回家，下过一场雨以后，天空被洗刷得干干净净，洗去了夏天的骄阳似火，洗去了归途的月明星稀。抬眼瞥见对面车窗，一个被夕阳裁剪得整齐的轮廓，就这样静静地映在玻璃上，一瞬间散发某种神圣的气息。突然间，我想到了被嘲笑不会撩妹的X君，想到了自嘲不会拒绝别人的Y君，想到了喜欢一个人而爱不得的Z君……大概这个模糊的轮廓，可以是这个世界上任何一个人。 &emsp;&emsp;我想说什么呢？你的生命也许从来都平淡无奇，可因为这一场秋雨的到来，在别人的眼睛里，就突然平添无数的神圣感。原来温暖从来都要自己去寻找，即使太阳的寿命意外的漫长，不至于像星辰一般昙花一现，你肉眼可以看到的星星，可能下一秒钟就消逝不见，就像这每天都见到的夕阳，有一天意外地点缀些金色或者黄色，你就会觉得它浑身都是温暖的力量。其实，那是极其平淡的一天，就像米花的味道一样，没有什么太特殊的含义，可你总愿意相信，当一个人的心足够虔诚的时候，神灵就可以听到你的心声，让那些奇迹发生。 &emsp;&emsp;米花之味，这部小清新得不像国产电影的电影，从一开始，就表现出了它不同于以往国产电影的气质，比如电影中卖鸡蛋的小女孩，在电影中前后共出现2次，第一次是女主辞掉城里工作回来的路上，第二次是女主独自驱车前往机场的路上。如果说第一次是女主出于善良而买小女孩的鸡蛋，那么第二次则是对家乡现状的一种无力感。这基本上奠定了这部电影整体的基调，现实与传统的始终形成鲜明的对比，甚至是作为矛盾冲突穿插在母女两人中间，可导演似乎并不想通过这些来表达什么观点，所以这就造成这部电影单看画面质感是非常美的，可整部电影的立意实在不算太高。 &emsp;&emsp;那么，我们在电影里看到了什么呢？跳广场舞大妈的一脸生无可恋、村里人夸夸其谈的致富梦想、表面奉承背地里说人长短、学校老师会接受学生“贿赂”、油腻感十足的新郎、“瓜分”募捐来的善款、搞封建迷信“请神”……这些非常真实的人物，像一张巨大的网将母女俩裹在其中，看起来两个人的矛盾，是留守儿童这样一个社会问题，可在我的理解中，这是现实与传统的一种碰撞，留守儿童不再是印象中内向闭塞的孩子，而或许是跟我们一样，知道什么是“吃鸡”，知道什么是“王者农药”，小镇村民不再是印象中善良淳朴的人们，而或许是知道生病了应该去医院，但“喊魂”这种事情同样需要，而对于募捐来的钱，无论是个人还是集体，都希望能分一点儿。 &emsp;&emsp;影片中喃杭的小伙伴喃湘露，是因为错过最佳治疗时机而死，而第一个送孩子去医院的人，恰恰是她们不大喜欢的老师，大人们说要等机场修好，就可以坐飞机去外面治病，接近尾声时，人们看到头顶呼啸而过的飞机，不知道会不会想起喃湘露这个孩子。母女俩完成和解是因为喃湘露的死亡，借喃杭的话说，“她不相信喃湘露已经死了，甚至都感觉不到悲伤”，可在一开始，女主就告诉女儿，以后不要和喃湘露一起玩儿。“请神”的时候，人们说已经有5年没有去祭拜过石佛啦。为什么要祭拜石佛呢？因为人们相信如果不这样做，以后会有更多的麻烦出现，可当一个地方被开发为旅游景点以后，我们以往所珍视的那些传统，究竟是否能在现代文明的洗礼下保存完整？ &emsp;&emsp;村民穿戴着传统的民族服饰，携带着供奉神灵的物品，一起到山里祭拜石佛，可门口悬挂着的“Closed”的木牌，连同将村民隔绝在外的那把铁锁，又仿佛将故事带入了后现代主义的胡同。如果石佛真的可以庇佑一方黎民，为何会被旅游开发者的一道铁门拦截？如果石佛真的可以感受到人们的虔诚，为何一定要到山林深处去朝圣祭拜？就像喃杭问她母亲，“我们给神跳舞，神就一定会知道吗？”，女主回答说，“只要你的心足够虔诚，神就可以感受得到”。这恰恰印证了老贺的举动，一行人被景区前的一道铁门给拦了下来，正暗自沮丧的时候，老贺说，“既然来都来了，无论在哪里跳舞，佛都会看见的”。 &emsp;&emsp;对于生活本身而言，鸡汤固然没有什么实际的用途，可人们往往又需要鸡汤，因为心里缺少了一样东西，就会很容易地被其它的东西填满，而这种东西我们都叫做它信仰。你总要试着去相信点什么，不管是唯物的还是唯心的。有时候我们之所以会焦虑，是因为我们想要索取的东西太多。其实生命里少了某些东西又能怎么样呢？你羡慕别人做什么事情都有人陪伴，可当你尝试去和别人一起做一件事情的时候，你就会发现，即使看电影这样一件小事，都会存在千差万别，比如你喜欢看好莱坞视觉大片，而我喜欢看日式田园小清新，真要找一部两个人都喜欢看的电影，难免会引发我的选择困难症。 &emsp;&emsp;有时候，你分不清喜欢一个人，到底是喜欢Ta还是喜欢Ta的习惯，分开以后的情侣，某一天意外地重逢，你说着对方那时这样或那样的习惯，而对方苦笑着说早就不喜欢那样子啦，那么，你开始怀疑，对方是不是真的喜欢这些，无论你是不是存在……喃杭打伤了大嘴，就在老师陪着大嘴在医院接受治疗的间隙，她对母亲撒谎说，“老师已经和大嘴回去了”……然后就是母女两人的冲突爆发，周围人的风言风语，母亲对女儿学习、生活上的种种不满，女儿对母亲的那种疏离感，相互纠缠在一起。喃湘露平时都见不到父母，甚至开玩笑地说，等到生一场大病看他们怎么办，可她依然相信，没有母亲会不爱自己的孩子。 &emsp;&emsp;最令我动容的是，喃杭说要给她变一个魔术，然后喃湘露就见到了自己的父母，三个人，六只眼睛，有惊异、有辛酸，霎时之间全部涌上心头。“神婆”说米花米酒都变味了不好吃，大概是因为我们缺少了那种简单和纯粹，母女俩一起炸米花的时候，中间女主被叫去一段时间，喃杭炸的米花在翻动的时候，从中间破碎成两半，或许人的心原本如此，当有了隔阂的时候，即便是再简单的事情，都会做不好。老人说山里不许女人进去，母女俩终于决定亲自走进洞里去，忽然发现，神圣无比的石佛，不过是在一个寻常无比的钟乳石洞里，听起来清脆无比的声音，不过是游客随手丢弃在地上的易拉罐…… &emsp;&emsp;心中去敬畏一样东西，不是永远被表象迷惑而且不敢有所怀疑，而是相信科学的解释，同样敬畏一切超越人力的力量，我怀疑云南的女孩子都会跳舞，比如曾经表演过千手观音的杨丽萍老师就来自云南，张大胡子甚至为了找一双好看的手，而让她出演了史上最美的梅超风，于是佛像前的一段舞蹈，成为了不亚于何小萍操场独舞的惊鸿一瞥，假如真的有来生，就祈祷喃湘露出生在一个富足的家庭里吧！你问神真的会灵验吗？不，不要去问神，而是去问你自己，所谓“心诚则灵”，相信一切美好的事情，All is well。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"影评","slug":"影评","permalink":"https://qinyuanpei.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"米花之味","slug":"米花之味","permalink":"https://qinyuanpei.github.io/tags/%E7%B1%B3%E8%8A%B1%E4%B9%8B%E5%91%B3/"}]},{"title":"基于Docker构建.NET持续集成环境","date":"2018-06-12T17:53:59.000Z","path":"posts/3995512051/","text":"&emsp;&emsp;最近在考虑将整个项目组的产品，努力向着持续集成(CI)/持续部署(CD)的方向靠拢，因为目前我们仅仅实现了基于 Docker 的自动化部署，而部署包的构建依然依赖于人工打包，而每个版本的测试和部署，基本上都要给所有相关人员发一遍邮件，而写邮件无非是填写版本号和变更历史。身处在这样一个社会化分工逐渐加剧的『摩登时代』，我们唯一的希望就追求技能的多元化，你越是担心有一天会被AI所替代，就越是应该去追求灵动与美。这个世界何尝不是一个运行中的大型机器，可恰恰就是这种掺杂了情感的冰冷法则，让我们意识到需要更多的理解和宽容。管理者常常迷信敏捷开发的人月神话，希望人可以像零件一样按部就班，在这场噩梦到来以前，为何不去做一点更有用的事情，让云计算帮我们解放双手。 背景说明&emsp;&emsp;我们的产品，从结构上来讲，分为后端、前端和客户端三个部分，其中，后端提供了从认证到上传、查询和下载等主要的AP接口；前端提供了基于后端API接口的页面，主要功能是监控和管理；客户端承担了主要的业务交互能力，主要功能是整合常用的硬件资源。从技术上来讲，后端是基于 Spring Cloud 的微服务架构，前端是基于node.js的典型前端工具链，而客户端是基于 .NET / Win32 的技术体系。所以，即使我们的客户端是运行在 Window 平台上，我们依然有大量的服务是运行在 Linux 环境下。负责部署的同事不愿意单独再构建一套持续集成(CI)环境，所以我们决定借助 Docker 完成整个持续集成(CI)环境的构建。 构建过程&emsp;&emsp;完成整个项目的构建，需要覆盖到代码编译、单元测试、静态检查、版本发布这四个基本环节，我们整体上使用 Jenkins 作为内部持续集成的平台，这意味着我们只需要在提交代码或者合并代码的时候，触发一个构建指令即可。这里我们考虑通过 Docker 来完成这些工作，一个整体上的设计思路如下图所示： 构建思路 MSBuild&emsp;&emsp;首先是 MSBuild，它是我们整个构建流程中最重要的环节，我们平时通过 Visual. Studio 编译一个项目，背后其实就是由 MSBuild 这个构建工具来驱动，而通过 MSBuild 我们定义更多的构建流程，例如执行单元测试、实现Zip打包等等的流程。在 Window 平台下我们安装 Visual Studio 后就可以使用 MSBuild ，那么在 Linux 平台下呢？目前， MSBuild 已经被微软开源并托管在 Github 上，大家可以通过这个地址：https://github.com/Microsoft/msbuild来访问。通过阅读 MSBuild的文档，我们了解到，目前 MSBuild 实际上有三个流向，分别是目前官方主推的 .Net Core 、传统的 .Net Framework以及由 Mono 托管的部分。 &emsp;&emsp;.Net Core中MSBuild实际上被集成在 .Net CLI 中，熟悉 .NET Core 的朋友一定都知道， .NET Core 类型的项目，是可以直接通过 dotnet 命令来创建项目、还原 Nuget 包、运行项目、构建项目和发布项目的，可以想象的到这些功能是依赖 MSBuild 和 Nuget 的，可惜这种目前对我们来说不太适合。接下来，我们有两个选择，一个是 Full Framework，一个是 Mono，因为我们的服务器是一台 Linux 服务器，所以 Full Framework 对我们来说不适合，我们在无奈的情况下选择了 Mono，按照官方文档，从源代码安装过程如下： 123git clone -b xplat-master https://github.com/mono/msbuild/cd msbuildmake &emsp;&emsp;果不其然，这个无论是在 Linux 主机还是D ocker 中都失败了，官方的源代码我们编译不过去，那就只能考虑非源代码安装啦！按照官方的说法，我们需要Mono，所以兴奋地跑到 Mono 官方去安装，根据以前使用 Mono的 经验，飞快地在终端里输入下面两行代码： 12sudo apt-get install mono-runtimesudo apt-get install mono-xbuild &emsp;&emsp;装完以后，发现可以使用 Mono 和 XBuild，可无奈是 XBuild 版本实在太低，换句话说我们从 Ubuntu 官方源里安装完的 Mono 相当于 .NET Framework 2.0 的版本，这怎么可以呢？果断从 Mono 官方下载最新版本的 Mono，这是一个经过反复试验的安装方法： 1234567891011sudo apt-get updatesudo apt-get upgrade -ysudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EFsudo apt install apt-transport-https -ysudo apt-get install wget -yecho \"deb https://download.mono-project.com/repo/ubuntu stable-trusty main\" | sudo tee /etc/apt/sources.list.d/mono-official-stable.listsudo apt-get updatesudo apt-get install aptitude -ysudo apt-get install -fsudo apt-get install -y gitsudo aptitude install -y mono-complete &emsp;&emsp;这里顺带安装了 git 和 wget，因为下面我们会用到这两个软件。 aptitude 实在是修复 Linux 依赖问题的神器，我准备找时间用它修复下我的 Linux 环境。 apt-transport-https 这个是为了支持 https 协议，这个不用说太多，我们选择了最全的一个 Mono 版本 mono-complete，它包含了我们在 Linux 下可以使用的所有程序集，换句话说，这些程序集以外的程序集，或者是和 Windows 联系紧密的 COM 组件、 OCX 等等，想都不要想啦，只有一件事情是对的，对平台的依赖越少，跨平台的可能性越高。 Nuget&emsp;&emsp;Nuget是 .NET 下使用最多的包管理器，虽然目前 .NET Core 里的依赖管理越来越像Maven，可我觉得作为整个构建工具里的一环，还是应该考虑进来，虽然我们的项目中的第三方库基本都靠拷。Nuget 只有单独的命令行版本和 Visual Studo 扩展两个版本，这里我们使用 wget 下载命令行版本，然后再通过 Mono 来调用 nuget.exe : 12sudo wget https://dist.nuget.org/win-x86-commandline/v4.6.2/nuget.exe /usr/local/bin/nuget.exealias nuget=\"mono /usr/local/bin/nuget.exe\" Sonar&emsp;&emsp;对于 Sonar 的话，这里我推荐用 SonarCloud，因为我们只需要通过 wget 下载 SonarScanner，然后通过 Mono 调用并提供 SonarCloud 提供的 token 即可。曾经博主写过一篇关于使用 SonarCloud为.NET/.NET Core项目提供静态检查的文章，在这篇文章中我们提到，SonarCloud 支持 .NET Framework 4.6+ 以上的版本以及 .NET Core 版本，所以，这里我们沿用当时的脚本即可，想了解 SonarCloud 的朋友，可以找到这篇文章进行深入了解。下面给出脚本： 123456sudo wget https://github.com/SonarSource/sonar-scanner-msbuild/releases/download/4.3.0.1333/sonar-scanner-msbuild-4.3.0.1333-net46.zip sonar-scanner.zipsudo unzip sonar-scanner.zipsudo alias sonar-scanner=\"mono ./sonar-scanner/SonarQube.Scanner.MSBuild.exe\"sonar-scanner begin /k:\"Sonar-HttpServer\" /d:sonar.organization=&lt;Your-Org&gt; /d:sonar.host.url=\"https://sonarcloud.io\" /d:sonar.login=&lt;Your-Token&gt;msbuild /t:Rebuildsonar-scanner end /d:sonar.login=&lt;Your-Token&gt; NUnit&emsp;&emsp;既然我们有了 Nuget，那么自然要用 Nuget 来做点事情。对于单元测试，微软提供的 MSTest 功能相对薄弱，关键是严重依赖 Visual Studio，一旦我们想要移植到 Linux 平台下，就会发现阻力重重，所以在平时开发中，我更建议大家去使用 NUnit 或者 XUnit，它们比 MSTest 功能强大，可以直接通过 Nuget 安装，同时自带 TestRunner，这是一个控制台程序，我们直接通过 Mono 调用它，并把单元测试项目生成的动态链接库作为参数传递给它即可。下面给出基本的脚本： 123nuget install NUnit.Runners -Version 3.8.0 -OutputDirectory ./TestRunneralias nunit=\"mono ./TestRunner/NUnit.ConsoleRunner.3.8.0/tools/nunit3-console.exe\"nunit &lt;Your-UnitTest-Project&gt; 牛刀小试&emsp;&emsp;下面我们来试试在 Docker 里完成镜像的构建，其实这里更推荐在Linux下安装 Docker，博主在 Window 平台下安装了 Docker for Windows，需要系统支持虚拟化技术。因为博主在构建镜像的时候，一直提示磁盘空间不足，所以，这里我们把 Dockerfile 放到 DaoCloud 上去跑，关于 Docker 的安装以后有机会在同大家分享。这里， DaoCloud 你可以理解为一个帮我们装好了 Docker 的云主机，事实上用 DaoCloud 以后，感觉测试 Dockerfile 可以更省时间啦，效率上相差十倍啊！ Dockerfile 其实就是本文中这些脚本的集合，这里我们给出完整的 Dockerfile，这个文件可以从这里获取： 1234567891011121314151617181920212223242526272829303132333435363738FROM ubuntu:14.04LABEL vendor=\"qinyuanpei@163.com\"# Install Mono &amp;&amp; XBuildRUN sudo apt-get updateRUN sudo apt-get upgrade -yRUN sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EFRUN sudo apt install apt-transport-https -yRUN sudo apt-get install wget -yRUN echo \"deb https://download.mono-project.com/repo/ubuntu stable-trusty main\" | sudo tee /etc/apt/sources.list.d/mono-official-stable.listRUN sudo apt-get updateRUN sudo apt-get install aptitude -yRUN sudo apt-get install -fRUN sudo apt-get install -y gitRUN sudo apt-get install -y zipRUN sudo apt-get install -y unzipRUN sudo aptitude install -y mono-complete# Intall NugetRUN sudo wget -O nuget.exe https://dist.nuget.org/win-x86-commandline/v4.6.2/nuget.exe #RUN alias nuget=\"mono nuget.exe\"# Install Sonar-ScannerRUN sudo wget -O sonar-scanner.zip https://github.com/SonarSource/sonar-scanner-msbuild/releases/download/4.3.0.1333/sonar-scanner-msbuild-4.3.0.1333-net46.zipRUN sudo unzip sonar-scanner.zip -d ./sonar-scanner#RUN alias sonar-scanner=\"mono .SonarQube.Scanner.MSBuild.exe\"# Install NUnitRUN mono nuget.exe install NUnit.Runners -Version 3.8.0 -OutputDirectory ./TestRunner#RUN alias nunit=\"mono ./TestRunner/NUnit.ConsoleRunner.3.8.0/tools/nunit3-console.exe\"# Build Project &amp;&amp; Sonar Analyse &amp;&amp; UnitTestRUN git clone https://github.com/qinyuanpei/HttpServer.gitRUN sudo mono ./sonar-scanner/SonarQube.Scanner.MSBuild.exe begin /k:\"Sonar-HttpServer\" /d:sonar.organization=\"qinyuanpei-github\" /d:sonar.host.url=\"https://sonarcloud.io\" /d:sonar.login=\"db795a28468dc7c12805b330afed53d362fdd2d9\"RUN msbuild /p:Configuration=Release ./HttpServer/HTTPServer/HTTPServer.slnRUN sudo mono ./sonar-scanner/SonarQube.Scanner.MSBuild.exe end /d:sonar.login=\"db795a28468dc7c12805b330afed53d362fdd2d9\"# RUN mono ./TestRunner/NUnit.ConsoleRunner.3.8.0/tools/nunit3-console.exe ./HttpServer/HTTPServer/HTTPServerLib.UnitTest/bin/Release/HttpServerLib.UnitTest.dllEXPOSE 2048 好了，下面我们通过 Dockerfile 来构建镜像，这里不需要考虑部署，我们就是在 Docker 这个环境里跑跑结果(PS：不知道为什么alias在 Docker 里不起作用)： 1docker build -t httpserver:v1 . 可以看到，我们整个过程除了单元测试没有通过以外，其它的环节都非常顺利，这其中一个重要的原因是，博主这个项目对 Window 依赖较少，它是一个 C# 开发的简易 Web 服务器，主要是类库和控制台程序，可以完美地运行在 Linux 平台下，所以，跨平台最终考验的还是开发人员。 Docker中构建的结果 One More Thing&emsp;&emsp;这里我们主要针对的是 .NET Framework，那么针对传统的 ASP.NET 以及最新的 .NET Core 又该如何做持续集成呢？这里简单说一下思路，具体的 Dockerfile 大家可以去 DockerHub 去找(抄)，这里我就不帮大家写了。对于传统的 ASP.NET，在本文的基础上增加 Jexus 就可以做 Linux 下的部署，当然，前提是要避免和 Window 太过紧密的耦合，否则即便是大罗神仙亲临，这持续集成永远都是个梦。对于 .NET Core ，只要安装了它的SDK，编译、依赖管理、发布、部署都不再是问题，只要完善下单元测试和静态检查就可以，因为它是可以自部署的，并且天生就是为了跨平台而生，如果有可能，还是考虑用 .NET Core 吧，Windows 最适合的还是吃鸡打游戏(逃…… 本文小结&emsp;&emsp;读过我之前博客的朋友，一定会发现，我今天这篇博客里所做的事情，同我曾经在 .NET 项目上使用 TravisCI 是完全一样的，所不同的是， TravisCI 里的构建环境是别人提供好的，而这里的构建环境是我们自己搭建的。这并不是在做无用功，如果你需要搭建私有的 Linux 下的构建环境，我相信这篇文章会带给你一点启示。项目组最后还是放弃了这个方案，因为产品里集成了太多和 Window 关联的东西。而负责部署的同事最终如释重托，因为他们不必去踩这些无聊的坑，可对我来说，这像一道屈辱的烙印刻在我的心上，我甚至试过在 Docker 环境里搭建 Window 的环境，哪怕最终我发现我不能把 Docker 当一个虚拟机来用，我越来越害怕自己对那些变化一无所知，还庆幸自己可以在时光的影子里偷懒。 &emsp;&emsp;有时候，人们假装配合持续集成的流程，因为它听上去非常美好，可对环境的依赖不愿意削弱，对单元测试不是那么重视，对代码质量不是那么在意，这一切又永远都只是听上去美好而已。我听到有面试官在面试的时候，批评面试者所做的运维工作不是那么的高大上，毕竟我们只是写了点脚本而已，离面试官心中的 DevOps 相去甚远。可 MSBuild是 XML 写成的脚本， make 不过是个纯文本的脚本，到底哪一种更高大上？我在这篇文章里使用了 Docker，能否让我的工作显得高大上？我们的工作到底有多少能适应 DevOps？我觉得想清楚这个再谈高大上，不是不可以啊？对吧？好了，这就是这篇文章的全部内容啦，谢谢大家！","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://qinyuanpei.github.io/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":".NET","slug":"NET","permalink":"https://qinyuanpei.github.io/tags/NET/"},{"name":"Docker","slug":"Docker","permalink":"https://qinyuanpei.github.io/tags/Docker/"},{"name":"MSBuild","slug":"MSBuild","permalink":"https://qinyuanpei.github.io/tags/MSBuild/"}]},{"title":"一个由服务器时区引发的Bug","date":"2018-06-05T11:03:57.000Z","path":"posts/172426938/","text":"&emsp;&emsp;太阳照常升起，在每个需要挤公交车上班的日子里，即使窗外早已大雨如注。想来只有在周末，太阳会陪着我一起起床，所谓睡觉睡到自然醒，在雨天里保持晴天的心情，相当大的程度上，是因为今天不必上班。因此，一周里的心情晴雨表，简直就是活生生的天气预报，可惜我并不能预测我的心情，因为Bug会在某一瞬间发动突然袭击。一周前测试同事小J得到用户的反馈，我们某一笔订单突然无法从系统中查到，可就在数分钟前用户创建了这笔订单。前端同事小Q立刻追踪了这个问题，发现查询交易的接口调用正常，而后端同事小L确认数据库中是有这条交易记录的。于是，为了解决这样一个诡异的问题，几乎花费了大家大半天的时间。而最后的问题根源，居然充满了无厘头的意味，如本文主题所言，这是一个由服务器时区引发的Bug。在这篇文章中，我想和大家聊一聊，关于时区以及日期/时间格式化的相关问题，希望大家会喜欢这个话题，就如同我希望大家会喜欢我一样。&emsp;&emsp;可能大家都不会意识到时区会成为一个问题，因为对大多数中国人而言，我们唯一的时间概念就是北京时间。我们不得不承认，互联网在弱化了空间地域性的同时，无形中疏远了人与人之间的距离，尤其当我们处在一个分布式架构的时代，云的存在让我们的Service分布在无数个服务器节点上去，我们甚至意识不到它们的存在。比如我们在阿里云上选购主机的时候，阿里云会让我们去选择主机所在的地域，因为选择离自己更近的地域，意味着可以更快的访问速度。再比如像亚马逊这样的云计算服务商，会在国内(宁夏·中卫)部署自己的资源，这显然是为了服务国内用户。那么，我们不得不去思考一个问题，假如我们要同时服务国内、外的用户，那么这些Service 可能会被同时部署到国内和国外的服务器上面。因此，我们就可能会遇到国内、外服务器时区不一致的问题，通常我们会以服务器时间为准并将其储到数据库中。此时，因为时区不一致，难免会产生本文中遇到的这个问题。 时区为什么会不同？&emsp;&emsp;既然时区是本文里的“罪魁祸首”，那么我们就会不由得思考这样一个问题，即为社么时区会不同。我们知道，地球是自西向东自转的，因此东边会比西边先看到太阳。相应地，东边的时间会比西边的早。这意味着时间并不是一个绝对的概念，即东边的时间与西边的事件存在时差。现实中的时差不单单要以小时计，而且还要以分和秒计，这给人们带来了不便和困扰。因此，1884年在华盛顿召开的国际子午线会议上，规定将全球划分为24个时区(东、西各十二个时区)，其中以英国格林尼治天文台旧址作为零时区，每个时区横跨经度15度，时间恰好为1小时，而东、西第12时区各跨经度7.5度，以东、西经180度为界。每个时区内时间，统一以该时区的中央经线的时间为主，相邻的两个时区间总是相差一个小时，这就是时区的由来，时区的出现解决了人们换算时间的问题。 世界时区分布 &emsp;&emsp;事实上，时区的划分并不是一个严谨的事情，因为常常会出现一种情况，一个国家或者一个省份同时跨着2个或者更多的时区。以中国为例，中国幅员辽阔，差不多横跨5个时区，理论上在国内应该有5个时间，但为了使用起来方便，我们统一使用的是北京时间，即东八区时间。什么叫做东八区呢？即东半球第八个时区，其中央经度为东经120度。时区的计算非常简单，当你往西走时，每经过一个时区，时间会慢一个小时；当你往东走时，每经过一个时区，时间会快一个小时。例如，日本的东京位于东九区，因此，北京时间2018年6月9日8点整，对应的东京时间应该是2018年6月9日9点。这样，我们就会遇到一个非常有趣的问题，如果一个人到世界各地去旅行，它就需要不停地去将手表拨快或者拨慢，即使我们现在有了智能手机，它一样会提供不同时区的时间选择，假如我们偷懒选择了网络时间，那么它将永远和当地时间保持一致，因为我十分地确信，东京的运营商绝对不会选择使用北京时间。 数据库里如何存储时间&emsp;&emsp;截至到目前为止，我们可以搞清楚的一件事情是，在不同的地域使用的时间是不同的，因为我们所使用的时间，本质上都是相对于格林尼治时间的相对时间，即使这些时间会因为地域存在差异，可从整个宇宙的角度来看，时间分明又是在绝对地流逝着，它对我们每一个人而言都是客观而公正的，当你发现时间越来越不够用的时候，你需要思考时间到底被浪费到什么地方去。我无意像霍金先生一样，去追溯时间的起源以及它的未来，在这篇文章里，我更关心的是，数据库里究竟是怎么样存储时间的，因为最根本的问题是，用户作为查询条件的时间，服务器上存储记录的时间，这两个时间的上下文发生了混乱。人类更喜欢在工作中不停地切换上下文，尤其是在面对无休止的会议、需求分析、Review等等诸如此类的中断的时候，你是否会想到频繁地切换上下文，本质上是需要付出代价的呢？ Time is All &emsp;&emsp;回到这个问题本身，我们现在来看看数据库中是如何存储时间的，这里我们选择三种最为常见的数据库来分析，它们分别是MySQL、Oracle 和 SQL Server。 MySQL&emsp;&emsp;对MySQL来说，它支持YEAR、DATE、TIME、DATETIME和TIMPSTAMP共5种数据类型。其中， YEAR类型占1个字节，取值范围为1901~2155，可以采用4位字符串或者4位数字赋值，不建议使用2位数字或者2为字符串赋值，因为容易混淆0和‘0’。 DATE类型占4个字节，取值范围为1000-01-01 ~ 9999-12-31，采用YYYY-MM-DD的格式赋值，不建议使用@或.这样的分隔符，不建议将年份表示为YY，理由同上。 TIME类型占3个字节，取值范围为-838:59:59 ~ 838:59:59，采用HH:MM:SS的格式赋值，不建议使用HH:MM或者SS的简写格式，以及混合使用D的格式。 DATETIME类型占8个字节，取值范围为1000-01-01 00:00:00 ~ 9999-12-31 23:59:59，标准格式为YYYY-MM-DD HH:MM:SS，规则同上 TIMESTAMP类型占4个字节，取值范围为19700101080001 ~ 20380119111407，系统可以使用CURRENT_TIMESTAMP或者自动输入当前的TIMESTAMP，需要注意的是，该数值与时区有关。 Oracle&emsp;&emsp;对Oracle来说，它支持DATE、TIMPSTAMP和INTERVAL共3种数据类型。其中， DATE类型占7个字节，是一种表示日期/时间的数据类型，本身包含世纪、世纪中的哪一天、月份、月份中的哪一天、小时、分钟和秒7个属性，例如2005-12-05 12:30:43对应的表示是120、105、12、5、12、31、44，我们注意到这里世纪和世纪中的年份，都被相应地增加了100，而分钟数和秒数分别增加了1，这里增加的100是为了区分公元前和公元后，一般在写入该类型的数据时，最好能显式地指定日期或者时间的格式。 TIMPSTAMP类型，同DATE类型类似，不同的是，TIMESTAMP类型可以支持秒分量的小数位数以及时区。秒分量的小数部分最多可以支持9位，当秒分量的小数部分为0时，它和DATE类型在功能上完全一致。 INTERVAL类型，顾名思义，这是一个表示时间间隔的数据类型，同.NET中的TimeSpan类型相似，它可以用来存储一个时间间隔，比如8个小时或者是30天，两个DATE或者TIMESTAMP相减可以得到INTERVAL，而DATE或者TIMESTAMP增加一个INTERVAL就可以得到相应的DATE或者TIMESTAMP。 SQL Server&emsp;&emsp;对SQL Server来说，它支持Date、Time、DateTime和DateTime2共4种数据类型。其中， Date类型仅存储日期，不存储时间，需要3个字节的存储空间，默认格式为yyyy-MM-dd(PS:为什么没有一个标准来统一这些占位符的大小写)，取值范围为0001-01-01 ~ 9999-12-31，可以采用字符串、GetDate()、SysDateTime()三种方式赋值。 Time类型仅存储时间，不存储日期，需要7个字节的存储空间，默认格式为hh:mm:ss.nnnnnnn，可以注意到默认的秒分量小数部分为7位，建议使用字符串或者SysDateTime()这两种方式赋值，不建议使用GetDate()，因为该方法返回值为DateTime类型，其时间部分的精度没有Time类型的经度高。 DateTime/DateTime2，这个命名好COM+啊，其中DateTime类型存储日期和时间，需要8个字节的固定存储空间，相对应地，DateTime2的存储空间则是不固定的，因为它可以指定秒分量的小数位。DateTime的默认格式为yyyy-MM-dd hh:mm:ss.xxx，取值范围为1753-01-01 00:00:00.000 ~ 9999-1-3123:59:59.997，精确度为3.33毫秒，相应地，DateTime2的秒分量小数位默认可达到7位。通过GetDate()和GetUTCDate()两个函数，可以为DateTime类型赋值；通过SysDateTime()和SysUTCDateTime()函数，可以为DateTime2类型赋值。通常来说，DateTime2相比DateTime，具有更好的性能表现。&emsp;&emsp;此时此刻，我们不得不面对这样一个现实，那就是：不同的数据库中对日期/时间的存储处理是不同的。看起来这像是一个显而易见的结论，因为这就像SQL这门语言一样，即使我们有着相同的标准，可最终我们面对的还是各种“方言”版本的SQL，甚至连这些难以统一的内置函数，都会成为某次面试中的题目。我们注意到，这些和日期/事件相关的数据类型，在对时区的支持上差异明显，MySQL中的DATESTAMP是标准的UNIX时间戳，存储的是自1970-01-01至今经过的秒数，这个数据的存取都是相对简单的，因为MySQL内部帮你做了大量的转换的工作，&emsp;&emsp;可它的缺点是什么呢？由于4个字节长度的限制，它最多到2038年，可现在都2018年了啊！DATETIME类型的数据范围好像可以解决这个问题，遗憾的是它没有办法包含时区信息，这就尴尬了啊！或许有人会想到能不能用int类型来存储日期，这理论上是没有问题啊，可你愿意每次存取都要做一遍转换吗？这意味着我们需要一种同时支持日期、时间和时区的表示方法，所以，下面我们来说一说DateTime相关的格式化，这里特指UTC时间、GMT时间、本地时间和Unix时间。 繁杂的日期格式&emsp;&emsp;我对日期/时间的格式化的厌恶，最早来自为Excel编写读写库，人们发明了各种各样的样式，虽然常用的无非那么多种，可对于一个编写Excel读写库的人来说，你不得不去在读写过程中面对各种各样的格式，或者是从字符串变为DateTime类型，或者是从DateTime变为字符串。我本人非常喜欢OADate这种方式，因为它真正地做到了样式与数据分离，我们大多数时候面对的时间，它到底是一种什么数据类型，为什么你在Excel里输入日期/时间字符串会被当作是日期/时间，而通过快捷键插入的系统时间同样会被当作是日期/时间，有没有一种统一的可以描述时间的方式呢？这里需要介绍UTC时间、GMT时间、本地时间和Unix时间4个概念。 UTC时间&emsp;&emsp;UTC时间，即Coordinate Universal Time。它是一种通用的时间表示方法，UTC是根据原子钟来计算时间，它是经过平均太阳时、地轴运动综合修正计算后的一个结果，使用秒作为计量单位，由于原子钟计量的时间精度非常高，因此，可以认为UTC一个世界标准时间。 GMT时间&emsp;&emsp;GMT时间，即Greenwhich Mean Time。如果大家对这个名词不熟悉，那么我相信，对于格林威治天文台，大家一定非常熟悉啦！ 十七世纪，为了满足英国海上霸权的扩张，格林威治皇家天文台开始对天文进行观测。历史上每一次霸权主义的扩张，其初衷必然是非正义的，可伴随着这个过程中而产生的文明，可谓是是泽被后世，前文中提到的时区划分，就是以格林尼治天文台旧址作为零时区，所以GMT时间和UTC时间等价，前者提出较早，基于天文观测；后者提出较晚，基于现代物理。 本地时间&emsp;&emsp;本地时间，即LocalTime。从定以上来讲，本地时间=UTC时间+时差，其中东半球时区记为正，西半球时区记为负。以东八区为例，UTC+0800，即为本地时间，这就是我们所熟悉的北京时间。因为同时存在UTC和GMT两种标准，所以我们在某些场合下会看到GMT+0800，这两者表示的实际上是同一个时间，都以秒作为单位。 Unix时间&emsp;&emsp;Unix时间，又称Unix时间戳，顾名思义，这是一种在Unix及类Unix操作系统中表示时间的方法。Unix时间戳其实就是UTC 时间在计算机领域的一个应用，我们所看到的计算时间，其实都是从1970-01-01 00:00:00开始，截止到此时此刻的总秒数，这个方案被Unix及类Unix操作系统继承下来，甚至影响到了大量非Unix操作系统，这个方案后来被称为POSIX标准，因为该时间又被称为POSIX时间。或许有朋友会感到疑惑，计算机是会关机和断电的啊，那么这个时间不就会丢失吗？事实上计算机内部有一个称为RCT的硬件模块，该模块内部独立供电，所以可以准确记录下这个时间。一个有趣的事情是，计算机内部使用32位整型来表示时间，而32位整型最大能表示为2147483647秒，我们做个简单计算:2147483647/365/24/60/60，就可以知道这个数值为68.1年，这意味着计算机内部能表示最大年份为1970+68=2038。想想看今天已经是2018年啦，难道在我们有生之年会有幸见到这个Bug吗？这对整个数字时代来说算不算一次世界末日呢？哈哈，实际上我们有了64位以后这个问题就可以解决了，至于64位出现类似问题，这个只能交给时间来解决啦，因为那时你和我都早已不复存在。 ISO8601&emsp;&emsp;OK，现在我们来一起看一个实际的格式化问题，我们在调用后端提供的API接口时，前端同事使用日期格式是：2018-06-05T03:03:57.000Z，而后端同事使用的日期格式是：2018-03-16T19:14:22.077+0800。这两种不同的日期格式到底是什么呢？和我们这篇文章中提到的内容又有什么关联呢？因为博主曾经在写一个小工具的时候，遇到无法解析这种格式日期的问题，所以对这两种日期格式可谓是记忆犹新。这两种日期格式实际源于一个国际标准ISO8601。&emsp;&emsp;根据该格式的定义，当日期和时间组合使用时，需要在时间面前增加一个大写字母T，而Z表示时区，且默认表示0时区，因此字母Z可以省略，以我国为例，我国是东八区，所以正确的写法是+08:00，由此可以得知，第二种写法实际上就是一个表示东八区时间的表示方法，虽然这个写法是错误的。第一种写法有什么问题呢？它表示的是0时区的时间，因此对中国用户而言，他们需要在这个时间上增加8个小时的时差，可如果这个时间是经过时区修正后的时间会怎么办呢？时间对每一个人都很重要，可看到它的稀奇古怪的表示方法，难免会让人感到风中凌乱啊……&emsp;&emsp;我们知道，Json.Net是.NET中一个非常流行的JSON解析和生成库，而我们在对一个实体进行序列化的时候，如果实体中属性的数据类型为DateTime，那么在序列化的时候就会出现一个非常有趣的现象。假如我们在数据库中有一个字段dateCreated，那么通过这个库转换出来的结果可能会是”/Date(1269582661683+0800)/“这样的结果，例如下面这段JSON： 1234&#123; \"DateCreated\":\"\\/Date(1528687303302)\\/\", \"UserName\":\"Payne Qin\"&#125; 出现这个结果的原因，是因为我们使用微软提供的JavaScriptSerializer，而这个序列化器遵循的实际上是Unix时间标准，换句话说，这里展示的这个数值是1970-01-01 00:00:00至今的毫秒数， 这一点我们通过一个简单的计算就可以得到验证。Json.Net中默认使用ISO8601风格的序列化器，我们一起来看下面的例子，这里我们定义一个简单的数据结构，按照惯例，这个数据结构用Foo类表示： 12345678class Foo&#123; [JsonConverter(typeof(IsoDateTimeConverter))] public DateTime IsoDateTime &#123; get; set; &#125; [JsonConverter(typeof(JavaScriptDateTimeConverter))] public DateTime JSDateTime &#123; get; set; &#125; public string UserName &#123; get; set; &#125;&#125; 此时，我们可以注意到序列化后的结果如下： 12345&#123; \"IsoDateTime\":\"2018-06-11T11:35:45.898768+08:00\", \"JSDateTime\":new Date(1528688145898), \"UserName\":\"Payne Qin\"&#125; 为了将这两种统一起来，建议通过JsonSerializerSettings，因为我们可以定制日期的样式： 1234var settings = new JsonSerializerSettings();settings.DateFormatHandling = DateFormatHandling.IsoDateFormat;settings.DateFormatString = \"yyyy-MM-ddTHH:mm:ss.fffzzz\";var json = JsonConvert.SerializeObject(entity,settings); 此时，可以注意到结果为： 12345&#123; \"IsoDateTime\":\"2018-06-11T11:45:46.981+08:00\", \"JSDateTime\":\"2018-06-11T11:45:46.981+08:00\", \"UserName\":\"Payne Qin\"&#125; JavaScriptDateTimeConverter和IsoDateTimeConverter，均是DateTimeConverter的子类，因此我们可以定义更多的转换器，毕竟喜欢折腾的人类永远不会满足，除了本文中介绍到的时间表示方法以外，我们还有CST和DST等不同的表示方法，对了，关于格式化参数fff/zzz等请参考这里，你就会知道人类是多么的无聊啊。 不同语言中对时区的处理&emsp;&emsp;好了，这篇文章基本上通篇都在讲时间，我们最初的问题是，服务器上的时区和当前时区不一致，导致在查询的时候时间无法对应起来。现在，我们应该可以达到一个共识，不管什么时候，我们都应该使用UTC时间或者GMT时间，而在拿到这样一个时间后，如果有必要请转换为本地时间，而当相关流程结束以后，最好将这个时间转换为UTC时间或者是GTM时间。现在，我们来看看不同的语言中是如何处理时区问题的，按照博主对语言的熟悉程度，博主选择了C#和Python两门语言来说明问题。 CSharp&emsp;&emsp;C#中关于日期/时间的API都集中在DateTime类中，而关于时区的API则集中在TimeZone和TimeZoneInfo类中，我们一起来看下面的代码： 1234567891011121314151617181920//当前时区：中国夏令时var timezone = TimeZone.CurrentTimeZone;//获取所有时区var timezones = TimeZoneInfo.GetSystemTimeZones();//获取时区ID：北京时间+08:00/China Standard Timevar timezoneId = TimeZoneInfo.GetSystemTimeZones()[102].Id;//当前系统时区：(UTC+08:00) 北京，重庆，香港特别行政区，乌鲁木齐var currentTimeZone = TimeZoneInfo.Local;//本地时间转换为UTC时间：2018/6/11 5:13:49var dtUTC2 = TimeZoneInfo.ConvertTimeToUtc(DateTime.Now);//将本地时间转换为指定时区的UTC时间：2018/6/11 5:13:49var dt = DateTime.SpecifyKind(DateTime.Now, DateTimeKind.Local);var dtUTC1 = TimeZoneInfo.ConvertTimeToUtc(dt, TimeZoneInfo.Local);//将指定时间从指定时区转换至目标时区的时间：2018/6/11 1:13:49var dtUTC3 = TimeZoneInfo.ConvertTime(dt, TimeZoneInfo.Local, TimeZoneInfo.GetSystemTimeZones()[30]);//当前UTC时间：2018/6/11 5:13:49var dtUTC = DateTime.UtcNow;//当前Unix时间：1528694152var startTime = TimeZone.CurrentTimeZone.ToLocalTime(new System.DateTime(1970, 1, 1));var dtUnix = (int)(DateTime.Now - startTime).TotalSeconds; Python&emsp;&emsp;Python中针对时区的处理，发扬了Python一贯主张简单的传统，有多传统呢，大概只需要两行代码，是的，你没有听错，只需要两行代码： 12tz = pytz.timezone('Asia/Shanghai')dt = datetime.datetime.now(tz) &emsp;&emsp;简单来说，在Python中我们只需要给定时区，即可将本地时间转化为指定时区对应的UTC时间，这里我们使用的是Python中的pytz这个库，如果你打开这个库的安装目录，就会发现其实它有大量时区相关的数据组成，如果我们直接调用pytz.timezone()就可以获得所有的时区信息。博主有一个Python脚本运行在TravisCI的服务器上，而TravisCI来自一家法国的技术公司，因此在不指定时区的情况下，会默认使用TravisCI服务器上的时间，这并不是我想要的结果，所以，我们需要pytz来解决这个问题，至于这里为什么我们使用的是上海而不是北京，这是因为中国横跨5个时区，在国内大家习惯使用北京时间，而在国外这些时区数据没有做及时更新，所以这算是一个关于时区的历史遗留问题吧！ 本文小结&emsp;&emsp;本文从实际生活中一个案例入手，首先，向大家解释了为什么我们需要时区，以及为什么地球上不同地域拥有不同的时间。接下来，我们以MySQL、Oracle和SQL Server三种数据库为例，了解了在数据库中是如何存储时间的，可以注意到大多数数据库都使用了时间戳来存储时间。由此，我们引出了UTC时间、GMT时间、本地时间以及Unix时间，并讲述了它们之间的区别。其中，UTC和GMT可以看作是等价的时间表示方法，两者仅仅是计量工具不同，在历史上提出的先后顺序不同，并且GMT时间是以UTC时间为基准的。而Unix时间是计算中表示时间的方法，其含义是自1970-01-01 00:00:00至今经过的总秒数，在此基础上我们引出了为什么32位计算机下能表示的最大年份是2037。在文章的最后，博主选择了最熟悉的C#和Python，向大家展示了和时区相关的操作。&emsp;&emsp;我承认，这篇文章相当地细碎，可能因此牵扯了太多的概念，我一直在犹豫要不要发到博客上来。其实，有太多的时候，越来越发觉自己写不出来一篇好的文章，大概我需要去读更多的书，或者去解决更多的问题，可坚持写博客的一个重要原因，无非是我觉得我需要花点时间区整理这些东西，因为别人没有去关注的一个问题，而我去尝试关注或者解决了，这就是我的收获啊，总而言之，在这篇相当细碎的文章背后，我收获的可能并不比这篇文章里写出来的少，原谅我这些唠叨的碎碎念吧，这篇文章就是这样啦，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"时区","slug":"时区","permalink":"https://qinyuanpei.github.io/tags/%E6%97%B6%E5%8C%BA/"},{"name":"时间","slug":"时间","permalink":"https://qinyuanpei.github.io/tags/%E6%97%B6%E9%97%B4/"},{"name":"格式化","slug":"格式化","permalink":"https://qinyuanpei.github.io/tags/%E6%A0%BC%E5%BC%8F%E5%8C%96/"}]},{"title":"关于电影《暗杀》背后的故事和想法","date":"2018-06-01T09:33:25.000Z","path":"posts/2462008667/","text":"&emsp;&emsp;最近看过了由全智贤主演的电影《暗杀》，虽然说这是一部我们早已熟稔的抗战题材电影，可是在全女神颜值和演技的诱惑下，我终于还是花了点时间来看这部电影。或许是因为我们见识过了太多的“抗日神剧”，所以在面对这样一部电影的时候，我们难免带着某种不屑的眼光去审视它。可是当你看完了这部电影，突然间兴奋到难以自制，不由地惊呼一声：想不到韩国拍这种主旋律电影都能这么好看。我想，这是一种由视角转换所引起的代入感，我曾经看过日本拍摄的甲午海战，日本在明治维新以后，积极地向西方学习先进技术，从天皇到官员，都能从俸禄中省出钱来发展海军事业，相比之下，以天朝上国自诩的大清帝国则是李鸿章一人在支撑着岌岌可危的朝廷。同样地，通过《浪客剑心》同名电影，你会意识到，在明治维新这场变革背后，可能会有无数个像志志雄这样的政治牺牲品。这些都是因为视角发生变化而引起的变化，同样地，在这部电影中，它讲述了韩、朝两国人记忆中的抗日战争，这场我们曾经经历过的抗日战争，在韩国人眼中到底是什么样子的，这或许对我们看待历史会有所启示。 一明一灭，两条暗杀线&emsp;&emsp;电影讲述了19世纪30年代，以安沃允(全智贤饰)为首的暗杀三人组，奉命刺杀日军驻朝鲜司令官及本国卖国贼的故事。故事发生在京城(即韩国首尔)和上海，时任韩国临时政府局务局局长的廉锡镇(李政宰饰)，在早年刺杀日军大将失败以后，暗地里早已投靠日本人，此时更将暗杀三人组的消息泄露给日方。一时间，暗杀三人组的刺杀行动和处决叛徒廉锡镇刺杀行动，构成了一明一暗两条线索，呼应了本片片名“暗杀”，而廉锡镇更是找来赏金猎人“夏威夷手枪”(河内宇饰)，意图阻挠暗杀三人组的刺杀行动，可以说，整个故事脉络就像这个刺杀行动一样简单直接，因此其故事悬念就落在了刺客的刺杀计划如何落实以及反派的阻挠方案将如何开展。所以，这个电影吸引人的地方就在于，即使你知道反派最终一定没有好下场，可不到全女神放下枪的那一刻，你总是不肯放下心来。因为即使是看双方斗智斗勇，在颜值与演技都在线的情况下，这一切依然显得赏心悦目。全女神在片中几乎承担了所有的动作戏份，可即便如此，李政宰在片中饰演的反派廉锡镇，风头一度不亚于全女神，这些我们后面再详细说。 &emsp;&emsp;电影中前期出现的场景都是在上海，可能有朋友会疑惑：为什么一部韩国拍的电影里会出现上海。这就要首先说说这段历史，当时韩国的临时政府是设在上海的，目的是方便金九、金元凤这样的革命志士开展救亡图存活动，因为当时的韩国(在南、北朝鲜没有分裂以前，指整个朝鲜半岛）早已笼罩在日军的军事统治阴影下。历史上，这段时期长达35年之久。日本是什么时候占领朝鲜的呢？没错，就是我们熟悉的中日甲午战争。当时北洋水师正是在运送陆军抵达朝鲜后的返航途中，与日本海军发生近代历史上第一次大规模铁甲舰海战。这场战争的结果我们都知道，北洋水师几乎全军覆没，清政府更是同日本签订了丧权辱国的马关条约。日本占领朝鲜半岛后，曾对当地人进行了惨无人道的屠杀，正是从那个时候起，朝鲜开始笼罩在日军的统治阴影之下，而流亡国外的临时政府，不得不寄居在上海的法租界，继续开展抗日活动。影片中的金九和金元凤，在历史上都可以找到记录。上海虹口爆炸事件，其实就是这部电影的历史原型，影片中二金的合作促成了三人暗杀组的成立，故事由此开始。 这个反派有点帅哦&emsp;&emsp;李政宰饰演的廉锡镇，在电影一开始是以革命志士的形象出现的，他刺杀日军大将的任务失败，直接导致他在被捕后遭受严酷的刑罚。与此同时，间接导致了女主安沃允的母亲被亲日派父亲康寅国派人杀死，安沃允与双胞胎姐姐美津子分离，直至多年后，来自东北抗日武装的安沃允，和自幼在日占区长大的美津子，终于在一个屋檐下相认，可转眼间，姐姐就被卖国贼康寅国给杀死了，电影中全女神亲眼目睹姐姐死亡的那一幕真的是令人心碎。可偏偏是这样一个人，亲手挑选了这三名暗杀组的成员，亲手将刺杀行动的情报泄露给日方人员，尤其是他从衣兜里取出假信件投入火堆，伪造出信件被毁的假象这一幕。面对金九的怀疑，在明知手枪里没有子弹的情况下“以死明志”。对昔日的同志毫不手软，两个被金九派去刺杀他的同志，均被他重伤甚至杀死。面对曾经刺杀过的日军大将，他可以厚颜无耻地邀功请赏，并接受日军授予的爵位。可恰恰是这样一个人，在喝醉酒以后，诉说朝鲜各种武装力量各自为政的现实，忏悔把暗杀三人组送去送死。在严刑拷打面前，他做了叛徒，一如暗杀组成员干革命要给钱，这些或许没有那么伟光正，可它是那么的真实。 演技与颜值同时在线的全女神&emsp;&emsp;全女神饰演的安沃允，是一个来自东北抗日武装的狙击手，一出场就瞬间狙杀四名敌人，身手当真是是不凡啊，更不必说端着汤姆生冲锋枪窜房顶跨屋脊，在负伤的情况下趴在疾驶的卡车引擎盖上。据说全女神电影中的动作戏都没有使用替身，一个明明可以靠颜值的人，尚且可以如此努力地去拼搏，那么身为普通人的你我，又有什么理由不努力呢？野蛮女友时期的全女神，或许看起来只是漂亮而已，而现在看来则是实力派。可她同样是一个憧憬着喝咖啡谈恋爱的少女，是一个看到姐姐洁白的嫁会衣泣不成声的妹妹，是一个面对亲生父亲无论如何都下不去手的狙击手。在假扮姐姐美津子参加婚礼以前，她做好了最坏的打算，就像她脑海中浮现过的画面一样，在敌人乱枪扫射下，献血染红了她洁白的婚纱……这或许是“夏威夷手枪”脑补的画面？这里有一个细节，“夏威夷手枪”将全女神送到医院以后，“夏威夷手枪”讨论起他对于暗杀行动的看法，全女神说了这样一段话，大意是“杀掉日军司令和汉奸康寅国，到底能不能让国家独立，这一点没有人会知道，但她必须要让人们知道，她们一直在战斗”…… &emsp;&emsp;这一刻，这个娇弱而坚强的女性形象就立起来了。全女神在本片中分饰两角，即姐姐美津子和妹妹安沃允，不过这种差异基本都是通过眼神表现出来的，姐姐身上有那种从小生活安逸的娇气，而妹妹身上有那种内敛冷静的帅气。战争从来都是残酷的，康寅国为了依附日本人，将美津子误认为安若允并杀死。在我看来，即便没有认错，以康寅国的为人，知道女儿和独立军有关联，他还是会这样做，因为女儿的幸福他完全不在乎，和日本人联姻无非是为了拉拢日本人。正如全女神所言，他用那双杀死了母亲的手，杀死了自己的女儿。人类的情感有时候就是这样诡异，一个对自己从来没有养育之恩的父亲，对方叛国投敌助纣为虐，即使两者间唯一的联系，是那可有可无的血缘关系，可最终还是需要“夏威夷手枪”，这个曾经是“杀父联盟”一员的人，替她开出这一枪。 一个超有力量感的故事结尾&emsp;&emsp;故事从挟持人质这里开始，就突然变得敷衍起来，可能这里就需要感情戏来作为某种过渡，假如两个人真的去了米拉波，这就真的变成了爱情电影，可这部电影不就是，一部打着主旋律幌子的动作电影吗？这种类型电影为了增加娱乐性，是需要幽默和爱情的。真正将影片推向高潮的是结尾出的审判，证人在开庭前就被廉锡镇派人杀死，于是没有可以再证明，廉锡镇曾经投敌叛国、出卖同志的罪行。这个世界上永远有大量的无知的人，他们选择用暴力来面对一名“韩奸”，可当廉锡镇脱下衣服，义正言辞地讲述自己“支持”独立运动的事迹时，这些人突然开始宣布这名“韩奸”无罪，这是否说明大众都是愚蠢的，可正是这些人的想法，在左右着我们每一个人，这和那些努力制造“焦虑”的人没有区别，我们不愿意相信真相，宁愿相信自己早已固化地思维，或者是人云亦云，没有自己独立的判断，这实在是件可怕的事情。法官失落地宣布证据不足、廉锡镇无罪释放的时候，大概内心会有某种无可奈何或者是不甘心。 &emsp;&emsp;这让我想起Unnatural里高濑这个案件，因为没有办法证明对方杀人，而关键的信息又被久部泄露出去，所以，这个案件一度到了要修改鉴定报告的程度，这和身为法医的三橙心中的使命感不相符合，关键时候，是神仓所长坚持递交了原始的鉴定报告。当我们想要制裁一个人的时候，能不能依然客观地去证明对方有罪，不冤枉任何一个人固然值得赞赏，可为了让对方伏法而采用非正义的手段是否是正确的呢？如果身为法医的三橙，用修改鉴定报告的方式，给高濑这个罪犯定刑的话，我相信，我们所有人都会失望，因为她不愿意输给非正常死亡，不愿意正常的人被乱入非正常的事件，采用非正常的方法去伤害别人或者是自己。相比中堂使用逼供的方式查找真相，她更希望中堂医生以一名法医学者的身份去战斗。自然，故事的结尾，所谓善恶有报，16年前的暗杀任务，终于在韩国光复以后，有安沃允和明宇重新执行，结尾处被乱枪打死的廉锡镇，在被问到为什么要出卖同志时，说了一句“我没想到会解放啊”，一句听起来像开玩笑的话，其实说出了战争年代人们的无奈，如果没有战争，或许这些事情就真的不会发生，可当战争机器被发动时，又有谁会想到这些呢？被卷入战争里人们没有选择，而发动战争的人从来不考虑以后。 写在战争结束以后&emsp;&emsp;旷日持久的战争终于结束了，当画面定格到全女神那张近乎素颜的脸上时，她突然想起那些曾经最为亲切的面孔，想起“炸弹专家”黄德三，想起“速射炮”邱尚沃，想起酒馆老板娘……战争带给我们的是永远的伤痛，今天我们对于日本这个国家，可能有时候还会充满抵触情绪，但我想说的是，这场战争并没有结束，金九认为日本人已经投降，不再需要可依靠捐助维持，以光明正大地回到国内搞建设，可事实上像廉锡镇这样投日派，并没有完全得到清算，所以，金九在回国后不久就被韩国激进分子刺杀，廉锡镇所说的独立运动派系之争，在历史上是真实存在着的，金九就是被卷入到这场政治斗争中的牺牲品，所以，金元凤最终选择了朝鲜，而这种派系之争，更是加剧了整个朝鲜半岛的分裂，在这片土地上，曾经一起战斗过的兄弟、朋友，最终变成兵戎相向的敌人。 &emsp;&emsp;可这真的是和平吗？战争真的结束了吗？被38线分割开的这两个国家，一个通过韩剧、料理和科技为世界所知，一个更像是改革开放初期的中国，不知道还说神秘还是落后。何况，这条38线是停战线，并非某种和平的象征，而直至今天，这种刺杀的阴影一直笼罩在韩国政坛上，韩国现任总统朴槿惠的父亲和母亲先后都死于刺杀，所以，即使战争结束了，就能换回和平吗？就能抚平人们心中的伤痛吗？朝鲜与韩国，也许在我们有生之年里，都难以看到他们真正地握手言和，就像苏联解体以后不会再联合在一起，欧盟并非想象中的牢不可破，爱尔兰和北爱尔兰原本就是一家，印度和巴基斯坦是殖民战争的遗留问题……战争，带来的坏处，永远比好处要多。我们向往铸剑为犁的和平生活，可战争结束以后，是否真的能带来和平，人心中的伤痛需要多久可以愈合，人与人的相争逐利之心需要多久可以平息。 &emsp;&emsp;2018年的儿童节，同往年不同，因为许嵩为炮火中的叙利亚孩子们，创作了一首新歌《大千世界》，这首歌以2017年4月15日叙利亚炸弹袭击事件为背景，呼唤爱与和平，控诉那些肆意发动战争，而将无辜孩童卷入战火的人们。大千世界里的大人们，不要忘了你们曾经都是孩子，当人们都在通过晒娃这种方式度过儿童节时，你是否会想到在世界的某个地方，有人在穿着捐助的衣服和玩具的同时，更是被迫享受着温柔的暴力，我们从小给小孩子的玩具枪，是否有一天会真的变成荷枪实弹呢？我们在盛世之年，我们在贫富之间，我们在虚实交错路口，不断找寻，任何形式的相遇。愿大千世界，再无战争，再无暴力，愿每个深爱的人，都能被温柔对待。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"影评","slug":"影评","permalink":"https://qinyuanpei.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"和平","slug":"和平","permalink":"https://qinyuanpei.github.io/tags/%E5%92%8C%E5%B9%B3/"},{"name":"全智贤","slug":"全智贤","permalink":"https://qinyuanpei.github.io/tags/%E5%85%A8%E6%99%BA%E8%B4%A4/"}]},{"title":"爱情像一场霍乱","date":"2018-05-22T09:05:34.000Z","path":"posts/3782208845/","text":"&emsp;&emsp;距离读完马尔克斯的《霍乱时期的爱情》这本书，差不多已经有一个月左右的时间啦。相比小说中错综复杂的人物关系，更加让人印象深刻的或许是“百年孤独”式的开头。不论是多年后面对行刑队的布恩迪亚上校，还是拍打鹦鹉结果从梯子上摔下来的乌尔比诺医生。在这一刻，因为人物的过去与现在层叠出的这种时空感，或许就是马尔克斯想要去描绘的魔幻现实主义。最近看了由小说改编的同名电影，感觉对这部小说的印象更为具体化，小说的时间跨度将近半个世纪，是选择乌尔比诺和费尔米纳这样稳定的婚姻关系，还是选择阿里萨和费尔米纳这样偏执的爱情故事。我想，这是一个值得去思考的问题吧。 &emsp;&emsp;当乌尔比诺从梯子上摔下来即将离开人世的时候，他拼尽最后一口气对费尔米纳说：“只有上帝才知道我有多爱你”。单单从这句话来看，他们两个人或许是相爱的。可明明不久前，两个人还在为了一块肥皂的事情而争吵。现在大家对出轨这个问题看得特别重，重要到不要说是肉体出轨，连精神出轨都是不能被原谅的。从去年至今，网络上各种出轨的舆论消息层出不穷，好像爱情越来越不值得期待。可你看乌尔比诺和费尔米纳的婚姻是什么样的呢？乌尔比诺在妻子外出期间出轨了一名黑人女子，虽然他选择主动向妻子承认出轨，及时回归家庭，可在我们这些外人看来，这样的婚姻是含有杂质的婚姻。从妻子费尔米纳的角度，她结婚以前是不吃茄子的，而结婚以后则适应了茄子，你可以说两个人在一起，一定会有一方选择妥协。可在一个动辄讲三观、讲兴趣、讲地位的年代，你是否会觉得两个人合适呢？ &emsp;&emsp;合适，是一个特别巧妙的词汇，巧妙之处在于它真正可以做到“以不变应万变”。乌尔比诺夫妇的婚姻，或许是大多数人的真实写照。两个人第一次见面，源于费尔米纳的一场疾病。当时外面正流行着霍乱疫病，费尔米纳因为怀疑被感染了霍乱不得不寻找医生治疗，恰好乌尔比诺正从巴黎旅行回来。在医学技术不发达的年代，医生是没有听诊器的，所以乌尔比诺必须贴着费尔米纳裸露的胸部听心跳。书作和电影中都详细地描绘了这个过程，两个青年男女在这种情况下发生了身体上的接触，费尔米纳更是被对方身上的男性气概所吸引。可这算是爱情吗？我更愿意相信，这是一种原始的欲望冲动，可你说这两个人间没有爱情，估计所有人都会反对，谁让我们都喜欢用海枯石烂表示爱情的忠贞，这两个人在一起生活50年，甚至作者都表示：一对恩爱的夫妻最重要的不是幸福，而是稳定的关系。 &emsp;&emsp;所以，不管你愿不愿意承认，爱情最终都会部分地转化为亲情，爱情本身是有瑕疵的、有缺陷的，争吵不可避免，犯错不可避免。诚然，我们都希望对方忠诚的对待自己，可人归根到底是一种对自我忠诚的动物，你说你不能接受对方变心，可人、时间和空间无时无刻不在发生着变化，喜欢或者不喜欢，不过是某一瞬间的状态，你必须相信，爱情本来就不完美、充满瑕疵，可这就是真实的爱情的样子啊，人们会记得你婚礼上的海誓山盟，唯独不会记得你每天柴米油盐的平平淡淡；人们会给他们愿意看到的表面现象去点赞，唯独不会关注你是不是真正的快乐。爱情里有人不厌其烦地寻找真爱，有人沉溺在回忆里不敢再触碰爱情，对我来说，这两种选择我都表示尊重，因为爱情本来就有它真实的样子。 &emsp;&emsp;我不知道，还会不会有人为了别人而苦等51年9个月零4天，一个人究竟有多大的勇气和执念，才能从一个朝气蓬勃的青年变成一个白发苍苍的老人。金庸先生的名篇《射雕英雄传》里，神算子瑛姑因为失去爱子而一夜白头，我想，这其中有对段皇爷见死不救的怨恨，有对周伯通求而不得的执念。可对阿里萨而言，从他遇见费尔米纳那天开始，他的生命就仿佛注定是属于她的，他坚持给她写信，在楼下为她拉小提琴，在长椅上刻下她的名字，甚至是喝花露水、吃玫瑰花。如果说爱情像一场霍乱，应该会没有怀疑，因为阿里萨的确像是生了一场霍乱，不然怎么会疯狂地爱直至偏执甚至有些荒唐。我完全可以理解阿里萨的举动，因为年轻时的我们都曾做出过类似的举动。我并不反对这样的爱情，可当你回头来看这两个人的爱情的时候，费尔米纳对阿里萨这个人几乎一无所知，除了知道对方的职业是报务员。 &emsp;&emsp;电影中费尔米纳甚至给阿里萨回了信，可就如同费尔米纳所言，“他们两个人之间只有虚幻，爱情蒙蔽了彼此的双眼”，大概所有一见钟情的人都没能考虑一个问题，那就是你真的了解对方这个人吗？非常不幸的是，即使亲近如父母、妻子和丈夫这样的关系，一个人也永远不可能了解另外一个人。一个人究竟要爱得多卑微，才会心心念念地等着对方的丈夫死掉，甚至怕对方比丈夫先死掉。假如阿里萨只是这样痴痴等待50年的话，我们最多只是替他感到惋惜而已，可偏偏阿里萨为了“报复”费尔米纳，缓解被她伤害的心，开始一次又一次地疯狂纵欲，在肉体的狂欢中不断强化精神层面上对费尔米纳的爱，据他自己记载，他和寡妇、少妇甚至少女都发生过关系，可当他终于等来费尔米纳的时候，他声称自己是一个处男。 &emsp;&emsp;人常常复杂到让你我怀疑人生，而阿里萨则是一个复杂到，让你觉得他还有点可怜的人。他视其它女性的肉体如无物，唯独将费尔米纳推上女神的圣坛。更微妙的是，费尔米纳居然是喜欢过阿里萨这个人的。她不过是在乌尔比诺和阿里萨间选择了更好的一个而已，可阿里萨这种病态的爱在我看来是极为自私的，因为无论两个人多么地爱彼此，一旦出现这种肉体的出轨，就意味着永远无法挽回。虽然费尔米纳选择嫁给了乌尔比诺，可假如有一个人在别人的身体上出轨无数次，在你的丈夫逝世以后告诉你，他等这一天已经等了51年9个月零4天，我不知道你会作何感想。我没有任何的封建思想残留，我尊重女性在丈夫死后改嫁的自由，可选择这样一个充满“缺点”的人，我觉得还是需要去认真想一想的。 &emsp;&emsp;两个人如果真心相爱，即便是满头白发的蹒跚老者，我认为结婚都是没有问题的，可当两个70多岁的老人坦诚相见时，当阿里萨看到费尔米纳干瘪下垂的胸部时，当各自看到对方充满皱纹和赘肉的身体时，我真的想知道，这50多年的等待真的值吗？或许是值的的，就像这两个人喜欢的都是有点幻想成分的对方一样，我向往永远靠精神慰藉彼此的帕拉图之恋，也不排斥男欢女爱的肉体之欢，可无论哪一种都必须建立在真实的现实中，一个虚幻的爱慕者，一个你并不真正了解的人，当幻想被打破的一瞬间，或许就是爱情破碎的时候，所以，我希望我们对待感情更慎重些，即使没有人爱你，学会自爱未尝不可。我们的生命原本就短暂，何苦要将这生命浪费在别人身上，况且我们有时候我们就像费尔米纳一样，分不清到底是爱还是孤独，人在经历枯燥和乏味以后是会变的，会变得对事物充满新鲜感，即使是曾经不喜欢的东西。 &emsp;&emsp;从某种角度而言，阿里萨是成功的，因为他用一生的时间得到了喜欢的女人。可我时常觉得人生有比这更重要的事情，就像你小时候看到喜欢的东西，却发现自己买不起的时候，你会怎么样做呢？我想大多数人都会选择不要了或者是等以后有机会再买。可人就是这样奇怪的动物，明明以前非常非常喜欢，可突然有一天发现咋再喜欢不起来。为什么我们对这件事情可以坦然接受，唯独在面对感情的时候常常无法自拔呢？你当初有没有得到这样一件喜欢的东西，或许会影响你在未来的人生轨迹，可在大多数情况下，我们的生命实在泛不起多少涟漪。有人说，人生下来的时候，结局就早已注定，我们唯一能做的事情，就是努力去填补和丰富这五六十年的时间。这样说来，人生实在是没有什么事情非做不可的，如果有，那只有一件事情，那就是努力地活下去。 &emsp;&emsp;《Unnatural》里中堂系一直对恋人的死无法释怀，整整八年时间一直都在调查恋人的死亡原因，直到真相被查明，得到恋人父亲的原谅。我不是说，人生不可以有执念，我只是希望大家明白，执念只会让你太关注结果而忽略过程，而我们的生命是需要一天天去度过的。就像阿里萨终于得到了费尔米纳，可两个70多岁的老人，在这个世界上还有多少时间可以挥霍呢？我倒情愿日子过得稍微慢一些，用一辈子的时间去了解对方，我们一直所希望看到的，不就是被人理解和认同吗？如果永远一个可以同你交流灵魂的人，那么就努力学习一个人去生活，人生没有那么多必须做的事情，只有你愿不愿意去做的事情。起风了，就当努力生存。活着不好吗？我实在不愿意再看到罗密欧与朱丽叶这样的悲剧，虽然我们都曾歌颂过这样的故事，可只要活着就会有新的机会啊。 &emsp;&emsp;有时候想想我们父母这一代人，几乎在毫无准备的情况下，被动地步入了婚姻的殿堂。时隔多年以后，或消融在柴米油盐的平淡里，或交织在子女亲情的羁绊中，或穿行在流水光阴的得失间……直至爱情彻底消亡最终变成亲情，像一滴松胶油慢慢变成一颗精美的琥珀。有人说，婚姻是爱情的坟墓，甚至结过婚的人会觉得婚姻非常无趣。那么，罗曼蒂克是否一定会消亡？如果是，是不是婚姻里有没有爱情都可以，因为总有一天它会枯竭，人生里充满太多无可奈何的事情，单单是爱情这一件事情就可以写满整个历史，爱情里有像童话一般美好的故事，同样有像悲剧一般哀伤的故事。 &emsp;&emsp;或许是我们这一代独生子女们，在接触到更广阔的网络世界后，极大地影响了我们对这个世界的认知，以至于我们觉得自己就是活得太明白了。可如果要这样稀里糊涂地度过余生中的五六十年，每个人突然间又不甘心接受这残酷的命运。当我发现，我要远离父母生活，甚至完全能力能力和精力照顾他们的时候，我很容易地想到我的未来，是不是会和他们一样。有人说，婚姻是为了找到一个人陪你一起往前走，可我们这些独生子女们，早就习惯了一个人去生活，生命里总是充满着无尽的变故，或许她曾经特别特别喜欢你，可突然有一天她就不再喜欢你了；或许你们曾经是特别特别友好的朋友，可突然有一天对方就突然离你远去；或许你们朝夕相处亲密无间，可到最后突然发现根本不了解彼此…… &emsp;&emsp;人明明都是会变的，可偏偏总爱把希望寄托在变化的事物上面。在一个周围一切都在变化的世界里，追求一成不变毫无疑问是贪心的，我们能追求的只有稳定，可难免会问一个不理智的问题：稳定可以理解为爱吗？这正是乌尔比诺和费尔米纳两个人的感情生活留给我们的谜题。年少时或许会憧憬阿里萨这样因爱成痴的故事，可正如村上春树所说，“哪里会有人喜欢孤独，不过是不喜欢失望罢了”。如果爱情是一场霍乱，我希望每个生病的人，都能尽早地从这场疾病中治愈。“起风了，当努力生存”，就像石原里美饰演的三橙说过的，“有时间绝望还不如去吃点好吃的呢”，比起找到心爱的人，学会如何爱自己不是更重要吗？","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"影评","slug":"影评","permalink":"https://qinyuanpei.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"阅读","slug":"阅读","permalink":"https://qinyuanpei.github.io/tags/%E9%98%85%E8%AF%BB/"},{"name":"马尔克斯","slug":"马尔克斯","permalink":"https://qinyuanpei.github.io/tags/%E9%A9%AC%E5%B0%94%E5%85%8B%E6%96%AF/"}]},{"title":"使用Jexus实现ASP.NET在Linux平台下的部署","date":"2018-05-20T14:00:03.000Z","path":"posts/815861661/","text":"&emsp;&emsp;Hello，大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是https://qinyuanpei.github.io。今天想写一点关于Linux部署ASP.NET相关的话题，为什么突然想写这个话题呢？因为就在几天前，我被我所认识的一位前辈深深地鄙视了一番，原因是我依然在使用一个落后的IoC框架——Unity，在如今已然是公元2018年的今天。我突然想到，距离.NET Core 2.0发布已经有一段时间，而.NET Core 3.0的roadmap已经开始提上日程，可我好像还没来得及认真地去对待这个现状。我一直在关注跨平台和跨语言的技术，就像我在大学里的时候就开始接触Linux一样，未来我们要面对的是种类繁多的终端平台，从PC时代到移动互联网，再到VR、AR、IoT和AI，有太多太多的事情在悄然发生着变化。偶尔我的内心会泛起焦虑和迷茫，可在时光蹉跎直至褪色以前，我或许只是变回了曾经的自己。既然要如同涅槃一般重新开始，为什么不首先重新拾起曾经关注的领域呢？所以，在这今天这篇文章里，你将看到：如何使用Jexus实现ASP.NET在Linux平台下的部署。 故事背景&emsp;&emsp;我们项目组在开发这样一种服务，它可以通过收集招聘网站的简历来提取相关信息，而这些信息将作为训练集供AI算法使用。考虑到Python在AI领域的优势，我们决定采用Python来开发自然语言处理相关的业务，而简历的收集则是通过.NET中的Web Service暴露给前端。整个开发相对顺利，可是在部署环节出现了问题。因为项目组以往的的项目都是部署在Linux Server上，所以在部署Web Service的问题上产生了分歧，负责运维的同事不愿意为这一个项目而单独配置一台Windows Server。这里需要说明的是，采用.NET来开发Web Service的一个重要原因是，这些简历中存在大量Word文档(.doc/.docx)，因此不得不采用Office提供的COM组件来支持文档的解析，虽然后来证明的确是这些COM组件拖了跨平台的后腿。所以，在这个时候，我们面临着两种选择，第一种方案是采用Windows Server来部署，我们的运维同事表示不开心；第二种方案是采用Linux Server来部署。我们知道.NET跨平台的一个关键技术是Mono，可Mono的问题是它的基础类库不大健全，相信微软收购Mono以后这个问题能够得到解决。目前官方主推的跨平台技术是.NET Core，考虑到迁移到.NET Core版本的成本，我们最终没有选择这个方案。事实上，即使采用.NET Core进行开发，最终我们的部署依然需要依赖Jexus。综合考虑这些因素，我们决定采用Jexus来将ASP.NET项目部署到Linux平台。 关于Jexus&emsp;&emsp;Jexus是由宇内流云开发的一款Linux平台上的高性能Web服务器，它是一个可以免费使用、不开源的项目，最大的特色是可以支持ASP.NET、ASP.NET Core、PHP。通俗地来讲，我们可以认为它是Linux平台上的IIS，这并不为过，因为你可以注意到Jexus Manager这个项目，它可以同时支持Jexus，IIS 和 IIS Express三种服务器的管理，并提供了各个平台下一致的使用体验，而Linux平台则主要是针对Jexus。Jexus提供了不亚于商用服务器的众多特性，比如多站点支持、使用应用程序池来调度管理工作进程、具有良好的稳定性和容错能力、支持 HTTPS 和 WebSockets、支持 FastCGI 协议和 OWIN 标准。除此以外，它同时支持 URL 重写、反向代理、压缩传输、入侵检测等重要功能。Jexus底层采用Linux中的epoll机制来处理网站请求，所以会比通常使用libuv实现的技术拥有更高的性能。作为一款跨平台软件，Jexus支持主流的Linux发行版本。目前，国内外已经有大量的网站采用Jexus作为它的服务器，我们可以在Jexus的官网上找到这些案例。虽然微软官方正在全力推广.NET Core，但对于那些需要维护的旧项目而言，迁移到全新的.NET Core平台着实是个不小的挑战，而且目前支持.NET Core版本的类库并不丰富，虽然最终的趋势一定是.NET Core替代Mono，但对于Mono而言，在.NET宣布开源以后，从.NET Framework中吸收的基础类库，极大的改善了Mono基础类库不完善的状况，而Mono针对CLR的实现、C#编译器的实现、AOT环境等等特性，或许可以为.NET跨平台提供借鉴，这是一个相互促进的过程。在新时代到来以前，我们暂时需要使用Jexus来过渡。 Hello Linux&emsp;&emsp;OK，下面我们来体验一下Jexus在Linux平台上的效果，这里我们以ASP.NET MVC4为例，我们直接通过Visual Studio创建一个项目即可，这里我们需要的是这个项目发布以后的所有文件。总之，这些文件需要通过某种方式放到Linux平台上，大家自己去想办法就好啦，这个不再说多余的话。 安装Jexus&emsp;&emsp;Jexus安装起来是非常简单的，这里博主使用的是Elementary OS，基于Ubuntu14.0的衍生版本。在终端下执行如下命令： 1curl https://jexus.org/release/x64/install.sh|sudo sh 你没有看错，真的只需要一行命令。事实上，Jexus分为两个版本，即通用版和独立版。其差别是通用版不含Mono运行时，独立版含有Mono运行时。官方建议使用独立版，如果有朋友想尝试安装通用版，请在终端下执行如下命令： 1curl https://jexus.org/release/install|sudo sh 无论采用哪一种方式安装，当你看到终端中显示：Jexus已经被成功安装到系统，就表示Jexus安装成功了。 配置Jexus&emsp;&emsp;Jexus部署到网站，需要两个东西，一个是网站内容(废话)，一个是网站配置。假定我们这里将这两个东西打包在一起，压缩包的名字为app.tar。为什么这里选择了.tar格式的压缩文件呢？因为在Linux平台下这个格式更好用些，我们熟悉的.zip格式，可能会需要我们安装相应的扩展。此时，我们可以使用如下脚本来部署网站： 123tar -xf app.tarsudo mv -f .aspnetconf usr/jexus/siteconf/aspnetconfsudo mv ./aspnet /var/www OK，现在来解释下这个脚本，这里我们需要部署一个名为“aspnet”的网站，所以，网站的内容被放置在“aspnet”这个目录里。该网站对应一个作用于Jexus的配置文件，配置文件的名字为aspnetconf。首先，我们将“aspnetconf”这个配置文件移动到了“usr/jexus/siteconf/”目录下，这是Jexus指定的配置路径，即每一个站点都有一个配置文件，且该配置文件被放置在“usr/jexus/siteconf/”目录下。然后，我们将“aspnet”这个文件夹移动到了“/var/www”目录下，这是Jexus指定的网站目录，即每一个站点都有一个文件夹，文件夹的名字可以理解为网站的名字。默认情况下，Jexus会在www目录里创建一个名为default的文件夹，即默认有一个名为default的站点，不过经过博主核实，最新版(v5.8.3)中是没有default站点。同理，Jexus会siteconf目录里创建一个名为default的配置文件。我们通常以这个配置文件为参照来编写我们自己的配置文件，例如下面是aspnetconf中的内容： 12345port=4000 root=/ /var/www/aspnet hosts= indexs= aspnet_exts= 其中， port表示Jexus Web服务器监听的端口(必填） root表示网站虚拟目录与其对应的物理目录，中间使用空格分开(必填） hosts表示网站域名(建议填写)，可以使用泛域名如.yourdomain.com或者填写表示默认网站，一个端口有且只有一个默认网站，选填 indexs表示网站首页文件名，如index.html、index.aspx等，多个文件名使用英文逗号分开，选填 aspnet_exts表示ASP.NET扩展名，不建议填写。如要填写，多个扩展名(不含.)使用英文逗号分开。 最简单的配置只需要port和root即可，更多的配置项可以参考官方文档。 基本使用&emsp;&emsp;Jexus的常用命令简单到只有3个，start、restart、stop。命令的基本格式为： 123sudo /usr/jexus/jws start [站点名(可选，不指定时表示所有)]sudo /usr/jexus/jws restart [站点名(可选，不指定时表示所有)]sudo /usr/jexus/jws stop [站点名(可选，不指定时表示所有)] 在这个例子里，我们执行如下命令来启动aspnet这个站点： 1sudo /usr/jexus/jws start aspnet 当终端中返回OK时，就表示启动成功啦，此时，我们打开浏览器，输入http://localhost:4000 就可以看到如下画面(这里的端口号为4000)： 运行在Linux上的ASP.NET 你就说，这算不算惊喜。我们还可以输入http://localhost:4000/info来验证Jexus是否配置正确，当Jexus被正确配置以后，你就会看到一个显示着“Welcome to Jexus”的页面。嗯嗯，好像是和Nginx挺像的哈！ Docker+&emsp;&emsp;接下来，让我们考虑将这些Linux上的工作转移到Docker中来做，因为借助Docker的容器技术，它可以为我们提供一个足以自给自足的环境。通过这个环境编译测试通过的镜像可以批量地部署到生产环境中。如果你不想在每一台Linux Server上都覆盖本文的流程，那么Docker将是提高你部署效率的不二选择，而且从认知完整性的角度来看待Docker，你就会发现它和Jekins、TravisCI、VSTS工具一样，都可以非常完美地被接入到持续集成(CI)的流程里去，譬如我们项目组采用的是Jekins + Gitlib + Docker的方案，所以，如果你想要选择一个最适合你的持续集成(CI)方案，无论如何，Docker都是需要去了解的一个知识。关于Docker的背景知识大家可以自己去了解，这里我们通过编写Dockerfile来完成网站镜像的构建： 1234567891011121314151617181920FROM ubuntu:14.04LABEL vendor=\"qinyuanpei@163.com\"# Prepare EnvironmentRUN sudo apt-get update RUN sudo apt-get install -yRUN sudo apt-get install -y curlRUN sudo apt-get install -y wgetRUN sudo curl -sSL https://jexus.org/release/x64/install.sh|sudo sh# Deploy WebsiteADD dest/ /RUN sudo mv -f aspnetconf /usr/jexus/siteconf/aspnetconfRUN sudo mkdir -p /var/wwwRUN sudo mv ./aspnet /var/www# Start JexusEXPOSE 4000WORKDIR /usr/jexusCMD sudo ./jws start aspnet 如果你熟悉Linux下的命令的话，你就会知道apt-get、curl、wget这些命令的含义，真正需要的解释的是ADD，它表示的是，将Dockerfile同级目录下的dest目录添加到Docker环境中，接下来的命令我们同样非常熟悉，因为这和Linux下操作是完全一样的。不过，这里的确有些坑需要踩，在博主构建镜像的过程中，发现容器环境和虚拟机环境还是有本质不同的，这里的mv命令在Docker下有时候会引发“hard link”的问题，从Stackoverflow上好像并没有找到太有价值的答案，总之，这个问题非常的玄学。接下来，我们会将Docker容器的4000端口暴露出来，为什么是4000端口呢？因为这个网站的配置中指向了4000端口，这一点在上文中我们已经提及。而入口处的命令，显然是启动Jexus服务，这个不再解释。 这里，我们通过如下命令来构建一个镜像版本： 1docker build -t jexus-aspnet:v1.0 . 假如这个镜像被成功构建出来，我们就可以使用这个镜像来启动网站啦。如下图所示： 使用Docker创建网站镜像 具体地，我们可以使用docke image命令来管理所有的docker镜像。这里我们启动网站： 1docker run -p 4050:4000 -t jexus-aspnet:v1.0 这里，我们将Docker容器的4000端口映射到主机的4050端口，当我们在浏览器中输入：http://localhost:4050，就可以得到和Linux下一样的结果。不过，在写作这篇博客时，博主使用的是Windows下的Docker，如果大家遇到相关问题，欢迎在博客评论区留言。 本文小结&emsp;&emsp;本文从一个实际工作的场景切入，分析和阐述了如何使用Jexus实现ASP.NET项目在Linux下的部署。为了简化这篇文章的写作，我们使用了一个ASP.NET MVC4的示例项目，真实的项目通常会有数据库，所以情况会比本文所介绍的流程更为复杂，可这让我们看到了一种可能性不是吗？通过查阅相关资料，博主发现ASP.NET Core的部署不需要Jexus，它只需要一个dotnet run命令即可。然后，作为一次体验Docker的过程，我们通过编写Dockerfile的方式让Jexus和Docker发生了某种奇妙的关联。作为本文的一个延伸，我们需要考虑网站服务停止后可以自动重启，这就是所谓的守护进程机制啦，感兴趣的朋友可以继续深入研究，Jexus提供了大量的优秀特性，这篇文章中所看到的不过是冰山一角。最终，我们的项目还是没有使用Jexus，这其中有对Jexus性能的不信任，有因为COM组件而做出的妥协，有对Mono非官方方案的鄙夷……可以说，技术选型是一个受到多种因素制约的问题，谁拥有了话语权，就可以左右技术选型的走向，这是否又印证了，人类并非如自己所标榜的那般理性和正义？好了，以上就是这篇文章的全部内容啦，今天是5月20日，如果没有人对你说“我爱你”，请记得对自己说“我爱你”，谢谢大家！","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://qinyuanpei.github.io/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Docker","slug":"Docker","permalink":"https://qinyuanpei.github.io/tags/Docker/"},{"name":"Linux","slug":"Linux","permalink":"https://qinyuanpei.github.io/tags/Linux/"},{"name":"Jexus","slug":"Jexus","permalink":"https://qinyuanpei.github.io/tags/Jexus/"}]},{"title":"使用SonarCloud为.NET/.NET Core项目集成静态检查","date":"2018-05-12T01:16:52.000Z","path":"posts/4891372/","text":"&emsp;&emsp;Hi，朋友们，大家好，欢迎大家关注我的博客，我是Payne，我的博客地址是http://qinyuanpei.github.io。在不知不觉间，5月份已然度过大半，最近无论是读书还是写作均停滞不前，被拖延症支配的我深感有虚度时光之嫌。今天这篇文章，我将为大家介绍如何使用SonarCloud，来为.NET/.NET Core项目集成静态检查。如果大家使用过SonarCube的话，对接下来我要讲的内容一定不会感到陌生，因为SonarCloud实际上就是SonarCube的“云”版本。在云计算概念深入人心的今天，我们可以通过互联网来访问各种各样的服务。譬如，我曾经为大家介绍过的TravisCI就是一个在线的持续集成(CI)服务。这些云服务可以让我们不再关心基础设施如何去搭建，进而集中精力去解决最核心、最关键的问题。和持续集成关注“持续”不同，静态检查关注的是代码质量。目前，SonarCloud支持.NET Framework 4.6以上及.NET Core版本。通过这篇文章，你将了解到SonarCloud的基本使用、SonarCloud与TravisCI的服务集成这两方面的内容。 SonarCloud&emsp;&emsp;静态检查，顾名思义就是通过扫描源代码来发现代码中隐藏的缺陷，譬如潜在的Bug、重复/复杂的代码等等，这些通常被称为代码中的“坏味道”，静态检查就是通过工具去扫描这些“坏味道”。Sonar是一个基于Java的代码质量管理工具，由Sonar和SonarScanner两个主要部分组成，前者是一个Web系统用以展示代码扫描结果，而后者是真正用以扫描代码的工具。Sonar具备良好的扩展性，众多的插件使得它可以和Jenkins等集成工具结合使用，同时可支持不同语言项目的扫描分析。在.NET中我们可以使用Stylecop来进行静态检查，无独有偶，ReShaper中同样提供了静态检查的特性。在这篇文章中我们主要使用Sonar来作为.NET项目的静态检查工具。 &emsp;&emsp;通常使用Sonar来构建静态检查工具时，需要我们在本地搭建一套运行环境，而SonarCloud是针对Sonar推出的一个“云”版本。我们只需要执行脚本就可以完成代码分析，而分析的结果则可以直接在SonarCloud网站中看到。这就是“云计算”的魅力所在，我们无需关心Sonar是如何安装以及配置的，当我们需要使用这种服务的时候直接使用就好了。目前，SonarCloud对开源项目是免费提供的。因此，如果你不想亲自去搭建一个静态分析的环境，那么你可以选择使用SonarCloud来对代码进行静态分析。SonarCloud支持17种语言的扫描分析，支持和Travis、VSTS、AppVeyor等CI工具集成，甚至你可以在SonarCloud上找到大量实际的项目。 &emsp;&emsp;我对SonarCloud感兴趣的一个重要原因是，它可以和TravisCI完美地集成在一起，而且在此之前，我曾经使用过一段时间的Sonar。在使用SonarCloud前，我们需要注册一个账号，这里建议使用Github账号授权登录，因为我们需要授权给SonarCloud来拉取代码，尤其当你使用TravisCI来集成SonarCloud的时候。除此之外，我们需要准备好以下工具： JDK，即Java SE Development Kit，运行SonarScanner时依赖Java环境。 Git，版本控制工具，如果身为一名程序员而没有安装Git，请面壁思过并自我检讨。 MSBuild，.NET平台项目构建工具，推荐一个无脑安装的方法，安装全宇宙无敌的IDE：Visual Studio。 SonarScanner，即Sonar的代码扫描器，注意这里有两个版本：.NET Framework 4.6 + 和 .NET Core，本文以.NET Framework 4.6 +为例。 第一个.NET项目&emsp;&emsp;好了，下面我们来使用SonarCloud对博主的一个项目HttpServer进行分析。首先，我们需要在SonarCloud中创建一个项目。如下图所示，我们首先选择Organization，默认情况下，通过Github授权登录以后，会生成一个格式为：${UserName}-github的组织名称，例如我这里是：qinyuanpei-github。这里我们选择默认组织，然后点击：Continue。 设置组织名称 &emsp;&emsp;接下来，我们需要设置一个Token，其目的是通过这个Token登录SonarCloud，然后把SonarScanner在本地扫描的结果发送到SonarCloud。这里我们可以选择生成一个新的Token或者是使用一个已经存在的Token。建议使用一个Token来管理所有的项目，因为这个Token显示一次后就不再显示，同时维护多个Token实在是太痛苦啦，当然，如果你能管理好所有Token的Key的话。设置完Token点击下一步： 设置Token &emsp;&emsp;设置完Token以后需要选择项目类型以及设置项目名称，在这个例子中，博主的项目名称是HttpServer，建议使用Sonar-${Project Name}的形式来为项目命名，而项目类型显然应该选择“C# or VB.NET”。 设置项目名称 &emsp;&emsp;接下来我们就得到最关键的信息，如图所示，这里有三条命令，我们将其复制下来，然后将其写到批处理(.bat)或者PowerShll脚本里。以后运行这三条命令，就可以对当前项目进行静态检查，是不是很简单啊？简单分析下，这三条命令，第一条命令根据我们设置的Token、项目名称、组织等信息“开始”对项目进行分析，注意到这里有一个“begin”；第二条命令是一个MSBuild命令，其目的是对整个项目重新构建；第三条命令是将静态分析的提交到SonarCloud，注意到这里有一个“end”。具体文档可以参考 这里 哦！ 复制3条命令 &emsp;&emsp;好了，现在我们在SonarCloud中就可以看到扫描结果啦，开心！如果执行命令出现问题，请确保正确安装了相关工具，并检查这些工具是否被添加到系统变量中，特别是Java需要设置JAVA_HOME。 扫描结果 TravisCI与SonarCloud的集成&emsp;&emsp;现在我们来回顾下整个过程，我们需要在本地安装SonarScanner，这是一个Java编写的应用程序，因此我们需要一个Java运行环境。每次都需要通过SonarCloud来创建项目，获得项目相关的信息以后，在命令中携带这些参数并执行命令，就可以在SonarCloud中获得本地的扫描结果。在整个过程中，我们依然需要一个本地的环境，这一点都不灵活。现实世界的复杂性，就在于我们无法为还原出完全一致的处境。&emsp;&emsp;所以，托尔斯泰开宗明义地说道：“幸福的家庭都是相似的，不幸的家庭各有各的不幸”，况且作为一个执着于让重复的事情自动化的人，如果让我做这件事情，我保证第一次会意外地觉得好奇，而等到第二次、第三次的时候我就会感到厌烦，这就是人们所说的三分钟热度。诚然，我的确是一个花心的双子座。我们提到，SonarCloud支持TravisCI，所以，接下来我们来考虑如何让TravisCI帮助我们运行Sonar。&emsp;&emsp;常规的思路是，下载SonarScanner并执行脚本。这种思路的问题在于TravisCI运行在Linux下，我们确定SonnarScanner是否可以支持Linux平台，尽管SonarScanner使用Java开发。通过阅读TravisCI的文档，我们发现TravisCI本身是支持SonarCloud的插件的，由此我们就可以着手将这一切交给TravisCI来做啦！&emsp;&emsp;关于如何使用TravisCI，这里不再赘述啦！大家可以参考我的这两篇博客，这两篇博客分别是：持续集成在Hexo自动化部署上的实践、基于Travis CI实现 Hexo 在 Github 和 Coding 的同步部署。当然第一手的资料必然是官方文档，我是不好意思随便对别人说RTFM的。按照文档说明，我们首先需要一个名为sonar-project.properties的配置文件，在该配置文件中配置了诸如项目名称、组织名称等关键信息，Sonar会自动读取这个配置文件里的信息并携带到命令中去，这个配置文件是在是太熟悉啦，假如你认真地读了这篇文章，并注意到了SonarCloud生成的三条命令。这个配置文件内容如下： 12345678910# must be unique in a given SonarQube instancesonar.projectKey=Sonar-HttpServer# this is the name and version displayed in the SonarQube UI. Was mandatory prior to SonarQube 6.1.sonar.projectName=HttpServersonar.projectVersion=1.0# Path is relative to the sonar-project.properties file. Replace \"\\\" by \"/\" on Windows.# This property is optional if sonar.modules is set.sonar.sources=.# Encoding of the source code. Default is default system encoding#sonar.sourceEncoding=UTF-8 &emsp;&emsp;配置文件中有来自官方的注释，我就不再狗尾续貂的去做相应的解释了。我们发现，这个里面是没有token的，按照官方文档中的说明，token应该配置在.travis.yml这个文件中，熟悉TravisCI的朋友就会知道，这个文件通常用来配置持续集成的流程。按照约定，SonarCloud属于TravisCI的一个插件，应该配置在addons节点下，我们注意到，在这里可以配置组织名称和token两个节点的信息。组织信息这个简单，直接按照前面的流程填写即可，需要注意的是这里的token。&emsp;&emsp;因为token采用明文配置的话，难免会存在安全风险，所以官方的建议是：使用TravisCI的终端工具进行加密。这是一个基于Ruby的命令行工具，直接在命令行中对token进行加密即可。不过想起很多年前，第一次接触Jekyll时被Ruby支配的恐惧感，我决定寻找新的出路。官方文档说可以在TravisCI中配置全局变量，这种方式我们接入Coding Page 时曾使用过，不过经过博主尝试，这种方式一直无法获得权限，所以，我不得不在配置文件中写明文，大家不要学我啊： 1234addons: sonarcloud: organization: \"在这里输入你的组织名称\" token: \"在这里输入你的token\" &emsp;&emsp;原本走到这一步时，我就该和大家对本文进行小结啦！可偏偏我注意到了SonarCloud生成命令中有MSBuild的身影，于是我开始尝试在TravisCI脚本中编写.NET相关的命令，因为我从未在TravisCI中对.NET项目进行持续集成，所以我很好奇它如果跑起来会是什么样子的。同样参照官方文档，发现目前TravisCI支持Mono和.NET Core的两个版本的构建工具，Mono我可以理解，因为TravisCI运行在Linux环境下，这和我们以前运行在Windows环境下是不一样的。而.NET Core原本就支持跨平台，目前官方释放出了2.0预览版，同时3.0的计划开始提上日程。无论或早或晚，我们面对的都将是一个多平台化的未来，永远不要固执地封闭在一个生态系统里，技术是如此，人生何尝不是如此呢？&emsp;&emsp;好啦，言归正传，了解到这种可能性以后，我开始尝试编写TravisCI脚本，官方默认的构建系统是XBuild，实际使用中遇到些问题，开始考虑能不能替换成MSBuild，事实上MSBuild目前已经是跨平台的，Nuget同样跨平台。微软收购Mono以后，Visual Studio基本上算是跨平台了，况且我们还有一个编辑器中的黑马Visual Studio Code。IIS目前可以考虑用Jexus替换，而有了OWIN这个服务器接口以后，我们有更多的Host可以去选择，现在剩下的只有SQL Server啦，可想而知，除了WinForm/WPF/COM等这种系统依赖性强的东西，大多数的服务其实都可以跑在Linux上。经过反复尝试，最终我们实现了：在TravisCI下使用MSBuild构建项目、使用Nuget在线安装NUnit并运行单元测试、使用SonarCloud对代码进行静态检查。一起来看脚本怎么写： 123456789101112131415161718192021222324252627282930313233343536373839jdk: - oraclejdk8mono: - latestlanguage: csharpsolution: ./HTTPServer/HTTPServer.slnnotifications: email: recipients: - 875974254@qq.com #请替换成你的邮箱，谢谢 - qinyuanpei@163.com #请替换成你的邮箱，谢谢 on_success: change # default: change on_failure: always # default: alwaysinstall: - cd ./HTTPServer - nuget restore ./HTTPServer.sln # restore nuget - nuget install NUnit.Runners -Version 3.8.0 -OutputDirectory ./TestRunner # install nunitscript: - msbuild /p:Configuration=Release HTTPServer.sln - mono ./TestRunner/NUnit.ConsoleRunner.3.8.0/tools/nunit3-console.exe ./HTTPServerLib.UnitTest/bin/Release/HttpServerLib.UnitTest.dll - sonar-scanner -Dsonar.verbose=true -Xbranches: only: - masteraddons: sonarcloud: organization: \"在这里输入你的组织名称\" token: \"在这里输入你的token\" cache: directories: - '$HOME/.sonar/cache' &emsp;&emsp;好啦，感受技术的魅力吧！可以注意到，我这里有4个单元测试，其中2个通过、2个失败。虽然单元测试没有通过，可我代码没有Bug呀！ NUnit运行结果 本文小结&emsp;&emsp;本文介绍了一个“云”服务：SonarCloud。SonarCloud是一个基于SonarCube的静态分析工具，通过SonarCloud我们无需搭建Sonar环境就可以对项目进行静态分析。为了验证和实现这个诉求，我们首先提供了通过SonarScanner来扫描代码的示例，其原理是在命令行参数中携带相关信息，通过token来验证和登录SonarCloud，在完成对代码的扫描以后，就可以在SonarCloud中查看整个项目的分析结果。&emsp;&emsp;接下来，为了验证SonarCloud和TravisCI进行集成的可行性，我们尝试通过travisCI脚本的方式来调用SonarCloud，其原理是通过配置文件获得相关信息由TravisCI完成所有的分析工作，这里需要注意的是要对token进行加密。在编写TravisCI脚本的过程中，我们一同验证了MSBuild、Nuget、NUnit等.NET常规工具或者类库在Linux平台下使用的可能性，最终在TravisCI的帮助下完成了从项目构建、单元测试再到代码的分析的整个流程。&emsp;&emsp;虽然静态分析并不能完全保证代码没有问题，可人类总是不情愿承认自己仅仅是一种高等动物而已，这个世界上有好多东西人们不一定会喜欢，因为它们要么是正确的要么是有益的。本文这个方案需要把代码暴露在Github，对于一般的服务集成，我们更推荐Jenkins + Sonar这样的组合，前者可以替换TravisCI提供持续集成服务，同Github、Gitlib等代码托管服务进行集成、同Stylecop、Sonar等静态检查工具进行集成，这方面的资料非常丰富，我们这里就不再多说啦，总而言之，让一切更好就是我们的目的，晚安！","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://qinyuanpei.github.io/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Mono","slug":"Mono","permalink":"https://qinyuanpei.github.io/tags/Mono/"},{"name":"Sonar","slug":"Sonar","permalink":"https://qinyuanpei.github.io/tags/Sonar/"},{"name":"Travis","slug":"Travis","permalink":"https://qinyuanpei.github.io/tags/Travis/"}]},{"title":"罗马数字与阿拉伯数字的相互转换","date":"2018-04-30T10:59:46.000Z","path":"posts/4158690468/","text":"&emsp;&emsp;最近遇到一道非常有趣的题目，题目大意如下：有一个富翁在银河系里做生意，而银河系使用的是罗马数字，所以他需要一个精明能干的助手，帮助他完成罗马数字与阿拉伯数字的相互转换，题目在这个背景下衍生出交易场景，我们需要帮助他计算出相关商品的价格。对于这道题目，如果剥离开这个题目本身的交易场景，这道题目本质上就是一个纯粹的算法问题。说来惭愧，博主当时并未能快速地解决这个问题，事后通过研读别人的文章始能有所领悟。所以，今天想在这篇文章里，同大家一起来讨论下这个问题。今天，全世界都在使用0到9这10个阿拉伯数字，比阿拉伯数字早2000年的罗马数字。为什么没有流传下来为后世所用呢？我觉得这是一个非常有意思的问题，数学同计算机学科间那种千丝万缕的联系、技术演进过程中若有若无的某种必然性……这些都是令我觉得非常有意思的地方。那么，一起来看看这个问题可好？ 罗马数字起源&emsp;&emsp;罗马数字，顾名思义，就是古罗马人使用的数字系统。在罗马数字中，共有7个基本数字，即I、V、X、L、C、D、M，它们分别表示1、5、10、50、100、500、1000。可以注意到，在这套数字系统中，0不被视作是一个整数。据说，曾经有一位罗马学者不顾教皇的反对，执意将与0相关的知识以及0在运算中的作用向民众传播，因此被教皇囚禁并投入监狱，理由是0是一个邪物，破坏了神圣的数。同样罗马数字无法表示小数(注：罗马数字有分数的表示方法，可仅仅能表示1/12的整数倍)，因此罗马数字常常用来表示纪年，在欧洲国家的古书籍、建筑和钟表中，我们都可以见到罗马数字的身影。我们熟悉的元素周期表，同样采用了罗马数字来表示元素所在的”族”。需要说明的是，罗马数字是一种计数规则，而非计算规则，这意味者罗马数字是没有进位和权重的概念的，所以一般罗马数字只用以计数而不用以演算。 &emsp;&emsp;既然罗马数字是一种计数规则，那么我们就不得不说一说它的组合规则，因为4000以内的数字，都可以用这7个基本数字组合表示。具体来讲，罗马数字的基本规则有以下4条： 重复次数：一个数字重复多少次，所表示的数字就是这个罗马数字的多少倍；一个罗马数字最多重复三次。这条规则该怎么理解呢？第一点，I、II、III分别表示1、2、3；第二点，4必须被表示为IV，而不是IIII。关于4的表示方法，在历史上一直存在争议，一种观点认为IIII这种写法占用书写空间，IV可以达到简化书写的作用；而一种观点则认为IV有亵渎神灵朱庇特、含不敬侮辱之意。 左减原则：当一个较小的数字被放在一个较大数字的左边时，所表示的数字等于这个大数减去这个小数，且左边最多只能放一个较小的数字。联系第一条原则，IV表示的实际上是V-I，所以这个数值表示4；同理，9为了满足第一条原则，必须被表示成IX。 右加原则：当一个较小的数字被放在一个较大数字的右边时，所表示的数字等于这个大数加上这个小数，且右边最多只能放一个较小的数字。这一条原则和第二条原则相对应，例如11会被表示成XI、21会被表示为XXI，以此类推。 搭配原则：I只能被放在V和X的左边；X只能被放在L和C的左边；C只能被放在D和M的左边；V、L、D不能被放在左边。这一条可以看作对是第二条的总结，所以没有什么可说的。 &emsp;&emsp;好了，通过这个这些规则我们就可以组合出不同的数字，我们可以注意到这些数字呈现出1、4、5、9的规律。什么是1、4、5、9的规律呢？我们可以注意到4和9是两个特殊的数字，4必须通过5左减来得到，9必须通过10左减来得到，这是因为罗马数字要满足最多重复三次的原则，而4和9相对1和5的偏移量恰好是4，所以它们的表示方法和其他数字不同。因为罗马数字没有进位和权重的概念，所以除了左减和右增这两种特殊情况以外，它的基本数字应该从左至右依次递减，即使在左减的情况下，左边的数字应该和右边的数字处在同一序列。这句话怎么理解呢？例如，90必须用100-10来表示；而99必须拆解为90和9，然后分别用100-10和10-1来表示，唯独不能通过100-1来表示，因为100和1分属两个不同的序列。 数字转换实现&emsp;&emsp;了解完罗马数字的历史渊源，我们就对罗马数字有了一定的了解。现在来考虑一个问题，即罗马数字和阿拉伯数字间的相互转换。罗马数字的确是古罗马人发明的，可阿拉伯数字实际上却是古印度人发明的。今天全世界人都在使用阿拉伯数字，因此这两者间需要一个转换器，这正是我们一开始所讨论的问题：假如银河系里的人们都使用罗马数字来计数，当一个地球上的富翁来到银河系以后，他要如何去和这里的人们进行交易。显然，这种转换应该是双向的，我们下面分别来看如何实现相应的转换。 阿拉伯转罗马&emsp;&emsp;首先来考虑阿拉伯数字转罗马数字，因为一个罗马数字必然是从左到右依次递减，所以我们只需要将这7个基本数字从大到小排列，找到第一个不小于指定数字的数位即可。例如1024显然超过了1000，而罗马数字中的1000对应M，因此1024的第一位应该是M。接下来24，显然超过10，因此1024的第二位数字应该是X。接下来14，显然超过10，因此1024的第三位数字同样是X。接下来4，这是一个特殊的数字，需要被表示为IV，这是1024的第四位数字。我们将整个过程串联起来，就可以得到1024的罗马数字形式MXXIV。我们注意的一点是，这里需要4和9这两个数字作为辅助数字，因为1到3、6到8的数字，我们总可以通过不断地重复1来得到，就像辗转相除法一样。如果没有这两个辅助数字会怎样呢？4会变成IIII，而9会变成VIIII，显然这是不符合我们预期的。整理下我们的思路，这段代码实现如下： 123456789101112131415161718192021222324public static string ConvertToRoman(int number)&#123; var output = new StringBuilder(); var digitMap = new Dictionary&lt;int,string&gt;() &#123; &#123;1,\"I\"&#125;,&#123;4,\"IV\"&#125;,&#123;5,\"V\"&#125;,&#123;9,\"IX\"&#125;, &#123;10,\"X\"&#125;,&#123;40,\"XL\"&#125;,&#123;50,\"L\"&#125;,&#123;90,\"XC\"&#125;, &#123;100,\"C\"&#125;,&#123;400,\"CD\"&#125;,&#123;500,\"D\"&#125;,&#123;900,\"CM\"&#125;, &#123;1000,\"M\"&#125; &#125;; var digits = digitMap.OrderByDescending(e =&gt; e.Key).ToList(); for (int i = 0; i &lt; digits.Count &amp;&amp; number &gt; 0; i++) &#123; if (number &lt; digits[i].Key) continue; while (number &gt;= digits[i].Key) &#123; number -= digits[i].Key; output.Append(digits[i].Value); &#125; &#125; return output.ToString();&#125; 罗马转阿拉伯&emsp;&emsp;接下来考虑罗马数字如何转换为阿拉伯数字，我们可以明确的一点是，罗马数字基本上是从左到右依次递减排列的，每一个数字的左侧和右侧出现的数字一定处于当前数字的同一序列。比如，I只能被放在V和X的左边；X只能被放在L和C的左边；C只能被放在D和M的左边。因此，我们从左到右依次遍历整个字符串，将每个字符转化为对应的阿拉伯数字然后累加即可，需要注意的是，当当前元素小于下一元素时，表示当前元素为负数；当当前元素大于下一元素时，表示当前元素为正数。显然，这里最后一位应该是正数，因为它没有下一个元素可以比较。至此，我们梳理出整个思路：从第一位到第n-1位依次循环，判断当前元素的正负然后累加，再加上最后一位元素的值即可。下面是代码实现： 1234567891011121314151617181920212223public static int ConvertToNumber(string romanNumber)&#123; var number = 0; var length = romanNumber.Length; var digits = new Dictionary&lt;string,int&gt;() &#123; &#123;\"I\",1&#125;,&#123;\"V\",5&#125;,&#123;\"X\",10&#125;,&#123;\"L\",50&#125;,&#123;\"C\",100&#125;,&#123;\"D\",500&#125;,&#123;\"M\",1000&#125; &#125;; for (int i = 0; i &lt; length - 1; i++) &#123; //前面 n-1 位数字通过左右比较决定正负 &amp; 第 n 位数字必然为正 if ((digits[romanNumber[i].ToString()] &gt;= digits[romanNumber[i + 1].ToString()]) || i + 1 &gt;= length) &#123; number += digits[romanNumber[i].ToString()]; &#125; else &#123; number -= digits[romanNumber[i].ToString()]; &#125; &#125; return number;&#125; 为什么会溢出&emsp;&emsp;相信上面这两段代码，大家都已然把玩过了。可我们仔细想想，就会觉得这事儿不靠谱。前段时间网络上一直流传着，我们这些佛系青年正在被同龄人抛弃。这个题目里我们所面对的，可是一个来自地球的的富翁啊！富翁的钱不都是按亿来计数的吗？我们没有一个亿这样的小目标，我们的目标是月入5万啊，这是一个社会上流行的说法。好了，回到这个题目中来，如果我们输入50000这个阿拉伯数字，它会输出什么呢？答案是50个M，这很罗马数字啊，当然更神奇的事情是什么呢？当我们尝试把这由50个M组成的罗马数字转换为阿拉伯数字时，会发现它不能像我们期望地输出50000，而会变成是一个负数。为什么这里是负数呢？答案是溢出啦！ &emsp;&emsp;过去，我们常常听到”溢出“这个词儿，最常见的是数据溢出。为什么会发生数据溢出呢？因为我们定义的数据超过了计算机所使用的数据的表示范围。这一点我们可能无法理解，一个相对粗浅的认识是，现代计算机的内存已经大到非常客观，甚至我们的硬盘都已经使用TB这样的容量单位，为什么还是会发生数据溢出呢？回到罗马数字这个问题，我们发现一个残酷的事实是，古罗马人并没有定义1000以上的数字表示，这或许和古罗马人发明数字的过程有关。古人最早都是使用手指、绳结、竹筹这样的工具来计数，在人们没有接触到相当大的数字以前，人们认为这些数的表示是足够的。同样的，我们的计算机经历了从8位、16位、32位到64位的发展。所以，这个世界上没有任何东西是一成不变的，一个技术方案势必要随着业务演化而扩展。 &emsp;&emsp;我们前面曾提到，这7个基本数字可以表示4000以内的数字，为什么是4000以内呢？因为根据罗马数字最多重复三次的规则，我们应该用5000-1000来表示4000，可问题是这7个基本数字中并没有5000的定义，这和计算机中的数据溢出是非常相似的，因为我们都无法通过现有的构造去描述一个新的东西。这和数学上的那些”扩充“有着极其相似的地方，当我们意识到所有的数不都是整数的时候，我们引入了分数/小数；当我们意识到所有的数不都是有理数的时候，我们引入了无理数； 当我们意识到所有的数不都是实数的时候，我们引入了虚数。在数学上，这叫做数的扩充；在计算机里，这叫做数据溢出。数学作为一本学科，可以通过完善理论来自圆其说；而编程语言里数据结构，是在一开始就定义好的一套规范，它无法更不应该经常去修改，关于如何去解决程序中数据溢出的问题，这已然是一个新的问题了，不过我们可以看看古罗马人是怎么做的。 &emsp;&emsp;聪明的罗马人自然想到了这个问题，他们提出的解决方案是这样的：在一个数字的上面加一条横线，表示这个数增值1000倍。所以，按照这个定义，4000应该由IV变化而来，9000应该由10000变化而来，而10000则可以看作是10的1000倍，即10000应该由X变化而来。我们在最初的规则中为什么没有说这一条呢？因为在数字上面增加一条横线，这更接近一个书写的行为，它增加了我们程序解析的难度，当一个数字的上面出现横线以后，我们就不能再按照原来的方式去转换。所以，考虑这个因素，实际上还是为了简化问题本身，这道题目中同样回避了这个问题。罗马人这个想法的确很好，可以解决眼下我们所面临的问题，可时间久了以后，罗马人发现这套计数规则书写了繁琐复杂，因而这套规则渐渐地就被人们放弃了。在2015年意大利官方宣布，国内街道编码、文件编码等全部废弃原有的罗马数字，改为使用阿拉伯数字。 选择阿拉伯数字&emsp;&emsp;历史最终选择了阿拉伯数字，而不是罗马数字，这并不是一个巧合，尽管罗马数字要比阿拉伯数字早2000年。罗马数字的缺陷不仅仅在于其书写的繁杂，一个更重要的原因是，它不能更好地推动数学学科的发展。罗马人发明罗马数字的目的是为了计数，可一旦产生了数，就势必会产生计算。可我们发现罗马数字并不适合计算，因为它对数字的构造并不是正交的。一个最为直观的例子是，数字可能会用一个字母、两个字母或者三个字母来表示，如果两个数字要进行加减法，我们会发现它的数字是无法”对齐“的，你必须非常小心地分清楚不同的数位，而罗马数字恰好是没有数位的概念的。同样，当数字加减时会产生进位或者借位，罗马数字的构造会导致牵一发而动全身，因为任何一个中间步骤，我们都必须将其记录下来，记录的代价是将整个结果重写。反观阿拉伯数字，0到9共10个数字可以表示一切，形式上的统一让计算更加便捷，书写更为简洁，这套定义可以扩展到无限大的数上面去，可以扩展到小数、分数甚至无理数、虚数。这是否意味着，一个统一化的定义或者构造，更适合去做相关的运算流程或者逻辑流程呢？ 本文小结&emsp;&emsp;本文从一道有趣的题目作为引子，引出这篇文章的主题：罗马数字。我们首先为大家回顾了罗马数字的历史渊源。罗马数字是一种由古罗马人创造的数字系统，这套数字系统主要的用途是进行计数。罗马数字由I、V、X、L、C、D、M共7个基本数字组成，其基本规则是最多重复三次、左减右增。接下来，我们分析了罗马数字与阿拉伯数字相互转换的规律，并提供相关代码实现。在当前方案的基础上，我们引出了罗马数字中的”4000“问题，联系计算机中的数据溢出的相关概念，我们分析了为什么当罗马数字超过4000时会发生”溢出“，以及罗马人是如何解决这个问题的。虽然罗马数字比阿拉伯数字早2000年，可历史最终选择了阿拉伯数字，这里我们简要地分析了原因，因为罗马数字并不适合计算，而数字作为数学的基本要素，一个不能被运用到计算出的数字系统，最终免除不了被人们抛弃的命运。好了，这篇五一节前的文章 就是这样啦，4月再见！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"算法","slug":"算法","permalink":"https://qinyuanpei.github.io/tags/%E7%AE%97%E6%B3%95/"},{"name":"数字","slug":"数字","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E5%AD%97/"}]},{"title":"邂逅AOP：说说JavaScript中的修饰器","date":"2018-04-15T21:20:03.000Z","path":"posts/3668933172/","text":"&emsp;&emsp;Hi，各位朋友，大家好，欢迎大家关注我的博客，我是Payne，我的博客地址是https://qinyuanpei.github.io。这个月基本上没怎么更新博客和公众号，所以今天想写一篇科普性质的文章，主题是JavaScript中的修饰器。 为什么使用了”邂逅”这样一个词汇呢？因为当你知道无法再邂逅爱情的时候，你只能去期待邂逅爱情以外的事物；当你意识到爱情不过是生命里的小插曲，你只能去努力弥补生命的完整性。在过往的博客中，我曾向大家介绍过譬如Spring.NET、Unity、AspectCore等AOP相关的框架，亦曾向大家介绍过譬如Python中的装饰器、.NET中的Attribute、Java中的注解等等。再我看来，这些都是非常相近的概念，所以今天这篇文章我们又双叒叕要说AOP啦！什么？你说JavaScript里居然AOP！这简直比任何特性都要开心好吗？而这就要从本文的主角——JavaScript中的修饰器说起。 什么是修饰器？&emsp;&emsp;JavaScript中的修饰器(Decorator)，是ES7的一个提案。目前的浏览器版本均不支持这一特性，所以主流的技术方案是采用Babel进行转译，事实上前端的工具链有相当多的工具都是这样，当然这些都是我们以后的话题啦！修饰器的出现，主要解决了下面这两个问题： 不同类间共享方法 在编译时期间对类及其方法进行修改 &emsp;&emsp;这里第一点看起来意义并不显著啊，因为JavaScript里有了模块化以后，在不同间共享方法只需要将其按模块导出即可。当然，在模块化这个问题上，JavaScript社区发扬了一贯的混乱传统，CommonJS、AMD、CMD等等不同的规范层出不穷，幸运的是ES6中使用了import和export实现了模块功能，这是目前事实上的模块化标准。这里需要关注的第二点，在编译时期间对类及其方法进行修改，这可以对类及其方法进行修改，这就非常有趣了呀！再注意到这里的修饰器即Decorator，我们立刻想Python中的装饰器，想到装饰器模式，想到代理模式，所以相信到这里大家不难理解我所说的，我们又双叒叕要说AOP啦！ &emsp;&emsp;那么说了这么多，JavaScript中的修饰器到底长什么样子呢？其实，它没有什么好神秘的，我们在Python和Java中都曾见过它，前者称为装饰器，后者称为注解，即在类或者方法的上面增加一个@符号，联想一下Spring中的Controller，我们大概知道它长下面这样： 1234567/* 修饰类 */@barclass foo &#123;&#125;/* 修饰方法 */@barfoo()&#123;&#125; &emsp;&emsp;OK，现在大家一定觉得，这TM简直就是抄袭了Python好吗？为了避免大家变成一个肤浅的人，我们一起来看看下面具体的例子： 修饰类12345678@setPropclass User &#123;&#125;function setProp(target) &#123; target.age = 30&#125;console.log(User.age) &emsp;&emsp;这个例子展示的是，我们如何通过修饰器函数setProp()来为User对象赋值，为什么叫做修饰器函数呢？因为这就是个函数啊，而且JavaScript和Python一样都是支持函数式编程的编程语言，所以大家看到这个大可不必感到吃惊，因为大道至简殊途同归。好了，注意到SetProp()方法有一个参数target，因为该方法修饰User类，所以它的参数就是User类，显然它为User类扩展了一个属性age，并给它赋值为30。相信有朋友一定会奇怪这个age是哪里定义的，我只能说JavaScript是个神奇的语言，一切都是对象，一切都是函数。现在，当我们执行到最后一句时，会输出30，这是因为修饰器对类进行修改。 &emsp;&emsp;现在我们尝试修改下这个方法，我们希望可以通过修饰器修改age属性的值，而不是让它成为一个固定数值30，这样就涉及到带参数的修饰器函数。修饰器函数本身会接收三个参数，第一个参数是被修饰的对象，因此为了增加一个新的参数，我们需要对原来的函数进行一层包装，你知道吗？此时我感到非常兴奋，因为这TM真的和Python一模一样啊。好了，遵从这个策略，我们修改原来的代码，并将其调整如下： 12345678910@setProp(20)class User &#123;&#125;function setProp(value) &#123; return function (target) &#123; target.age = value &#125;&#125;console.log(User.age) 此种差别，大家可以非常明显地看出来，我们在使用修饰器函数setProp()的时候，现在允许传入一个参数20，此时的结果是非常地显而易见的，这段代码将如你所愿地输出20。 修饰方法&emsp;&emsp;既然修饰器可以修饰类，那么可不可以修饰方法呢？答案自然是可以的。因为当修饰器修饰类的时候，修饰器函数的参数是一个对象，即target，而当修饰器修饰方法的时候，修饰器函数的参数是一个函数。可函数难道就不是对象吗？.NET里的委托最终不是同样会生成一个类吗？Python中不是有函数对象这一概念吗？那么，我们继续看一个例子 ： 123456789101112131415161718class User &#123; @readonly getName() &#123; return 'Hello World' &#125;&#125;// readonly修饰函数，对方法进行只读操作function readonly(target, name, descriptor) &#123; descriptor.writable = false return descriptor&#125;let u = new User()// 尝试修改函数，在控制台会报错u.getName = () =&gt; &#123; return 'I will override'&#125; 在这个例子中，我们通过修饰器函数readonly()对getName()方法进行修饰，使其变成一个readonly的方法。我们提到修饰器函数有三个参数，target指被修饰的对象，name指被修饰器对象的名称，descriptor指被修饰对象的defineProperty。因为设置descriptor的writable属性为false以后，这个函数就无法被覆盖重写，所以代码中尝试重写该方法时就会报错；同理，如果我们对descriptor的value属性进行修改，则可以对该函数进行重写。 总结&emsp;&emsp;相信熟悉Python中的朋友，应该会知道在Python中内置了大量的装饰器，譬如@property可以让一个方法像属性一样被调用、@staticmethod可以让一个方法变成静态方法、@classmethod可以让一个方法变成类方法等。那么，作为Python的追随者，JavaSript中是否存在相类似的概念呢？答案还是肯定的啊！哈哈。具体大家可以参考这里：ES6 Decorator AOP与修饰器&emsp;&emsp;熟悉我写作风格的朋友，应该可以猜到我接下来要做什么了。的确，作为一个在某些方面有强迫症的人，我一直在不遗余力地向大家推广AOP，因为我相信AOP真的可以帮大家去做很多事情。比如最简单的记录日志，或许在前端项目中大家更习惯用console.log()来记录日志，甚至是使用alert()，毕竟这些东西不会在界面上展示出来，所以写一写这些东西好像无可厚非。可当你有了AOP以后，为什么还要做如此出力不讨好的事情呢？我写这篇文章的一个重要原因，正是我看到在前端同事的代码中，使用修饰器做了一个简单的AOP，这非常符合我的品味。具体怎么样去做呢？我们一起来看这段代码： 1234567891011121314151617class Bussiness &#123; @log step1() &#123;&#125; @log step2() &#123;&#125;&#125;function log(target,name,decriptor)&#123; var origin = descriptor.value; descriptor.value = function()&#123; console.log('Calling function \"$&#123;name&#125;\" with ', argumants); return origin.apply(null, arguments); &#125;; return descriptor;&#125; &emsp;&emsp;我们刚刚提到通过修改descriptor的value属性可以达到重写方法的目的，那么这里就是利用这种方式对原来的方法进行了修改，在调用原来的方法前调用console.log()写了一行日志。的确，就是这样一行平淡无奇的代码，将我们从泥潭中解救出来。试想看到一段日志记录和业务流程掺杂的代码，谁会有心情去解读代码背后真实的含义，更不必说将来有一天要去删除这些日志有多么艰难啦。AOP的基本思想是在代码执行前后插入代码片段，因为根据JavaScript中的原型继承，我们可以非常容易地为Function类型扩展出before和after两个函数： 12345678910111213141516171819Function.prototype.before = function(beforefunc)&#123; var self = this; var outerArgs = Array.prototype.slice.call(arguments,1); return function&#123; var innerArgs = Array.prototype.slice.call(arguments); beforefunc.apply(this,innerArgs); self.apply(this,outerArgs) &#125;;&#125;;Function.prototype.after = function(afterfunc)&#123; var self = this; var outerArgs = Array.prototype.slice.call(arguments,1); return function&#123; var innerArgs = Array.prototype.slice.call(arguments); self.apply(this,outerArgs) afterfunc.apply(this,innerArgs); &#125;;&#125;; &emsp;&emsp;想象一下，现在我们在重写descriptor的value属性的时候，可以同时指定它的before()方法和after()方法，所以最初的这段代码可以继续被改写为： 123456789101112var func = function()&#123; console.log('Calling function \"$&#123;name&#125;\" with ', argumants); return origin.apply(null, arguments);&#125;;func.before(function()&#123; console.log('Start calling function $&#123;name&#125;');&#125;)();func.after(function()&#123; console.log('End calling function $&#123;name&#125;');&#125;)(); &emsp;&emsp;所以，所有让你觉得会增加风险的东西，都是源于你内心的恐惧，因为你不愿意去尝试改变，这是真正的复用，如果Ctrl + C和Ctrl + V可以被称为复用的话，我觉得每一个人都可以说自己是网红啦！这并不是一个笑话，还有什么比写一个@log更简单的吗？同样，我们可以使用修饰器去统计代码运行的时间，而不是在所有地方用两个Date()对象去相减。遵从简洁，从心开始： 123456789101112131415161718function time()&#123; return function log(target,name,decriptor)&#123; var origin = descriptor.value; descriptor.value = function()&#123; let beginTime = new Date(); let result = origin.apply(null, arguments); let endTime = new Date(); let time = endTime.getTime() - beginTime.getTime(); console.log(\"Calling function '$&#123;name&#125;' used '$&#123;time&#125;' ms\"); return result; &#125;; return descriptor; &#125;;&#125;@timefoo() &emsp;&emsp;再比如，我们的业务中要求：用户在访问相关资源或者是执行相关操作时，需要确保用户的状态是登录着的，因此，我们不可避免地在代码中，使用if语句去判断用户是否登录，试想如果所有的业务代码都这样写，两个模块间就存在了直接耦合，当然我们可以说这是最简单的做法，因为它照顾了大部分人的思维和情绪，可你看Angular/Redux/TypeScript等项目中无一不遍布着修饰器的身影，当一种框架逐渐流行并成为一种趋势的时候，好像大家立刻就忘记了一件事情：原本我们都是非常排斥这些奇技淫巧的，可因为框架的流行你就默认接受了这种设定。那么，这个逻辑如何使用修饰器来编写会怎么样呢？ 123456789101112131415161718192021222324252627class User &#123; @checkLogin getUserInfo() &#123; console.log('获取已登录用户的用户信息') &#125; @checkLogin sendMsg() &#123; console.log('发送消息') &#125;&#125;// 检查用户是否登录，如果没有登录，就跳转到登录页面function checkLogin(target, name, descriptor) &#123; let method = descriptor.value descriptor.value = function (...args) &#123; //假想的校验方法，假设这里可以获取到用户名/密码 if (validate(args)) &#123; method.apply(this, args) &#125; else &#123; console.log('没有登录，即将跳转到登录页面...') &#125; &#125;&#125;let u = new User()u.getUserInfo()u.sendMsg() &emsp;&emsp;显然，现在我们可以避免模块间的直接耦合，无需在每个业务方法中重复去写if语句，更重要的是通过JavaScript中的模块化规范，我们可以把checkLogin这个方法，扩展到更多的业务类及其方法中去，而唯一的代价就是在方法上增加@checkLogin修饰，你说，有这样优雅的策略，你为什么就不愿意去使用呢？在ASP.NET中我们通过Authorize特性就可以为API和页面授权，现在看来这是不是有点异曲同工之妙呢？你现在还觉得这样麻烦吗？ 本文小结&emsp;&emsp;这篇文章从一个前端项目中的日志拦截器(InterceptLog)为引子，引出了ES7提案中的一个特性：修饰器。修饰器的出现，解决了两个问题：第一、不同类间共享方法；第二、在编译时期间对类及其方法进行修改。虽然目前修饰器不能直接在浏览器中使用，可是通过Babel这样的转译工具，我们已经可以在项目中提前感受这一特性，这里表扬下前端组的同事们。JavaScript中的修饰器同Python中的修饰器类似，可以修饰类及其方法。JavaScript中的修饰器不建议修饰函数，因为存在一个函数提升的问题，如果一定要修饰函数，按照高阶函数的概念直接包装函数即可。通过修饰器可以简化我们的代码，在本文中我们例举了日志记录、运行时间记录、登录检查三个AOP相关的实例，希望大家可以从这篇文章中有所收获。 &emsp;&emsp;最后，请允许博主爆一个料，因为要写一个简单的修饰器，需要安装若干Babel甚至是Webpack插件，我这篇文章中的代码，截止到写这篇文章时都没能在实际环境中运行，这不能怪我啊，因为前端的工具链实在是太长太多啦，这当然不能和直接内置装饰器的Python相比啊，这真的不是吐槽诶，我需要一个开箱即用的特性就这么难吗？人生苦短，我用Python！(逃 参考文章 读懂ES7中JavaScript修饰器 ES7 Decorator 入门解析 ES7 Decorator 装饰者模式 ECMAScript 6 入门","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://qinyuanpei.github.io/tags/AOP/"},{"name":"ES6","slug":"ES6","permalink":"https://qinyuanpei.github.io/tags/ES6/"},{"name":"JS","slug":"JS","permalink":"https://qinyuanpei.github.io/tags/JS/"}]},{"title":"一念执着，千山无阻","date":"2018-04-03T09:08:04.000Z","path":"posts/2613006280/","text":"&emsp;&emsp;上周看了部印度电影《小萝莉的猴神大叔》，以一言敝之，这是一部被名字耽误的好电影，就像我们所熟知的《三傻大闹宝莱坞》、《偶滴个神呐》、《外星醉汉PK地球神》等等电影一样。不过作为一部由“印度三汗”之一萨尔曼·汗主演的电影，可能因为其在国内的知名度不及阿米尔·汗，所以早在这部2015年就上映的电影，并未在国内产生太显著的影响力。相反，同档电影《环太平洋2》票房热度居高不下，大概是因为景甜姐姐终于不负国人期望去拯救全人类啦。即使当时电影院里看这部电影的人寥寥无几，可我觉得还是有必要给大家说一说这部电影，一个即使你能猜对所有情节依然会喜欢的电影。 小萝莉与猴神大叔 &emsp;&emsp;影片一开始，讲述的是来自巴基斯坦穆斯林家庭的小女孩沙希达的故事。沙希达到6岁还不会说话，她的父母对此感到焦虑不已。祖父建议带她到神庙里去向神祈祷，可这座神庙在印度境内，并且两国间互相仇视达半个世纪之久。因为沙希达的父亲曾在巴基斯坦军方服过5年兵役，因此他没有办法申请前往印度的签证。无奈之下，沙希达的母亲独自带领女儿前往印度，不想在返回巴基斯坦的途中，沙希达在列车停靠期间，为下车救一只小羊羔而和母亲走散，并被一节载满粮食的火车带到印度。沙希达在那里遇到了“猴神”帕万，面对印度警方的无动于衷，大使馆因为印巴冲突而关门，黑中介拐卖幼童等等一系列的变故，帕万不得不走上亲自送沙希达回家的旅程…… 沙希达与小羊羔 &emsp;&emsp;电影的主线是非常清晰的，不同的是，整个电影被放在一个充斥着宗教矛盾、种姓歧视、印巴冲突的大背景里，所以导演试图去表达的内涵，就不再单纯地是为了讲这样一个故事，一如“三傻”抨击印度教育制度、OMG/偶滴个神/PK探讨宗教和神一样，这部电影里有许多值得去探讨的东西。电影两条相互交叉的线索构成，男主帕夫是一个虔诚的宗教信徒，他信奉的是印度猴神哈奴曼，并努力将宗教的教义落实到言行中去，甚至在生活中显得憨厚而木讷，导演在刻画这个人物时明显夸大了这一点，印象最深的是男主考高中就考了10次，最终父亲居然因为这个“惊喜”而去世。男主寄身在父亲身前的好友家中，并邂逅了一份“坎坷”的爱情。男主的确是一个普世价值中的失败者，没有稳定的工作，岳父要求他在六个月内买一套婚房，甚至从被黑中介欺骗这里可以看出，他并不是一个社会经验丰富的人。善良的男主在猴神节上给沙希达买了薄饼和饮料，沙希达就认定他是一个值得信赖的人，两个人的故事就此展开。 小孩子都懂得说谎 &emsp;&emsp;帕夫最初希望向印度警方寻求帮助，可警方认为警察局并不是孤儿院，拒绝为沙希达提供相关帮助。无奈之下，帕夫将小女孩带回岳父家中，起初人们见到这个可爱的小女孩，一度认为这是这个小女孩来自印度的某个高贵种姓。种姓制度是一种以血统论为基础的等级制度，广泛存在于印度社会运作与生活中，虽然印度早在1947年就脱离了英国殖民者的统治，可这种在殖民时期被固定和僵化的制度，在今天依旧影响深远。无独有偶，印巴冲突正是英国殖民统治者将印度划分为两个地区统治的结果，电影中印度的印地语和巴基斯坦的乌尔都语，其实是非常相似的两门语言。曾经有两个自命不凡的民族，一个是德意志雅丽安族，一个是扶桑国大和民族，一起发动第二次世界大战，为了所谓的种族优越性，大肆迫害犹太人和中国人，一个6岁的孩子因为可爱就被迫贴上这种种族的标签，人类繁衍至今，这种病态的虚荣心不觉得可悲吗？ 有什么区别？ &emsp;&emsp;如果说这种自带歧视的贴标签行为，仅仅是人类的一厢情愿的话，那么接下来沙希达所到的一切事情更像是一种本能。男主的岳父家是一个典型的印度佛教徒家庭，沙希达因为受到肉食的诱惑而到领居家吃鸡肉，当她遇到清真寺就会像母亲一样裹上头巾上前参拜……男主起初不愿意或者说不敢去清真寺内，或许是因为两种截然不同的宗教信仰，让他习惯性地去排斥一种新的文化。这何尝不是我们呢？一旦长大三观就特别难更改，面对三观不合这样的问题，大家都出奇地相信分手就能解决问题。可人类不曾见过一颗恒星的诞生和消亡，可我们就固执地相信这短短几十年里的所见所闻。其实我们大可不必去接受什么，就像这世间有千万种书千万句话，渐渐地丰富了我们原本枯竭的生命。男主纠结于该不该到清真寺里招人，他的女朋友则告诉他，沙希达只是一个6岁的孩子，宗教对她来说有什么意义呢？是啊，我们简简单单地来到这个世界上，等离开时突然发现平添了无数个毫无意义的身份，我承认，沙希达从背后抱住男主的时候，我一个大男人心里像是被温暖到了。 沙希达像母亲一样参拜 &emsp;&emsp;真正揭开小女孩身份的是一场球赛，一场特殊的球赛，一场发生在印度和巴基斯坦间的球赛。这里有一个细节，小女孩的母亲怀孕期间就是在看一场板球比赛。在这场比赛中，印度输掉了比赛，当所有人都一脸失落时，唯独沙希达高兴地手舞足蹈，甚至冲到电视机面前，亲吻巴基斯坦国旗。男主小心翼翼地问小女孩，“巴基斯坦？”。小女孩的确认让男主悲喜交加，喜的是终于知道小女孩的身世，悲的是两国积怨久矣为岳父所不容。事实上两国曾因为流民而引发流血事件，电影中男主岳父仇视巴基斯坦人的原因恰在于此。这让我想到，阿米尔·汗主演的电影PK中，女主嘉谷爱上了一个穆斯林男孩，父母对穆斯林的偏见以及宗教对这段感情的干涉，差点让两个真心相爱的人分开。男主再次遭遇无奈，他前往领事馆希望寻求领事馆的帮助，领事馆以沙希达没有护照为由，拒绝为男主提供帮助，这里导演让我们了解了两国间的冲突到底有多严重，一场动乱导致领事馆暂停营业一个月。男主通过岳父介绍，找到一家旅游中介公司，对方声称需要12万卢比(约合人民币10000多元)，男主的女朋友甚至拿出了准备买房子的钱，可黑心中介转手就把沙希达卖到了妓院，一个6岁的小女孩啊，妓院是什么地方？ 安全感十足的大叔 &emsp;&emsp;电影开始介绍男主时说他学习不好，更不擅长体育运动(摔跤)。妓院里男主一个房间一个房间的找小女孩，当找到小女孩的时候，这个电影突然燃了起来，虽然按照角色设定，男主不应该有这样的身手，可事实上这名印度演员萨尔曼·汗，就是以健身达人的称号闻名于世的，据说他参与演出的电影都会安排裸露上身的戏份，这一次我们就当做主角光环好啦，甚至当看到黑中介在电线上荡秋千时，小女孩那纯真的笑脸，我能想到的只有一句话，“愿你被世界温柔对待”，这样一个可爱的小女孩，我愿意她一直都长不大，因为这个世界并没有那么好，幸运的是，她遇到了善良的猴神大叔。我很想知道，为什么人长大以后，反而更加不惮于勇险恶的用心去猜度别人，这到底是一种成熟，还是一种倒退。你大概不会想到，一个印度人，为了帮助一个萍水相逢的巴基斯坦人，在没有签证的情况下，冒着被当做间谍的风险，偷偷穿过两国边界的防线，只为了送这个小女孩回家，你说他不为博眼球出名，不为做好事谋利，他到底是为了什么？原谅我说句俗气的话，这就是爱啊！ 公交车司机的神助攻 &emsp;&emsp;在穿越巴基斯坦边防线的时候，男主坚持要得到边防战士的批准后再入境，虽然这是一个讲述诚实和信念的励志故事，可我还是想说，遵从某种信念，并不是教条地照本宣科，而是在道德和法律允许的条件下适当变通。为什么要强调道德和法律呢？因为万物皆虚，万事皆座啊，《刺客信条》里刺客的信仰是每一代刺客都在追求的东西，以阿泰尔为例，他年轻时因为所罗门神殿任务的失败，而被降级为新手刺客，在完成刺杀9个圣殿骑士的任务中，他开始变得冷静而沉着，“万物皆虚，万事皆允”的理念开始变得越来越清晰。帕夫常常说他向哈奴曼神保证永远不偷偷摸摸，可他先后躲在清真寺里、车顶逃避警察搜捕，反而是那位伊斯兰教阿訇令人印象深刻，男主说自己不能进清真寺，阿訇说清真寺从来不锁门，所以任何人都可以进去。阿訇送男主一行三人离开后，以伊斯兰教礼仪祝福男主，并询问在印度教中如何表达祝福，随后以印度教礼仪向男主行礼，并煞有介事地问，“哈奴曼神在这里还管用？”。是啊，两个信仰不同的国家，素来相互仇视，可到了人家的地方，居然还要祈求本国的神灵护佑，这是不是有点讽刺呢？其实，宗教并不是要教会我们去排斥什么，而是要学会拥有一颗包容的心，只要一件事情的出发点是善良的，我相信这不会违背任何宗教的教义，佛家讲因果，道家讲无为，儒家讲修身，本质上都是劝人向善，大概爱是人类共同的语言，同样是神共同的语言。 阿訇以印度教礼仪祝福众人 &emsp;&emsp;一旦明白了这一点，你就会理解男主接下来所做的事情，比如在电话里向警察撒谎以躲避警察追捕、身为一个印度教徒参拜伊斯兰教神殿、在身上蒙上黑色衣袍伪装成伊斯兰教女子、以伊斯兰教礼仪向帮助他的人表示感谢……所谓“大道至简“，我希望我们相互去借鉴和学习不同领域里的东西，而不是相互对立和排斥彼此。《笑傲江湖》里的五岳剑派，一心想成为能和少林武当抗衡的江湖势力，其实像左冷禅这样的“宗师”级人物，如果可以以华山石壁上魔教长老破除各派剑法的图形为基础，集结各派所长，创造一门新的武功并不是不可能，奈何江湖人物一样逃不过权势的诱惑，想要扫除魔教势力，先破武当，再灭少林，再加上狭隘的门户之见，五岳剑派的辉煌不过是转眼云烟。想想《碧血剑》里大反派玉真子，一人一剑就敢上华山挑战，华山派的衰落可见一斑。如今全世界都被互联网连接在一起，文化间的相互影响越来越深，宗教如是，文化如是，不要以狭隘的民族观去审视我们不懂的文化，就如同不要觉得朋友圈里你不懂的东西Low一样，心态要开放，眼光要长远。 突然觉得生活美好起来 &emsp;&emsp;这部电影有太多的意料之中，同样有太多的意料之外。我知道小女孩会和母亲重逢，可我不知道真正打动我的是那一声叔叔；我知道男主会被警方逮捕，可我不知道巴方会想到屈打成招，理由仅仅是因为对方是一个印度人；我知道小女孩并不是哑巴，可我不知道原来说出一句话需要莫大的勇气……这里感谢那个电视台记者，这是一个媒体人的自我修养；感谢那个正直的警官，他没有给他的国家丢脸；感谢那些冲开边防线的巴基斯坦人民，有一种力量叫做民心所向。我希望两个国家可以像电影一样美好，不再有冲突，不再有流血，即使我知道现实中的困难远比电影中的多……可这的确是一群成年人的童话，就像电影最终定格在沙希达和她的猴神大叔拥抱在一起一样，有些美好值得我们去期待，有些东西值得我们去追寻，它们或许是爱，或许是正义，或许是善良，或许是信念，或许是和平，或许是勇敢……我猜中了故事的结尾，依然为这个故事而热泪盈眶，这一切并非是因为我矫情，而是因为我简单，简单到有些东西不必理解得那么深刻，就像我单纯地喜欢着你却不知道为什么一样。好了，这篇影评终于写完啦，晚安！^_^ 永恒的瞬间","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"影评","slug":"影评","permalink":"https://qinyuanpei.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"印度","slug":"印度","permalink":"https://qinyuanpei.github.io/tags/%E5%8D%B0%E5%BA%A6/"}]},{"title":"漫谈应用程序重试策略及其实现","date":"2018-03-31T19:20:54.000Z","path":"posts/115524443/","text":"&emsp;&emsp;最近随项目组对整个项目进行联调，在联调过程中暴露出各种问题，让我不得不开始反思，怎么样更好地去做好一件事情，譬如说在开发过程中如何保证Web服务的稳定性，在敏捷开发中如何降低文档维护的成本，以及如何提高多环境服务部署的效率等等。我为什么会考虑这些问题呢？通常我们都是在约定好接口后并行开发的，因此在全部接口完成以前，所有的服务都是以渐进的形式进行集成的，那么如何保证服务在集成过程中的稳定性呢？尤其当我们面对开发/测试/生产三套环境时，如何提高服务部署的效率呢？当接口发生变更的时候，如何让每一个人都知悉变化的细节，同时降低人员维护文档的成本呢？这些问题或许和你我无关，甚至这不是一个技术问题，可恰恰这是我们时常忽视的问题，我是我想要写这篇文章的一个重要原因。 代码越来越复杂&emsp;&emsp;面对这种问题，尤其是当你发现，它并不是一个纯粹的技术问题的时候。选择一件你喜欢的事情的去做，固然可以令你开心；而选择一件你不喜欢的事情去做，则可以令你成长。我们每一个人都不是人类学家，可生命中80%的时间都在研究人类。当你接收到一条别人的讯息时，不管这个讯息本身或对或错，在生而为人的角色预设中，你都必须去提供一个响应，甚至是比对方期望更高的一个响应。可是服务器会返回403、404或者500甚至更多的状态码，人生有时候并没有机会去选择Plan B或者Plan C。所以，即使所面临境地再艰难，能不能勇敢地再去尝试一次，说服对方或者选择妥协，就像一段代码被修改得面目全非，可人类本来就是喜欢皆大欢喜的动物，总希望别人都认认真真，而自己则马马虎虎，因为“认真你就输了”，有谁喜欢输呢？ &emsp;&emsp;好了，现在假设我们有这样一个业务场景，我们需要调用一个WebAPI来获取数据，然后对这些数据做相关处理。这个API接口被设计为返回JSON数据，因此，这个“简单”的业务场景通过以下代码来实现： 12345def extract(url): text = requests.get(url).content.decode('utf-8') json_data = json.loads(text) data = json_data['raw_data'] return data &emsp;&emsp;这个代码非常简单吧！可是过了十天半个月，每次解析JSON数据的时候随机出现异常，经验丰富的同事建议增加try…except，并在捕获到异常以后返回None。于是，extract()方法被修改为： 123456789def extract(url): text = requests.get(url).content.decode('utf-8') try: json_data = json.loads(text) data = json_data['raw_data'] return data except Exception: print(\"JSON数据无效，重试！\") return None &emsp;&emsp;修改后的代码，果然比修改前稳定啦，可是负责后续流程的同事开始抱怨，现在代码中出现大量判断返回值是否为None的代码片段，甚至在Web API返回正确结果的情况下，依然会返回None，为此，机智的同事再次修改代码如下： 123456789def extract(url): text = requests.get(url).content.decode('utf-8') try: json_data = json.loads(text) data = json_data['raw_data'] return data except Exception: print(\"JSON数据无效，重试！\") return extract(url) &emsp;&emsp;可以预见的是，使用递归可能会导致递归的深度问题，假如调用者传入一个错误的URL，将导致这里无限递归下去，于是考虑限制重试的次数；增加重试次数的限制以后，发现每次重试需要有一个时间间隔……更不必说要在这里增加日志记录，以及在特定场景下需要将异常抛出，由此可见这段简单的代码会变得越来越复杂，如下所示： 123456789101112def extract(url): text = requests.get(url).content.decode('utf-8') try: json_data = json.loads(text) data = json_data['raw_data'] return data except Exception: for i in range(3): print('正在进行第&#123;0&#125;次重试'.format(str(i)) result = extract(url) if(result!=None): return result &emsp;&emsp;可以注意到，这是一个非常合理的代码演进过程。在这个演进过程中，一段非常简单的代码变得越来越复杂。在我写下这篇文章前，我亲眼目睹了这种复杂的代码，是如何难以复用以及集成的，日志记录、异常处理等流程和正常流程“混合”在一起，甚至你不得不通过函数的返回值来判断是否异常，我一直在想怎么样去解决这些“corner”问题，就像人们一致认为：王垠博士擅长解决的是理想状态下的纯问题。而现实世界中存在着各种各样的“corner”问题，这或许就是学术界与工业界的区别，那么怎么样去更好地解决这一切问题呢？ 应用程序重试策略&emsp;&emsp;既然我们可以预见到这些问题的存在，那么，现在让我们正式切入今天这篇博客的主题，即应用程序重试策略。我们在这里以一种渐进式的方式，向大家展示了一个简单的应用程序，是如何因为异常处理变得越来越复杂的，这里我们选择重试，是因为现实世界本身存在不稳定性，即使我们现在有各种自动化工具来替代传统运维。就像有时候你怀疑是代码出现Bug，实际上则是服务器在某一段时间内宕机，当这种事情就发生在你身边的时候，你不得不去着手解决这些“corner”问题，而这恰好是人生的无奈之处。 Try-Catch-Redo策略&emsp;&emsp;这应该是我们最容易想到的一种重试策略了，其思路是对函数的返回值和异常进行处理，其缺点是无法解决重试无效的问题。这里我们将问题简化为对异常进行处理，其基本的代码实现如下： 123456789101112131415161718private void Retry()&#123; try &#123; var result = DoWork(); if(!result)&#123; //重试一次 Thread.Sleep(1000); DoWork(); &#125; &#125; catch(Exception e) &#123; //重试一次 Thread.Sleep(1000); DoWork(); &#125;&#125; &emsp;&emsp;可以注意到，这种策略最多可以重试一次，因此如果重试后无效，这个策略就变得毫无意义起来，我们需要寻找一种更好的方式。 Try-Catch-Redo-Retry策略&emsp;&emsp;考虑到第一种策略无法解决重试无效的问题，我们在此基础上增加对重试次数以及重试间隔的控制，这就是Try-Catch-Redo-Retry策略，其基本实现如下： 123456789101112131415161718192021222324private void Retry()&#123; //最大重试次数为5次 int times = 5; //重试间隔为10秒 int interval = 10; //存储异常的列表 var exceptions = new List&lt;Exception&gt;(); while(true) &#123; try &#123; var result = DoWrok(); if(result) return result; &#125; catch(Exception ex) &#123; if(--times&lt;=0) throw new AggregateException(exceptions); exceptions.Add(ex); Thread.Sleep(TimeSpan.FromSeconds(interval)); &#125; &#125;&#125; &emsp;&emsp;可以注意到，通过while(true)结构的确可以增加重试的次数。问题在于：如果不设置合理的循环跳出条件，就有可能造成逻辑上的死循环。尤其当循环体内的逻辑执行时间较长时，会增加用户的等待时间，这看起来亦非良策啊！ Retry-Builder策略&emsp;&emsp;Try-Catch-Redo和Try-Catch-Redo-Retry这两种策略理解起来非常容易，可这两种策略都有一个致命的缺陷，即正常逻辑和重试逻辑重度耦合。我们希望采用一种更优雅的方法，以一种非侵入式的方式给正常逻辑增加重试重试逻辑。需要考虑的是，在确保重试次数和重试间隔可配置的前提下，支持自定义重试源，即可以捕捉一个或多个异常以及对返回值进行处理。在这里推荐三个框架，分别是Java中的Spring-Retry和Guava-Retrying、.NET中的Polly。其中Spring-Retry是基于Throwable类型的重试机制，即针对可捕获异常执行重试策略，并提供相应的回滚策略；而Guava-Retrying提供了更为丰富的重试源定义，譬如多个异常或者多个返回值；而Polly则提供了除重试以外的断路器、超时、隔板隔离、缓存、回退等多种策略。这三者的相似之处在于，通过一个Factory来创建满足不同重试策略的Retryer，然后由Retryer来通过回调来执行重试逻辑，我不喜欢Java中回调函数写法，所以这里以Polly为例： 12345678910111213141516171819try&#123; var retryTwoTimesPolicy = Policy .Handle&lt;DivideByZeroException&gt;() .Retry(3, (ex, count) =&gt; &#123; Console.WriteLine(\"执行失败! 重试次数 &#123;0&#125;\", count); Console.WriteLine(\"异常来自 &#123;0&#125;\", ex.GetType().Name); &#125;); retryTwoTimesPolicy.Execute(() =&gt; &#123; var a = 0; var b = 1/a; &#125;);&#125;catch (DivideByZeroException e)&#123; Console.WriteLine($\"Excuted Failed,Message: (&#123;e.Message&#125;)\");&#125; &emsp;&emsp;可以看到，写出一段语义化的代码是多么的重要，因为我相信大家都看懂了。这里的Policy承担了RetryBuilder的角色，它定义了这样一种策略：当程序引发DivideByZeroException时进行重试，重试次数为3次，并且以匿名函数的方式指定了重试时的回调函数；而创建的retryTowTimesPolicy承担了Retryer的角色，它通过Execute()方法来定义要执行的重试逻辑。当3次都重试失败时就会引发DivideByZeroException并在最外层函数中被捕捉到。我经常听到有人说设计模式没有用，我想说因为你从来都不知道什么叫做大道至简，引入无数个中间层是无法让你直接看到代码定义，可计算机领域里有一句名言，“任何一个问题都可以通过引入一个中间层来得到解决”。 装饰器/AOP策略&emsp;&emsp;我从来不惮于将各种重复的工作自动化，这并不是我喜欢在别人面前炫技，而是因为在现实生活中我是一个懒惰的人，甚至是每天早上10点开站会这样的事情，我都愿意让计算机程序去提前通知我做好准备。我并不是一个不懂得自律的人，仅仅是因为我觉得我们可以用这个时间去做些别的事情。AOP是一种可以在运行时期间动态修改代码的技术，我们自然可以想到给所有的函数都加上异常处理和重试的特性，幸运的是Python中的有这样一个第三方库：Tenacity，它可以帮助我们优雅地实现重试： 123456789from tenacity import retryfrom json.decoder import JSONDecodeError@retry(retry=retry_if_exception_type(JSONDecodeError), wait=wait_fixed(5), stop=stop_after_attempt(3))def extract(url): text = requests.get(url).content.decode('utf-8') json_data = json.loads(text) data = json_data['raw_data'] return data &emsp;&emsp;通过@retry这个装饰器函数，我们就可以知道，这里设计的重试策略是：当引发JSONDecodeError这个异常时，每隔5秒中重试一次，最大重试次数为3次。Python中的装饰器，本质上就是高阶函数的概念，修饰器函数对被修饰函数进行“操作”后返回一个新的函数，这个特性在.NET中可以通过委托/匿名方法/lambda来实现，结合Unity、AspectCore等AOP框架，相信大家完全可以将这个特性移植到.NET中来，当语言的差别变得微乎其微的时候，原理的重要性不言而喻。 重试策略核心理念&emsp;&emsp;好了，截止到目前，我们分析了四种不同的重试策略，并且这四种重试策略是随着我们认知的加深而逐渐递进的。那么，通过这四种不同的重试策略，我们能否梳理出一个相对完整的应用程序重试策略呢？换言之，当为应用程序增加重试相关的功能时，我们都需要考虑哪些因素，因为使用这些框架会是非常简单的过程，而更重要的则是我们逐步演进的思考过程。当我们所依赖的是一个不稳定的场景，譬如远程调用、数据加载、数据上传等场景时，或者是在异常场景中需要重试以满足业务稳定性的要求等等，就可以考虑使用重试策略。这里简单地做一下梳理： 重试逻辑与正常逻辑解耦，整个设计是非侵入式的。 支持自定义策略，譬如重试次数、重试间隔、重试源、重试超时时间等。 支持自定义断言，即可以使用Predict或者类似表达式来定义返回值满足的条件。 支持多种异常，即可以针对特定的Exception或者自定义的Exception进行拦截。 断言实例和异常实例，作为正常逻辑和重试逻辑两者间的媒介进行交互。 通过命令模式，由Retryer对象完成对正常逻辑的调用，同时在内部封装重试逻辑。 一个简单的Retry实现&emsp;&emsp;好了，熟悉我写作风格的朋友，一定知道我不喜欢空泛地讲一套理论，我更喜欢通过“造轮子”的这种方式，以加深对一个事物或者原理的认识。对于今天这篇文章，我的初衷是想告诉大家如何优雅地去实现Retry，因为在现实中我们总会遇到各种各样的枷锁，这些枷锁约束着你写出糟糕的代码，我们比别人用心甚至更努力，反而常常被认为是有代码洁癖或者是炫技，可不管怎么样，人生是我们自己的，如果没有办法说服别人在项目中使用这些技术，那我们就在项目以外的地方去使用，或者是告诉别人我们有一种相对优雅的设计，如果这个设计恰好对别人有用，对我们来说就是一种莫大的幸福。参考Polly的API风格，这个Retry被我设计成了下面的样子： 123456789101112131415161718192021try&#123; var result = Retry.Default .Times(3) .Interval(2) .Catch&lt;DivideByZeroException&gt;() .Reject((count,ex)=&gt; &#123; var message = string.format(\"第&#123;0&#125;次重试，异常来自:&#123;1&#125;\", count, ex.Message); Trace.WriteLine(message); &#125;) .Execute&lt;int&gt;(()=&gt; &#123; var m = 0; return 3 / m; &#125;);&#125;catch(Exeption ex)&#123; Trace.WriteLine(ex.Message);&#125; &emsp;&emsp;我承认它和Polly非常地像，不过我并没有去看Polly是如何实现的，目前它的实现完全来自这篇文章中我们提到的这些策略。我在为它增加了针对返回值的断言支持，通过Return方法来实现，而对异常的支持则是通过Catch方法来实现，除此以外，它支持异步方法调用，我们熟悉的Task/async/await这些API都可以使用。目前它还是一个玩具儿，因为我发现最难的部分，其实是断言或者说自定义表达式的设计，对于线程安全相关的问题，我会在慢慢地去完善它，如果你对它感兴趣的话，可以通过这里访问：RetryIt。好了，感谢大家关注我的博客，今天这篇先写到这里啦，欢迎大家在博客中留言！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"异常","slug":"异常","permalink":"https://qinyuanpei.github.io/tags/%E5%BC%82%E5%B8%B8/"},{"name":"重试","slug":"重试","permalink":"https://qinyuanpei.github.io/tags/%E9%87%8D%E8%AF%95/"},{"name":"想法","slug":"想法","permalink":"https://qinyuanpei.github.io/tags/%E6%83%B3%E6%B3%95/"}]},{"title":"使用Unity框架简化应用程序异常处理及日志记录流程","date":"2018-03-21T19:35:40.000Z","path":"posts/3291578070/","text":"&emsp;&emsp;最近公司安排学习项目代码，前后花了一周左右的时间，基本熟悉了项目中的各个模块，感觉项目难度上整体偏中等。这是一个具备完整前端和后端流程的项目，在学习这个项目的过程中，我逐渐发现某些非常有趣的东西，比如在Web API的设计中采用严谨而完善的错误码、使用OAuth和JWT对API资源进行访问控制，在JavaScript中使用修饰器特性来实现日志记录等等，这些东西我会在后续的博客逐步去整理，今天想说的是如何通过Unity框架来简化应用程序异常处理和日志记录流程，而之所以关注这个问题，是因为我发现项目中接近滥用的异常处理，以及我不能忍受的大量重复代码。 背景描述&emsp;&emsp;由于业务场景上的需要，我们在产品中集成了大量第三方硬件厂商的SDK，这些SDK主要都是由C/C++编写的动态链接库，因此在使用这些SDK的过程中，通常频繁地使用返回值来判断一个方法是否成功被调用，虽然项目上制定了严格的错误码规范，可当我看到大量的Log()方法和业务逻辑混合在一起时，我内心依然是表示拒绝的，甚至我看到在捕获异常以后记录日志然后继续throw异常，这都是些什么鬼操作啊，考虑到我的语言描述得可能不太准确，大家可以从下面两段代码来感受下整体画风： 1234567891011121314151617public short LoginTerminal(string uid,string pwd)&#123; try &#123; Log.BeginLog() return SDK.Login(uid,pwd) &#125; catch(Exception ex) &#123; log.LogError(ErrorCode.E2301,ex) throw new TerminalException(ex.Message); &#125; finally &#123; Log.EndLog() &#125;&#125; &emsp;&emsp;这是一段相对完整的业务逻辑代码，当然这里都是伪代码实现，这里我比较反感的两个地方是：第一，从头出现到尾的BeginLog()/EndLog()这对方法；第二，在Catch块中记录完日志然后将异常再次抛出。经过我对项目的一番了解，BeginLog()/EndLog()这对方法会在日志中记录某个方法开始执行和结束执行的位置。在方法执行前后插入代码片段，这不就是面向切面编程(AOP)的思想吗？这里记录完日志然后再抛出异常的做法，我个人是不大认同的，因为我觉得拦截异常应该有一个统一的入口，因为异常会继续向上传递，既然如此，为什么我们不能统一地去处理异常和记录日志呢？难道就一定要让Log这个静态类无处不在吗？同样地，我们注意到项目还会有下面这样的代码： 1234567891011121314public void ProcessTerminal(object sender,ProcessEventArgs args)&#123; try &#123; Log.BeginLog(); var terminal = (Termainal)sender; var result = terminal.Process(args); &#125; finally &#123; Log.EndLog(); &#125;&#125; &emsp;&emsp;这种代码看起来不再关注异常，可和第一段一样，从头出现到尾的BeginLog()/EndLog()简直不能忍，而且这里的try…finally结构难免让人想起using的语法糖，那么这样是不是可以考虑让这个Log拥有类似的结构，换言之，我们总不能一直都在每一个方法里，重复写BeginLog()/EndLog()这两个方法吧，既然EndLog()方法总是在finally块里被执行，那为什么不考虑把它放到Dispose()方法里(前提是有一个结构实现IDispose接口)。你问我是不是有代码洁癖啊？我真的没有，我就是懒，不喜欢重复做一件事情。所谓”管中窥豹，可见一斑”，大家可以想象整个项目会是什么样子。 &emsp;&emsp;好了，为了避免让自己写这种糟糕的代码，我决心使用Unity框架来简化下这里的异常处理和日志记录流程，一个有追求的程序，如果可以交给自动化工具去做的事情，为什么要一次又一次地重复去写呢？我们可以吐槽一段代码写得有多糟糕，可我们所做的任何努力，都是为了让自己不变成这个样子。Unity框架提供的AOP，即面向切面编程，不就可以做这样的事情吗？所以，能动手的就直接动手，君子有所为有所不为，不要重复自己， Unity框架与AOP&emsp;&emsp;好啦，交待完故事背景，今天的主角终于可以登场啦！经常关注我博客的朋友，一定知道我个人比较喜欢IoC/AOP这类所谓的”奇技淫巧”，就在今天我还在和一位同事在讨论Ioc，这位同事认为Ioc增加了代码的复杂性，不认为Ioc会为项目带来明显的便利性。其实我相信大道至简，任何框架对我们而言都是高度抽象的，可正是因为有了这些抽象的层次，我们渐渐学会了关注核心的东西。这里提到了Ioc，即控制反转，或者我们可以称之为依赖注入，那么Unity框架就是.NET下众多依赖注入框架之一，这里称之为Unity框架，主要是避免和跨平台游戏引擎Unity产生混淆，以下全部称之为Unity框架。Unity框架中提供了核心的依赖注入相关的接口，而微软的企业最佳实践库中为Unity扩展出了AOP相关的功能。除此以外，Spring.NET、Aspect.Core、AspectF等都是.NET下的AOP方案。那么在今天的故事中，我们遇到了的一个场景是在指定方法执行前、后插入代码片段，这是面向切面编程(AOP)的基本思想，为此，我们考虑使用Unity框架来简化应用程序中异常处理及日志记录流程。 Unity中的三种拦截器&emsp;&emsp;Unity中提供了三种典型的拦截器，为了选择一种合适的拦截器来实现我们的功能，我们首先来了解下这三种不同的拦截器各自的应用场景： TransparentProxyInterceptor：即透明代理拦截器，基于.NET Remoting 技术实现代理，它可以拦截对象的所有函数，缺点是被拦截对象必须继承自MarshalByRefObject。 InterfaceInterceptor：顾名思义，即接口拦截器，仅拦截指定接口，显然只要目标类型实现了指定接口就可以拦截。C#不支持多继承，选择这种方式对代码的影响最小。 VirtualMethodInterceptor：顾名思义，即虚方法拦截器，仅拦截虚方法，这个对目标类型的要求就非常高啦，一般我们不会考虑这种方式。 对Unity框架而言，不管我们使用哪一种拦截器，我们都需要通过UnityContainer这个容器来为目标类型注入拦截器，这样Unity框架会帮助我们生成代理对象，我们只要在使用代理对象的时候，这些拦截器才会真正工作。博主曾经以为定义好下面这些Handler就可以了，简直是图样图森破。好了，一个基本的代码流程如下，请不要问我配置文件怎么配，我真的不喜欢配置文件，搞得跟某配置狂魔语言似的，反正这些配置文件这次记住了下次还是会忘的，可下面这几行代码是不会轻易忘记的啊： 123var container = new UnityContainer().AddNewExtension&lt;Interception&gt;().RegisterType&lt;IBussiness, Bussiness&gt;();container.Configure&lt;Interception&gt;().SetInterceptorFor&lt;IBussiness&gt;(new InterfaceInterceptor());var bussiness = container.Resolve&lt;IBussiness&gt;(); 注意，这里不要直接从Github或者Nuget上下载Unity框架，因为最新版的Unity我实在是不会用啊！:joy: 我喜欢开箱即用的产品，我愿意钻研啊，可DeadLine永远会有终点！我们需要从微软企业最佳实践库中下载以下动态链接库： CommonServiceLocator.dll Microsoft.Practices.Unity.Configuration.dll Microsoft.Practices.Unity.dll Microsoft.Practices.Unity.Interception.Configuration.dll Microsoft.Practices.Unity.Interception.dll考虑到我们这里需要实现两种功能，针对异常的异常处理流程，以及正常的日志记录流程，为此我们将实现ExceptionHandler和LogHandler两个组件。下面我们来一起了解这两个组件的实现过程，这里博主选择了最简单的ICallHandler接口，而非更一般的IInterceptionBehavior接口，主要希望让这个过程更简单些，同时实现在方法粒度上的可控，即我们可以选择性的去拦截某一个方法，而非全部的方法，因为在实际业务中并非所有的方法都需要拦截。 LogHandler的实现&emsp;&emsp;LogHandler主要用于记录日志，所以我们需要记录方法的名字，方法的参数以及方法执行的结果，甚至是是否引发异常，这些功能在AOP中是相对基础的功能，Unity框架为我们提供了这些基础设施，我们只要就可以获取到这些信息，然后将其记录到日志中即可。这里的代码如下： 123456789101112131415161718192021public class LogHandler : ICallHandler&#123; int ICallHandler.Order &#123; get; set; &#125; IMethodReturn ICallHandler.Invoke(IMethodInvocation input, GetNextHandlerDelegate getNext) &#123; var methodInfo = input.MethodBase; var methodName = methodInfo.Name; Logger.Log(string.Format(\"----------开始调用&#123;0&#125;----------\", methodName)); var parameters = methodInfo.GetParameters(); var arguments = input.Arguments; var logInfo = parameters.Select(e =&gt; string.Format(\"&#123;0&#125;:&#123;1&#125;\", e.Name, arguments[e.Position])); Logger.Log(\"传入的参数为:\" + string.Join(\",\", logInfo.ToArray())); var result = getNext()(input, getNext); if (result.Exception != null) Logger.Log(string.Format(\"调用异常:&#123;0&#125;-&#123;1&#125;\", result.Exception.Message, result.Exception.StackTrace)); Logger.Log(string.Format(\"调用&#123;0&#125;的结果为：&#123;1&#125;\", methodName, result.ReturnValue)); Logger.Log(string.Format(\"----------结束调用&#123;0&#125;----------\", methodName)); return result; &#125;&#125; 为了让这个Handler更好用一些，我们希望它可以以Attribute的方式出现在方法上面，这样被标记过的方法就会被Unity框架拦截，所以我们需要一个继承自Attribute类的东西，知道我为什么不喜欢配置文件吗？因为我有Attribute啊！幸运的是Unity框架为我们提供了这样一个基类：HandlerAttribute，由此下面的代码可以这样写： 12345678[AttributeUsage(AttributeTargets.Method,AllowMultiple = true)]class LogHandlerAttribute : HandlerAttribute&#123; public override ICallHandler CreateHandler(IUnityContainer container) &#123; return new LogHandler(); &#125;&#125; ExceptionHandler的实现&emsp;&emsp;对于ExceptionHandler来说，它相比LogHandler增加的功能在于，它需要处理异常，按照目前项目的异常处理习惯，这种和硬件相关的方法都会被定义为一个ErrorCode，为此我们的ExceptionHandler类中需要增加一个ErrorCode类型的成员，这是一个枚举类型。这里的代码实现如下： 123456789101112131415161718192021222324252627public class ExceptionHandler : ICallHandler&#123; int ICallHandler.Order &#123; get; set; &#125; public string ErrorCode &#123; get; set; &#125; IMethodReturn ICallHandler.Invoke(IMethodInvocation input, GetNextHandlerDelegate getNext) &#123; var methodInfo = input.MethodBase; var methodName = methodInfo.Name; Logger.Log(string.Format(\"--------------方法&#123;0&#125;执行开始--------------\", methodName)); var parameters = methodInfo.GetParameters(); var arguments = input.Arguments; var logInfo = parameters.Select(e =&gt; string.Format(\"&#123;0&#125;:&#123;1&#125;\", e.Name, arguments[e.Position])); Logger.Log(\"传入的参数为:\" + string.Join(\",\", logInfo.ToArray())); var result = getNext()(input, getNext); if (result.Exception != null) &#123; Logger.Log(string.Format(\"Error Code is &#123;0&#125;\", ErrorCode)); result.Exception = null; Logger.Log(string.Format(\"--------------方法&#123;0&#125;执行结束--------------\", methodName)); throw new Exception(ErrorCode); &#125; Logger.Log(string.Format(\"--------------方法&#123;0&#125;执行结束--------------\", methodName)); return result; &#125;&#125; 可以注意到ExceptionHandler相比LogHandler的变化，主要发生在异常处理这部分，如你所愿，我在拦截到异常以后抛出了一个对应ErrorCode的异常，虽然我不赞同这种做法，但为了尊重现有项目的编程风格，我只能写有这样一行看起来非常拙劣的代码，我真的没有代码洁癖，我仅仅是觉得它还不够好，就像我觉得自己还不够好一样，同样，它需要定义一个对应的Attribute类，这样我们可以更加自由地使用这些特性： 12345678[AttributeUsage(AttributeTargets.Method,AllowMultiple = true)]class LogHandlerAttribute : HandlerAttribute&#123; public override ICallHandler CreateHandler(IUnityContainer container) &#123; return new LogHandler(); &#125;&#125; 本文小结&emsp;&emsp;好了，现在我们可以来看，如何使用这篇文章中定义的两个组件： 1234567var container = new UnityContainer().AddNewExtension&lt;Interception&gt;().RegisterType&lt;IBussiness, Bussiness&gt;();container.Configure&lt;Interception&gt;().SetInterceptorFor&lt;IBussiness&gt;(new InterfaceInterceptor());var bussiness = container.Resolve&lt;IBussiness&gt;();var sum = bussiness.Add(12,23);Console.WriteLine(sum);var div = bussiness.Divide(1,0)Console.WriteLine(div) IBussiness接口及其实现类Bussiness定义如下： 123456789101112131415161718192021public interface IBussiness&#123; int Add(int a, int b); int Divide(int a, int b);&#125;public class Bussiness : MarshalByRefObject, IBussiness&#123; [LogHandler] public int Add(int a, int b) &#123; return a + b; &#125; [ExceptionHandler(ErrorCode = \"E2303\")] public int Divide(int a, int b) &#123; return a / b; &#125;&#125; 好了，现在我们来看一下结果： 使用AOP简化后的异常处理和日志记录流程 &emsp;&emsp;我们为此付出的代价是什么？第一，要有一个接口，写接口难道还有疑问吗？第二，要添加Attribute到指定方法上面，我保证这点时间足够你写好几遍重复代码了。第三，需要依赖注入机制，这个可能是到目前为止最大的影响，因为有了依赖注入以后，对象的实例化都交给了Unity框架，看起来我们好像被束缚了手脚，不能再任性地new一个对象实例出来，可这不正是依赖注入的精髓所在吗？我们就是需要Unity框架，来帮助我们管理这些模块间的依赖关系及其生命周期，如果你觉得这点代码不能接受，抱歉，任何依赖注入框架拯救不了你！ &emsp;&emsp;今天这篇文章，我们从一个实际项目的背景出发，引出使用Unity框架来简化异常处理和日志记录流程这一想法，在正式实践这一想法前，我们首先了解了Unity框架中提供的三种拦截器及其各自优劣，在此基础上我们实现了LogHandler和ExceptionHandler两个组件，并展示了如何使用这两个组件，探讨使用整个AOP机制对现有项目的影响有多大，以及为什么我们需要Unity框架等问题，框架固然重要，了解为什么使用框架则更重要！好啦，这就是今天这篇文章的内容啦，再次谢谢大家关注我的博客，各位晚安！:smile:","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://qinyuanpei.github.io/tags/AOP/"},{"name":"日志","slug":"日志","permalink":"https://qinyuanpei.github.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"异常","slug":"异常","permalink":"https://qinyuanpei.github.io/tags/%E5%BC%82%E5%B8%B8/"}]},{"title":"基于新浪微博的男女性择偶观数据分析(下)","date":"2018-03-17T15:28:40.000Z","path":"posts/3083474169/","text":"&emsp;&emsp;各位朋友，大家好，我是Payne，欢迎大家关注我的博客。我的博客地址是：https://qinyuanpei.github.io。对于今天这篇文章的主题，相信经常关注我博客的朋友一定不会陌生。因为在2017年年底的时候，我曾以此为题写作了一篇文章：基于新浪微博的男女择偶观数据分析(上)。这篇文章记录了我当时脑海中闪烁着的细微想法，即当你发现一件事物背后是由哲学或者心理学这类玄奥的科学在驱动的时候，不妨考虑使用数学的思维来让一切因素数量化，我想这是最初数据分析让我感兴趣的一个原因。因为当时对文本的处理了解得非常粗浅，所以在第一次写作这篇文章的时候，实际的工作不过是在分词后绘制词云而已。等到我完成对微信好友信息的数据分析以后，我意识到微博这里其实可以继续发掘。关于微信好友信息的数据分析，可以参考这篇文章：基于Python实现的微信好友数据分析。在这样的想法促使下，便有了今天这篇文章，因为工作关系一直没有时间及时整理出来，希望这篇文章可以带给大家一点启示，尤其是在短文本分类方面，这样我就会非常开心啦！:slightly_smiling_face: 故事背景&emsp;&emsp;关于故事背景，我在 基于新浪微博的男女择偶观数据分析(上) 这篇文章中说得非常清楚啦。起因就是我想知道，男性和女性在选择伴侣的时候，到底更为关注哪些因素？在对微信好友信息进行数据分析的时候，我们可以非常直接地确定，譬如性别、签名、头像、位置这四个不同的维度，这是因为我们处理的是结构化的数据。什么是结构化的数据呢？一个非常直观的认识是，这些数据可以按照二维表的方式组织起来。可对于微博这样一个无结构的文本数据类型，我们除了对词频、词性等因素做常规统计分析以外，好像完全找不到一个合理有效的方案，因为我们很容易就明白一件事情，即：在短短的140个字符中，人类语言的多样性被放大到淋漓尽致 。为了将种种离散的信息收敛在一个统一的结构里，我们必须为这些文本构建一种模型，并努力使这种模型可以量化和计算。我们通过词云对微博进行可视化分析，更多是针对词频的一种分析方法，这种方法虽然可以帮助我们找出关键字，可是因为最初写作这篇文章时，对数据分析领域相关知识知之甚少，而且在分析的过程中没有考虑停用词，所以我认为在文本分类或者是主题提取层面上，我们都需要一种更好的方法。 常见的技术方法&emsp;&emsp;这篇文章涉及的领域称为文本分类或者主题提取，而针对微博、短信、评论等这类短文本的分类，则被称为短文本分类。为什么要进行文本分类呢？第一，提取出潜在主题以后可以帮助我们做进一步的分析。譬如博主这里想要从相亲类微博中分析男性和女性的择偶观，首先要解决的就是主题建模问题，因为在择偶过程中要考虑的因素会非常多，我们到底要选取哪些因素来分析呢？这些因素在特定领域中被称为特征，所以文本分类的过程伴随着特征提取。第二，短文本数据通常只有一个主题，看起来这是在简化我们的分析过程，实则传统的基于文档的主题模型算法在这里难以适用。因为这类主题模型算法都假定一篇文档中含有多个主题，而我们分析的是群体现象，这种个体上的差异必须设法将其统一于一体，比如美元和$属于同一个主题，我们需要一种策略来对其进行整合。 &emsp;&emsp;传统主题提取模型通常由文本预处理、文本向量化、主题挖掘和主题表示等多个流程组成，每个流程都会有多种处理方法，不同的组合方法会产生不同的建模结果。目前，人们在传统主题提取模型的基础上，发展起了以CNN和RNN为代表的深度学习方法，在这里我们依然关注传统主题提取模型，因为这个领域对博主而言是个陌生的领域，这里我们更多的是关注传统主题提取模型。按照传统主题提取模型，文本分类问题被拆分为特征工程和分类器两个部分，其中，特征工程的作用是将文本转化为计算机可以理解的格式，并提供强特征表达能力，即特征信息可以用以分类，而分类器基本上是统计学相关的内容，其作用是根据特征对数据进行分类。下面来简单介绍下常见的技术方法。 特征工程&emsp;&emsp;特征工程覆盖了文本预处理、特征提取和文本表示三个流程。文本预处理通常指分词和去除停用词这两个过程，可以说分词是自然语言处理的基本前提。特征提取实际上囊括两个部分，即特征项的选择和特征项权重的计算。选择特征项的基本思路是：根据某个评价指标对原始数据进行排序，然后从中选择分数最高的评价指标，同时过滤掉其余的评价指标。通常可以选择的评价指标有文档频率、互信息、信息增益等，而特征权重的计算主要是经典的TF-IDF算法及其扩展算法。文本表示是指将文本预处理后转化为计算机可以理解的格式，是决定分类效果最重要的部分。传统做法是使用词袋模型(BOW)或者向量空间模型(VSM)，比如Word2Vec就是一个将词语转化为向量的相关项目。因为向量模型完全忽视文本的上下文，所以为了弥补这种技术上的不足，业界同时使用基于语义的文本表示方法，比如常见的LDA语义模型。 分类器&emsp;&emsp;分类器主要是统计学里的分类方法，基本上大部分的机器学习方法都在文本分类领域有所应用，比如最常见的朴素贝叶斯算法(Naive Bayes)、KNN、支持向量机(SVM)、最大熵(MaxEnt)、决策树和神经网络等等。简单来说，假设我们所有的数据样本可以划分为训练集和测试集。首先，分类器可以在训练集上执行分类算法以生成分类模型；其次，分类器可以通过分类模型对测试集进行预测以生成预测结果；最后，分类器可以计算出相关的评价指标以评估分类的效果。这里最常用的两个评价指标是准确率和召回率，前者关注的是数据的准确性，后者关注的是数据的全面性。 TF-IDF与朴素贝叶斯&emsp;&emsp;TF-IDF(term frequency–inverse document frequency)是一种被用于信息检索与数据挖掘的统计学方法，常常被用来评估某个字词对于一个文件集或者是一个语料库中的一份文档的重要程度。在特征工程这里我们提到，特征工程中主要通过特征权重来对数据进行排序和分类，因此TF-IDF本质上是一种加权技术。TF-IDF的主要思想是：字词的重要性与它在文件中出现的次数成正比上升，与此同时与它在语料库中出现的频率成反比下降。这句话是什么意思呢？如果某个词或者短语在一篇文章中出现的频率(即TF)较高，并且在其它文章中出现的频率(即IDF)较低，那么就可以人为这个词或者短语可以作为一个特征，具备较好的类别区分能力，因此适合用来作为分类的标准。TF-IDF实际上是TF * IDF，即TF(term frequency，词频)与IDF(inverse document frequency，逆文档频率)的乘积，具体我们通过下面的公式来理解： term frequency，词频 &emsp;&emsp;显然，这里的TF表示某一词条在文档中出现的频率。再看IDF: inverse document frequency，逆文档频率 &emsp;&emsp;这里的D表示语料库中文档的数目，而分母表示的是含有指定词的文档的数目，这里两者求商后取对数即可得到IDF。需要注意的是，当该词语不在语料库中时，理论上分母会变成0，这将导致计算无法继续下去，因此为了修正这一错误，我们在分母上加1，这样就可以得到IDF更为一般的计算公式。按照这样的思路，我们将两段文本分完词以后，分别计算每一个词的tf-idf并按照tf-idf对其进行排序，然后选取前N个元素作为其关键字，这样我们就获得了两个N维向量，按照向量理论的相关知识，两个向量间的夹角越小，其相关性越显著，这就是文本相似度判断的常规做法，在这个过程中，我们覆盖到了文本预处理、特征提取和文本表示三个过程，相信大家会对这个过程有更好的理解。 &emsp;&emsp;好了，那么什么是特征呢？这里计算出来的tf-idf实际上就是一组特征，这个特征是上下文无关、完全基于频率分析的结果，现在这些结果都是计算机可以处理的数值类型，所以特征工程要做的事情，就是从这些数值中分析出某一种规律出来。譬如，我们通过分析大量的气象资料，认为明天有80%的概率会下雨，那么此时下雨的概率0.8就可以作为一个特征值，在排除干扰因素的影响以后，我们可以做一个简单的分类，如果下雨的概率超过0.8即认为明天会下雨，反之则不会下雨。这是一个接近理想的二值化模型，在数学中我们有一种概率分布模型称为0-1分布，即一件事情只有两个可能，如果该事件会发生的概率为p，则该事件不会发生的概率为1-p。如果所有的问题都可以简化到这种程度，我相信我们会觉得这个世界枯燥无比，因为一切非黑即白、非此即彼，这会是我们所希望的世界的样子吗？&emsp;&emsp;为什么在这里我要提到概率呢？因为这和我们下面要提到的朴素贝叶斯有关。事实上，朴素贝叶斯的理论基础，正是我们所熟悉的条件概率。根据概率的相关知识，我们有以下公式，即全概率公式：P(A|B) = P(AB)/P(B)。我们对A和B进行交换，同理可得：P(B|A) = P(A/B)/P(A)。由此我们即得到了贝叶斯公式： 贝叶斯公式 &emsp;&emsp;所以，朴素贝叶斯本质上是一种基于概率理论的分类算法。我们知道条件概率成立的前提是各个事件都是独立的，因此在朴素贝叶斯算法中假设所有特征间都是独立的，可当我们逐渐地了解这个世界，就会明白这个世界并不是非黑即白、非此即彼的，甚至一件事情会受到来自方方面面的因素影响，就像我们从前学习物理的时候喜欢用控制变量法一样，总有一天你会明白当时的想法太天真。朴素贝叶斯算法中的“朴素”，通常被翻译为Naive，而这个词就是表示天真的意思，这正是朴素贝叶斯的名称由来，它简单粗暴地认为各个特征间是相互独立的，有人认为这种假设是相当不严谨的，所以相当排斥这种分类的理论，所幸朴素贝叶斯在实际应用中分类效果良好，尤其是在解决垃圾邮件过滤这类问题上，所以到今天为止，朴素贝叶斯依然是一个相当经典的分类算法，它是一个根据给定特性/属性，基于条件概率为样本赋予某个类别标签的模型。 数据分析&emsp;&emsp;好了，讲述这些理论知识实在是一件苦差事，因为让读者了解一套新的知识，远远比让自己了解一套新的知识容易，所以在描述这些理论的时候，我努力地避免给大家留下晦涩深奥地印象，可这样难免会让读者觉得我不太专业。可是，谁让我们生活在一个被无数前辈开垦过地世界里呢？作为一个资深的“调包侠”，这些理论我们能理解多少算多少，最终我们需要的只是一个库而已，所以在正式进入下面的内容时，我们首先来梳理侠整体数据分析的思路，这样我们就能对整个过程有一个相对感性的认识了。关于如何从新浪微博抓取数据，这个我们在上篇有详细的介绍，这里不再重复阐述，所有数据我们都存储在数据库里，下面的图示不再展示关于数据库的细节： 特征分析流程图 &emsp;&emsp;简单来讲，这是一个有监督的、使用二元分类的特征提取过程。这里的语料库是由人工进行编制的文本资料，语料库的好坏将直接影响到分类的效果。比如说，我们希望提取的特征是陕西省的地理信息，那么我们就需要准备一个，由陕西省所辖的所有地级市组成的文本文件，这里为了方便后续处理，我们建议每行存放一个短文本信息。 &emsp;&emsp;接下来，我们会从数据库中读取所有的数据，然后进行预处理操作，这里的预处理是指分词和去除停用词，停用词表是从网络上下载的，然后根据我们自己的需要再在基础上进行添加，我们会选取前20个词语作为关键词，这里使用了结巴分词的相关接口，其算法原理正是tf-idf。我们会使用这20个关键词，和语料库中每一个主题下的内容进行比较，这里的相似度由SnowNLP提供支持，其计算结果是一个20维的向量，我们对向量进行归一化后，如果其向量中所有维度的值的最大值&gt;=0.95，则认为该文本和这一主题相关，因此该主题的权重会增加1，否则会继续计算下一个文本的相似度。 &emsp;&emsp;我们汇总所有主题的权重，即可统计出各个主题出现的频率。比如我们这里关注A、B、C三个主题，而经过计算这三个主题各自出现的频率为0.1、0.8和0.1，所以我们这里可以理解为：这里有80%的把握认为文本和B主题有关，由此我们选取出了分类的特征，这里我们使用一个元组来表示特征，其表示为([0.1,0.8,0.1],”B”)。依次类推，我们就获得了全部的特征信息。接下来，我们使用nltk中提供的朴素贝叶斯分类器对内容进行分类，训练集和测试集合各占50%，最终通过准确度来评估整个分类的效果。 特征分析&emsp;&emsp;特征分析的难点主要在特征的提取，在这里我们通过不同主题的频率来选取特征： 123456789101112131415161718192021222324252627def buildFeatures(sentence,document): tokens = jieba.analyse.extract_tags(sentence) tokens = list(filter(lambda x:x.strip() not in stopwords, tokens)) features = &#123;&#125; for (subject,contents) in document.items(): for content in contents: if(similarText(tokens,content)): if(subject in features): features[subject]+=1 else: features[subject]=1 total = sum(features.values()) for subject in features.keys(): features[subject] = features[subject] / total # 特征归一化 for subject in subjects: if(subject not in features.keys()): features[subject] = 0 # 预测结果 max_value = max(features.values()) suggest_subject = ' ' for (key,value) in features.items(): if(value == max_value): suggest_subject = key return features, suggest_subject 其中，stopwords我们从一个指定文件中读取： 1stopwords = open('stopwords.txt','rt',encoding='utf-8').readlines() 这里有一个计算句子和主题相似度的方法similarText()，其定义如下： 123456789# 文本相似度def similarText(tokens,content): snow = SnowNLP(tokens) similar = snow.sim(content) norm = math.sqrt(sum(map(lambda x:x*x,similar))) if(norm == 0): return False similar = map(lambda x:x/norm,similar) return max(similar)&gt;=0.95 我们通过下面的代码来构建特征，以及使用朴素贝叶斯分类器进行分类，核心代码如下： 12345678910111213141516171819def analyseFeatures(): rows = loadData() document = loadDocument(subjects) features = [buildFeatures(row[0],document) for row in rows] length = len(features) print('数据集: ' + str(length)) cut_length = int(length * 0.5) print('训练集: ' + str(cut_length)) train_set = features[0:cut_length] print('测试集: ' + str(length - cut_length)) test_set = features[cut_length:] classifier = nltk.NaiveBayesClassifier.train(train_set) train_accuracy = nltk.classify.accuracy(classifier,train_set) print('准确度: ' + str(train_accuracy)) counts = Counter(map(lambda x: x[1],test_set)) for key, count in counts.items(): freq = count/len(test_set) print(\"主题&lt;&#123;0&#125;&gt;: &#123;1&#125;\".format(key,freq)) &emsp;&emsp;下面是特征提取相关的结果，因为最近对语料库进行了调整，所以准确度只有92%，用一位前辈的话说，数据分析就像炼丹，在结果没有出来以前，没有人知道答案会是什么。这里使用的是nltk内置的朴素贝叶斯分类器，而nltk是一个自然语言处理相关的库，感兴趣的朋友可以自行了解，这里推荐一本书：《NLTK基础教程(用NLTK和Python库构建机器学习应用)》。下图中展示了各个主题在整个微博文本中所占的比重： 特征提取及其分类效果 年龄分布&emsp;&emsp;对于男女性的年龄分布，我们通过正则来提取微博中年龄相关的数值，然后统计不同年龄出现的频数，并将其绘制为柱形统计图，相关代码实现如下： 1234567891011121314151617181920def analyseAge(): ages = [] rows = loadData() pattern = re.compile(r'\\d&#123;2&#125;\\年|\\d&#123;2&#125;\\岁') for row in rows: text = row[0].decode('utf-8') matches = pattern.findall(text) if(len(matches)&gt;0): match = matches[0] if(u'年' in match): now = datetime.datetime.now().year birth = int(''.join(re.findall(r'\\d',match))) ages.append(now - 1900 - birth) else: ages.append(int(''.join(re.findall(r'\\d',match)))) ages = list(filter(lambda x: x&gt;10 and x&lt;40, ages)) freqs = Counter(ages).items() freqs = sorted(freqs,key=lambda x:x[0],reverse=False) freqs = dict(freqs) drawing.bar('男女性择偶观数据分析:年龄分布',freqs,'年龄','人数',None) &emsp;&emsp;通过图表，我们可以发现：择偶年龄重点集中在24~28岁之间，并且整个年龄区间符合正态分布。每年过年的时候，我们都会听到年轻人被催婚的声音，甚至作为一个单身的人，每一个节日都像是我们的忌日，因为无论在哪里，你都可以被秀恩爱或者被撒狗粮。“哪有人会喜欢孤独呢？不过是不喜欢失望”，当这句话出现在我的Kindle屏幕上，出现在村上春树的《挪威的森林》里，我突然有种扎心的感觉。有一天，当我不在视爱情为必需品时，我突然意识到生命里有太多比感情重要的事情。我不希望我们因为一句年龄到了就去结婚，如果人生的一切都有期限都要按部就班，那么为什么我们不能平静地面对衰老和死亡呢？人天生起点就是不一样的，所以你不必努力去迎合别人定制的标准，就像学生时代大家面对的是同一张考卷，有的人交卷交得早，有的人交卷交得晚，有的人考试成绩好，有的人考试成绩差，可这不过是一场考试而已，不是吗？如果我的时间不能浪费在我喜欢的人身上，我宁愿永远将时间浪费在自己的身上，除了生与死以外，结婚和繁衍并不是必答题，我可以不结婚啊，一如我可以交白卷啊！ 男女性择偶观数据分析:年龄分布 性别组成&emsp;&emsp;性别组成，我们主要从微博中的关键字入手，因为这些微博明确了择偶的是男嘉宾还是女嘉宾，我们通过这些特征就可以分析出男女性别比例。相关代码实现如下： 12345678910def analyseSex(): rows = loadData() sexs = &#123;'male':0, \"female\":0&#125; for row in rows: text = row[0].decode('utf-8') if u'男嘉宾[向右]' in text: sexs['male']+=1 elif u'女嘉宾[向右]' in text: sexs['female']+=1 drawing.pie('男女性择偶观数据分析:男女性别比例',sexs,None) &emsp;&emsp;通过下面的图表，我们可以非常直观地看到，男性数量是超过女性数量的，两者比例接近1.38:1。这和目前中国的实际基本相符，考虑到人们有更多的相亲渠道可以选择，我认为实际的比例应该会更大，媒体称适婚男性比女性多出3000万，性别比例的失衡难免会让男生找不到对象。可找不着对象有什么关系呢？人生短短一世，活着时候能见到最多不过四世同堂，血缘关系并不能让后辈替你完成未竟之事，当一个离开了这个世界，它与世界的关联就变得微乎其微，时间会让记忆逐渐模糊直至遗忘，你无法将这点微弱的安全感寄托在某一个人身上，人生而有涯，而知无涯，能在这个世界里流传下去的只有思想，我不想和任何人去攀比，因为生而为人，我很抱歉。 男女性择偶观数据分析:男女性别比例 身高分布&emsp;&emsp;身高分布，同样采用关键字匹配的方式实现，不同的是，择偶者通常会在微博中给出自己的身高以及对伴侣期望的身高，由此我们对微博中的身高进行了提取，分别获得了男性、女性身高分布及其身高差分布。这是我最开始研究这个问题的初衷，现在的结果印证了当时的想法，我内心其实是特别开心的，这正是为什么要花时间和精力写这篇文章的原因所在。这里，相关的代码实现如下： 12345678910111213141516171819202122232425262728293031# 身高分布def analyseHeight(): heights = [] rows = loadData() pattern = re.compile(r'1\\d&#123;2&#125;|\\d&#123;1&#125;\\.\\d&#123;1,2&#125;|\\d&#123;1&#125;\\米\\d&#123;2&#125;') for row in rows: text = row[0].decode('utf-8') matches = pattern.findall(text) if(len(matches)&gt;1): matches = map(lambda x:int(''.join(re.findall(r'\\d',x))),matches) matches = list(filter(lambda x: x&lt;190 and x&gt;150, matches)) if(len(matches)&gt;1): height = &#123;&#125; height['male'] = max(matches) height['female'] = min(matches) heights.append(height) # 男性身高分布 male_heights = list(map(lambda x:x['male'],heights)) male_heights = Counter(male_heights).items() male_heights = dict(sorted(male_heights,key=lambda x:x[0],reverse = False)) drawing.bar('男女性择偶观数据分析:男性身高分布',male_heights,'身高','人数',None) # 女性身高分布 female_heights = list(map(lambda x:x['female'],heights)) female_heights = Counter(female_heights).items() female_heights = dict(sorted(female_heights,key=lambda x:x[0],reverse = False)) drawing.bar('男女性择偶观数据分析:女性身高分布',female_heights,'身高','人数',None) # 男女身高差分布 substract_heights = list(map(lambda x:x['male']-x['female'],heights)) substract_heights = Counter(substract_heights).items() substract_heights = dict(sorted(substract_heights,key=lambda x:x[0],reverse = False)) drawing.bar('男女性择偶观数据分析:男女身高差分布',substract_heights,'身高差','人数',None) &emsp;&emsp;虽然女生都希望男生180以上，据说这样可以举高高、有安全感，可是作为一个成年人，我们必须勇敢地打破这种不切实际的幻想，因为身高和外貌都是父母给我们的，那些基因里决定的东西，往往是我们无法通过后天努力来弥补的。如果可以的话，我希望自己再长高5厘米，可如果我再无法长高，我希望你能接受现在的我，接受一个人身高上的缺陷，和接受一个人人性中的缺点，在我看来是一模一样的。可人类最大的问题， 就在于愿意相信自己眼睛看到的，耳朵听到的，并且这是两个人建立联系的前提，人家愿意了解你有趣的灵魂，前提是你有一副好看的皮囊，人类啊，说到底是一种比较高级的动物而已，就像动物用皮毛、肤色去吸引同类一样，如你所见，男生平均身高其实只有175而已！ 男女性择偶观数据分析:男性身高分布 &emsp;&emsp;女性的身高通常不会被作为筛选条件，正如社会群体通常都是对男性提出各种要求一样，两个同等条件下的男、女性，人们理所当然地对男性提出了更高的要求，可其实大家都是母亲十月怀胎而来，同样地都在这个世界里生活了20多年。所以这个世界上有太多地问题，其实都是人们自己造成的。比如女性一定要找一个穿高跟鞋后还要比她高的男性，而男性一定要找一个身高上和他相差不大的女性，男性的身高不足175，同女性的身高不足165一样，都是人们眼中比较尴尬的身高，可你看这图表中女性的平均身高是160，那么，就让大家一起尴尬吧，不知道当年小平爷爷和拿破仑将军的夫人心里是怎么想的啦！ 男女性择偶观数据分析:女性身高分布 &emsp;&emsp;最初我研究这个问题的时候，我发现微博上有好多身高不足160的女性，要求伴侣期望身高都是175以上，作为一个身高只有170的男生，我感到绝望和悲伤啊，后来和一位朋友聊天，他说他觉得我连170都没有，我想说人类为什么要这般奇怪，譬如体重一定要说得比实际轻、身高一定要说得比实际高、年龄一定要说得比实际小……难道这样不感觉累吗？那么到底有多少人希望两个人的身高差超过20厘米呢？网络上流传的所谓最萌身高差到底萌不萌呢？你看孟德尔通过豌豆杂交试验来研究遗传问题，两个身高差超过20厘米的人的后代，平均下来难道不是只有170吗？图表表明，男女性之间最佳的身高差是15厘米。 男女性择偶观数据分析:男女身高差分布 地理分布&emsp;&emsp;因为在这些微博中会出现相亲者的地理信息，所以我们整理了陕西省各县市的名称作为关键字，试图分析出这些相亲者的地理分布，这里我们简单绘制了一个柱形图，相关代码实现如下： 1234567891011121314# 地区分析def anslyseLocation(): freqs = &#123; &#125; citys = [u'西安',u'铜川',u'宝鸡',u'咸阳',u'渭南',u'延安',u'汉中',u'榆林',u'安康',u'商洛'] rows = loadData() for row in rows: text = row[0].decode('utf-8') for city in citys: if(city in text): if(city in freqs.keys()): freqs[city]+=1 else: freqs[city]=1 drawing.bar('地区分布图',freqs,'地区','人数',None) &emsp;&emsp;这里的结果令人出戏，因为西安作为陕西省的省会城市，在所有地区中一骑绝尘。考虑到在这些微博中”西安”存在干扰，所以这个结果并不是非常严谨，不能作为一个有效的分析指标，而且这里存在同义词，比如”本地”和”土著”其实都表示西安，而我们统计的时候并没有考虑这种情况，所以这里绘制的地区分布图表，大家看看就好啦！ 男女性择偶观数据分析:地区分布图 星座分布&emsp;&emsp;这里为什么要分析星座呢？理论上来讲，我是不大相信这些东西的，可当你经历的事情多了以后，你就会下意识地认为这些东西说得很对，我想古代的占卜算卦基本上是同样的东西，其实世间好多事情之间应该是没有直接的联系的，无非是在千百年的历史积淀中，逐渐地形成了一套建立在经验上的理论体系，这就像我们今天所追捧的机器学习，我们有千百年的历史长河去收集数据，每一个相信这些理论的人都是一个数据样本，这些理论体系通过不断地训练和模拟，逐渐可以正确地预测某些事情，让我们相信万事万物间存在某种联系。可即便如此，人类依旧免不了对各种事物存在偏见，比如星座中经常无辜躺枪的处女座、双子座和天蝎座，人类最擅长的认知方式，就是用一个群体现象来预测个人现象，可讽刺的是朴素贝叶斯就是这样的思想，所以这里我们简单地统计了下各种星座的频数分布： 12345678910111213141516171819# 星座分析def analyseStar(): stars = ['白羊','金牛','双子','巨蟹','狮子','处女','天秤','天蝎','射手','摩羯','水瓶','双鱼'] freqs = &#123;&#125; rows = loadData() for row in rows: text = row[0].decode('utf-8') for star in stars: if(star in text): if(star in freqs.keys()): freqs[star]+=1 else: freqs[star]=1 for star in stars: if(star not in freqs.keys()): freqs[star] = 0 freqs = Counter(freqs).items() freqs = dict(freqs) drawing.pie('男女性择偶观数据分析:星座分布',freqs,None) &emsp;&emsp;这个结果相对客观些，因为12个星座基本上平分秋色啦，并不存在某种星座独领风骚的情况，简直是人与自然的大和谐了呢？ 男女性择偶观数据分析:星座分布 本文小结&emsp;&emsp;这篇文章写到这里，我其实已经非常疲惫啦，因为这篇文章的上篇与下篇中间相隔了差不多三个月，而且我写作上篇的时候，并没有打算写这一篇文章出来，再者两篇文章写作时的心境完全不同，所以现在写完这篇文章，终于有种如释重负的感觉，一来没有因拖延症而放弃这篇文章，二来为了了解相关的理论以及训练数据花费大量精力，我必须对自己的过去有一个总结，这是我今年年初给自己制定的目标，不管有没有喜欢我，我总要去做这些事情，不是因为我想要证明什么或者做给谁看，而是我认为这件事情比某些事情有趣而且重要。这篇文章首先承接上文，交待故事的背景，即为什么要做这样的数据分析；然后我们简单介绍了文本分类的常用的技术方法，主要以特征工程和分类器为主；接下来我们介绍了两个经典的理论：tf-idf和朴素贝叶斯，这是本文文本分类的理论基础；在数据分析这部分，我们对特征、年龄、性别、身高、地区和星座等进行了分析，并借助Python中的图表模块完成了数据的可视化工作。好啦，以上就是这篇文章的全部内容啦，欢迎大家积极留言和评论，晚安！","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"微博","slug":"微博","permalink":"https://qinyuanpei.github.io/tags/%E5%BE%AE%E5%8D%9A/"},{"name":"朴素贝叶斯","slug":"朴素贝叶斯","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/"},{"name":"文本分类","slug":"文本分类","permalink":"https://qinyuanpei.github.io/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/"}]},{"title":"行走在消逝中","date":"2018-03-15T21:29:47.000Z","path":"posts/2809571715/","text":"&emsp;&emsp;从昨天到今天，关于霍金逝世的消息，一直在朋友圈里刷屏。昨天同事告诉我这个消息的时候，我心底先是一片恍惚，而后习惯性地打开微信，发现朋友圈和公众号里都在讨论这件事情。而等到我吃饭的时候，居然听到临桌的一名男生，在向同伴讲述霍金辐射的理论，堪称我在这一天所见过的一股清流。不知道从什么时候开始，一个人物的突然离去，总是会让人们在短时间内亢奋起来，仿佛一场集体缅怀的狂欢。回顾最近这些年来已故的名人，例如杨绛先生、杨洁导演、词作家闫肃、作家黄易等等，每每提及不禁令人一阵唏嘘，正所谓“逝者已矣，生者如斯”。可我想说的是，不要总是等到离开的时候，才会想起一个人的存在。 &emsp;&emsp;印象中第一次有这种感觉是在2011年，那时我刚刚考上大学，我只记得那时站在太阳底下的我，突然大声地向周围人宣布乔布斯逝世的消息。我清晰地记着父母惊愕的表情，因为在他们的人生字典里，全然不知道乔布斯是谁，可在19岁的我看来，那就像是某种重大的事情发生，至少从今天的角度来看，在我出生的1992年里，苏联正式解体，我们的生命总是不可避免地和某种历史进程关联起来。因为从中学时候就开始住校，印象中每次回家都既陌生而熟悉，偶尔会听到妈妈讲，家族里某一位长辈突然过世。这种事情听得多了，居然不会再觉得惊讶。可是想起这些人里，有人曾经出过数学题考问过我，有人你曾经帮过他们做过什么事情……刹那间觉察到时光的残忍——所谓的物是人非，大概就是你还在此处，而别人早已暗自走远。 &emsp;&emsp;坦白地讲，我对霍金的认知永远都停留在《时间简史》这本书上，记得16年买了Kindle以后，的确买了这本书来读，大概读了十来页便读不下去。霍金和海伦·凯勒一样，是被我划定到身残志坚这类写作素材的范畴里。当时，语文老师让我们关注每年的感动中国人物评选，其初衷便是为了丰富我们的写作素材。回想那些年里，遭受无数次宫刑而忍辱负重的司马迁、实验了3000多种材料终于制造出灯泡的爱迪生、披发行吟泪洒汨罗而心系家国的屈原……这些在学生时代频频被消费的历史人物，在今天看来是否有些相似呢？据说知乎上一天内产生了700多个霍金相关的问题，一个曾经活在我们作文里的人物，在他离开这个世界以后，再次成为我们热议的话题，好像他从来没有在这个世界上存在过一样，这是一件可怕的事情。 &emsp;&emsp;我认为尊重一名物理学家的基本要求是相信科学。伴随着霍金变成人们关注的热点，网络上开始流传伽利略、爱因斯坦和霍金三个人之间巧合的时间线问题，仿佛我们面对的不是一名为宇宙物理学做出巨大贡献的科学家，而是一个被神化的“活佛”转世。有人说，人类都是一群戏精。集体缅怀一个伟人吧，立马有人跳出来说，伟人的著作都没读过一本，蹭什么热度；大家都不关注这件事情吧，立马有人跳出说，“将军坟前无人问，戏子家事天下知”，根本没有人关心科技工作者。可你看关注的时候，大家都在关注什么，譬如定要给物理学领域内的专家学者们排出个优劣来，定要将一个人的私事深挖出来品判人品。杨绛先生说，“我们曾如此渴望命运的波澜，到最后才发现：人生最曼妙的风景，竟是内心的淡定与从容。我们曾如此期盼外界的认可，到最后才知道：世界是自己的，与他人毫无关系。“，这是最浅显不过的道理，可惜想要做到实在太难。 &emsp;&emsp;我一直相信“人生而孤独”，除了亲情血缘以外，人与人间的联系，有时脆弱得像一只挂在风筝上的线，随时都会有断开的危险。有些人不知不觉就渐渐走远了，我们一路踟蹰而雁行，在相遇中失散，在失散中相遇，可当两个人再次相遇时，已然不是当初的彼此。我是一个不太会维护亲密关系的人，不知道是我自己走得太快，还是别人走得太快，无数的人在我这里出现然后离开，仿佛是在追逐风中的花瓣，等到风停了的时候，花瓣已不见，花香已飘远。有时候会突然问自己，想把别人留在我的生命里，是不是一件自私的事情。游戏制作人陈星汉有一款游戏叫做《风之旅人》，在广阔无垠的沙漠场景中，最多只有两个玩家出现，出现的时间和地点随机，对方可能来自任何一个国家，你对他/她的的身份信息一无所知，两个人唯一的互动方式是“共鸣”。两个靠在一起的人，可以通过“共鸣”来为对方的围巾补充能量，最重要的一点是，一旦两个人走失，就永远不会再相遇，这是这款游戏超现实意义的一个体现。 &emsp;&emsp;我不知道，两个人从无话不说到无话可说需要多久；我只知道，真正想要离开的人，从来都是不动声色的。自那以后，我不知道对方会在哪里，会变成什么样子，每天都会做哪些事情。我承认，别人的世界和你毫无关联，可你终究不愿意让自己成为孤岛，所以你会感到痛苦和挣扎，会想要找一个能永远陪伴你的人。可生老病死是人生里无可避免的结果，我们终其一生所寻找的灵魂伴侣，是否真的可以陪伴彼此到生命尽头。如果一切注定都要失去，我宁愿一直这样下去，我从来没有把生育看做是我生命的一种延续，因为每一个人的生命都注定独一无二，你不能想当然地认为，血缘关系会替你继承什么东西。从你死亡的那一刻起，一切都变成新的东西。 &emsp;&emsp;人的一生会死亡三次，第一次是医生宣布你的死亡，这是肉体上的死亡；第二次是人们来参加你的葬礼，这是社会学意义上的死亡；第三次是这个世界没有人再记得你，这是哲学意义上的死亡。或许这个世界再无霍金，可他的思想和著作一直就在那里，时间会记录着人类的过去和未来，而他是搭乘时光列车满世界旅行的自由灵魂。一个人可以不结婚，可以不生孩子，因为这是你生而为人的选择，世俗的力量是如此的强大，以至于我们都以为，人生就是一个跳一跳游戏，每一个年龄就应该跳到相应的位置。我的人生目标里没有结婚生子，如果我注定留不下任何人，如果我注定永远要被这个世界所遗忘，我宁愿在我还活着的时候，努力去写字去发出声音，即使在这空荡荡的宇宙里听不到回声，可声音不是一直都在传播着吗？ &emsp;&emsp;有时候，想想人生难免会觉得失望。我们明明知道世界是自己，和他人毫无关联，可我们还在努力地和这个世界发生着关联；我们明明不愿意让别人了解自己的生活，可我们对这个世界的表达欲从来没有衰减过。从镌刻在龟壳上甲骨文到以丝帛作为书写材料，再到造纸术的产生，再到今天的各种芯片，甚至内容的形式从文本演变为图片再演变为视频……可我们怎么就变成了一堆“亡灵”，从前QQ好友列表一片隐身，如今朋友圈剩下一条横线。如果一定要别人不再想起你，等你真正离开这个世界的时候，才会突然间被想起，我会很心疼一条鱼的记忆，因为一条鱼的记忆只有8秒。 &emsp;&emsp;如果下一刻失去记忆的，是你和我这般普通人，我们没有机会像霍金一样，被大家集体缅怀，你希望被那一个人记着，记多长时间呢？就像我总和朋友们说，回家以后找时间相聚，可在家时会觉得家人最为重要，在某一瞬间发现自己并没有那么多时间；就像我总计划着找机会去看望语文老师，可和朋友约不到一起时便无从谈起……我突然间想到，高中的第一堂语文课上，老师安排大家写一篇作文，题目好像叫做《回首向来》亦或者是《行走在消逝中》，那时我的作文没有写完，反而被老师叫起来当众朗读，我说“回首向来萧瑟处，也无风雨也无晴”，记忆明明是有的，可我突然叫不出来有些人的名字，甚至在某一个清晨惊醒，梦到过往的某一天考试迟到，或者是快要交卷发现作文没有写……我稍稍一定神，考试那好像是很多年前的事情了吧…… &emsp;&emsp;我其实很想留下来陪你或者陪Ta呀，可时光列车从来不会留给我思考的时间，有时候我走得快，有时候你走得快，像无法逃离黑洞的光一样，拼命地往前走往前走。在广阔无垠的宇宙中，我们生活在彼此平行的世界里，有时看得见彼此，有时看不见彼此，靠着彼此间微弱的万有引力，不至于失散得太远，在成为一颗孤独的白矮星之前，请记住我。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"时间","slug":"时间","permalink":"https://qinyuanpei.github.io/tags/%E6%97%B6%E9%97%B4/"},{"name":"霍金","slug":"霍金","permalink":"https://qinyuanpei.github.io/tags/%E9%9C%8D%E9%87%91/"},{"name":"请记住我","slug":"请记住我","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%B7%E8%AE%B0%E4%BD%8F%E6%88%91/"}]},{"title":"我是猫，一只特立独行的猫","date":"2018-03-06T08:57:48.000Z","path":"posts/352037321/","text":"&emsp;&emsp;终于在除夕夜到来前，在Kindle上读完了2017年的最后一本书，来自夏目漱石先生的《我是猫》。起初买这本书的动机说起来非常滑稽，一来以为这会是一本诙谐幽默的书，二来对夏目这个名字莫名地充满好感。我读的是曹曼翻译的中文译本，读时觉得这位作者的文字清新素雅，即使全书行文节奏堪称缓慢到极点，想来应该是我们这个时代的人物。及至翻阅作者生平，始知这位被誉为“国民大作家”的日本作家，早在100年前就在日本文学史上享有盛名。这种感觉如何去形容呢？大概就是杨过从剑冢石刻的寥寥数语中，遥想独孤求败”生平求一敌手而不可得”的寂寥难堪。这位老先生的文字可以说非常”摩登“了，因为在100年后的今天再次读来，竟完全读不出违和感来，所谓”嬉笑怒骂皆成文章“，讽刺与幽默杂然相陈，这是我喜欢这本书的理由。 &emsp;&emsp;对于《我是猫》这本书，按照作者的话说，它是一部没有什么情节的小说，因为它完全是以一只猫的视角来行文，这只生活在一个教师家庭里的猫，每天都会接触到形形色色的文人，譬如：不食人间烟火，空有一番理论而不去实践的独仙；整天磨玻璃球，做事一丝不苟甚至古板木呐的寒月；表面上每天都很乐观，实则唯恐天下不乱的米亭；做事三分钟热情，自命清高的苦沙弥……等等。在猫的眼睛这里，这些人整天聚在一起讨论没有意义的事情，对现实世界心怀不满，不思进取就会怨天尤人，甚至金田及其夫人的”拜金主义“，为金钱而陷害苦沙弥的邻居，唯利是图、虚伪圆滑的铃木，这些人在猫的眼睛里都是丑陋而黑暗的。这只猫平静地叙述着它的见闻，仿佛它早已经整个人类和社会看穿看透，或许带着些嘲讽，或许带着些同情。 &emsp;&emsp;每年的2月22日是日本的猫节，这是我在读完这本书以后知道的。而猫在日本的文化形象中是非常神圣的，据说这是因为猫最早由遣唐使带来日本，首先作为宫廷宠物出现，直至江户时代进入”寻常百姓家“。除此之外，日本作为重度渔业国度，对稻米的珍惜使其在捕鼠护粮方面极为重视，猫作为老鼠的天敌自然而然地受到喜爱。相传招财猫起源于东京世田谷的豪德寺，因此猫在日本被人们当作神明供奉。再比如日本动漫中的机器猫、龙猫和Hello Kitty都是猫在日本文化中的经典形象，日本的文学作品比如《草枕子》、《源氏物语》等里面都有关于猫的故事。时至今日，依然有大量德川家族与猫的故事流传。因此，猫在日本人眼中有一种浓厚的贵族气息。陈凯歌导演的《妖猫传》，改编自日本作家梦枕貘的小说《沙门空海》，猫在其中的重要性不言自明。 &emsp;&emsp;这是一本“猫眼看世界”的书，这是一个怎样的世界呢？1871年，日本历史上最为大刀阔斧的一次改革——明治维新，开始在全国范围内推行。改革带来经济飞速发展的同时，带来了各种矛盾日益突出的社会问题。36年的1905年，时年38岁的夏目漱石，以猫的视角，如初入人类社会一般，探讨当时知识分子的心理状态和对社会变迁的感慨，并因此一举成名，获得社会广泛关注，被认为是日本批判现实主义文学的丰碑。每一个时代都有它的无奈，或许我们今天难以想象老先生当时的心境，不过从这些猫的口吻里，从这些辛辣的讽刺和戏谑中，我们总能读出作者当时内心的苦闷。猫眼里那些荒诞不经的行为，恰恰就是你我每天的生活，我们总说人类和猫是好朋友，可那仅仅是我们以为的，在猫的眼睛里，我们就像一群神经病。 &emsp;&emsp;猫是如何看待人类的呢？猫说：世间的奢侈往往是无能的表现。猫一年到头都穿着同一件衣服，而人类好像不把尽可能多的东西往身上照顾就难受，人类给羊添麻烦，受蚕照顾，承蒙棉花的恩泽，你看吧，我们的所作所为连只猫都看不下去。人类羡慕猫的悠闲，故而感慨道：什么时候能像猫一样轻松就好了。可明明是人类自己制造出一堆乱七八糟的事情给自己，到头来还抱怨真痛苦真痛苦，就像自己生起一堆火，到头来嚷着热死了热死了。这一切在猫看来都是庸庸碌碌的。猫甚至断言道：人类不可能永远繁荣昌盛下去。嗯，我愿静候属于猫族时代的到来。从前是“人类一思考，上帝就发笑”，而现在是“人类一思考，猫君就发笑”。猫觉得人类模仿它们的声音时是愚蠢的，尤其是在抚摸它们的时候，因为根本不存在撒娇声，只有被撒娇声，因为我们期待的是，猫向我们撒娇，可难道不是我们在向猫撒娇？ &emsp;&emsp;个体的荒谬，在人类的个性面前根本不值一提，就如同人类的个性得到完全解放以后，永远像一锅众口难调的羹汤。小说中苦沙弥、迷亭、寒月、东风和独仙时常在一起聊天，话题涉及哲学、艺术，爱情、生活等多个方面，这只“毒舌”的猫，就在无意识地引导和放大这些观点，“我认为这个世界上，没有比爱和美更受人尊重的了”，所以这本书里的观点，其实并不是完全的消极的，就像这只猫平静地看着这个世界，它对人类有过嘲讽，有过同情，它甚至没有自己的名字，当它失足淹死在水缸里的时候，对这个世界更多的是种悲天悯人吧！我们这个世界上有五种毒药，佛家所谓的“贪嗔痴慢疑”，作者提到“可没有任何一个人，能够全然抛开自己去研究外界，如果人类能够把自己疏离出来，那么疏离的瞬间，也就没有了自己”，人类常常不愿放过自己，更不愿放过别人，因为所有无解的问题，都可以制造一个意义出来，而我们早已习惯这一切。 &emsp;&emsp;曾经有朋友问我，为什么喜欢猫这种动物，我回答说，因为我就像一只猫，一只特立独行的猫，对所有人都很友善和蔼，却喜欢独来独往。因为维护这种若即若离的关系，对我来说比任何事情都要困难。人类以为猫都是傲娇的动物，其实这是人类的一厢情愿，因为从智力上来说，猫的智力是不及狗的。猫自然对人是有感情的，不过在人类驯养动物的历程中，狗更聪明、更懂得如何向人类索取，我们所认定的感情，在狗的世界里或许并不是。人类难以理解的事物，所谓阳春白雪，所谓曲高和寡，不自然地背负上高冷的名声，对一只猫而已，到底是我们不了解猫，还是不了解我们自己。人总在试图驯化猫这种动物，可猫无非是人类的一种折射而已，它就像那些独立潇洒的人一样，不藉由粘人和撒娇来获取安全感，在这个世上没有谁会离不开谁。你走，我不必送你；你来，不管多大风多大雨，我都去接你。这是我——一只猫的自白。 &emsp;&emsp;有时候，难免会觉得人类自作聪明，喜欢给世间的事物贴上不同的标签，譬如二哈、喵星人、汪星人、猫主子……可你知道猫如何评价人类的吗？作者说，“这些人虽然看起来快活，但是如果叩问他们的心底，却可以听见悲凉的回响”。为什么会听见悲凉的回响呢？大概是人类丰富而有趣的个性，不断地尝试挑战世俗的眼光，结果被世俗打败而变得世俗，这听起来简直就像是，英雄杀死魔王又变成魔王的故事的翻版。“每个人地位都提高，等同于每个人的地位都下降。人类不再做让自己委屈的事情，正是个人力量变强的证明；几乎不再插手别人的事情，反而是群体力量变弱的证明”。一点亏都不愿意吃，一点小便宜就要占，无一不是为了证明个人意志的强化，可人与人间的空间越来越狭窄，日益窘迫，为了扩充自己膨胀到近乎爆炸。人与人之间那点空间，是一切痛苦的根源，你说这还不算作悲凉吗？没有谁可以完全了解一个人，不完全认知是人类关系的反应剂，痛苦、误会、偏见……等等纷至沓来，你以为你模仿猫叫，猫就真的听懂了吗？ &emsp;&emsp;夏目先生在后记里写道，“世事变迁就像猫的眼珠一样变幻莫测，短短几个月世间，就可以去那极乐世界，或者可以把薪水花光光。年底过去了，正月过去了，花朵凋谢，新叶又生。以后世界将如何变化，我不了解，只不过水缸中猫的瞳孔，应该可以凝成永恒”。我想，世界会一如既往地这样无奈下去，时间会一如既往地这样消逝下去，而你和我会一如既往地平庸且烦恼下去。假如有这样一只猫，通过瞳孔记下了我的生平，不知道它会如何评价我呢？就像在某一个下雨天，突然想到某一个人，单单是因为怕这世界里，从此再没了对方的音讯。可单单是想到又有什么意义呢？《笑傲江湖》里令狐冲率领江湖群雄，前往少林寺解救被困的圣姑，这个将来会成为他妻子的人，而眼下更是生死未知、前途未明，可在一片寂静中听到雪花簌簌落下时，他想到的却是：小师妹不知这时候不知在干甚么。及至岳林珊为林平之所杀，临死托付令狐冲替她照顾小林子，内心却又不知做何感想了吧……","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"夏目漱石","slug":"夏目漱石","permalink":"https://qinyuanpei.github.io/tags/%E5%A4%8F%E7%9B%AE%E6%BC%B1%E7%9F%B3/"},{"name":"日本文学","slug":"日本文学","permalink":"https://qinyuanpei.github.io/tags/%E6%97%A5%E6%9C%AC%E6%96%87%E5%AD%A6/"},{"name":"我是猫","slug":"我是猫","permalink":"https://qinyuanpei.github.io/tags/%E6%88%91%E6%98%AF%E7%8C%AB/"}]},{"title":"基于Travis CI实现 Hexo 在 Github 和 Coding 的同步部署","date":"2018-02-27T10:45:04.000Z","path":"posts/1113828794/","text":"&emsp;&emsp;各位朋友，大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是 https://qinyuanpei.github.io .在曾经的一篇博客：《持续集成在Hexo自动化部署上的实践》中，我为大家分享了在线持续集成服务 Travis CI 的相关内容，在这篇文章中我们通过 Travis CI 为 Hexo 提供了自动部署的支持。其原理是Github为 Travis CI 分配一个token，当我们向 Github 推送新的代码以后，Travis 就会从代码仓库中拉取代码，并通过 npm 安装依赖生成静态页面，我们将这些静态页面推送到 master 分支，即可完成对Hexo的部署操作。这个流程从去年10月份建立以来，一直运行得非常稳定，对我个人而言，随着博客里得内容越来越多，在本地生成静态页面需要20多秒得时间，而有了持续集成服务以后，我可以用这个时间去做更多的事情，当持续集成流程发生异常的时候，微信上会收到 Travis 发送的邮件，整个过程简直令人心情愉悦。 &emsp;&emsp;今天想继续写点这个话题相关的内容，即如何通过 Travis CI 实现 Hexo 在 Github 和 Coding 的同步部署。显然，部署 Hexo 到 Github Pages 我们已经实现，今天我们着重来说 Coding Pages。为什么我们需要 Coding Pages 呢？主要从两个方面考虑，首先，因为 Github Pages 屏蔽了百度的爬虫，所以我们托管在 Github 上的博客，无法被搜索引擎正常收录；其次，由于 Github Pages 的服务器在国外，所以在国内博客的速度会受到影响，而且“防火墙”的国情决定了 Github 是一个不稳定的网站。曾经经历过短时间内无法使用 Github 的情形，故而，为了保证博客可以更加稳定地运行，我们必须为博客提供一个备份镜像，这就是我们今天要提到的 Coding Pages 服务啦。在正式使用这个服务前，我们首先简单介绍下这个服务。 &emsp;&emsp;我们知道 Github Pages 是 Github 提供的静态页面托管服务，其初衷是为个人项目或者组织项目创建演示或者文档站点，而 Coding Pages 则是国内的代码托管平台 Coding 提供的类似服务，国内类似的代码托管平台还有码云、Gitlab 等。Coding Pages 支持自定义域名、SSL 等基本特性，随着官方不断对这一服务进行升级，目前该服务除支持静态页面部署以外，同时支持 PHP 和 MySQL这类动态页面部署的特性。对 Hexo 来说，静态页面部署的特性完全可以支撑我们这个想法。我的想法是以 Github 作为代码的主仓库，其上面的 blog 分支存放博客的源代码， master 分支存放博客的静态页面，在此基础上，我们同时推送静态页面到 Github 和 Coding 的代码仓库，这样就可以实现两个平台的同步部署，这里的部署自然是指由 Travis 完成的自动化部署。整体的流程设想如下图所示： 博客同步部署流程图 &emsp;&emsp;通过这个流程图，我们可以注意到，新增加的工作量，主要体现在 Travis 向 Coding 的代码仓库推送静态页面，因此我们首先要有一个 Coding 的代码仓库。关于如何注册 Coding 及在 Coding 上创建代码仓库，这里不再详细赘述啦，大家可以自行百度、Google 或者阅读官方文档。Travis CI 的行为主要由 .travis.yml 这个文件来决定，要推送静态页面到 Coding 的代码仓库，Travis CI 需要有代码仓库的读写权限。顺着这个思路，尝试让 Coding 授权 给 Travis CI，结果从文档中发现Travis CI 并不支持 Coding，而 Coding 官方支持的持续集成 flow.ci 需要使用者从 Docker 创建镜像，所以看起来这条路无法走通。从搜索引擎中检索相关问题，从 Git 工作机制的角度入手，可以想到三种常见思路，即 SSH Key、Hexo 的 deploy 插件和 HTTPS协议。 &emsp;&emsp;第一种思路是考虑让 Travis CI 的远程服务器共享本机的SSH Key，通过 ssh-copy-id 命令即可实现，可问题是 Travis CI 每次创建虚拟机环境是变化的，因此我们无法确定目标主机的 IP 或者计算机名称等信息，这种思路不适合 Travis CI。而 Travis CI 官方同样提供了命令行工具来完成这个工作，因为 Travis CI 是基于 Ruby 开发而来，所以需要 Ruby 的环境支持，作为一个为逃避 Jekyll 而选择 Hexo 的人，我是不会让自己再受到 Ruby 的摧残的，所以这种思路基本放弃。第二种思路是使用 Hexo 提供的 deploy 插件，例如 hexo-deploy-git 这个插件支持通过 git 部署，而 Coding 和 Github 都支持 Git 相关的协议，所以可以考虑使用这个插件来完成这个操作，目前网络上可以检索到的资料，都是使用这个插件来完成同步部署。可是经过我一位使用过这个插件的朋友确定，该插件需要再执行 git 命令行期间输入用户名和密码，Travis CI 是不会给你机会输入用户名和密码的，所以这种思路再次放弃。第三种 HTTPS 协议，这个想都不用想是需要输入密码的，所以果断直接放弃。 &emsp;&emsp;正所谓”行至水穷处，坐看云起时”，山重水复之间，柳暗花明之际，我意外发现 Coding 提供了和 Github 类似的”访问令牌”，我们在使用 Travis CI 的时候，实际上做了两步授权操作，第一次是授权 Travis CI 读取我们在 Github 上的仓库列表，这是一个通过 OAuth 授权的过程；第二次授权是授权 Travis CI 向指定仓库推送或者拉取内容，这是一个通过 Token 授权的过程。我们会在 Travis CI 的后台设置中将 Token 作为全局变量导出，这样我们就可以在 .travis.yml 文件中引用这些全局变量。我意识到这是一个值得一试的想法，首先我们在 Coding 的”个人设置”页面中找到访问令牌，新建一个新的访问令牌，这里我们选第一个权限即可，因为我们只需要为 Travis 提供基本的读写权限，这样我们会生成一个 Token，这里注意保存 Token，因为它在这里只显示这一次，我们将 Token 填写到 Travis CI 的后台，取名为 CO_Token 即可，依次如下图所示： 在Coding中新建访问令牌 在Coding中保存访问令牌 在Travis中新建全局变量 &emsp;&emsp;好了，现在有了Token，就意味着 Travis CI 有权限向 Coding 推送或者拉取内容了，那么怎么让它工作起来呢？我们记得 Travis CI 有一个叫做 .travis.yml 的配置文件对吧？这里我们需要简单修改下这个文件，让 Travis CI 在生成静态页面以后同时推送静态页面到 Coding。修改后的关键配置如下，我已经写好了详细注释，关于这个文件配置可以参考这里，这里不再详细说明： 123456789101112131415161718192021222324252627after_script: - cd ./public - git init - git config user.name \"qinyuanpei\" - git config user.email \"qinyuanpei@163.com\" - git add . - git commit -m \"Update Blog By TravisCI With Build $TRAVIS_BUILD_NUMBER\" # Github Pages - git push --force --quiet \"https://$&#123;CI_TOKEN&#125;@$&#123;GH_REF&#125;\" master:master # Coding Pages - git push --force --quiet \"https://qinyuanpei:$&#123;CO_TOKEN&#125;@$&#123;CO_REF&#125;\" master:master - git tag v0.0.$TRAVIS_BUILD_NUMBER -a -m \"Auto Taged By TravisCI With Build $TRAVIS_BUILD_NUMBER\" # Github Pages - git push --quiet \"https://$&#123;CI_TOKEN&#125;@$&#123;GH_REF&#125;\" master:master --tags # Coding Pages - git push --quiet \"https://qinyuanpei:$&#123;CO_TOKEN&#125;@$&#123;CO_REF&#125;\" master:master --tagsbranches: only: - blogenv: global: # Github Pages - GH_REF: github.com/qinyuanpei/qinyuanpei.github.io # Coding Pages - CO_REF: git.coding.net/qinyuanpei/qinyuanpei.coding.me.git &emsp;&emsp;好了，现在我们就可以同时部署博客到 Github 和 Coding了，现在大家可以使用下面两种方式来访问我的博客。需要说明的是，使用 Coding Pages 的特性需要开启仓库的 *Pages *服务，并且 Coding 支持免费托管私有项目，虽然目前仓库的容量存在限制，对我们部署 Hexo 来说完全足够啦，下图是 Coding 上展示的提交历史，排版效果棒棒哒，哈哈，好了，以上就是这篇文章的内容啦，希望大家喜欢哦！ Coding上展示的提交历史 Github Pages 镜像 Coding Pages 镜像 &emsp;&emsp;本文使用的 .travis.yml 文件可以从这里 获取哦！","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://qinyuanpei.github.io/tags/Hexo/"},{"name":"Travis","slug":"Travis","permalink":"https://qinyuanpei.github.io/tags/Travis/"},{"name":"CI","slug":"CI","permalink":"https://qinyuanpei.github.io/tags/CI/"}]},{"title":"基于Python实现的微信好友数据分析","date":"2018-02-24T12:50:52.000Z","path":"posts/2805694118/","text":"&emsp;&emsp;最近微信迎来了一次重要的更新，允许用户对”发现”页面进行定制。不知道从什么时候开始，微信朋友圈变得越来越复杂，当越来越多的人选择”仅展示最近三天的朋友圈”，大概连微信官方都是一脸的无可奈何。逐步泛化的好友关系，让微信从熟人社交逐渐过渡到陌生人社交，而朋友圈里亦真亦幻的状态更新，仿佛在努力证明每一个个体的”有趣”。有人选择在朋友圈里记录生活的点滴，有人选择在朋友圈里展示观点的异同，可归根到底，人们无时无刻不在窥探着别人的生活，唯独怕别人过多地了解自己的生活。人性中交织着的光明与黑暗，像一只浑身长满刺的刺猬，离得太远会感觉到寒冷，而靠得太近则害怕被刺扎到。朋友圈就像过年走亲戚，即便你心中有一万个不痛快，总是不愿意撕破脸，或屏蔽对方，或不给对方看，或仅展示最后三天，于是通讯录里的联系人越来越多，朋友圈越来越大，可再不会有能真正触动你内心的”小红点”出现，人类让一个产品变得越来越复杂，然后说它无法满足人类的需求，这大概是一开始就始料不及的吧！ 引言&emsp;&emsp;有人说，人性远比计算机编程更复杂，因为即使是人类迄今为止最伟大的发明——计算机，在面对人类的自然语言时同样会张惶失措 。人类有多少语言存在着模棱两可的含义，我认为语言是人类最大的误解，人类时常喜欢揣测语言背后隐藏的含义，好像在沟通时表达清晰的含义会让人类没有面子，更不用说网络上流行的猜测女朋友真实意图的案例。金庸先生的武侠小说《射雕英雄传》里，在信息闭塞的南宋时期，江湖上裘千丈的一句鬼话，就搅得整个武林天翻地覆。其实，一两句话说清楚不好吗？黄药师、全真七子、江南六怪间的种种纠葛，哪一场不是误会？一众儿武功震古烁今的武林高手，怎么没有丝毫的去伪存真的能力，语言造成了多少误会。 &emsp;&emsp;可即便人类的语言复杂得像一本无字天书，可人类还是从这些语言中寻觅到蛛丝马迹。古人有文王”拘而演周易”、东方朔测字卜卦，这种带有”迷信”色彩的原始崇拜，就如同今天人们迷信星座运势一般，都是人类在上千年的演变中不断对经验进行总结和训练的结果。如此说起来，我们的人工智能未尝不是一种更加科学化的”迷信”，因为数据和算法让我们在不断地相信，这一切都是真实地。生活在数字时代的我们，无疑是悲哀的，一面努力地在别人面前隐藏真实地自己，一面不无遗憾地感慨自己无处遁逃，每一根数字神经都紧紧地联系着你和我，你不能渴望任何一部数字设备具备真正的智能，可你生命里的每个瞬间，都在悄然间被数据地折射出来。 &emsp;&emsp;今天这篇文章会基于 Python 对微信好友进行数据分析，这里选择的维度主要有：性别、头像、签名、位置，主要采用图表和词云两种形式来呈现结果，其中，对文本类信息会采用词频分析和情感分析两种方法。常言道：工欲善其事，必先利其器也。在正式开始这篇文章前，简单介绍下本文中使用到的第三方模块： itchat：微信网页版接口封装Python版本，在本文中用以获取微信好友信息。 jieba：结巴分词的 Python 版本，在本文中用以对文本信息进行分词处理。 matplotlib： Python 中图表绘制模块，在本文中用以绘制柱形图和饼图 snownlp：一个 Python 中的中文分词模块，在本文中用以对文本信息进行情感判断。 PIL： Python 中的图像处理模块，在本文中用以对图片进行处理。 numpy： Python中 的数值计算模块，在本文中配合 wordcloud 模块使用。 wordcloud： Python 中的词云模块，在本文中用以绘制词云图片。 TencentYoutuyun：腾讯优图提供的 Python 版本 SDK ，在本文中用以识别人脸及提取图片标签信息。以上模块均可通过 pip 安装，关于各个模块使用的详细说明，请自行查阅各自文档。 数据分析&emsp;&emsp;分析微信好友数据的前提是获得好友信息，通过使用 itchat 这个模块，这一切会变得非常简单，我们通过下面两行代码就可以实现： 12itchat.auto_login(hotReload = True)friends = itchat.get_friends(update = True) &emsp;&emsp;同平时登录网页版微信一样，我们使用手机扫描二维码就可以登录，这里返回的friends对象是一个集合，第一个元素是当前用户。所以，在下面的数据分析流程中，我们始终取friends[1:]作为原始输入数据，集合中的每一个元素都是一个字典结构，以我本人为例，可以注意到这里有Sex、City、Province、HeadImgUrl、Signature这四个字段，我们下面的分析就从这四个字段入手： 好友信息结构展示 好友性别&emsp;&emsp;分析好友性别，我们首先要获得所有好友的性别信息，这里我们将每一个好友信息的Sex字段提取出来，然后分别统计出Male、Female和Unkonw的数目，我们将这三个数值组装到一个列表中，即可使用matplotlib模块绘制出饼图来，其代码实现如下： 12345678910111213141516171819def analyseSex(firends): sexs = list(map(lambda x:x['Sex'],friends[1:])) counts = list(map(lambda x:x[1],Counter(sexs).items())) labels = ['Unknow','Male','Female'] colors = ['red','yellowgreen','lightskyblue'] plt.figure(figsize=(8,5), dpi=80) plt.axes(aspect=1) plt.pie(counts, #性别统计结果 labels=labels, #性别展示标签 colors=colors, #饼图区域配色 labeldistance = 1.1, #标签距离圆点距离 autopct = '%3.1f%%', #饼图区域文本格式 shadow = False, #饼图是否显示阴影 startangle = 90, #饼图起始角度 pctdistance = 0.6 #饼图区域文本距离圆点距离 ) plt.legend(loc='upper right',) plt.title(u'%s的微信好友性别组成' % friends[0]['NickName']) plt.show() &emsp;&emsp;这里简单解释下这段代码，微信中性别字段的取值有Unkonw、Male和Female三种，其对应的数值分别为0、1、2。通过Collection模块中的Counter()对这三种不同的取值进行统计，其items()方法返回的是一个元组的集合，该元组的第一维元素表示键，即0、1、2，该元组的第二维元素表示数目，且该元组的集合是排序过的，即其键按照0、1、2 的顺序排列，所以通过map()方法就可以得到这三种不同取值的数目，我们将其传递给matplotlib绘制即可，这三种不同取值各自所占的百分比由matplotlib计算得出。下图是matplotlib绘制的好友性别分布图： 微信好友性别分析 &emsp;&emsp;看到这个结果，我一点都不觉得意外，男女比例严重失衡，这虽然可以解释我单身的原因，可我不觉得通过调整男女比例就能解决问题，好多人认为自己单身是因为社交圈子狭小，那么是不是扩展了社交圈子就能摆脱单身呢？我觉得或许这样会增加脱单的概率，可幸运之神应该不会眷顾我，因为我的好运气早在我24岁以前就消耗完啦。在知乎上有一个热门的话题：现在的男性是否普遍不再对女性展开追求了？，其实哪里会有人喜欢孤独呢？无非是怕一次又一次的失望罢了。有的人并不是我的花儿，我只是恰好途径了她的绽放。曾经有人说我是一个多情的人，可她永远不会知道，我做出的每一个决定都炽热而悲壮。所谓”慧极必伤，情深不寿；谦谦君子，温润如玉”，世人苦五毒者大抵如此。 好友头像&emsp;&emsp;分析好友头像，从两个方面来分析，第一，在这些好友头像中，使用人脸头像的好友比重有多大；第二，从这些好友头像中，可以提取出哪些有价值的关键字。这里需要根据HeadImgUrl字段下载头像到本地，然后通过腾讯优图提供的人脸识别相关的API接口，检测头像图片中是否存在人脸以及提取图片中的标签。其中，前者是分类汇总，我们使用饼图来呈现结果；后者是对文本进行分析，我们使用词云来呈现结果。关键代码如下 所示： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869def analyseHeadImage(frineds): # Init Path basePath = os.path.abspath('.') baseFolder = basePath + '\\\\HeadImages\\\\' if(os.path.exists(baseFolder) == False): os.makedirs(baseFolder) # Analyse Images faceApi = FaceAPI() use_face = 0 not_use_face = 0 image_tags = '' for index in range(1,len(friends)): friend = friends[index] # Save HeadImages imgFile = baseFolder + '\\\\Image%s.jpg' % str(index) imgData = itchat.get_head_img(userName = friend['UserName']) if(os.path.exists(imgFile) == False): with open(imgFile,'wb') as file: file.write(imgData) # Detect Faces time.sleep(1) result = faceApi.detectFace(imgFile) if result == True: use_face += 1 else: not_use_face += 1 # Extract Tags result = faceApi.extractTags(imgFile) image_tags += ','.join(list(map(lambda x:x['tag_name'],result))) labels = [u'使用人脸头像',u'不使用人脸头像'] counts = [use_face,not_use_face] colors = ['red','yellowgreen','lightskyblue'] plt.figure(figsize=(8,5), dpi=80) plt.axes(aspect=1) plt.pie(counts, #性别统计结果 labels=labels, #性别展示标签 colors=colors, #饼图区域配色 labeldistance = 1.1, #标签距离圆点距离 autopct = '%3.1f%%', #饼图区域文本格式 shadow = False, #饼图是否显示阴影 startangle = 90, #饼图起始角度 pctdistance = 0.6 #饼图区域文本距离圆点距离 ) plt.legend(loc='upper right',) plt.title(u'%s的微信好友使用人脸头像情况' % friends[0]['NickName']) plt.show() image_tags = image_tags.encode('iso8859-1').decode('utf-8') back_coloring = np.array(Image.open('face.jpg')) wordcloud = WordCloud( font_path='simfang.ttf', background_color=\"white\", max_words=1200, mask=back_coloring, max_font_size=75, random_state=45, width=800, height=480, margin=15 ) wordcloud.generate(image_tags) plt.imshow(wordcloud) plt.axis(\"off\") plt.show() &emsp;&emsp;这里我们会在当前目录新建一个HeadImages目录，用以存储所有好友的头像，然后我们这里会用到一个名为FaceApi类，这个类由腾讯优图的SDK封装而来，这里分别调用了人脸检测和图像标签识别两个API接口，前者会统计”使用人脸头像”和”不使用人脸头像”的好友各自的数目，后者会累加每个头像中提取出来的标签。其分析结果如下图所示： &emsp;&emsp;可以注意到，在所有微信好友中，约有接近1/4的微信好友使用了人脸头像， 而有接近3/4的微信好友没有人脸头像，这说明在所有微信好友中对”颜值 “有自信的人，仅仅占到好友总数的25%，或者说75%的微信好友行事风格偏低调为主，不喜欢用人脸头像做微信头像。这是否说明”好看的皮囊”并非是千篇一律，长得好看的人实在是少数中的少数。所以，当女生的妆容越来越向着”韩式半永久粗平眉”、”瓜子脸”和”大红唇”靠拢的时候，当男生的服饰越来越向着”大背头”、”高领毛衣”和”长款大衣”靠拢的时候，我们能不能真正得个性一次。生命中有太多被世俗绑架着的事情，既要和别人不一样 ，同时还要和大多数人一样，这是人生在世的无可奈何。考虑到腾讯优图并不能真正得识别”人脸”，我们这里对好友头像中的标签再次进行提取，来帮助我们了解微信好友的头像中有哪些 关键词，其分析结果如图所示： 微信好友头像标签词云展示 &emsp;&emsp;通过词云，我们可以发现：在微信好友中的签名词云中，出现频率相对较高的关键字有：女孩、树木、房屋、文本、截图、卡通、合影、天空、大海。这说明在我的微信好友中，好友选择的微信头像主要有日常、旅游、风景、截图四个来源，好友选择的微信头像中风格以卡通为主，好友选择的微信头像中常见的要素有天空、大海、房屋、树木。通过观察所有好友头像，我发现在我的微信好友中，使用个人照片作为微信头像的有15人，使用网络图片作为微信头像的有53人，使用动漫图片作为微信头像的有25人，使用合照图片作为微信头像的有3人，使用孩童照片作为微信头像的有5人，使用风景图片作为微信头像的有13人，使用女孩照片作为微信头像的有18人，基本符合图像标签提取的分析结果。 好友签名&emsp;&emsp;分析好友签名，签名是好友信息中最为丰富的文本信息，按照人类惯用的”贴标签”的方法论，签名可以分析出某一个人在某一段时间里状态，就像人开心了会笑、哀伤了会哭，哭和笑两种标签，分别表明了人开心和哀伤的状态。这里我们对签名做两种处理，第一种是使用用结巴分词进行分词后生成词云，目的是了解好友签名中的关键字有哪些，哪一个关键字出现的频率相对较高；第二种是使用SnowNLP分析好友签名中的感情倾向，即好友签名整体上是表现为正面的、负面的还是中立的，各自的比重是多少。这里提取Signature字段即可，其核心代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051def analyseSignature(friends): signatures = '' emotions = [] pattern = re.compile(\"1f\\d.+\") for friend in friends: signature = friend['Signature'] if(signature != None): signature = signature.strip().replace('span', '').replace('class', '').replace('emoji', '') signature = re.sub(r'1f(\\d.+)','',signature) if(len(signature)&gt;0): nlp = SnowNLP(signature) emotions.append(nlp.sentiments) signatures += ' '.join(jieba.analyse.extract_tags(signature,5)) with open('signatures.txt','wt',encoding='utf-8') as file: file.write(signatures) # Sinature WordCloud back_coloring = np.array(Image.open('flower.jpg')) wordcloud = WordCloud( font_path='simfang.ttf', background_color=\"white\", max_words=1200, mask=back_coloring, max_font_size=75, random_state=45, width=960, height=720, margin=15 ) wordcloud.generate(signatures) plt.imshow(wordcloud) plt.axis(\"off\") plt.show() wordcloud.to_file('signatures.jpg') # Signature Emotional Judgment count_good = len(list(filter(lambda x:x&gt;0.66,emotions))) count_normal = len(list(filter(lambda x:x&gt;=0.33 and x&lt;=0.66,emotions))) count_bad = len(list(filter(lambda x:x&lt;0.33,emotions))) labels = [u'负面消极',u'中性',u'正面积极'] values = (count_bad,count_normal,count_good) plt.rcParams['font.sans-serif'] = ['simHei'] plt.rcParams['axes.unicode_minus'] = False plt.xlabel(u'情感判断') plt.ylabel(u'频数') plt.xticks(range(3),labels) plt.legend(loc='upper right',) plt.bar(range(3), values, color = 'rgb') plt.title(u'%s的微信好友签名信息情感分析' % friends[0]['NickName']) plt.show() &emsp;&emsp;通过词云，我们可以发现：在微信好友的签名信息中，出现频率相对较高的关键词有：努力、长大、美好、快乐、生活、幸福、人生、远方、时光、散步。果然我的微信好友都是温暖、正直的好青年啊！ :smile:其实，签名这个设定，从某种程度上是在反映人的一种心态，人在年轻时不免”为赋新词强说愁”，等到你真正到了这个精神境界，突然发现年轻时图样图森破，或许这就是我们不愿意让别人了解过去的原因，因为伴随着人的成长，某一种瞬间的状态简直不忍直视，QQ空间陪伴了我们这代人的整个青春，令人印象深刻的”那年今日”功能，有时让我们感到回忆的温暖，有时让我们感到岁月的萧杀，”当时只道是寻常”的物是人非，”回首向来萧瑟处”的淡定从容，”今夕复何夕”的失落惆怅……都在这一行行签名里留下深深浅浅的印记。在知乎上有关于签名的话题讨论，对此感兴趣的朋友不妨找时间看看。:smile: 微信好友签名信息词云展示 &emsp;&emsp;通过柱状图，我们可以发现：在微信好友的签名信息中，正面积极的情感判断约占到55.56%，中立的情感判断约占到32.10%，负面消极的情感判断约占到12.35%。这个结果和我们通过词云展示的结果基本吻合，这说明在微信好友的签名信息中，约有87.66%的签名信息，传达出来都是一种积极向上的态度。朋友圈中基本上有两类用户，第一类用户使用朋友圈记录自己的生活，第二类用户使用朋友圈输出自己的观点。显然，对于第二类用户，它并不介意别人了解它的过去，它更在乎它从始至终输出的观点是否一致。所以，不管朋友圈里别人在或晒美食、或晒旅游、或秀恩爱、或晒宝宝、或煲鸡汤等等，在我看来这都是一种生活方式，精神层次和物质层次比你高的人群，觉得你朋友圈里的内容”无趣”，这是符合人类一贯的认知方式的，在大多数情况下，反而是那些和你层次差不多的人群，对不熟悉的人或者事物妄加判断，如果你不喜欢我朋友圈里的内容，请直接屏蔽我就好，因为这样我们还可以做朋友；如果你因为喜欢A而在我这里和我说B不好，这就真的是三观不合啦。我相信没有完全兴趣匹配的两个人，即使是男女朋友或者情侣之间，总之人与人相处嘛，真诚和互相尊重是基本要求。 微信好友签名信息情感分析展示 好友位置&emsp;&emsp;分析好友位置，主要通过提取Province和City这两个字段。Python中的地图可视化主要通过Basemap模块，这个模块需要从国外网站下载地图信息，使用起来非常的不便。百度的ECharts在前端使用的比较多，虽然社区里提供了pyecharts项目，可我注意到因为政策的改变，目前Echarts不再支持导出地图的功能，所以地图的定制方面目前依然是一个问题，主流的技术方案是配置全国各省市的JSON数据，这里博主使用的是BDP个人版，这是一个零编程的方案，我们通过Python导出一个CSV文件，然后将其上传到BDP中，通过简单拖拽就可以制作可视化地图，简直不能再简单，这里我们仅仅展示生成CSV部分的代码： 1234567891011def analyseLocation(friends): headers = ['NickName','Province','City'] with open('location.csv','w',encoding='utf-8',newline='',) as csvFile: writer = csv.DictWriter(csvFile, headers) writer.writeheader() for friend in friends[1:]: row = &#123;&#125; row['NickName'] = friend['NickName'] row['Province'] = friend['Province'] row['City'] = friend['City'] writer.writerow(row) &emsp;&emsp;下图是BDP中生成的微信好友地理分布图，可以发现：我的微信好友主要集中在宁夏和陕西两个省份。数字时代的神经牵动着每一个社交关系链的人，我们想要竭力去保护的那点隐私，在这些数据中一点点地折射出来。人类或许可以不断地伪装自己，可这些从数据背后抽离出来的规律和联系不会欺骗人类。数学曾经被人称为最没有用的学科，因为生活中并不需要神圣而纯粹的计算，在不同的学科知识里，经验公式永远比理论公式更为常用。可是此时此刻，你看，这世界就像一只滴滴答答转动着的时钟，每一分每一秒都是严丝合缝的。 微信好友地理分布图 本文小结&emsp;&emsp;写这篇文章的时候，我一直不知道该如何下笔，因为微信是一个神奇的存在，它是一个国民级别的全民APP，所以，微信的产品设计一直都是一个有趣的现象，从最初底部Tab的数目、每个Tab的名称、”发现”页面的定制、小程序入口、朋友圈入口到朋友圈评论等等一系列的设计细节，都是值得我们透过人性和心理去研究的。即使是被人们封神的”张小龙”，在面对结构最为复杂的中国用户群体的时候，他的潇洒中依旧不免充满无奈，从对朋友圈的置之不理就可以看出，这是一个怎么做都不会让人满意的功能，任何一个生态在面对巨大的用户群体的时候，功能的增减就会变成一个难题，所谓”林子大了什么鸟都有”，知乎面对的是同样的问题，营销类公众号在不断消费社会话题的同时，引导着一批又一批粉丝的价值取向，人类总渴望着别人了解自己，可人类真的了解自己吗？这篇博客是我对数据分析的又一次尝试，主要从性别、头像、签名、位置四个维度，对微信好友进行了一次简单的数据分析，主要采用图表和词云两种形式来呈现结果。总而言之一句话，”数据可视化是手段而并非目的”，重要的不是我们在这里做了这些图出来，而是从这些图里反映出来的现象，我们能够得到什么本质上的启示，我一位朋友问我怎么什么都想抓取，为什么啊，因为我不懂人类啊！","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"Wechat","slug":"Wechat","permalink":"https://qinyuanpei.github.io/tags/Wechat/"},{"name":"matplotlib","slug":"matplotlib","permalink":"https://qinyuanpei.github.io/tags/matplotlib/"}]},{"title":"使用Python生成博客目录并自动更新README","date":"2018-02-23T09:32:45.000Z","path":"posts/1329254441/","text":"&emsp;&emsp;各位朋友，大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是：https://qinyuanpei.github.io。首先在这里祝大家春节快乐，作为过完年以后的第一篇文章，博主想写点内容风格相对轻松的内容。自从博主的博客采用 TravisCI 提供的持续集成(CI)服务以以来，博客的更新部署变得越来越简单，所有的流程都被简化为Git工作流下的提交(commit)和推送(push)操作。考虑到博客是托管在 Github 上的，一直希望可以自动更新仓库主页的README文件，这样可以显示每次提交代码后的变更历史。基于这样一个构想，我想到了为博客生成目录并自动更新README，其好处是可以为读者建立良好的文档导航，而且Markdown是一种简单友好的文档格式，Github等代码托管平台天生就支持Markdown文档的渲染。关于博客采用 TravisCI 提供持续集成(CI)服务相关内容，可以参考 持续集成在Hexo自动化部署上的实践 这篇文章。 &emsp;&emsp;好了，现在考虑如何为博客生成目录，我们这里需要三个要素，即标题、链接和时间。标题和时间可以直接从 _posts 目录下的Markdown文档中读取出来，链接从何而来呢？我最初想到的办法是读取每个Markdown文档的文件名，因为我的使用习惯是采用英文命名，这样当博客的永久链接(permalink)采用默认的:year/:month/:day/:title/形式时，每个Markdown文档的文件名等价于文章链接。事实证明这是一个愚蠢的想法，因为当你改变了永久链接(permalink)的形式时，这种明显投机的策略就会彻底的失败。相信你在浏览器种打开这篇文章时，已然注意到链接形式发生了变化，当然这是我们在稍后的文章中讨论的话题啦。至此，我们不得不寻找新的思路，那么这个问题该如何解决呢？ &emsp;&emsp;我意识到我的博客配置了 hexo-generator-json-content 插件，这个插件最初的目的是为博客提供离线的搜索能力，该插件会在博客的根目录里生成一个content.json文件，而这个文件中含有我们想要的一切信息，因此我们的思路转变为解析这个文件，人生苦短啊，我果断选择了我最喜欢的Python，这里我们会提取出所有的文章信息，按照日期由近到远排序后生成列表。Python强大到让我觉得这篇文章无法下笔，所以这里直接给出代码啦： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# -*- coding: utf-8 -*-import osimport reimport sysimport jsonimport datetime# 文档实体结构定义class Post: def __init__(self,date,link,title): self.date = date self.link = link self.title = title def getTitle(self): return self.title def getLink(self): return 'https://qinyuanpei.github.io/' + self.link def getDate(self): d = re.findall(r'\\d&#123;4&#125;-\\d&#123;1,2&#125;-\\d&#123;1,2&#125;',self.date)[0] t = re.findall(r'\\d&#123;2&#125;:\\d&#123;2&#125;:\\d&#123;2&#125;',self.date)[0] dt = '%s %s' % (d,t) return datetime.datetime.strptime(dt,'%Y-%m-%d %H:%M:%S')# 从JSON中加载文档数据def loadData(): json_file = open('./public/content.json','rb') json_data = json.load(json_file) for item in json_data: yield Post(item['date'],item['path'],item['title'])# 从列表生成Markdown文件def mkMarkdown(items): mdfile = open('README.md',mode='wt',encoding='utf-8') itemTpl = '* &#123;0&#125; - [&#123;1&#125;](&#123;2&#125;)\\n' for item in items: mdfile.write(itemTpl.format( datetime.datetime.strftime(item.getDate(),'%Y-%m-%d'), item.getTitle(), item.getLink() ))if(__name__ == \"__main__\"): items = sorted(loadData(),key=lambda x:x.getDate(),reverse=True) mkMarkdown(items) &emsp;&emsp;这里需要注意的有两个地方，第一，从JSON中解析出来的日期形式为：2018-02-23T01:32:45.000Z。对于这个形式的日期，博主先后尝试了内建的time模块和第三方的datetime模块，发现均无法直接转换为日期类型，所以首先采用正则匹配出日期和时间，然后再组合为标准的%Y-%m-%d %H:%M:%S的格式，这样就可以使用datetime模块进行处理啦，我还是想吐槽人类对各种各样format的执着，这些通配符在不同的语言中存在差别，就像SQL和正则引擎或多或少地存在兼容性问题一样。如果有朋友知道如何对这种日期形式进行转换，欢迎在博客中评论留言，再次谢谢大家。第二，使用内置函数sorted()对数据进行排序，lambda表达式使用起来非常棒，因为默认是升序排列地，而我们需要的是日期由近到远，所以这里选择了降序排列。 &emsp;&emsp;现在我们更新博客时的流程将发生变化，首先通过 hexo generate 或 hexo g命令生成博客，这样Hexo会为我们生成 ** content.json，然后我们执行这段Python脚本，就可以生成REAMD.md文件，这里我们将这个文件推送到blog分支。相对应地，我们修改 TravisCI 的脚本文件 **.travis.yml 文件如下： 1234script: - hexo clean - hexo generate - cp README.md ./public/README.md &emsp;&emsp;显然，这是告诉 TravisCI 在生成博客以后，将 README.md 文件复制到输出文件，这样当我们推送博客(指生成的静态页面)到 master 分支的时候，它会和 blog 分支同步共享同一份 README 。我想一定有朋友会问我，难道生成 README.md 文件的步骤不能交给 TravisCI 来处理？一定要在推送到 blog 分支以前手动地去执行脚本吗？我最初尝试过让 TravisCI 去执行这个 Python 脚本，可我发现一个残酷的事实时，我们这个虚拟机环境是 nodejs 的，这在我们定义 .travis.yml 文件时就指定了，因此这个环境中可能是没有 Python 支持的。起初我以为 Linux 系统自带 Python ， 因此尝试在 .travis.yml 文件中使用 pip 安装相关依赖，然后我发现持续集成服务华丽丽地挂了，因为 TravisCI 默认的 Python 版本是 Python2.7 , 除非我们指定的是一个 Python 的语言环境，所以这种想法不得不作罢，暂时就手动更新好啦。 &emsp;&emsp;好了，这篇文章核心的内容就这么多，下面想说些关于 Hexo 的延伸话题。 Hexo 是一个基于 nodejs 的静态博客生成器，按理说使用 nodejs 去扩展功能是最佳的实践方式，所以即使 Python 再强大，我们在这里看到的依然存在着天然的割裂感， 我们能不能将执行Python脚本的这个过程合并到 hexo generate 或者 hexo g这个步骤中去呢？ 通过官方文档中关于事件和生成器的描述，我们获得了两种新的思路，分别是在生成页面以后通过 child_process 模块调用 python 脚本、通过 Locals 变量获取全部文章信息后生成Markdown。从方案是否优雅的角度上来讲，我个人更倾向于第二种方案。基本的代码如下： 12345678910//方案一hexo.on('generateAfter', function(post)&#123; //TODO:通过content.json文件生成markdown文档&#125;);//方案二hexo.extend.generator.register(\"markdown\", function(locals)&#123; var posts = locals.posts; //TODO:通过posts属性生成markdown文档&#125;); &emsp;&emsp;显然，我是不会写 nodejs 的，如果有时间和精力的话，我可能会考虑采用第二种方案写一个插件，可是像我这么懒的一个人，还是不要提前立 flag 啦，毕竟人生苦短呐，我都选择使用 Python 这门语言来写啦，我干嘛非要再花时间去迎合它呢？好啦，这篇文章就是这样啦，本文中的脚本可以到 这里 来获取，本文生成的目录可以到 这里 来访问，再次谢谢大家！","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"Github","slug":"Github","permalink":"https://qinyuanpei.github.io/tags/Github/"},{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"Script","slug":"Script","permalink":"https://qinyuanpei.github.io/tags/Script/"}]},{"title":"愿你和我一样喜欢蛋炒饭","date":"2018-02-10T16:12:25.000Z","path":"posts/1933583281/","text":"&emsp;&emsp;周末花了一个晚上的时间看了部电影，由黄渤主演的《蛋炒饭》。有人说，这是一部刻意模仿《阿甘正传》的电影，充满胶片质感的纪录片风格，相似的镜头语言和表现手法，无一不在努力告诉你，这是一部本土化的《阿甘正传》。可是如同巧克力之于蛋炒饭，两种截然不同的食物会有不同的味道，电影所反映的实则是两种不同的内涵。如果说《阿甘正传》代表的是极具美国精神的励志故事，那么《蛋炒饭》代表的则是小人物为理想打拼的乌托邦。说《蛋炒饭》是本土化的《阿甘正传》其实不无道理，因为电影里充满了太多相似，这种在由时代感打磨出的细腻的情感，让我觉得这是一部值得一看的电影。 电影《阿甘正传》经典开头 &emsp;&emsp;电影开头苏茉莉坐在游乐园长凳上自下而上的长镜头，不禁让人联想到《阿甘正传》的开场，联想到那片空中摇曳着的羽毛；电影中反复出现的台词，来自大卫父亲的那句：做蛋炒饭要慢要慢，一如《阿甘正传》里的经典台词：人生就像一盒巧克力，你永远不知道下一块会是哪种？电影令我印象深刻的地方，在于它具厚重的时代感，中美建交、改革开放、金融危机、邓丽君、摇滚音乐、周杰伦、周笔畅……看起来王大卫好像和阿甘一样，参与并影响了众多历史事件。可我的理解是，阿甘最终成为了流浪街头的大富翁，而王大卫一直一无所有，因为他一辈子都在做一件事情，那就是做蛋炒饭。 最美好的年纪 &emsp;&emsp;整个电影采用的是倒叙的表现手法。主人公王大卫是一个智商不太高，而且有语言表达障碍的“傻子”，他第一次出场是替好兄弟打抱不平，结果他就像星爷《功夫》里的少年一样，以为自己的武功盖世无双，结果自然是被人打得头破血流；他书包里藏着的“复仇”的板砖，在外国友人访华的时候，一板砖破坏了中美友谊，结果自然是被校长通报批评；他家祖上是宫廷御厨，父亲即将退休食堂安排他去顶岗，一心想做厨师的他差点烧了厨房，结果自然是迫使父亲替他求情以保住工作；他从小喜欢的女孩苏茉莉要和好兄弟发生关系，她吻了他一下叫他在门口把风，结果自然是茉莉被渣男欺骗然后甩了他；他用母亲变卖古董的钱来了饭店，好兄弟嫉妒他做了老板，骗走他的产业后远走高飞，结果自然是他从老板变成杂工。 有些爱就像一阵风 &emsp;&emsp;看这个电影的时候，我一直觉得人生是绝望的，父母先后离开人世，哥哥在面前自杀而死，喜欢的女生抛弃自己，好兄弟发小欺骗自己……周围人对他全部是冷嘲热讽，每次发工资的时候，嘲弄他什么时候攒够钱赎回饭店；每次娱乐圈有绯闻传来的时候，说他“媳妇”苏茉莉又登上杂志封面；“好兄弟“因为金融危机背负债务，他就拎着辛苦攒下的一袋子零钱去帮他还债，结果半夜“好兄弟”开着车跑了……我不知道，我们该不该认同这种无条件“傻”的行为，电影想告诉我们的或许是“以德报怨，以德服人”这种儒家的传统思想，即在复杂的社会中，如何以一种淳朴单纯的心态，追寻本心，不畏曲折。所谓“众生虽苦，诸恶莫作”，这个社会复杂险恶是现实，可温润善良则是一种选择。我们抱怨时代给我们选择狭窄，因为我们放弃了那些艰难的选择，最终选择大多数人选择的那条路。 李红兵：人都是会变的 &emsp;&emsp;可我还是想说，无条件的善良是懦弱，我们选择善良，是因为我们不想伤害别人，可在今天这样一个时代，善良常常被当做是懦弱的表现，一个人努力让心变狠变硬，或许会达到通常意义上的成功，可成功的定义从来都是被人绑架着的，电影中“好兄弟”登上了“胡弄排行榜”，我不知道这是不是导演的一种讽刺，一个人靠着骗取好兄弟的产业而发家，即使收获了声名和利益，当他一个人在高速公路上疾驶，打算远走他乡的时候，内心是不是会有一点羞愧和遗憾呢？我们说，这是一部乌托邦式的电影，因为现实中像李红兵这样的人，绝对不会陡然间良心发现，把饭店归还王大卫，甚至王大卫拉开窗帘阳光照射进来，阳光下苏茉莉牵着女儿的手对他微笑，大卫的蛋炒饭得到溥仪认可，入选国际非遗名录……我宁愿相信，这是一种美好的理想。 大卫做蛋炒饭 &emsp;&emsp;大卫在电影中做过三次蛋炒饭，第一次是他顶替父亲的岗位到食堂工作，结果想做厨师的他差点烧了厨房，付出的代价是，因为御厨身份而自豪的父亲，向一辈子没低过头的食堂经理低头；第二次是他陪苏茉莉到医院流产，打完胎的苏茉莉说自己饿，他冒着被饭店人追打的危险，给苏茉莉做了一份蛋炒饭，付出的代价是，苏茉莉同他告别，独自到南方发展演艺事业；第三次是李红兵归还了饭店，成名后的王大卫，当着记者的面做了一次蛋炒饭，溥仪评价大卫的蛋炒饭，比他爷爷做得还要好，蛋炒饭入选国际非遗名录。大卫的一生都在做一件事情，那就是做蛋炒饭，这种专注是他和阿甘不一样的地方，在一个浮躁的时代，我们每天都在追逐都在忙碌，可我们追逐的是什么呢？或许是一盘蛋炒饭的安宁，从这个角度来说，蛋炒饭这种食物，真的是质朴而简单的存在啦。 有些人像你生命里的天使 &emsp;&emsp;如果你看过《阿甘正传》这部电影，会觉得苏茉莉和珍妮这两个角色是相似的。她们看起来都知道自己想要些什么，苏茉莉选择发展演艺事业进入娱乐圈，珍妮一直知道自己想要什么，她想做一名歌手，为了唱歌吃尽苦头，在酒吧、街头甚至任何可以唱歌的地方，只有有场合给她吉他，她就可以唱，甚至为了唱歌而穷困潦倒到卖身吸毒……她可以真挚地给成名的阿甘一个拥抱，而不愿依附他达到自己成名的目的，她深爱阿甘的同时，深知阿甘不会同自己结婚，因为童年的经历让她内心无比自卑，她始终打不开心里的结，她选择为阿甘生下孩子，这是一种自我成全。 愿茉莉一直这样美好 &emsp;&emsp;苏茉莉成名后取艺名苏菲，据说这个人物原型来自王菲，苏茉莉在成名过程中不断豪门势力，从最初回北京办演唱会拉赞助，到嫁入豪门以后受不了娱乐圈绯闻骚扰，进而宣布退出娱乐圈回到北京，她是一个不知道自己想要什么的人，直到故事最后她终于发现，原来那个深爱着自己的人，一直就在默默地等自己回来。所以对比两部电影中的女主，就可以发现，两部电影阐述的观点是截然相反的，即阿甘是迷茫的，而珍妮是坚定的；王大卫是坚定的，而苏茉莉是迷茫的。当你不知道想要什么的时候，不妨慢下来做份蛋炒饭，或许你就会找到答案。 你饿不饿，我做蛋炒饭给你吃呀 &emsp;&emsp;故事接近尾声的时候，王大卫再次登上三个人从小便常去的城楼，猛然间看到三个孩子正在那里玩耍，孩子们说这是他们的地盘，王大卫还是像从前一样，知趣地准备转身离开，阳光照耀城楼的刹那，我分明看见他脸上满意的笑容，那种历经沧桑后初心不改的从容。每个人，都既注定的命运，同时有偶然，两者都在同时发生，就像那片羽毛，努力飘啊飘啊，终于飘到阿甘脚下，然后又无可奈何的飘离阿甘。羽毛不是飞鸟，无法掌控飞行的方向，其实很想和你在一起，但偏偏风把距离吹得好远。如果可以的话，我想你和我一样，都喜欢蛋炒饭。你饿不饿，我做蛋炒饭给你吃呀？","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"影评","slug":"影评","permalink":"https://qinyuanpei.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"蛋炒饭","slug":"蛋炒饭","permalink":"https://qinyuanpei.github.io/tags/%E8%9B%8B%E7%82%92%E9%A5%AD/"}]},{"title":"基于Python实现Windows下壁纸切换功能","date":"2018-02-05T16:48:39.000Z","path":"posts/2822230423/","text":"&emsp;&emsp;在过去一年多的时间里，我尝试改变博客的写作风格，努力让自己不再写教程类文章，即使在这个过程中，不断地面临着写作内容枯竭的痛苦。因为我渐渐地意识到，告诉别人如何去做一件事情，始终停留在”术”的层面，而比这个更为重要的是，告诉别人为什么要这样做，这样就可以过渡到”道”的层面。古人云：形而上者谓之道，形而下者谓之器。我们常常希望通过量变来产生质变，可是如果在这个过程中不能及时反思和总结，我们认为的努力或许仅仅是重复的劳作而已。如你所见，在这篇文章里，我们将通过Python和Windows注册表实现壁纸切换功能，主要涉及到的Python中的requests、pyinstaller这两个模块的使用，希望大家喜欢。 故事缘由&emsp;&emsp;人们常常相信事出有因，可这世界上有些事情，哪里会有什么原因啊，比如喜欢与不喜欢。做这样一个小功能的初衷，起源于我对桌面壁纸的挑剔。作为一个不完全的强迫症患者，我需要花费大量时间去挑选一张壁纸，丝毫不亚于在网上挑选一件喜欢的商品。我注意到知乎上有这样的话题：有哪些无版权图片网站值得推荐？，因此对于桌面壁纸的筛选，我渐渐地开始摆脱对搜索引擎的依赖，我个人比较喜欢Pexels和Unsplash这两个网站，所以我想到了从这两个网站抓取图片来设置Windows壁纸的方案。市面上类似的商业软件有百度壁纸、搜狗壁纸等，可这些软件都不纯粹，或多或少地掺杂了额外功能，个中缘由想来大家都是知道的。联想到微信最新版本的更新，”发现”页面支持所有项目的隐藏，甚至是盟友京东的电商入口和腾讯最赚钱的游戏入口，这让我开始正视腾讯这家公司，我收回曾经因为抄袭对腾讯产生的不满，腾讯是一家值得尊重的互联网公司。做一个纯粹的应用程序，这就是我的初心。 设计实现&emsp;&emsp;好了，现在我们考虑如何来实现这个功能，我们的思路是从Unsplash这个网站抓取图片，并将其存储在指定路径，然后通过Windows API完成壁纸的设置。Python脚本会通过pyinstaller模块打包成可执行文件，我们通过修改注册表的方式，在右键菜单内加入切换壁纸的选项，这样我们可以直接通过右键菜单实现壁纸切换功能。在编写脚本的时候，起初想到的是抓包这样的常规思路，因为请求过程相对复杂而失败，后来意外地发现官方提供了API接口。事实上Pexels和Unsplash都提供了API接口，通过调用这些API接口，我们的探索进行得非常顺利，下面是具体脚本实现： 123456789101112131415161718192021222324252627282930313233# Query ImagessearchURL = 'https://unsplash.com/napi/search?client_id=%s&amp;query=%s&amp;page=1'client_id = 'fa60305aa82e74134cabc7093ef54c8e2c370c47e73152f72371c828daedfcd7'categories = ['nature','flowers','wallpaper','landscape','sky']searchURL = searchURL % (client_id,random.choice(categories))response = requests.get(searchURL)print(u'正在从Unsplash上搜索图片...')# Parse Imagesdata = json.loads(response.text)results = data['photos']['results']print(u'已为您检索到图片共%s张' % str(len(results)))results = list(filter(lambda x:float(x['width'])/x['height'] &gt;=1.33,results))result = random.choice(results)resultId = str(result['id'])resultURL = result['urls']['regular']# Download Imagesprint(u'正在为您下载图片:%s...' % resultId)basePath = sys.path[0]if(os.path.isfile(basePath)): basePath = os.path.dirname(basePath)baseFolder = basePath + '\\\\Download\\\\'if(not path.exists(baseFolder)): os.makedirs(baseFolder)jpgFile = baseFolder + resultId + '.jpg'bmpFile = baseFolder + resultId + '.bmp'response = requests.get(resultURL)with open(jpgFile,'wb') as file: file.write(response.content)img = Image.open(jpgFile)img.save(bmpFile,'BMP')os.remove(jpgFile) &emsp;&emsp;这部分代码非常简单，需要关注的地方有：第一，这个API对应的密钥是公共的，即所有人都可以使用，这里随机从指定的分类中去搜索图片。第二，这里使用filter()函数过滤出宽高比超过1.33的图片，即分辨率为1366 * 768的图片。这里需要注意的是，在Python3.X下filter需要转化为list，否则会引发一个异常。第三，下载的图片默认为JPEG格式，而Windows下设置壁纸使用的是位图格式，即BMP格式，所以在这里我们使用PIL模块来完成格式转换。这里需要注意的是，PIL模块目前不支持Python3.X以后的版本，我们这里使用的是Pillow模块，该模块可以通过pip直接完成安装。 &emsp;&emsp;现在，我们将壁纸下载到本地以后，就可以着手设置壁纸相关的工作。这些工作主要借助为win32api和win32gui这两个内置模块，我们一起来看具体代码： 12345678print(u'正在设置图片:%s为桌面壁纸...' % resultId)key = win32api.RegOpenKeyEx(win32con.HKEY_CURRENT_USER, \"Control Panel\\\\Desktop\",0,win32con.KEY_SET_VALUE)win32api.RegSetValueEx(key, \"WallpaperStyle\", 0, win32con.REG_SZ, \"2\") #2拉伸适应桌面,0桌面居中win32api.RegSetValueEx(key, \"TileWallpaper\", 0, win32con.REG_SZ, \"0\")win32gui.SystemParametersInfo(win32con.SPI_SETDESKWALLPAPER, bmpFile, 1+2)print(u'成功应用图片:%s为桌面壁纸' % resultId) &emsp;&emsp;这部分内容非常简单，基本没有复杂的东西在里面。接下来我们需要通过pyinstaller模块将脚本打包成可执行文件，实际上这个步骤完全可以省略，因为现在我们通过命令行就可以实现壁纸切换，为什么要做这样额外的工作呢？考虑到Windows下GUI更为便捷一点，所以我们打包成可执行文件，主要是为了给右键菜单添加功能，我们最终点击想要实现的功能是，点击右键菜单就可以完成壁纸的切换。首先通过pip安装pyinstaller模块，在终端下执行命令： 1python -m pip install pyinstaller 安装完成后按照官方文档即可在./dist/目录中找到生成的可执行文件，如果打包出错可以修改Python根目录下的./Scripts/pyinstaller-script.py文件，修改第一行Python.exe的路径，删除两端的引号即可，如下图所示。关于pyinstaller模块打包时的详细参数设定，请自行查阅官方文档。 pyinstaller-script.py文件 &emsp;&emsp;现在，在生成可执行文件以后，我们打开注册表，定位到以下节点：计算机\\HKEY_CLASSES_ROOT\\Directory\\Background\\shell，然后创建一级子节点WallPaper，其默认值填写”更换壁纸”，接下来创建二级子节点command，注意这个名称不能修改，其默认值填写可执行文件路径，本例中为：E:\\Software\\WallPaper\\main.exe，如下图所示： 为右键菜单增加更换壁纸选项 &emsp;&emsp;好了，现在我们可以看看在右键菜单中增加”更换壁纸”选项以后的效果： 最终效果 文本小结&emsp;&emsp;本文使用Python实现了Windows下切换壁纸的功能，通过requests模块从网络上抓取图片，通过PIL模块实现JPEG格式到BMP格式的转换，通过win32api和win32gui模块实现壁纸设置，并通过修改注册表的方式，将这一功能整合到系统菜单中，可以非常便捷地更换桌面壁纸。作为一个设计上的扩展，我们需要考虑更多的问题，比如当网络断开的时候如何避免异常，如何接入更多的在线图库API，如何支持可配置的图片分类信息以及如何将修改注册表的过程自动化等等，这些问题博主会利用空闲时间去解决，今天这篇文章就是这样啦，本文源代码可以通过这里获取，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"脚本","slug":"脚本","permalink":"https://qinyuanpei.github.io/tags/%E8%84%9A%E6%9C%AC/"},{"name":"Windows","slug":"Windows","permalink":"https://qinyuanpei.github.io/tags/Windows/"}]},{"title":"深入浅出理解Python装饰器","date":"2018-01-23T15:55:13.000Z","path":"posts/2829333122/","text":"&emsp;&emsp;各位朋友，大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是https://qinyuanpei.github.io。今天我想和大家一起探讨的话题是Python中的装饰器。因为工作关系最近这段时间在频繁地使用Python，而我渐渐意识到这是一个非常有趣的话题。无论是在Python标准库还是第三方库中，我们越来越频繁地看到装饰器的身影，从某种程度上而言，Python中的装饰器是Python进阶者的一条必由之路，正确合理地使用装饰器可以让我们的开发如虎添翼。装饰器天然地和函数式编程、设计模式、AOP等概念产生联系，这更加让我对Python中的这个特性产生兴趣。所以，在这篇文章中我将带领大家一起来剖析Python中的装饰器，希望对大家学习Python有所帮助。 什么是装饰器&emsp;&emsp;什么是装饰器？这是一个问题。在我的认知中，装饰器是一种语法糖，其本质就是函数。我们注意到Python具备函数式编程的特征，譬如lambda演算，map、filter和reduce等高阶函数。在函数式编程中，函数是一等公民，即“一切皆函数”。Python的函数式编程特性由早期版本通过渐进式开发而来，所以对“一切皆对象”的Python来说，函数像普通对象一样使用，这是自然而然的结果。为了验证这个想法，我们一起来看下面的示例。 函数对象123456def square(n): return n * nfunc = squareprint func #&lt;function square at 0x01FF9FB0&gt;print func(5) #25 可以注意到，我们将一个函数直接赋值给一个变量，此时该变量表示的是一个函数对象的实例，什么叫做函数对象呢？就是说你可以将这个对象像函数一样使用，所以当它带括号和参数时，表示立即调用一个函数；当它不带括号和参数时，表示一个函数。在C#中我们有一个相近的概念被称为委托，而委托本质上是一个函数指针，即表示指向一个方法的引用，从这个角度来看，C#中的委托类似于这里的函数对象，因为Python是一个动态语言，所以我们可以直接将一个函数赋值给一个对象，而无需借助Delegate这样的特殊类型。 使用函数作为参数1234def sum_square(f,m,n): return f(m) + f(n) print sum_square(square,3,4) #25 使用函数作为返回值1234567def square_wrapper(): def square(n): return n * n return square wrapper = square_wrapper()print wrapper(5) #25 &emsp;&emsp;既然在Python中存在函数对象这样的类型，可以让我们像使用普通对象一样使用函数。那么，我们自然可以将函数推广到普通对象适用的所有场合，即考虑让函数作为参数和返回值，因为普通对象都都具备这样的能力。为什么要提到这两点呢？因为让函数作为参数和返回值，这不仅是函数式编程中高阶函数的基本概念，而且是闭包、匿名方法和lambda等特性的理论基础。从ES6中的箭头函数、Promise、React等可以看出，函数式编程在前端开发中越来越流行，而这些概念在原理上是相通的，这或许为我们学习函数式编程提供了一种新的思路。在这个示例中，sum_square()和square_wrapper()两个函数，分别为我们展示了使用函数作为参数和返回值的可行性。 12345678def outer(m): n = 10 def inner(): return m + n return outerfunc = outer(5)print func() #15 1234567891011#内函数修改外函数局部变量def outer(a): b = [10] def inner(): b[0] += 1 return a + b[0] return innerfunc = outer(5)print func() #16print func() #17 &emsp;&emsp;对Python这门语言来说，这里的outer()函数和inner()函数分别被称为外函数和内函数，变量n的定义不在inner()函数内部，因此变量n称为inner()函数的环境变量。在Python中，一个函数及其环境变量就构成了闭包(Closure)。要理解闭包我认为我们可以把握这三点：第一，外函数返回了内函数的引用，即我们调用outer()函数时返回的是inner()函数的引用；第二，外函数将自己的局部变量绑定到内函数，其中变量b的目的是展示如何在内函数中修改环境变量；第三，调用内函数意味着发生出、入栈，不同的是每次调用都共享同一个闭包变量，请参考第二个示例。好了，现在讲完闭包以后，我们就可以开始说Python中的装饰器啦。 装饰器&emsp;&emsp;装饰器是一种高级Python语法，装饰器可以对一个函数、方法或者类进行加工。所以，装饰器就像女孩子的梳妆盒，经过一番打扮后，可以让女孩子更漂亮。装饰器使用起来是非常简单的，其难点主要在如何去写一个装饰器。带着这个问题，我们来一起看看Python中的装饰器是如何工作的，以及为什么我们说装饰器的本质就是函数。早期的Python中并没有装饰器这一语法，最早出在Python 2.5版本中且仅仅支持函数的装饰，在Python 2.6及以后版本中装饰器被进一步用于类。 123456789101112def decorator_print(func): def wrapper(*arg): print arg return func(*arg) return wrapper@decorator_printdef sum(array): return reduce(lambda x,y:x+y,array)data = [1,3,5,7,9]print sum(data) &emsp;&emsp;我们注意到装饰器可以使用def来定义，装饰器接收一个函数对象作为参数，并返回一个新的函数对象。装饰器通过名称绑定，让同一个变量名指向一个新返回的函数对象，这样就达到修改函数对象的目的。在使用装饰器时，我们通常会在新函数内部调用旧函数，以保留旧函数的功能，这正是“装饰”一词的由来。在定义好装饰器以后，就可以使用@语法了，其实际意义时，将被修饰对象作为参数传递给装饰器函数，然后将装饰器函数返回的函数对象赋给原来的被修饰对象。装饰器可以实现代码的可复用性，即我们可以用同一个装饰器修饰多个函数，以便实现相同的附加功能。在这个示例中，我们定义了一个decorator_print的装饰器函数，它负责对一个函数func进行修饰，在调用函数func以前执行print语句，进而可以帮助我们调试函数中的参数，通过@语法可以让我们使用一个名称去绑定一个函数对象。在这里，它的调用过程可以被分解为： 12sum = decorator_print(sum)print sum() 接下来，我们再来写一个统计代码执行时长的装饰器decorator_watcher: 12345678def decorator_watcher(func): def wrapper(*arg): t1 = time.time() result = func(*arg) t2 = time.time() print('time:',t2-t1) return result return wrapper 此时我们可以使用该装饰器来统计sum()函数执行时长： 123456@decorator_watcherdef sum(array): return reduce(lambda x,y:x+y,array)data = [1,3,5,7,9]print sum(data) 现在，这个装饰器打印出来的信息格式都是一样的，我们无法从终端中分辨它对应哪一个函数，因此考虑给它增加参数以提高辨识度： 1234567891011121314151617def decorator_watcher(funcName=''): def decorator(func): def wrapper(*arg): t1 = time.time() result = func(*arg) t2 = time.time() print('%s time:' % funcName,t2-t1) return result return wrapper return decorator@decorator_watcher('sum')def sum(array): return reduce(lambda x,y:x+y,array)data = [1,3,5,7,9]print sum(data) 装饰器同样可以对类进行修饰，譬如我们希望某一个类支持单例模式，在C#中我们定义泛型类Singleton。下面演示如何通过装饰器来实现这一功能： 12345678910111213141516171819instances = &#123;&#125;def getInstance(aClass, *args): if aClass not in instances: instances[aClass] = aClass(*args) return instances[aClass]def singleton(aClass): def onCall(*args): return getInstance(aClass,*args) return onCall@singletonclass Person: def __init__(self,name,hours,rate): self.name = name self.hours = hours self.rate = rate def pay(self): return self.hours * self.rate &emsp;&emsp;除此以外，Python标准库中提供了诸如classmethod、staticmethod、property等类装饰器，感兴趣的读者朋友可以自行前去研究，这里不再赘述。 装饰器与设计模式&emsp;&emsp;装饰器可以对函数、方法和类进行修改，同时保证原有功能不受影响。这自然而然地让我想到面向切面编程(AOP)，其核心思想是，以非侵入的方式，在方法执行前后插入代码片段，以此来增强原有代码的功能。面向切面编程(AOP)通常通过代理模式(静态/动态)来实现，而与此同时，在Gof提出的“设计模式”中有一种设计模式被称为装饰器模式，这两种模式的相似性，让我意识到这会是一个有趣的话题，所以在接下来的部分，我们将讨论这两种设计模式与装饰器的内在联系。 代理模式&emsp;&emsp;代理模式，属于23种设计模式中的结构型模式，其核心是为真实对象提供一种代理来控制对该对象的访问。在这里我们提到了真实对象，这就要首先引出代理模式中的三种角色，即抽象对象、代理对象和真实对象。其中： 抽象对象：通过接口或抽象类声明真实角色实现的业务方法。 代理对象：实现抽象角色，是真实角色的代理，通过真实角色的业务逻辑方法来实现抽象方法。 真实对象：实现抽象角色，定义真实角色所要实现的业务逻辑，供代理角色调用。 &emsp;&emsp;下面是一个典型的代理模式UML图示： 代理模式 &emsp;&emsp;通过UML图我们可以发现，代理模式通过代理对象隐藏了真实对象，实现了调用者对真实对象的访问控制，即调用者无法直接接触到真实对象。“代理”这个词汇是一个非常生活化的词汇，因为我们可以非常容易地联系到生活种的中介这种角色，譬如租赁房屋时会存在房屋中介这种角色，租客(调用者)通过中介(代理对象)来联系房东(真实对象)，这种模式有什么好处呢？中介(代理对象)的存在隔离了租客(调用者)与房东(真实对象)，有效地保护了房东(真实对象)的个人隐私，使其免除了频繁被租客(调用者)骚扰的困惑，所以代理模式的强调的是控制。 &emsp;&emsp;按照代理机制上的不同来划分，代理模式可以分为静态代理和动态代理。前者是将抽象对象、代理对象和真实对象这三种角色在编译时就确定下来。对于C#这样的静态强类型语言而言，这意味着我们需要手动定义出这些类型；而后者则是指在运行时期间动态地创建代理类，譬如Unity、Ca’stle、Aspect Core以及ASP.NET中都可以看到这种技术的身影，即所谓的“动态编织”技术，通过反射机制和修改IL代码来达到动态代理的目的。通常意义上的代理模式，都是指静态代理，下面我们一起来看代码示例： 12345678910111213141516171819202122public class RealSubject : ISubject&#123; public void Request() &#123; Console.WriteLine(\"我是RealSubject\"); &#125;&#125;public class ProxySubject : ISubject&#123; private ISubject subject; public ProxySubject(ISubject subject) &#123; this.subject = subject; &#125; public void Request() &#123; this.subject.Request(); &#125;&#125; &emsp;&emsp;通过示例代码，我们可以注意到，在代理对象ProxySubject中持有对ISubject接口的引用，因此它可以代理任何实现了ISubject接口的类，即真实对象。在Request()方法中我们调用了真实对象的Request()方法，实际上我们可以在代理对象中增加更多的细节，譬如在Request()方法执行前后插入指定的代码，这就是面向切面编程(AOP)的最基本的原理。在实际应用中，主要以动态代理最为常见，Java中提供了InvocationHandler接口来实现这一接口，在.NET中则有远程调用(Remoting Proxies)、ContextBoundObject和IL织入等多种实现方式。从整体而言，生成代理类和子类化是常见的两种思路。相比静态代理，动态代理机制相对复杂，不适合在这里展开来说，感兴趣的朋友可以去做进一步的了解。 装饰器模式&emsp;&emsp;装饰器模式，同样是一种结构型模式，其核心是为了解决由继承引发的“类型爆炸”问题。我们知道，通过继承增加子类就可以扩展父类的功能，可随着业务复杂性的不断增加，子类变得越来越多，这就会引发“类型爆炸”问题。装饰器模式就是一种用以代替继承的技术，即无需通过继承增加子类就可以扩展父类的功能，同时不改变原有的结构。在《西游记》中孙悟空和二郎神斗法，孙悟空变成了一座庙宇，这是对原有功能的一种扩展，因为孙悟空的本质依然是只猴子，不同的是此刻具备了庙宇的功能。这就是装饰器模式。下面，我们一起来看一个生活中的例子。 咖啡种类 &emsp;&emsp;喜欢喝咖啡的朋友，看到这张图应该感到特别亲切，因为咖啡的种类的确是太多啦。在开始喝咖啡以前，我完全不知道咖啡会有这么多的种类，而且咖啡作为一种略显小资的饮品，其名称更是令人目不暇接，一如街头出现的各种女孩子喜欢的茶品饮料，有些当真是教人叫不出来名字。这是一个典型的“类型爆炸”问题，人们在吃喝上坚持不懈的追求，让咖啡的种类越来越多，这个时候继承反而变成了一种沉重的包袱，那么该如何解决这个问题呢？装饰器模式应运而生，首先来看装饰器模式的UML图示： 装饰器模式 &emsp;&emsp;从这个图示中可以看出，装饰器和被装饰者都派生自同一个抽象类Component，而不同的Decorator具备不同的功能，DecoratorA可以为被装饰者扩展状态，DecoratorB可以为被装饰者扩展行为，可无论如何，被装饰者的本质不会发生变化，它还是一个Component。回到咖啡这个问题，我们发现这些咖啡都是由浓缩咖啡、水、牛奶、奶泡等组成，所以我们可以从一杯浓缩咖啡开始，对咖啡反复进行调配，直至搭配出我们喜欢的咖啡，这个过程就是反复使用装饰器进行装饰的过程，因此我们可以写出下面的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142//饮料抽象类abstract class Drink&#123; public abstract Drink Mix(Drink drink);&#125;//牛奶装饰器class MilkDecorator : Drink&#123; private Drink milk; MilkDecorator(Drink milk) &#123; this.milk = milk; &#125; public override Drink Mix(Drink coffee) &#123; return coffee.Mix(this.milk); &#125;&#125;//热水装饰器class WaterDecorator : Drink&#123; private Drink water; WaterDecorator(Drink water) &#123; this.water = water; &#125; public override Drink Mix(Drink coffee) &#123; return coffee.Mix(this.water); &#125;&#125;//一杯浓缩咖啡var coffee = new Coffee()//咖啡里混入水coffee = new WaterDecorator(new Water()).Mix(coffee)//咖啡里混入牛奶coffee = new MilkDecorator(new Milk()).Mix(coffee) &emsp;&emsp;在这里我们演示了如何通过装饰器模式来调配出一杯咖啡，这里我没有写出具体的Coffee类。在实际场景中，我们还会遇到在咖啡里加糖或者配料来收费的问题，此时装饰器模式就可以帮助我们解决问题，不同的装饰器会对咖啡的价格进行修改，因此在应用完所有装饰器以后，我们就可以计算出最终这杯咖啡的价格。由此我们可以看出，装饰器模式强调的是扩展。什么是扩展呢，就是在不影响原来功能的基础上增加新的功能。 区别和联系&emsp;&emsp;代理模式和装饰器模式都是结构型的设计模式，两者在实现上是非常相似的。不同的地方在于，代理模式下调用者无法直接接触到真实对象，因此代理模式强调的是控制，即向调用者隐藏真实对象的信息，控制真实对象可以访问的范围；装饰器模式下，扩展功能的职责由子类转向装饰器，且装饰器与被装饰者通常是“同源”的，即派生自同一个父类或者是实现了同一个接口，装饰器关注的是增加被装饰者的功能，即扩展。两者的联系在于都需要持有一个“同源”对象的引用，譬如代理对象与真实对象同源，装饰器与被装饰者同源。从调用的层面上来讲，调用者无法接触到真实对象，它调用的始终是代理对象，对真实对象的内部细节一无所知，这是代理模式；调用者可以接触到装饰器和被装饰者，并且知道装饰器会对被装饰者产生什么样的影响，通常是从一个默认的对象开始”加工”，这是装饰器模式。 装饰器与面向切面&emsp;&emsp;这篇文章写到现在，我发觉我挖了一个非常大的坑，因为这篇文章中涉及到的概念实在太多，务求每一个概念都能讲得清楚透彻，有时候就像莫名立起来的flag，时间一长连我自己都觉得荒唐。有时候感觉内容越来越难写，道理越来越难同别人讲清楚。写作从一开始坚持到现在，就如同某些固执的喜欢一样，大概连我都不记得最初是为了什么吧。好了，现在来说说装饰器与面向切面。我接触Python装饰器的时候，自然而然想到的是.NET中的Attribute。我在越来越多的项目中使用Attribute，譬如ORM中字段与实体的映射规则、数据模型(Data Model)中字段的校验规则、RESTful API/Web API设计中的路由配置等，因为我非常不喜欢Java中近乎滥用的配置文件。 &emsp;&emsp;C#中的Attribute实际上是一种依附在目标(AttributeTargets)上的特殊类型，它无法通过new关键字进行实例化，它的实例化必须依赖所依附的目标，通过分析IL代码我们可以知道，Attribute并非是一种修饰符而是一种特殊的类，其方括号必须紧紧挨着所依赖的目标，构造函数以及对属性赋值均在圆括号内完成。相比较而言，Python中的装饰器就显得更为顺理成章些，因为Python中的装饰器本质就是函数，装饰器等价于用装饰器函数去修饰一个函数。函数修饰函数，听起来感觉不可思议，可当你理解了函数和普通对象一样，就不会觉得这个想法不可思议。有时回想起人生会觉得充满玄学的意味，大概是因为我们还没有学会把自己看得普通。 &emsp;&emsp;通过这篇文章的梳理，我们会发现一个奇妙的现象，Java的Spring框架采用了动态代理了实现AOP，而Python的装饰器简直就是天生的AOP利器，从原理上来讲，这两门语言会选择什么样的方案都说得通。Java是典型的面向对象编程的语言，所以不存在任何游离于Class以外的函数，代理模式对类型的要求更为强烈些，因为我必须限制或者说要求Proxy实现里面的方法，而装饰器模式相对更为宽松些，遇到Python这样的动态类型语言，自然会显得事半功倍。这说明一个道理，通往山顶的道路会有无数条，从中找出最为优雅的一条，是数学家毕生的心愿。AOP是一种思想，和语言无关，我常常听到Java的同学们宣称AOP和IOC在Java社区里如何流行，其实这些东西本来就是可以使用不同的方式去实现的，有些重要的东西，需要你剥离开偏见去认知。 &emsp;&emsp;关于C#中的Attribute和AOP如何去集成，在Unity和Aspect Core这两个框架中都有涉及，主流的AOP都在努力向这个方向去靠拢，Java中的注解同样不会跳出这个设定，因为编程技术到了今天，语言间的差别微乎其微，我至今依然可以听到，换一种语言就能让问题得到解决的声音，我想说，软件工程是没有银弹的，人类社会的复杂性会永远持续地存在下去，你看微信这样一个社交软件，其对朋友圈权限的粒度之细足以令人叹服。有朋友尝试在C#中借鉴Python的装饰器，并在一组文章中记录了其中的心得，这里分享给大家，希望对这个问题有兴趣的朋友，可以继续努力研究下去，AOP采用哪种方式实现重要吗？有人用它做权限控制，有人用它做日志记录……允许差异的存在，或许才是我们真正需要从这个世界里汲取的力量。 轻量级AOP框架-移植python的装饰器(Decorator)到C#(思考篇) 轻量级AOP框架-移植python的装饰器(Decorator)到C#(编码篇) 本文小结&emsp;&emsp;本文是博主学习Python时临时起意的想法，因为曾经有在项目中使用过AOP的经验，所以在学习Python中的装饰器的时候，自然而然地对这个特性产生了兴趣。有人说，装饰器是Python进阶的重要知识点。在今天这篇文章中，我们首先从Python中的函数引出”函数对象”这一概念，在阐述这个概念的过程中，穿插了函数式编程、高阶函数、lambda等等的概念，”函数是一等公民”，这句话在Python中出现时就是指装饰器，因为装饰器的本质就是函数。然后我们讨论了两种和装饰器有关的设计模式，即代理模式和装饰器模式，选择这两种模式来讨论，是因为我们在Java/C#和Python中看到了两种截然不同的实现AOP的思路，这部分需要花功夫去精心雕琢。博主有时候觉得力不从心，所以写作中有不周到的地方希望大家谅解，同时积极欢迎大家留言，这篇文章就先写到这里吧，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"AOP","slug":"AOP","permalink":"https://qinyuanpei.github.io/tags/AOP/"},{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"装饰器","slug":"装饰器","permalink":"https://qinyuanpei.github.io/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/"}]},{"title":"AI时代：聊聊大数据中的MapReduce","date":"2018-01-19T00:45:08.000Z","path":"posts/2911923212/","text":"各位朋友，大家好，我是Payne，欢迎大家关注我的博客。最近读一本并行计算相关的书籍，在这本书中作者提到了MapReduce。相信熟悉大数据领域的朋友，一定都知道MapReduce是Hadoop框架中重要的组成部分。在这篇文章中，博主将以函数式编程作为切入点，来和大家聊一聊大数据中的MapReduce。如今人工智能正成为行业内竞相追逐的热点，选择MapReduce这个主题，更多的是希望带领大家一窥人工智能的门庭，更多深入的话题需要大家来探索和挖掘。 MapReduce的前世今生MapReduce最早是由Google公司研究并提出的一种面向大规模数据处理的并行计算模型和方法。2003年和2004年，Google公司先后在国际会议上发表了关于Google分布式文件系统(GFS)和MapReduce的论文。这两篇论文公布了Google的GFS和MapReduce的基本原理和主要设计思想，我们通常所说的Google的三驾马车，实际上就是在说GFS、BigTable和MapReduce。因此，这些论文的问世直接催生了Hadoop的诞生，可以说今天主流的大数据框架如Hadoop、Spark等，无一不是受到Google这些论文的影响，而这正是MapReduce由来，其得名则是因为函数式编程中的两个内置函数: map()和reduce()。 我们常常说，脱离了业务场景去讨论一项技术是无意义的，这个原则在MapReduce上同样适用。众所周知，Google是一家搜索引擎公司，其设计MapReduce的初衷，主要是为了解决搜索引擎中大规模网页数据的并行化处理。所以，我们可以说，MapReduce其实是起源自Web检索的。而我们知道，Web检索可以分为两部分，即获取网页内容并建立索引、根据网页索引来处理查询关键字。我们可以认为互联网上的每个网页都是一个文档，而每个文档中都会有不同的关键字，Google会针对每一个关键字建立映射关系，即哪些文档中含有当前关键字，这是建立索引的过程。在建立索引以后，查询就会变得简单，因为现在我们可以按图索骥。 互联网诞生至今，网站及网页的数量越来越庞大，像Google这样的搜索引擎巨头是如何保证能够对Web上的内容进行检索的呢？答案是采用并行计算(Parallel)。硬件技术的不断革新，让计算机可以发挥多核的优势来处理数据，可当数据量庞大到单机无法处理的程度，就迫使我们不得不采用多台计算机进行并行计算。我们知道并行计算的思想是，将大数据分割成较小的数据块，交由不同的任务单元来处理，然后再将这些结果聚合起来。因此，可以将MapReduce理解为一种可以处理海量数据、运行在大规模集群上、具备高度容错能力、以并行处理方式执行的软件框架。MapReduce是分治思想在大规模机器集群时代的集中体现(如图所示)，其中，Mapper负责任务的划分，Reducer负责结果的汇总。 MapReduce原理图 MapReduce的推出给大数据并行处理带来了巨大的革命性影响，使其成为事实上的大数据处理的工业标准，是目前为止最为成功、最广为接受和最易于使用的大数据并行处理技术。广为人知的大数据框架Hadoop，正是受到MapReduce的启发。自问世来，成为Apache基金会下最重要的项目，受到全球学术界和工业界的普遍关注，并得到推广和普及应用。MapReduce的非凡意义在于，它提出了一个基于集群的高性能并行计算模型，允许使用市场上普通的商用服务器构成一个含有数十、数百甚至数千个节点的分布式并行计算集群，可以在集群节点上自动分配和执行任务以及收集计算结果，通过Mapper和Reducer提供了抽象的大数据处理并行编程接口，可以帮助开发人员更便捷地完成大规模数据处理的编程和计算工作。今天，Google有超过10000个不同的项目已采用MapReduce来实现。 函数式编程与MapReduce我们提到，MapReduce之得名，其灵感来自函数式编程中的两个内置函数：map()和reduce()。函数式编程中，有一个重要的概念叫做高阶函数，是指函数自身能够接受函数，并返回函数的一种函数。我们所熟悉的C#和Java都是典型的面向对象编程(OOP)的语言，在这类编程语言中类(Class)是第一等公民，即不允许有独立于类的结构出现在代码中。虽然微软从未公开表示C#支持函数式编程，可从LINQ中我们依然可以窥见高阶函数的身影，譬如我们熟悉的Select()、Where()等扩展方法，就可以让我们按照函数式编程的风格去编写代码，这正是为什么Java 8开始支持Stream API的原因。最经典的函数式编程语言当属Haskell语言，我们今天见到的各种编程语言，在考虑引入函数式编程风格的时候，或多或少地都会受到这门语言影响。当你开始适应函数作为第一等公民、高阶函数、柯里化以及惰性求值以后，你或许就会感受到函数式编程特有的美感。 这里我们选择Python来阐述函数式编程与MapReduce的关系。Python可以让我们轻易地在多种不同的编程风格间切换，事实上现在的编程语言都有向着混合式编程风格发展的趋势。我们提到MapReduce来自两个内置函数：map()和reduce()。其中，map()方法可以对指定集合中的元素按照指定函数进行映射，并将映射后的结果以集合形式返回。譬如我们有一个集合[1,3,5,7,9]，我们希望对集合中的每一个元素做平方运算。借助Python中的map()方法和lambda表达式，这个问题可以通过1行代码得到解决。同理，如果我们希望对该集合内的元素做求和运算，我们可以借助于Python中的reduce()方法，该方法位于functools模块中。在某些编程语言中该方法又被成为fold()方法，实际上这两种叫法是等价的，我们关注函数式编程的本质即可。什么是本质呢？当然是函数啦。 1234567891011121314151617181920212223242526272829303132list = map(lambda x: x * x, [1,3,5,7,9]) #[1,9,25,49,81]sum = functools.reduce(lambda x,y: x+y, [1,3,5,7,9]) #25``` 好了，现在我们来分析下这两个函数，这将帮助我们更好地理解MapReduce。map()方法在这里被称为映射函数，它可以将一种类型映射为一种新的类型。举一个生活中的例子，譬如我们做菜的时候，必不可少的一个环节是将各种各样的食材切碎， 此时作用在这些食材的这个操作就是一个Map操作，你给Map一个洋葱就可以得到洋葱丝。同样地 ，你给Map一个番茄就可以得到番茄块。所以Map处理的原始数据，每条数据间没有相互联系，聪明的你告诉我洋葱和番茄有什么关系。相比map()方法，reduce()方法复杂的地方在于，它要求lambda表达式中必须是两个参数。如果继续沿用做菜这个生活化的例子，reduce()方法是将Map操作中切好的食材混合在一起。假设我们要做一份辣椒酱，辣椒酱需要的材料有辣椒、姜和蒜，因此在第一步Map的时候，这些食材将具有相同的Key。对同一类数据，我们就可以使用reduce()进行左/右折叠操作，这相当于我们将同一道菜的食材一起放到锅里，所以 Reduce阶段处理的数据是以Key-Value形式组织的，同一个Key下的Value具有相关性。这样，从理论上它就完全符合函数式编程里的map()和reduce()啦。 # C#并行编程里的PLINQ关于MapReduce中一个经典案例是，统计不同文章中出现的关键字的频率。对这样一个问题，我们基本上可以想到下面四种方法：* 写一个单线程程序，顺序地遍历所有文章，然后统计每个关键字出现的频率。* 写一个多线程程序，并发地遍历所有文章，然后统计每个关键字出现的频率。* 写一个单线程程序，部署到N台不同的计算机上，然后将文章分割成N份分别输入，再由人工汇总N份结果。* 使用MapReduce，程序部署、任务划分、结果汇总全部交给框架去完成，我们定义好任务即可。通过对比，我们可以非常容易地分析出来，第一种方法最简单同时最耗时；第二种方法理论上比第一种高效，尤其是当计算机是多核或者多处理器的时候，缺点是要解决线程同步的问题；第三种方法初现集群的思想，可无法解决程序部署、任务划分和结果汇总等一系列问题；第四种方法本质上就是第三种方法， 可是MapReduce解决了第三种方法全部缺陷，所以它或许是目前最完美的方法。我们下面来考虑，如何模拟这个过程，因为博主不可能为了写一篇科普性质的文章，专门去准备一个Hadoop的开发环境啊，哈哈。PLINQ，即Parallel LINQ，是.NET 4.0中增加的任务并行库(**TPL**)中的一部分。并行编程中有两个基本的概念，**任务并行**和**数据并行**。前者是指，将程序分割成一组任务并使用不同的线程来运行不同的任务，这种方式被称为**任务并行**；而后者是指，将数据分割成较小的数据块，对这些数据进行并行计算，然后聚合这些计算结果，这种编程模型称为**数据并行**。伴随着并行算法的出现，并行集合相继而来，显然LINQ的并行版本就是PLINQ。这里我们来看一个使用PLINQ实现的词频统计代码，这将作为我们实现MapReduce的一个示例：```CSharp//Origin Textsstring strTarget = @\"\";//Mapstring[] words = strTarget.Split(' '); ILookup&lt;string, int&gt; map = words.AsParallel().ToLookup(p =&gt; p, k =&gt; 1); //Reducevar reduce = from IGrouping&lt;string, int&gt; wordMap in map.AsParallel() where wordMap.Count() &gt; 1 select new &#123; Word = wordMap.Key, Count = wordMap.Count() &#125;; //Show Resultsforeach (var word in reduce) Console.WriteLine(\"Word: '&#123;0&#125;' : Count: &#123;1&#125;\", word.Word, word.Count); 本文小结今天Google发布了全新的AI服务工具Cloud AutoML，从这个产品的名字就可以看出，这是一个试图将人工智能大众化的产品。目前AI是行业中不容置疑热点，国外的科技巨头如Google、微软，国内的科技巨头如腾讯、阿里和百度等，无一不在积极布局AI的上下游产业链。最近CSDN发布了人工智能方向的发展规划，整个产品线的基本都在做战略上调整，我们这些曾经的老用户被新的社区 运营搞得非常郁闷，因为所有的资源都在向着人工智能和区块链倾斜。上周在知乎上看到一篇讽刺国内区块链发展乱象的文章，大概就是说国人喜欢拿一个Token当做加密货币来买，实则连底层技术、分布账本、钱包等基础设施都没有。对于这一点我深有体会，任何新的商业模式在中国都火不过1年，譬如在2017年里被发扬广大的共享经济，有多少共享单车是靠技术和产品赢得市场的，我相信大部分都是沾了人口基数大的光。目前的人工智能，核心算法及技术都掌握在科技巨头手上。我们所追逐的人工智能，有多少是需要靠不断调整参数反复去训练来达到的呢？我觉得找到切实可靠的需求落脚点，比追逐一个又一个热点要更现实，我们大部分工程师都是在科学家工作的基础上做集成应用，所以拨开泡沫看清方向比盲目跟风更重要呀。 这篇文章蹭了人工智能的热点，其实它对MapReduce并没有做多少深入的研究。我们从Google的业务场景着手分析，思考为什么Google需要MapReduce，即提出MapReduce是为了解决一个什么样的问题？答案是为了适应Google在大规模Web检索业务方面的需要。通过梳理Web检索的一般流程，我们意识到，Web检索可以分为两部分，即获取网页内容并建立索引、根据网页索引来处理查询关键字，从而引出了Mapper和Reducer两个基本的数据处理单元，MapReduce是分治思想在大规模机器集群时代的集中体现，其中，Mapper负责任务的划分，Reducer负责结果的汇总。接下来，我们顺着函数式编程的思路，分析了函数式编程中的map()和reduce()，这两个核心的函数同MapReduce在思想上的一致性，这正是为了印证前文中MapReduce得名的由来。考虑到C#中提供了PLINQ，而在阅读《C#多线程编程》这本书时，同样提到了MapReduce这种并行计算模型，所以在这里将这两者进行结合，提供了一个通过并行计算统计单词频率的简单示例。以上就是这篇文章的所有内容了，如果大家对文章有什么意见或者建议，可以在文章评论区留言，这篇文章就是这样了，谢谢大家，晚安！","categories":[{"name":"人工智能","slug":"人工智能","permalink":"https://qinyuanpei.github.io/categories/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/"}],"tags":[{"name":"AI","slug":"AI","permalink":"https://qinyuanpei.github.io/tags/AI/"},{"name":"MapReduce","slug":"MapReduce","permalink":"https://qinyuanpei.github.io/tags/MapReduce/"},{"name":"FP","slug":"FP","permalink":"https://qinyuanpei.github.io/tags/FP/"},{"name":"大数据","slug":"大数据","permalink":"https://qinyuanpei.github.io/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"}]},{"title":"无问东西：你曾是少年","date":"2018-01-19T00:42:06.000Z","path":"posts/1983298072/","text":"如果提前了解了你所要面对的人生，你是否还有勇气前来？ 这是电影《无问西东》里提出的一个问题。作为一部清华大学建校100周年的献礼片，在因为种种原因而被雪藏6年以后，终于以这样一种倔强而孤傲的姿态，进入到人们的视野。 绘制彩红的张果果 电影一开始，透过玻璃注视着四胞胎的张果果(张震饰)，第一次向我们发问：如果提前了解了你所要面对的人生，你是否还有勇气前来。而在电影接近尾声的时候，张果果再一次注视着四胞胎，在窗户上为它们勾勒彩虹，此时旁白再次想起，一问一答间，张果果心中已然找到答案。我想知道的是，屏幕前的你，是不是同样找到了答案？ 这是一部讲述传承的电影，它不同于目前电影市场上任何一种主流的类型，它从一开始就注定是一部不讨巧、不友善、不商业的电影。其故事跨度将近一个世纪，或许我们所看到的，不过是历史长河里的星星点点，可依然难掩背后熠熠生辉的文人风骨，这种由时代所赋予的文化气息，让它成为一部瑕不掩瑜的电影，所以即使这部电影在叙事、配乐和剪辑上存在缺陷，这依然是一部值得关注的电影。 电影尝试用四个平行的板块，讲述四个不同历史阶段的故事，这些故事中的人物彼此关联，组成了一幅波澜壮阔的历史画面，而影片中想要去表达的精神内核，恰好是关联起这些人物的一种特质，我们称之为传承的东西。按照影片线性叙事的结构，我们可以梳理出这样四条线索。 上进求学的吴岭澜 1923年，北平，清华学堂的高材生吴岭澜(陈楚生饰)，面对选择文理科时的迷茫与彷徨，校长梅贻绮告诉他什么是真实，适逢泰戈尔访华到清华园演讲，在听到“不要忘记你们的真心和真性”后，开始思考人生的意义。 捐躯赴国的沈光耀 1938年，昆明，世家子弟沈光耀面对山河破碎的现实，在忠与孝的两难抉择中深感困惑，直到听到吴岭澜说“不要放弃对生活的思索，对自己的真实”，毅然选择投笔从戎，成为飞虎队队员，在国家危亡之际战死沙场。 青春阳光的陈鹏 1962年，北京，清华毕业生陈鹏，在面对国家的大爱与恋人的小爱的选择时，饱含着对恋人王敏佳的爱远赴沙漠投身科研，他质问为支边而蒙蔽内心的李想什么是真实，他用爱托着恋人鼓励她努力活下去，为爱而奉献一生。 寻找本心的张果果 2010年，北京，广告总监张果果，在明争暗斗的职场上遭人排挤，在面对职场中的名利诱惑时，在面对四胞胎永无止境的救助要求时，李想用生命拯救了张果果的父母，完成自我救赎，而张果果则在迷茫中找会初心，让爱传承下去。 看这样一部电影的时候，像是在经历一件久远的事情。“这个时代缺少的不是完美的人，缺少的是从自己心底里给出的，真心、正义、无畏和同情”，这是电影中飞虎队教练在招收飞行员时所说的话。我想我们喜欢这部电影，恰恰是因为我们缺少这些东西，这些让我们感到温暖而纯粹的东西。借用吴岭澜在影片中的一句话，“此刻我终于不觉得这样的思考是羞耻的，甚而是你们人生必须的”，面对一个我们无力反驳的现实，或许思考有时候会显得更为苍白。彼时，清华大学校长梅贻绮对迷茫中的吴岭澜这样说道，“人把自己置身于忙碌之中，有一种麻木的踏实，但丧失了真实”，那么你知道什么是真实吗？ 循循善诱的清华校长梅贻琦 聆听泰戈尔演讲的吴岭澜 电影中第一个人物，是1924年就读于清华大学的吴岭澜，他见证过泰戈尔访问清华，最终从摇摆不定到听从内心声音，找寻人生的意义。吴岭澜当时是清华大学的一名学生，他的理科成绩属于不列，而当时最好的学生都会去读理科，所以他开始面临学业选择上的困惑。校长梅贻绮给他的答案是：“真实是你看到什么，听到什么，做什么和谁在一起，有一种从心灵深处满溢出来的不懊悔也不羞耻的平和与喜悦”。当时诗人泰戈尔访问清华，演讲的主题是”对自己的真诚”，这次演讲促使吴岭澜心态发生最终变化，转学文科，并最终成为西南联大的一名文科教授。电影对吴岭澜的描绘着重放在他和校长梅贻绮的谈话，以及他出现在泰戈尔演讲现场时那双坚定而执著的眼睛。影片中泰戈尔并没有给出完整的正脸，我们可以看到的只有他标志性的长头发和白头发，可见当时泰戈尔的演讲激起了这代青年人内心的热潮。 历史上的西南联大 西南联大师生合影 历史上的西南联合大学，始于1938年4月。“七七事变”后，京津地区陷入日军炮火，彼时的清华、北大和南开三校一致决定南迁，遂组成西南联合大学。电影中投笔从戎的沈光耀(王力宏饰)就是这段历史时期的一个缩影，西南联大是中国高等教育史上最伟大的传奇，在短短8年间，汇聚并培养了一大批精英，譬如陈寅恪、钱穆、梁思成、朱自清、闻一多、冯友兰……可以说这是近代最为光华璀璨的时期，可谓群贤毕至、风华绝代。短短8年间，西南联大共毕业学生3882名，其中诺贝尔奖获得者2位、国家最高科学技术奖获得者4位、两弹一星功勋奖章获得者8位、两院院士171位及人文大师100多位。 静坐停雨 电影中这段我最喜欢的场景是“静坐听雨”。历史上西南联大的校舍，是由梁思成夫妇参与设计的。因为战争时期物资非常紧缺，校方无法提供充足的建筑材料，所以梁思成夫妇的设计方案一改再改，从楼房变成了平房，从砖墙变成了泥墙，最终124亩的校园里，只有图书馆和实验室以青瓦覆顶，教室用铁皮，宿舍则用茅草。铁皮屋顶最害怕下雨，而昆明偏偏是多雨气候，因此就有了雨声太大导致学生无法听清老师讲课，老师无奈地在黑板上写下“静坐听雨”四个字，这样苦涩中带着温情的画面。电影中沈光耀推开教室窗户，听到的是雨中体育系学生坚持出操的呐喊，看到的是雨中垂钓者的“一蓑烟雨任平生”的从容。我们今天的大学占地越来越大，楼越盖越高，可再找不回这种令人动容的场景。我本科有位老师喜欢讲《大学》，他说这大学不是“高楼大厦之谓”，而是“大师之谓”，这一刻我很想再听老师讲一次大学之道。 汪曾琪有篇散文《跑警报》，讲述的正是当时的师生躲避日军飞机轰炸的故事，电影中沈光耀(王力宏饰)在锅炉房相遇煮冰糖银耳的桥段，正是取材于这篇散文。在影片中，吴岭澜(陈楚生饰)是一个对沈光耀产生深远影响的人，吴岭澜此时已成为西南联大文学系教授，他冒着被轰炸的危险把煮冰糖银耳的沈光耀从校舍拉了出来，一句“学生不走老师怎么能走”，足以让其形象瞬间高大起来。电影中吴岭澜躲避轰炸的时候带了只鸽子，而历史真实的故事则是金岳霖抱着一只鸡。当时流传着这样一个段子，“陈寅恪跑警报是为了保护国粹，刘文典跑警报是为了庄子，沈从文跑警报到底是为了什么“。在防空洞里吴岭澜讲述泰戈尔的“真实就是你所见所闻”，将真实传承到沈光耀心里，所以他会冒着受罚的风险向饥民空投物资，所以他会不顾家人反对毅然选择投笔从戎、加入飞虎队，直至弹尽粮绝的最后一刻，他毫不犹豫地选择同日军舰艇同归于尽，这是他们的青春故事。 研制原子弹归来的陈鹏 用深情撑住恋人的陈鹏 陈鹏(黄晓明饰)在影片中是清华大学的一名学生，在毕业后参与原子弹的研制工作。他对恋人王敏佳矢志不渝的爱，成为了支撑她熬过人生低谷的强大动力。影片中的王敏佳一心想帮助曾经的老师摆脱“家庭暴力”，结果反倒被师母诬陷她勾引自己老师，而她的虚荣心迫使她被组织审查直至接受批斗。在批斗中王敏佳失去了美丽的面庞，她的好朋友李想为争取支援边区的名额，不敢承认自己的错误并坚决同她划清了界限。只有陈鹏自始至终守护在王敏佳身边。可陈鹏依然在国家和个人的抉择中，选择了远赴沙漠参与原子弹的研制工作，对他而言，照顾王敏佳和研制原子弹，就是他生命的全部。可当陈鹏回到曾经熟悉的地方时，却发现恋人因为“破四旧”运动而不见踪影。在爱人与国家面前，在爱情与理想面前，我们到底应该怎么去选择，我想大概就是电影中陈鹏告诉李想那句话，“死者已矣，生者如斯”，这是“晃晃”哥哥和神父教给他的大爱。 眼神里都是戏的领导 现代人的感情，就剩这么点了 生活在现代都市的张果果(张震饰)，在尔虞我诈的人际关系中艰难前行，他恪守上下级的职场伦理却被有预谋地当作了替罪羊。面对女下属的质疑，不得不以高深莫测的“你猜”来掩饰内心的焦虑。对父母缺乏耐心以至于出去吃饭的时候直接将碗筷丢进垃圾框，他习惯性地防备着身边的一切，一如喜欢给自己覆盖一层冰冷盔甲的你我。他怕四胞胎家人纠缠而从医院匆匆离开，却又主动掏出名片在门口等人家追上来；目睹四胞胎家人住在没有暖气的出租屋里，冷峻着脸转身离开却又悄声让助理帮忙找个好点的两居室；他买来各种奶粉默默研究选出最满意的奶粉并长期供给，却又不愿意让四胞胎家人对他抱太高期望……起初会觉得这个角色和整个故事无关，可当张果果的父母交代出李想在边区为救自己而牺牲的故事，这一刻我们终于明白，这种传承从未改变，经历过迷茫和无助的张果果终于找回初心，自信地对这个世界说：“我和他们不一样”。 我相信每个时代里的青年都曾这样迷茫过，就像我们今天所要面对的这种困局一样。媒体称我们这一代人是得过且过的佛系青年，我们为工作中无法得到别人认可而焦虑过，我们为空有适婚的年龄而无适婚的感情而烦闷过，我们为透支父母毕生积蓄来买房而羞愧过……可你看每一个在时代洪流中挣扎的人，其生命无一不被同时打上时代和民族的烙印。吴岭澜是因真心而重新选择自己的人生，沈光耀是因为正义而投笔从戎，陈鹏是因为无畏而托住恋人投身科研，张果果是因为同情而重拾本心迷途知返。列夫·托尔斯泰说过，幸福的人生都是相似的，不幸的人生各有各的不同。每个时代有每个时代的不幸，我们今天不单单要面对水涨船高的房价，更要面对逐渐枯竭甚至贫瘠的心灵。有人说，这部拍给清华学生看的电影，对改善我们的生活毫无意义，可这世上有多少东西，说出来以后能不变得庸俗呢？ 那时的爱情真美好 这个校服好帅诶 不管多远都要去寻找你 最后的国学大师，王国维 那时的青春真美好 同样是在迷茫的20多岁，有人找到了真性在生命里惊鸿一瞥，有人在沉浮中随波逐流迷失本心，前者是沈光耀目睹战友牺牲与敌舰同归于尽，后者是李想为争取支边名额背弃朋友间的友谊。陈鹏的爱慷慨而深沉，王敏佳不幸而无能为力……每个时代都是写意的，有佚群绝类的意气，有献血淋漓的痛苦，今天的人们注定无法理解曾经艰苦的生活，而曾经的人们同样无法理解现代人所面对的压力。现实中的离婚和出轨，让美好的爱情变得遥不可及。我们今天越是期待什么，我们的心里就越是缺乏什么。白居易说《长恨歌》是虚构的，而感情是真实的，这或许完全是我们的内心在作怪。世道艰辛，梦想与现实，家国与大义，爱情与理想，名利与善良，仿佛冥冥之中被逼迫到进退两难境地的每一个人，众生皆苦，各自悲欢。张果果在酒吧里拎着半瓶红酒自嘲道，“现代人的情感，就这么多了”，当本心迷失，便是我们有火车，有高铁，有飞机，都不知道要去哪里了！ 路一直都在远方 古人说“为天地立心，为生民立命，为往圣继绝学，为万世开太平”，这是传统知识分子对文化传承的一种使命感。在这部电影中，防空洞里师生背诵《楚辞》、讲述泰戈尔，这是我理解的文化上的传道；王国维在一片英语声中转身离去，那个萧疏没落的背景像是很久很久以前的事情；沈光耀的母亲不愿意他为功名荣辱，在不知人生为何物的时候匆匆离开；师母看到被人打得半死的王敏佳，内心残存的善念觉醒愧而坠井……这些游曳在光影里的残余画面，显得温暖而残酷，终于化作电影结束时一个又一个陌生而熟悉的名字。我们之所以怀念青春，是因为青春本该就是这个样子，真实勇敢，无惧无悔。世俗这样强大，强大到生不出改变它们的念头来。可是无论外界的社会如何跌宕起伏，都对自己真诚，坚守原则。内心没有了杂念和疑问，才能勇往直前。愿你在被打击时，记起你的珍贵，抵抗恶意；愿你在迷茫时，坚信你的珍贵，爱你所爱，行你所行，听从你心，无问西东。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"影评","slug":"影评","permalink":"https://qinyuanpei.github.io/tags/%E5%BD%B1%E8%AF%84/"},{"name":"无问西东","slug":"无问西东","permalink":"https://qinyuanpei.github.io/tags/%E6%97%A0%E9%97%AE%E8%A5%BF%E4%B8%9C/"}]},{"title":"致前任：愿余生各自安好","date":"2018-01-12T00:39:39.000Z","path":"posts/1358971951/","text":"也许是因为年纪大了的缘故，渐渐地如同上瘾一般喜欢上怀旧，喜欢怀旧到了什么程度呢？想着再次重温下小马哥的英雄本色，想着再次感受下星球大战里的刀光剑影……可是每次都因为不同的原因而落空，之所以没有去看《英雄本色》，是因为附近的电影院都没有排片，那么这一次呢，好像是因为一部和前任有关的电影《前任攻略3：再见前任》。 或许前任与现任永远都是一道无解的题目，就如同网上流传着的一个问题，“我和你妈同时掉水里你会先救哪一个”，我们发现对这个问题而言，即使代入现任和前任这样的设定，它看起来依然是说得通的。那么，在我们心里是如何对待现任和前任的呢？我想，在很多人的潜意识里，前任代表了那个你曾经认定要一直走下去的人。我们曾经用天真对一个人好，发自内心地去爱，最终却用尽全力去遗忘释怀。这部电影所讲述的恰好是这样一个写实的场景。最近看到一段这样的话，我们总是用前任的错误惩罚下一任，或者是用对前任的亏欠弥补下一任。这两种做法均无可厚非，甚至听起来第二种做法更好，可如果扪心自问，到底是爱前任多些，还是爱现任多些，我想这是一个问题。电影里的两对情侣，孟云和林佳，余飞和丁点，同时因为生活中的矛盾分手，好兄弟和好闺蜜再度走到一起，这个时候，我们觉得失恋应该是痛苦的一件事情，没有喝醉到不省人事，没有悲伤到歇斯底里，这都不算做失恋吧。 可或许是我们想多了，有时候两个人分开以后，难过的只有自己，对对方而言或许是种解脱，于是我们在电影里看到了一幕幕单身男女嗨翻天的景象，我们常常听到这样一句话，两个人不合适就分手呗，讽刺的是，我们一边渴望着美好的爱情，一边对待感情弃若敝履，我们谈恋爱的时间越来越短，对彼此越来越没有耐心，有人说，这是因为我们长大了，知道20多岁的年龄，不能再像10多岁一样挥霍，像孟云和林佳这样的情侣，现实中举不胜举，为了彼此一点可怜的自尊，谁都不肯先放下身段同对方和解，等到矛盾积累得越来越多，任何一件事情都有可能成为，压死骆驼的最后一根稻草。这个时候，还要试图用扮演至尊宝说“我爱你”和疯狂吃芒果吃到过敏，这样幼稚可笑的事情来满足各自的虚荣心，好像我们每个人都实现了对彼此的承诺，真正爱你的人，怎么会舍得离开你呢，明明是自私得只懂得爱自己，非要坚持说是对方不够爱自己，真正爱你的人，爱一直都在心里。 我不知道这样一部电影，是如何让大家产生共鸣，在观影的时候哭得稀里哗啦的，电影中两位男主在“隔壁老王”，讨论是生男孩好还是生女孩好，讨论和双胞胎姐妹约会的好处，和一众长着网红脸的95后在Party上狂嗨……各种段子让分手变成一场狂欢，而狂欢下的两种状态，有余飞和丁点这种“以分手的名义，撒着思念的娇”的，有孟云和林佳这种因为沟通不善而渐行渐远的。我们常常听到一个词叫做合适，其实以人类这种奇葩的性格，又怎么会找到完全合适的两个人呢？这一切都是需要去不断磨合的，我们看待感情的角度是功利的，如果两个人走到一起甚至结婚，我们觉得这就是合适的，那么像孟云和林佳这种相爱五年的情侣，我觉得我们很难用一句合适或者不合适来说说清楚，两个人在一起一定要多沟通，有问题不要想着第二天再解决。在感情中不要用“作”这种手段去测试对方，一个人喜欢你，愿意忍让你，并不代表你可以毫无底线。也许很多时候，我们都喜欢把话埋在心里，我们都觉得谁先主动谁就输啦，即使此刻赢得了面子，最终还是会输掉了里子。 这部电影可谓是为“前任系列”画上了一个完美的结局，然而这样一部名不见经传的电影，可以在猫眼电影上获得9.2分的高分，一度超越近期口碑极佳的《芳华》，这种前半段走肾后半段走心的编排方式，成功地将观众的情绪带向高潮。有人说在这部电影里找到了自己的影子，可在我看来大家都在努力给自己加戏，两个人会分开一定是有某种原因的，我们总幻想着离开的时候，如何惊天地泣鬼神一般轰轰烈烈，可真正的离开从来都是悄无声息的。一场体面的分手，是两个彼此伤痕累累的的人，在面对这段感情时，即使知道其中存在的问题，但是发现一切再无法回到以前，因为在这个被称为成长的过程中，感情早已被当作燃料的消耗殆尽。所以，我们说：我依然爱你，但我不再喜欢你了，所以我们只能走到这里了。体面的分手，或许应该是这个样子的，是一切大彻大悟以后的慈悲，是用尽了力气后的平静，是虽然结局不如意，但我没有后悔遇见你，是接受成长带来的痛苦，是学会如何更好地爱自己、爱别人。 有人说，前任就像黑夜中摇曳着的烛火，坍塌在无边的夜色中。或许会有无数根的蜡烛，能照亮你的黑暗，但再不会有这样一个人，能这样一往无前地在黑暗中，为你烫出一个洞，然后用温暖填满。成长是件非常痛苦的事情，你不一定会得到什么，但一定会失去什么，有些人注定是让你成长的，所以请好好再见，不负遇见。有些人会永远停留在你的心里，他们曾经出现，并成为你人生的一部分，我们会爱上下一个，再下一个。放过前任，放过自己，这或许是最好的结局。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"前任","slug":"前任","permalink":"https://qinyuanpei.github.io/tags/%E5%89%8D%E4%BB%BB/"},{"name":"公众号","slug":"公众号","permalink":"https://qinyuanpei.github.io/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/"}]},{"title":"《C#多线程编程实战》读书笔记","date":"2018-01-07T21:34:36.000Z","path":"posts/345410188/","text":"本文是一篇读书笔记，由《C#多线程编程实战》一书中的内容整理而来，主要梳理了.NET中多线程编程相关的知识脉络，从Thread、ThreadPool、Task、async/await、并发集合、Parallel、PLINQ到Rx及异步I/O等内容，均有所覆盖。为了帮助大家理解本文内容，首先给出博主在阅读该书过程中绘制的思维导图，大家可以根据个人需要针对性的查漏补缺。 《多线程编程实战》思维导图 线程基础 Tips1：暂停线程，即通过Thread.Sleep()方法让线程等待一段时间而不用消耗操作系统资源。当线程处于休眠状态时，它会占用尽可能少的CPU时间。 Tips2：线程等待，即通过Join()方法等待另一个线程结束，因为不知道执行所需要花费的时间，此时Thread.Sleep()方法无效，并且第一个线程等待时是处于阻塞状态的。 Tips3：终止线程，调用Abort()方法会给线程注入ThreadAbortException异常，该异常会导致程序崩溃，且该方法不一定总是能终止线程，目标线程可以通过处理该异常并调用Thread.ResetAbort()方法来拒绝被终止，因此不推荐使用Abort()方法来终止线程，理想的方式是通过CancellationToken来实现线程终止。 Tips4：线程优先级，线程优先级决定了该线程可占用多少CPU时间，通过设置IsBackground属性可以指定一个线程是否为后台线程，默认情况下，显式创建的线程都是前台线程。其主要区别是：进程会等待所有的前台线程完成后再结束工作，但是如果只剩下后台线程，则会直接结束工作。需要注意的是，如果程序定义了一个不会赞成的前台线程，主程序并不会正常结束。 Tips5：向线程传递参数，可以通过ThreadStart或者lambda表达式来向一个线程传递参数，需要注意的是，由lambda表达式带来的闭包问题 Tips6：竞争条件是多线程环境中非常常见的导致错误的原因，通过lock关键字锁定一个静态对象(static&amp;readonly)时，需要访问该对象的所有其它线程都会处于阻塞状态，并等待直到该对象解除锁定，这可能会导致严重的性能问题， Tips7：发生死锁的原因是锁定的静态对象永远无法解除锁定，通常Monitor类用以解除死锁，而lock关键字用以创建死锁，Monitor类的TryEnter()方法可以用以检测静态对象是否可以解锁，lock关键字本质上是Monitor类的语法糖。123456789101112bool acquiredLock = false;try&#123; Monitor.Enter(lockObject, ref acquiredLock)&#125;finally&#123; if(acquiredLock) &#123; Monitor.Exit(lockObject) &#125;&#125; Tips8：不要在线程中抛出异常，而是在线程代码中使用try…catch代码块。线程同步 Tips9：无须共享对象，则无须进行线程同步，通过重新设计程序来移除共享状态，从而避免复杂的同步构造；使用原子操作，这意味着一个操作只占用一个量子的时间，一次就可以完成，并且只有当前操作完成后，其它线程方可执行其它操作，因此，无须实现其它线程等待当前操作完成，进而避免了使用锁，排除了死锁。 Tips10：为了实现线程同步，我们不得不使用不同的方式来协调线程，方式之一是将等待的线程设为阻塞，当线程处于阻塞状态时，会占用尽可能少的CPU时间，然而这意味着会引入至少一次的上下文切换。上下文切换，是指操作系统的线程调度器，该调度器会保存等待的线程状态，并切换到另一个线程，依次恢复等待的线程状态，而这需要消耗更多的资源。 Tips11：线程调度模式，当线程挂起很长时间时，需要操作系统内核来阻止线程使用CPU时间，这种模式被称为内核模式；当线程只需要等待一小段时间，而不需要将线程切换到阻塞状态，这种模式被称为用户模式；先尝试按照用户模式进行等待，如线程等待足够长时间，则切换到阻塞状态以节省CPU资源，这种模式被称为混合模式。 Tips12：Mutex是一种原始的同步方法，其只对一个线程授予对共享资源的独占访问，Mutex可以在不同的程序中同步线程。 Tips13：SemaphoreSlim是Semaphore的轻量级版本，用以限制同时访问同一个资源的线程数量，超过该数量的线程需要等待，直到之前的线程中某一个完成工作，并调用Release()方法发出信号，其使用了混合模式，而Semaphore则使用内核模式，可以在跨程序同步的场景下使用。 Tips14：AutoResetEvent类用以从一个线程向另一个线程发送通知，该类可以通知等待的线程有某个事件发生，其实例在默认情况下初始状态为unsignaled，调用WaitOne()方法时将会被阻塞，直到我们调用了Set方法；相反地，如果初始状态为signaled，调用WaitOne()方法时将会被立即处理，需要我们再调用一次Set方法，以便向其它线程发出信号。 Tips15：ManualResetEventSlim类是使用混合模式的线程信号量，相比使用内核模式的AutoResetEvent类更好(因为等待时间不能太长)，AutoResetEvent像一个旋转门，一次仅允许一个人通过，而ManualResetEventSlim是ManualResetEvent的混合版本，一直保持大门开启直到手动屌用Reset方法。 Tips16：EventWaitHandle类是AutoResetEvent和ManualResetEvent的基类，可以通过调用其WaitOne()方法来阻塞线程，直到Set()方法被调用，它有两种状态，即终止态和非终止态，这两种状态可以相互转换，调用Set()方法可将其实例设为终止态，调用Reset()方法可以将其实例设为非终止态。 Tips17：CountdownEvent类可以用以等到直到一定数量的操作完成，需要注意的是，如果其实例方法Signal()没有达到指定的次数，则其实例方法Wait()将一直等待。所以，请确保使用CountdownEvent时，所有线程完成后都要调用Signal()方法。 Tips18：ReaderWriterLockSlim用以创建一个线程安全的机制，在多线程中对一个集合进行读写操作，ReaderWriterLockSlim代表了一个管理资源访问的锁，允许多个线程同时读取，以及独占写。其中，读锁允许多线程读取数据，写锁在被释放前会阻塞其它线程的所有操作。 Tips19：SpinWait类是一个混合同步构造，被设计为使用用户模式等待一段时间，然后切换到内核模式以节省CPU时间。使用线程池 Tips20：volatile关键字指出一个字段可能会被同时执行的多个线程修改，声明为volatile的字段不会被编译器和处理器优化为只能被单线程访问。 Tips21：创建线程是昂贵的操作，所以为每个短暂的异步操作创建线程会产生显著的开销。线程池的用途是执行运行时间短的操作，使用线程池可以减少并行度耗费及节省操作系统资源。在ASP.NET应用程序中使用线程池时要相当小心，ASP.NET基础切实使用自己的线程池，如果在线程池中浪费所有的工作者线程，Web服务器将不能够服务新的请求，在ASP.NET中只推荐使用I/O密集型的异步操作，因为其使用了一个不同的方式，叫做I/O线程。 Tips22：APM，即异步编程模型，是指使用BeginXXX/EndXXX和IAsyncResult对象等方式，其通过调用BeginInvoke方法返回IAsyncResult对象，然后通过调用EndInvoke方法返回结果，我们可通过轮询IAsyncResult对象的IsCompleted或者调用IAsyncResult对象的AsyncWaitHandle属性的WaitOne()方法来等待直到操作完成。 Tips23：ThreadPool.RegisterWaitForSingleObject()方法允许我们将回调函数放入线程池中的队列中，当提供的等待事件处理器收到信号或发生超时时，该回调函数将被调用，这做鱼我们为线程池中的操作实现超时功能。具体思路是：ManualResetEvent + CancellationToken，当接收到ManualResetEvent对象的信号时处理超时，或者是使用CancellationToken来处理超时。 Tips24：CancellationToken是.NET4.0中被引入的实现异步操作的取消操作的事实标准，我们可以使用三种方式来实现取消过程，即轮询IsCancellationRequested属性、抛出OperationCanceledException异常、为CancellationToken注册一个回调函数。 Tips25：Timer对象用以在线程池中创建周期性调用的异步操作。 Tips26：BackgroundWorker组件，是典型的基于事件的异步模式，即EAP，当通过RunWorkerAsync启动一个异步操作时，DoWork事件所订阅的事件处理器，将会运行在线程池中，如果需要需要取消异步操作，则可以调用CancelAsync()方法。使用任务并行库 Tips27：TPL即任务并行库，在.NET 4.0中被引入，目的是解决APM和EAP中获取结果和传播异常的问题，TPL在.NET4.5中进行了调整，使其在使用上更简单，它可以理解为线程池之上的又一个抽象层，对程序员隐藏了与线程池交互的底层代码，并提供了更方便的细粒度的API。TPL的核心概念是任务，一个任务代表了一个异步操作，该操作可以通过多种方式运行，可以使用或者不使用独立线程运行。TPL相比之前的模式，一个关键优势是其具有用于组合任务的便利的API。 Tips28：Task.Run是Task.Factory.StartNew的一个快捷方式，后者有附加的选项，在无特殊需求的情况下，可以直接使用Task.Run，通过TaskScheduler，我们可以控制任务的运行方式。 Tips29：使用Task实例的Start方法启动任务并等待结果，该任务会被放置在线程池中并且主线程会等待，直到任务返回前一直处于阻塞状态；使用Task实例的RunSynchronously方法启动任务，该任务是运行在主线程中，这是一个非常好的优化，可以避免使用线程池来执行非常短暂的操作；我们可以通过轮询Task实例的状态信息来判断一个任务是否执行结束。 Tips30：通过Task实例的ContinueWith方法可以为任务设置一个后续操作，通过TaskContinuationOptions选项来指定后续任务以什么样的方式执行。 Tips31：通过Task实例的FromAsync可以实现APM到Task的转换 Tips32：通过TaskCompletionSource可以实现EAP到Task的转换 Tips33：TaskScheduler是一个非常重要的抽象，该组件实际上负责如何执行任务，默认的任务调度程序将任务放置在线程池的工作线程中。为了避免死锁，绝对不要通过任务调度程序在UI线程中使用同步操作，请使用ContinueWith或async/await方法。使用C# 6.0 Tips34：异步函数是C# 5.0引入的语言特性，它是基于TPL之上的更高级别抽象，真正简化了异步编程。要创建一个异步函数，首先需要使用async关键字标注一个方法，其次异步函数必须返回Task或Task类型，可以使用async void的方法，但是更推荐async Task的方法，使用async void的方法的唯一合理的地方就是在程序中使用顶层UI控制器事件处理器的时候，在使用async关键字标注的方法内部，可以使用await操作符，该操作符可与TPL任务一起工作，并获取该任务中异步操作的结果，在async方法外部不能使用await关键字，否则会有编译错误，异步函数代码中至少要拥有一个await关键字。 Tips35：在Windows GUI或ASP.NET等环境中不推荐使用Task.Wait和Task.Result，因为非常有可能会造成死锁。async可以和lambda表达式联用，在表达式体中应该至少含有一个await关键字标示，因为lambda表达式的类型无法通过自身推断，所以必须显式地向C#编译器指定类型。 Tips36：异步并不总是意味着并行执行 Tips37：单个异步操作可以使用try…catch来捕获异常，而对于一个以上的异步操作，使用try…catch仅仅可以从底层的AggregateException对象中获得第一个异常，为了获得所有的异常，可以使用AggregateException的Flatten()方法将层级异常放入一个列表，并从中提取出所有的底层异常。 Tips38：通过Task实例的ConfigureAwait()方法，可以设置使用await时同步上下文的行为，默认情况下，await操作符会尝试捕捉同步上下文，并在其中执行代码，即调度器会向UI线程投入成千上百个后续操作任务，这会使用它的消息循环来异步地执行这些任务，当我们不需要在UI线程中运行这些代码时，向ConfigureAwait方法传入false将会是一个更高效的方案。 Tips39：async void方法会导致异常处理方法，会放置到当前的同步上下文中，因此线程池中未被处理的异常会终结整个进程，使用AppDomain.UnhandledException事件可以拦截未处理的异常，但不能从拦截的地方恢复进程，async void的lambda表达式，同Action类型是兼容的，强烈建议仅仅在UI事件处理器中使用async void方法，在其他情况下，请使用返回Task或者Task的方法。使用并行集合 Tips40：ConcurrentQueue使用了原子的比较和交换(CAS)，以及SpinWait来保证线程安全，它实现了一个先进先出(FIFO)的集合，这意味着元素出队列的顺序与加速队列的顺序是一致的，可以调用Enqueue方法向对接中加入元素，调用TryDequeue方法试图取出队列中第一个元素，调用TryPeek方法试图得到第一个元素但并不从队列中删除该元素。 Tips41：ConcurrentStack的实现同样没有使用锁，仅采用了CAS操作，它是一个后进先出(LIFO)的集合，这意味着最后添加的元素会先返回，可以调用Push和PushRange方法添加元素，使用TryPop和TryPopRange方法获取元素，使用TryPeek方法检查元素。 Tips42：ConcurrentBag是一个支持重复元素的无序集合，它针对以下情况进行了优化，即多个线程以这样的方式工作：每个线程产生和消费其自身的任务，极少发生线程间的交互(因为要交互就要使用锁)。可以调用Add方法添加元素，调用TryPeek方法检查元素，调用TryTake方法获取元素。 Tips43：ConcurrentDictionary是一个线程安全的字典集合的实现，对于读操作无需使用锁，对于写操作则需要使用锁，该并发字典使用多个锁，在字典桶之上实现了一个细粒度的锁模型(使用锁的常规字典称为粗粒度锁)，参数concurrentLevel可以在构造函数中定义锁的数量。这意味着预估的线程数量将并发地更新该字典。由于并发字典使用锁，如无必要请避免使用以下操作：Count、IsEmpty、Keys、Values、CopyTo及ToArray，因为需要获取该字典中的所有锁。 Tips44：BlockingCollection是一个针对IProducerConsumerCollection泛型接口实现的高级封装，它有很多先进的功能来实现管道场景，即当你有一些步骤需要使用之前步骤运行的结果时。BlockingCollection类支持分块、调整内部集合容量、取消集合操作、从多个块集合中获取元素等。 Tips45：对BlockingCollection进行迭代时，需要注意的是，使用GetConsumingEnumerable()进行迭代，因为虽然BlockingCollection实现了IEnumerable接口，但是它默认的行为是表示集合的“快照”，这不是我们期望的行为。使用PLINQ Tips46：将程序分割成一组任务并使用不同的线程来运行不同的任务，这种方式被称为任务并行将数据分割成较小的数据块，对这些数据进行并行计算，然后聚合这些计算结果，这种编程模型称为数据并行 Tips47：结构并行确实更易维护，应该尽可能地使用，但它并不是万能的。通常有很多情况我们是不能简单地使用结构并行，那么以非结构化的方式使用TPL任务并行也是完全可以的。Parallel类中的Invoke方法是最简单的实现多任务并行的方法，Invoke方法会阻塞其它线程直到所有线程都完成。 Tips48：Parallel类中的For和ForEach方法可以定义并行循环，通过传入一个委托来定义每个循环项的行为，并得到一个结果来说明循环是否成功完成，ParallelOptions类可以为并行循环定义最大并行数，使用CollectionToken取消任务，使用TaskScheduler类调度任务。 Tips49：ParallelLoopState可以用于从循环中跳出或者检查循环状态，它有两种方式：Break和Stop，Stop是指循环停止处理任何工作，而Break是指停止其之后的迭代，继续保持其之前的迭代工作。 Tips50：同Task类似，当使用AsParallel()方法并行查询时，我们将得到AggregateException，它将包含运行PLINQ期间发生的所有异常，我们可以使用Flatten()方法和Handle()方法来处理这些异常。 Tips51：ParallelEnumerable类含有PLINQ的全部逻辑，并且作为IEnumerable集合功能的一组扩展方法，默认情况下结果会被合并单个线程中，我们可以通过ForAll方法来指定处理逻辑，此时它们使用的是同一个线程，将跳过合并结果的过程，除了AsParallel()方法，我们同样可以使用AsSequential()方法，来使得PLINQ查询以顺序方式执行(相对于并行) Tips52：PLINQ中提供了丰富用以PLINQ查询的选项，例如WithCancellation()方法用以取消查询，这将导致引发OperationCanceledException异常，并取消剩余的工作；例如WithDegreeOfParallelism()方法用以指定执行查询时实际并行分割数，可以决定并行执行会占用多少资源及其性能如何；例如WithExecutionMode()可以重载查询执行的模式，即我们可以决定选择以顺序执行还是并行执行的方式去执行查询；例如WithMergeOptions()方法可以用以调整对查询结果的处理，默认PLINQ会将结果合并到单个线程中，因此在查询结果返回前，会缓存一定数量的结果，当发现查询花费大量时间时，更合理的方式是关闭结果缓存从而尽可能快地得到结果；例如AsOrdered()方法，用以告诉PLINQ我们希望按照集合中的顺序进行处理(并行条件下，集合中的项有可能不是按顺序被处理的)使用异步I/O Tips53：异步I/O，对服务器而言，可伸缩性是最高优先级，这意味着单个用户消耗的资源越少越好，如果为每个用户创建多个线程，则可伸缩性并不好，在I/O密集型的场景中需要使用异步，因为不需要CPU工作，其瓶颈在磁盘上，这种执行I/O任务的方式成为I/O线程。在异步文件读写中，FileOptions.Asynchronous是一个非常重要的选项，无论有无此参数都可以，以异步的方式使用该文件，区别是前者仅仅是在线程池中异步委托调用，而后者可以对FileStream垒使用异步I/O。 Tips54：对HttpListener类，我们可以通过GetContextasync()方法来异步地获取上下文。 Tips55：对数据库而言，我们可以通过OpenAsync()、ExecuteNonQueryAsync()等方法异步地执行SQL语句。 好了，以上就是这篇读书笔记的主要内容啦，听说掌握了这55条Tips的人，都敢在简历上写”精通多线程编程“，哈哈，晚安啦，各位！","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"多线程","slug":"多线程","permalink":"https://qinyuanpei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"},{"name":"编程","slug":"编程","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E7%A8%8B/"},{"name":"笔记","slug":"笔记","permalink":"https://qinyuanpei.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"读书","slug":"读书","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%BB%E4%B9%A6/"}]},{"title":"2017，在驻足间回首","date":"2017-12-31T21:30:45.000Z","path":"posts/2676125676/","text":"&emsp;&emsp;当朋友圈开始集体缅怀18岁的时候，我们说，从此以后是00后的天下，因为所以的90后都成年了。或许我们都是喜欢怀旧的人，所以我们选择以这样一种方式，在狂欢中失去的同时，在失去中缅怀着，仿佛这种死磕到底的做法，会让这一切来得更晚一些。一群人抱着手机等待着新年的到来，和曾经无数个无眠的夜晚一样，我们并不知道明天会有什么，就像钟表的指针哒哒地作响，生命的齿轮永不停歇地转动。我们习惯性地期盼明天会更好，因为我们都知道“往者不可谏，来者犹可追”。那么，在新年钟声敲响以前，让记忆彻底来一场独自的狂欢吧！ 多情应笑我&emsp;&emsp;我不知道该从哪里开始回顾我的2017年，如果一定要找一个起点开始说，我想应该是裴武刚离开西安。那时青龙寺樱花正在盛开，在他离开西安以前，我曾带他一起去那里游玩。他曾遗憾没有好好在西安游玩一番，在分别前我们一起去吃羊肉泡馍，真正体会到什么叫做相顾无言，直到十一回家去兰州转车，我们再次联系到彼此，所以当你想做一件事情的时候，最好就是趁着现在去做，一个过期的承诺是没有意义的，人生本就是大海里航行的一叶扁舟，你可以祈祷它不遭遇狂风暴雨，可事实上你并不能替任何人做这样一个决定，越想做好一件事情就越是要减少拖延。“人生不相见，动如参与商”，人生本不完美，缺憾能少一分便是一分。 &emsp;&emsp;我记得我们吃完泡馍，两个人都抢着付钱，老板娘笑着说：“大家都是好朋友，谁付都是一样的，以后还有机会”。两个人一阵默然。从那时算起，到今天差不多8个月，我们再没有见过面，偶尔会在微信上聊聊天。人生的无奈就在于，你埋头忙碌的时候，对离别的处境毫不在意，等到你过头来再看时，不禁怅然若失，感情就这样一天天变淡，可是不是你努力融入对方的生活，就能够留住彼此在心中的位置呢？有人告诉我，她不属于你，她不适合你，可是不是换一个性格完全相反的人，就一定会是合适的人选呢？我们的大脑，同绝对理性的计算机最大的不同是，我们评价和认识一个人的标准，永远没有办法达到统一，就像你喜欢吃葱，而我喜欢吃香菜，你不能因此指责别人三观不正，这或许仅仅是你们的喜好不同而已，这个理性而感性的世界，有时真的让人抓狂。 &emsp;&emsp;我一直没有告诉任何人，我和小古分开快两年的时间了。有人说，时间会慢慢磨去一切痕迹，而对于她，始终就像我心上的一颗痣，时间会把它变成一颗琥珀，时间越久越显得珍贵，我知道有人会嘲笑这固执的感情，就像我会在分开一年后，坐一个晚上的火车到洛阳，仅仅是为了见她一面而已，我永远记得她穿裙子的样子，我永远记得那条挂满灯笼的路，我永远都想再抱她一次……我听到莎莉花园的时候，会突然想起那个下午，当我们听到一家店里传来的音乐声，我们互相对彼此说我知道……我们在彼此不成熟的年龄深爱上彼此，等一天幡然醒悟的时候发现追悔莫及，离开她以后我发现我会单身很久，因为除了她我好像都不会同别人谈恋爱，这种迹象在我身上更加明显，因为无论你怎么尝试去改变，你永远无法逃开被拒绝的命运。我们喜欢喜欢一个人的时候，通常靠眼缘这种特别主观的东西，可太多时候我们无法完全了解一个人。 &emsp;&emsp;从前我们喜欢一个人的时候，喜欢爱得轰轰烈烈，相信爱情可以战胜一切；等到长大以后，我们习惯爱得小心谨慎，试探和套路混杂不清真真假假。有人告诉你，要相信爱情是存在的，你只是还没有等到那个合适的人出现；有的人告诉你，不要在一棵树上吊死。成年人的感情和时间都非常有限，不要把精力浪费在一个不喜欢你的人身上。可兜兜转转就到了25岁，一个谈爱已晚、谈死尚早的尴尬年纪。有时候我会想，大学毕业了就可以结婚成家的人，或许是最幸福的人，因为你再找不到那样单纯的爱情。我见过情侣间吵架无数分分合合，我见过向现实妥协随便找个人结婚……我想找一个可以托付终生的人，因为父母总有一天会先我们而去，如果需要有人陪伴在我生命的一刻，我希望那个人会是你，可我决不会如此自私，因为我不想你在这个世界里孤单。我曾被人温柔地对待过，我想温柔地对待你，不是因为亏欠或者内疚而弥补什么，而是我知道“爱人者人恒爱之”。 &emsp;&emsp;我曾经被一个女孩子拒绝过，我天真的以为，出场顺序会决定两个人的命运，直到她平静地说出，“就算我不和他在一起，我绝不会和你在一起“，原来一个在小古心里待她特别好的人，在别人眼中居然是如此的不堪，我记得我在她面前结结巴巴说英语的窘迫，我记得她告诉我她要订婚时我写满难过的脸……我好像被施诅咒一样，在和小古分开后，我喜欢过两个有男朋友的女生，有时候我都想告诉自己，我不再是那个十八九岁的少年，长大以后的爱情夹杂着现实，变得更加让人迷惑，可我再找不回那种“赌书泼茶”的感觉，或许求而不得是人生常态，王尔德说“人生有两种悲剧，一种是想得到的得不到，一种是想得到的得到了”，我对小古说，给我留一个梦好吗？她说好的呀。对这个世界而言，我们两个人的故事，或许一点都不美丽。可真正让我怀念的，恰好是这些微不足道的故事，有时候我会分不清，喜欢的到底是真实的她，还是想象中的她，或许我真正喜欢的，是曾经那个年轻而勇敢的少年，佛家有”贪嗔痴慢疑“，所谓五毒心者，都说人要学会放下执念，可如果从来没有得到过，又要放下什么呢？人因为“求而不得”而痛苦，从来没有拥有过的人，是无所谓拿起和放下的。 做人没意思&emsp;&emsp;大概从8月份开始学习做饭，而学习做饭的动机早就模糊不清，我只知道，从那一刻开始，我的生活开始慢慢发生变化，从一个不知道做饭需要买什么调味品的人，变成一个喜欢逛超市、喜欢看商品价格的人，变成一个喜欢周末去超市购物、喜欢钻研美食的人，变成一个懂得如何照顾自己、爱惜自己的人。西安的面食对我而言是粗犷的，如同这片关中大地上粗犷的民风，所以最初就买了本菜谱学习做饭，我学做饭的动机，其实是非常简单的，最低要求是以后讨不着老婆不会饿死自己，进阶要求是两口子过日子必须要有一个具备这项生活技能，现在我们看到有把吃作为爱好的吃货，可这样的人是不能称之为吃货的，因为吃货如果就是花花钱动动嘴这样简单，就对不起古往今来的吃货们，譬如苏东坡之于红烧肉，季鹰之于鲈鱼，袁枚之于《随园食单》，能做会吃这是真吃货。有人说，征服一个吃货的心，首先要征服她的胃。可也许这仅仅是一个理由，当你征服她的胃，你会发现还有更多的东西等你去征服。现在，先让我征服这本菜谱，我刚刚学会其中的10来道家常小炒。 &emsp;&emsp;除了做饭这件事情以外，我一直在坚持的事情是读书，去年国庆的时候买了Kindle，而年初则办理了省图的借书卡。一旦这两者结合起来以后，读书就变成了一件趣事。因为Kindle不擅长阅读技术类书籍，所以技术类书籍主要来自纸质书，而人文类书籍主要来自电子书。最早是Wesley推荐读陈忠实的《白鹿原》，这本书让我了解了许多陕西的风土人情。在同名电视剧中，张嘉怡饰演的白嘉轩，生平念念不忘的是妻子亲手做的油泼面。陕西的面食的确让人印象深刻，原本出生在北方的我，在这里仿佛第一次来到北方。此外，由电影《嫌疑人X的献身》追溯到原著，逐渐接触了《白夜行》和《解忧杂货店》这样典型的东野圭吾作品，程浩的《站在两个世界边缘》，毛姆的《月亮与六便士》，堀辰雄的《起风了》，《小王子》，沈复的《浮生六记》以及《追风筝的人》，而纸质书基本都是Web前后端(JavaScript/ASP.NET/SPA)相关的书籍，Python相关的书籍和数学相关的书籍，这些书籍不能在这里展开讨论，感兴趣的朋友可以在博客里留言。 &emsp;&emsp;我是一个喜欢看电影的人，就是单纯地喜欢听人讲故事，这和约会意义上的看电影不同，我就是单纯地去看个电影而已。不过作为一个日常单身狗，总是要学会面对这个世界里满满的恶意。2017年看的第一部电影是韩寒的《乘风破浪》，这是一个笑点中夹杂着泪点的故事，剧情上借鉴了陈可辛导演的《难兄难弟》。接下来，2017年看过的超级英雄电影有《神奇女侠》、《蜘蛛侠 : 归来》、《雷神 : 诸神的黄昏》、《猩球崛起》。2017年看过的动画电影有《大护法》和《寻梦环游记》，其中前者是电影风格和政治隐寓吸引了我，而后者是讲述了一个亡灵节背景下的暖心故事，告诉我们如何去面对死亡、如何平衡家庭与梦想等。2017年看过一部讲述野外探险的电影《七十七天》，由赵汉唐和江一燕主要，这个电影是部旅游风景片，江一燕的存在感略弱，男主最终在雷雨夜里丧生，告诫人们要懂得量力而行，我们觉得去趟西藏就能净化心灵，可比净化心灵更重要的是好好活着。2017年最后一部电影是陈凯歌的《妖猫传》，改编自梦枕貘的《沙门空海》，以唐朝时期僧人空海和诗人白居易为主角，讲述唐玄宗和杨玉环的爱恨纠葛，这部电影视觉美是无与伦比的，虽然后期剧情呈现方式存在瑕疵，但可以让我们重新感受大唐盛景，以一种新的方式解读《长恨歌》，我觉得这样就很好啦！ emsp;&emsp;2017年写作方面相对去年明显退步，因为有两个月一直没有时间写东西，尤其是拖延症发作的时候，一篇博客大概两三个周甚至一个月方能写完，这大概是2017年最让人遗憾的事情。2017年共撰写博客16篇，访客量增加约30万，受到CSDN运营梦姐的离开以及CSDN战略调整的影响，2017年博客流量的主要来源是旧文章。2017年技术博客的写作，基本延续2016年的策略，不再写面向新手的教程类内容，而是侧重对技术的整合和改进，尽可能地去写一种思路或者想法，与此同时，希望在技术博客以外扩展更多的，譬如写对生活的感悟、对电影的思考等等，计划中打算开通知乎专栏(已开通)、开通个人微信公众号(正在准备)。总而言之，希望拓宽博客的流量渠道，提升个人品牌的影响力，你可以不用长得特别帅，但要有一种不怒自威的气场，因为要想成为架构师，这是件任重而道远的事情！ New TodoList(“2018”)&emsp;&emsp;写这样一个TodoList，我总觉得像在立一个个flag，因为2017年计划的MongoDB就没有达到目标，所以2018的TodoList我希望可以更接地气一点，具体来讲，我从技术、生活两个方面来制定目标： 首先，希望2018年的我在技术方面： 学会一个前端框架(Vue/Angular/React) 继续完善HttpServer(支持RESTful) Web后端认证授权及中间件(OWIN/OAuth) 继续学习Python数据分析(Pandas) 写一个微信小程序(词典/小工具) 建立知乎专栏/个人微信公众号 其次，希望2018年的我在生活方面： 认真谈恋爱，找个女朋友 提升整体审美及品味(穿衣/吃饭/健身) 去一趟莫高窟或者苏州园林(做想做的事) 争取涨薪，继续存钱 租一个可以更好做饭的房子 和任何人都聊得来(沟通技巧/情商) 2018，愿期望不负，愿你被温柔对待，岁月静好，现世安稳，心安处即吾家，晚安！","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"总结","slug":"总结","permalink":"https://qinyuanpei.github.io/tags/%E6%80%BB%E7%BB%93/"},{"name":"回首","slug":"回首","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%9E%E9%A6%96/"},{"name":"展望","slug":"展望","permalink":"https://qinyuanpei.github.io/tags/%E5%B1%95%E6%9C%9B/"},{"name":"随笔","slug":"随笔","permalink":"https://qinyuanpei.github.io/tags/%E9%9A%8F%E7%AC%94/"}]},{"title":"基于新浪微博的男女性择偶观数据分析(上)","date":"2017-12-23T20:28:40.000Z","path":"posts/1386017461/","text":"&emsp;&emsp;或许是因为我喜欢的姑娘从来都不喜欢我，而感情上的挫折一度让我陷入无尽的自卑。朋友在朋友圈里发布一条关于皮影戏的动态，我开玩笑说这个皮影戏结局应该是个悲剧，因为我注意到在剧中，无论一个人如何卖力地表演甚至双腿跪倒在地，有的人从故事开场到结束一直对此无动于衷。朋友回复我说，这不就是你现在的状态吗？我沉默半天终于熄灭手机屏幕。我听到过各种各样让我放弃她的话，即使这种念头在我脑海里萌生已久，是幻想让我硬生生地拖了这么久。当你努力想要融入对方的生活，而等待你的是一道冰冷的墙。这种感觉像什么呢？大概就是一个又一个“好友”安安静静地躺在联系人的置顶名单里，不敢发消息让对方知道，更不愿残忍地把对方删除。我安慰自己说，对我而言，我失去的是一个不喜欢你的人；而对对方而言，失去的是一个喜欢她的人。你当然可以说我没有那么喜欢她，如果一定要喜欢到卑微如尘土的地步，我宁愿一个人单身到天荒地老。 &emsp;&emsp;当我意识到人与人间，即使亲近如父母尚且无法完全理解彼此的时候，我忽然发现一个有趣的现象，我们喜欢一个人的时候，首先注意到的会是外表，我们将其称之为眼缘，所以人与人间的感情纽带最初会是吸引，而后是了解彼此的优缺点，最终是相互理解和扶持。可我们知道，外表是可以伪装出来的，所以我们习惯通过外表和言语来评价一个人，这就像是数学归纳法，我们总认为推倒第一块多诺米骨牌，就意味着所有多诺米骨牌都会倒下。可现实世界矛盾的地方就在于，我们认为理所当然正确的事情，或许正是我们无法证明其正确性的，这在数学上称为哥德尔不完备定理。所以，一件残酷的事情是，当你无法吸引一个人的时候，通往内心世界的路就被堵死了。朋友圈里精彩纷呈的社交互动，并不代表有人愿意真正了解你的生活，何况是你吸引不到的人呢？我很想知道，我们在选择伴侣的时候到底看中什么，所以我一直在关注@西安月老牵线上发布的征婚交友类微博，本文的故事从这里正式展开。 身高175的悲伤&emsp;&emsp;或许你以为我会无聊到试图从微博上找到女朋友，可事实上作为一个程序员的我，即使整天投入精力在编程上，依然无法避免对象空引用的异常出现。如果说找到女朋友是个小概率事件，那么在我看来，找到一个真正懂我、喜欢我的女朋友，基本上是不可能事件。你不要觉得我对没有调整好心态、对生活过分悲观，如果你了解贝叶斯公式就会真正地理解我说的话。这个微博开始引起我的注意，是我发现身高在155到165左右的女生，对男生的要求基本上无疑例外地是175+到180+，我想知道到底有多少女生是有这样的想法，这是我想要抓取新浪微博的数据进行分析的初衷。更重要的是，身高不到175的我在面对这种要求的时候是悲伤的，因为我想起了《巴黎圣母院》中的卡西莫多，一个外表丑陋而拥有高尚人格的“丑八怪”。现代人整天都特别忙碌，以至于没有人会有耐心，园艺在忍受着你丑陋的外表的同时，同你讲一只小兔子亲了它喜欢的长颈鹿一下这种故事。 &emsp;&emsp;我听到这样一句话，“好看的皮囊千篇一律，有趣的灵魂万里挑一”，可谁会觉得像卡西莫夫这样的人，会拥有或者配拥有高尚的人格呢？我们这副皮囊不管好看与否，它们都是父母给予我们的最好的礼物。难道一个所谓情商高的人，会在收到别人的时候因为礼物不好看而生气吗？ 我想起《画心》里懊悔受狐妖小唯皮相蛊惑而自毁双目的霍心，美丑都是父母赐予我们的，不该被我们拿来一番大肆炫耀，可我还是想知道，我们评价一个人的标准到底是什么？因为我渐渐明白，有些人不喜欢我们，并不是我们不好，而仅仅是某一点和对方不匹配。喜欢一个人的时候，像拔下身上的一根根刺，因为你越是得不到回应，就越像变成对方期待的样子，这个过程会让你觉得自己一无是处。直到今天看到一句话，一句足以热泪盈眶的话，如果不曾喜欢你，我本来非常可爱的。有时候，人做一件事情，或许就是在和自己过不去，比如说这件事情。 花点时间爬爬微博&emsp;&emsp;好了，现在我们来考虑从新浪微博上抓取@西安月老牵线上发布的微博，因为这是我们进行数据分析的前提。事实上，在写这篇文章前我曾花了大量时间来调试爬虫，然后用了一天的时间对数据进行清洗，最终利用晚上下班的时间生成词云。由此我们可以理出整体的思路： 流程图 &emsp;&emsp;通过流程图我们可以注意到，在这里我选择了Python来实现整个功能。转眼间我已经25岁了，这是种什么样的概念呢？两年前我23岁的时候，听别人讨论结婚这个问题，我觉得它离我还很遥远。如今看着周围人都结婚了，我竟有种“高处不胜寒”的感觉。所以呢，人生苦短，当你不能阻止时间一天天消逝的时候，你只能趁着现在去做你想做的事情，为了节省时间去做技术以外的尝试，我选择拥有全世界最丰富的库的Python。 &emsp;&emsp;这段时间学习数据分析，我渐渐意识到我们所熟悉的这个世界，如果以一种理性的角度，完全通过数据来解构的话，我们在这个数字时代里留下的每一条讯息，都冷冰冰地暴露着我们的喜怒哀乐，每一张照片里细微的表情变化，每一段文字里隐匿着的真实意图，都能被人脸识别和自然语言处理等等，这类人工智能为代表的技术所解读，我们努力想在朋友圈里隐藏些什么，当朋友圈的访问范围从半年逐渐缩小到三天，我们究竟能隐藏下什么呢？ 微博爬虫分析&emsp;&emsp;首先，我们需要从微博上抓取数据下来，我没有去做抓包分析这样的重复性工作，因为我注意到这个问题，在网络上有很多朋友在讨论，我主要参考了以下内容： Python 爬虫如何机器登录新浪微博并抓取内容？ https://github.com/xchaoinfo/fuck-login 用Python写一个简单的微博爬虫 通过以上内容，我了解到在抓取新浪微博数据的问题上，我们基本会有以下思路： 保存cookie信息，利用requests库发起请求并带上cookie 利用requests库模拟登录新浪微博并在请求过程中保持cookie 利用selenium库模拟登录新浪微博然后取得页面内容 利用PhantomJS库模拟登录新浪微博然后取得页面内容 可以看出差异主要集中在cookie的获取以及是否支持headless模式，并且我们得到一个共识，抓取新浪微博移动版要比PC版要容易，因为移动版优先为小尺寸屏幕设备提供服务，因而页面结构相对整洁便于我们提取数据。起初博主认为第一种方式太简单粗暴，坚持要采用第二种方式去实现，最终证明还是太年轻了啊，新浪微博的登录给人的感觉就是蛋疼，这里就简单介绍下思路哈。 &emsp;&emsp;首先我们会向服务器发出一次GET请求，它返回的结果是一段JavaScript代码，然后我们需要用正则匹配出其中的JSON字符，这样我们就获得了第二次请求需要用到的参数；接下来，第二次请求是一个POST请求，我们需要将用户名采用Base64加密，密码则采用RSA加密，需要用到第一次请求返回的参数。实际上，新浪微博官方给我们提供API获取微博数据，可这个API可以获取的微博数据非常有限，更让人难以接受的是新浪微博的应用授权方式，如果我们采用调用API的方式，在这里会有第三次POST请求，有朋友分析了完整的模拟登录过程，可我对此表示毫无兴趣啊。最早我采用了模拟这种方式，抓取第一页的时候还是登录的状态，可等到抓取第二页的时候变成了注销的状态，整个过程使用的是同一个session对象，所以我最后果断放弃了这种方式。 &emsp;&emsp;好了，现在我们只需要在Chrome里F12找到Network选项卡，抓一次包取得cookie，然后在请求的时候带上cookie即可。我们不用过分担心cookie过期的问题，在博主测试的时候，一个cookie可以持续工作3至5天，而且在后面我们会讲到，这个爬虫抓取的数据量其实并不大，在一两个小时内就可以完成抓取，没有必要将爬虫考虑得太严谨。在下图中我们标记出了博主计算机上存储的cookie，我们通过cookie就可以免登录抓取信息啦。 提取Cookie &emsp;&emsp;解决登录的问题以后，回到这个问题本身，我们需要抓取@西安月老牵线发布的所有微博，移动版对微博做了分页处理，所以我们只需要知道总共有多少页，然后循环去提取每一页里的信息即可，因为我们注意到每一页的地址都符合https://weibo.cn/u/3232168977?page=2这样的形式。首先页数，我们可以通过name为mp的隐藏控件来获得，其value属性表示总页数。其次，每条微博存放在class为c，id以M_开头的div标签里，在这里我们只需要文本信息，顺藤摸瓜我们发现信息被存放在class为ctt的span标签里，这里博主遇到一个奇怪的问题，BeautifulSoup默认的解析器html.parser，不知道因为原因无法解析出标签，而lxml当时因为pip的问题无法安装，所以不能使用XPath来解析DOM解构，在这里我认为XPath更适合这个场景，如果有时间可以考虑对代码进行重构。 &emsp;&emsp;在抓取微博的过程中，博主发现官方的反爬虫策略非常给力，连续工作超过5分钟IP就会被封锁，进而无法访问微博的服务器， 大概经过20至30分钟后会自动解封。或许主流的方案是花钱买动态代理，可我这个就是临时起意的一个想法，所以我采取了最简单粗暴的方法，让线程睡一会儿，在这样条件下，我花了大概1个半小时到2个小时左右的时间，从微博上抓取了5600条数据，并将其存储在了SQLite数据库中。什么？你问我为什么不考虑多线程，因为我这个人懒啊，这个问题最难的地方在数据分析，数据抓取方面我不太关注效率，因为我有足够的时间去等这些数据，所以关于性能方面的问题，有时间我们再做进一步讨论吧！ 数据处理过程&emsp;&emsp;数据处理这块，我本来打算尝试下MongoDB这个数据库的，而实际上这是我今年计划要去学习的内容之一，后来因为种种原因一直搁置到现在，可当我注意到Windows下安装MongoDB的繁琐后，我果断放弃了这种念头回归简单的SQLite，我基本上是交叉使用Windows和Linux，而我知道Linux下安装MongoDB是非常简单的。我反复强调我喜欢小而美的东西，就是因为我想保留对方案的选择权。在这里我们的数据处理，主要是数据清洗和中文分词。首先，我们来一起看看数据库表的设计： 数据表结构 &emsp;&emsp;我这里一切从简，所以将这5600多条数据都存储在一张表里，表中有四个字段ID、Post、Wish和Tags。显然，ID是自增的主键，为每条微博提供一个唯一的标识；Post存储我们从微博上抓取的原始信息，这里不含HTML标签，可是会含有微博表情字符啊摔；Wish存储每条微博中对伴侣的要求具体有哪些，这里我们主要通过关键字来截取可谓简单粗暴，具体原因稍后会讲到:)；Tags存储Wish字段经过分词以后的结果，这里我们使用结巴分词和SnowNLP，该字段中存储的是序列化后的JSON字符串，下面我们具体来讲这些字段的处理。 &emsp;&emsp;首先，分析@西安月老牵线发布的微博我们可以发现，所有征婚相关的微博都是以#征婚交友#或者#月老爱牵线#这样的话题开始，并且每条微博都是先介绍个人情况，然后再描述对理想伴侣的期望，所以我们只需要找出每条微博里对理想伴侣的期望相关的描述，然后再根据这条微博是由男嘉宾还是女嘉宾发布的，即可汇总出男、女性对各自伴侣的期望到底是什么，我们将这部分信息更新在Wish字段里，我们一起来看具体的代码： 12345678910111213141516171819202122232425262728# Filter Datasql = \"SELECT ID, Post FROM table_weibo WHERE POST LIKE '%%%%%s%%%%' OR POST LIKE '%%%%%s%%%%'\"sql = sql % (u'#征婚交友#',U'#月老爱牵线#')self.cursor.execute(sql)rows = self.cursor.fetchall()# Adjust Datapatterns = ['想找','希望找','要求','希望另一半','择偶标准','希望对方','希望','找一位','找一个','一半','找','想','喜欢','择偶条件','寻','期待','女孩','男孩','女生','男生','女士','男士','理想型']sql = \"UPDATE table_weibo SET Wish = ? WHERE ID = ?\"for row in rows: id = row[0] post = row[1] match = -1 for pattern in patterns: if(pattern in post): match = post.find(pattern) + len(pattern) break if(match != -1): wish = str(post[match:]) wish = wish.replace('#西安月老牵线#','') wish = wish.replace('[心]@月老蜀黍' ,'') wish = wish.replace('#月老爱牵线#' ,'') self.cursor.execute(sql,(wish,id)) else: self.cursor.execute(sql,('',id))self.connect.commit() &emsp;&emsp;可以注意到，我们首先按照话题对微博进行了筛选，然后通过关键字列表patterns来截取我们所需要的Wish字段，实际上这里是需要反复去调整patterns的，直到所有满足我们期望的数据都被提取出来，所以这是一个渐进式的数据处理过程。或许我们能想到通过NLP相关的技术来分析这段文本，我尝试通过SnowNLP去分析这样一段长度为100到500的文本，因为SnowNLP具备分析一段话的摘要及关键字的能力。可我发现这样实践下来效果并不太好，这是因为SnowNLP本身是以电商网站的评论数据为基础的，所以遇到我们微博这样相对灵活的文本信息时，它提取出的关键字并不能完全地符合我们的期望。固然，我们可以通过训练SnowNLP来达到我们的目的，可训练需要准备大量的文本信息作为支撑。作为一个懒惰的人，我最终选择了通过关键字来提取关键信息，准确度基本可以保证90%以上，因为暴力截取难免会拆分出不符合期望的信息。 &emsp;&emsp;接下来，我们有了针对男、女择偶要求期望的Wish字段，可这些信息对我们而言，依然显得繁重而冗余，所以接下来我们考虑对Wish字段进行分词，最初的设想是通过词性和语法来分析，可当我分完词以后我就不得不佩服中文的博大精深，这里我选择了两个中文处理相关的库，即结巴分词和SnowNLP，它们都是开源项目并且有大量的文档作为参考，这里想说的是，SnowNLP中支持中文文本的情感分析，这是我最初想要使用这个库的一个重要原因，因为我想从这些微博中找出评价一个人的形容词或者名词，而这些词的情感分析，可以作为我们是否将其作为一个评价指标的重要依据。 &emsp;&emsp;可我们有句话叫做“认真你就输了”，尤其在女性的思维模式中，充满太多太多不能直接去理解的信息。这种我不用举例子啦，现在铺天盖地的直男癌/女权癌席卷而来，其实有太多问题无关对错，你输就输在没有照顾好对方的情绪，我们现在常常把情商挂在嘴上，可情商概念中的自我意识、控制情绪、自我激励、认知他人情绪和处理相互关系，有60%说的是自我管理，而其余的40%，恰恰就是我们日常理解中关于人际关系方面的，所以我们说人工智能不能完全代替人类，因为只有绝对理性的世界是恐怖的，可只有情绪化的感情而不讲道理的世界则是空虚的。我们可以去追逐人类内心中的灵性，即真、善、美，这是任何冰冷的计算机所不具备的东西。可我们能不能真诚一点呢，明明知道这一切都是套路可你还满心期待，我们并非不懂得什么是爱，爱不是我用一个又一个套路去套路你，而是我明知这是套路还愿意陪你表演下去，我没有在讽刺浙江卫视某节目，愿温柔的你被这个世界温柔地对待。 &emsp;&emsp;关于结巴分词和SnowNLP地对比评测，大家可以参考：Python︱六款中文分词模块尝试，这里博主发现SnowNLP适合做大颗粒分词拆分，而结巴分词适合做小颗粒分词拆分。其实，从分词效果上来讲，结巴分词是要比SnowNLP效果更好一些的，可我这样说不是会显得情商比较高吗？这样你们会喜欢吗？最终我们采取的方案是两者混用，故而我们有了这样的代码： 123456789def generateTags(self,text): snow = SnowNLP(text) sentences = snow.tags tags = [] for s in sentences: words = pseg.cut(s[0]) for w in words: tags.append(&#123;'word':w.word,'flag':w.flag&#125;) return json.dumps(tags) &emsp;&emsp;可以注意到，这里我们使用结巴分词获得了每个词的词性，不过到我写这篇文章的时候，对于词性的处理我依然没有什么好的想法，这里仅将其作为结果以JSON的形式存储到数据库中，现在我们基本上完成了所有数据处理的流程，在这个过程中会有些特殊的中文字符，我们采取暴力替换的方式进行去除即可，对此不在这里展开说啦。下图展示了数据库中部分数据： 处理后的数据 处理结果呈现&emsp;&emsp;说起这篇文章，可以说这是我第一次接触数据分析，我们这个时代积累了大量的数据，所以我们有基于大数据的推荐和预测等等相关场景，知乎和微博的首页Feed流经过无数次算法调整，可人们依然在抱怨算法向人们推荐了无关的内容，这是否说明，我们所期待的智能，仅仅是让我们觉得智能而已，这一系列基于统计的数据分析理论，是否一定是符合某种冥冥之中的规则，我想起《模仿游戏》中和卷福扮演的图灵形成鲜明对比的，正是以休.压力山大为代表的统计方法派，电影中他们试图通过分析字母出现的频率来破解恩尼格玛。对于数据分析而言，如果说可视化是面向人类的分析手段，那么数据挖掘就是面向机器的分析手段。作为一个刚刚入门的萌新，我描述的是我对数据分析的一种感觉。回到本文主题，这里我选择以词云作为最终处理结果的呈现载体。 &emsp;&emsp;词云，即WordCloud，是一种展现关键字出现频率的表达方式，如果你对博客写作比较熟悉的话，就会知道诸如WordPress、Ghost、Hexo等都提供了标签云功能，我们每篇文章中都会给文章添加若干标签，而标签基本可以让读者了解这个博客都有哪些内容，在标签云中出现频率越高的标签其字体通常会越大，这样我们可以非常直观地了解到，每个因素在整体上占到的比重。本文之所以采用这种方案，正是希望通过词云来呈现男女在择偶观上更看重什么。生成词云的方式有很多，具体可以参考这篇文章：除了 Tagxedo外，还有什么好的软件制作可以词云?，而博主最终选择了wordcloud，你可以看到Python基本上是万能的语言，有这么多优秀的第三方库可以用，我就问你怕不怕，关于这个库的用法，请参考：https://amueller.github.io/word_cloud/，如果通过pip无法直接安装该库，可以通过这里下载.whl文件进行安装，注意升级pip到最新版本即可。 &emsp;&emsp;参照官方的示例，我们从数据库中根据Post来过滤性别，根据Tags来获取关键字，然后将所有Tags串联成一个字符串，传递给WordCloud模块即可。下面给出代码片段： 1234567891011121314151617# Filter Datasql = \"SELECT Post, Tags FROM table_weibo WHERE Tags &lt;&gt; ''\"self.cursor.execute(sql)rows = self.cursor.fetchall()# Filter Tagsmale_tags = ''female_tags = ''for row in rows: post = row[0] tags = json.loads(row[1]) if u'男嘉宾[向右]' in post: female_tags += ','.join(map(lambda x:x['word'],tags)) elif u'女嘉宾[向右]' in row[0]: male_tags += ','.join(map(lambda x:x['word'],tags)) # WordCloud self.generateWordCloud(female_tags,'female.png','output_female.png') self.generateWordCloud(male_tags,'male.png','output_male.png') &emsp;&emsp;在这里我们主要将男嘉宾/女嘉宾分别筛选出来，然后将分词结果用逗号串联起来，这样即可得到male_tags和female_tags，我们会将其传递给WordCloud模块，可以注意到我们为男性/女性词云分别设置了不同的背景图片，最终会生成两张不同的图片，这里主要参考了Image-colored这个示例，代码片段展示如下： 123456789101112131415161718192021def generateWordCloud(self,text,background,output): back_coloring = np.array(Image.open(background)) stopwords = set(STOPWORDS) stopwords.add(u'西安') stopwords.add(u'生活') wordcloud = WordCloud( font_path='simfang.ttf', # 设置字体 background_color=\"white\", # 背景颜色 max_words=5000, # 词云显示的最大词数 mask=back_coloring, # 设置背景图片 stopwords=stopwords, #停用词设置 max_font_size=75, # 字体最大值 random_state=42, width=1000, height=860, margin=15,# 设置图片默认的大小,但是如果使用背景图片的话,那么保存的图片大小将会按照其大小保存,margin为词语边缘距离 ) wordcloud.generate(text) plt.imshow(wordcloud) plt.axis(\"off\") plt.show() wordcloud.to_file(output) &emsp;&emsp;这里我们注意到添加了两个停止词，这是因为我们发现，西安和生活这两个关键词，在整体中所占权重虽然较高，可是因为我们这里抓取的是西安本地的微博，所以这两个关键词对我们而言是没有意义的。再对这两个关键字进行剔除以后，我们最终生成的词云如图： 男性心目中的伴侣 女性心目中的伴侣 这是个看脸的世界&emsp;&emsp;对这样一个显然成立的结论，我是表示失望的，这种感觉像什么呢？就像你期待着对方说喜欢你，结果到最后她还是会说我们不合适。可花费如此大的篇幅来讲这样一个悲伤的故事，我们就象征性地分析下结论吧！首先，我们注意到男性心目中的伴侣，排名靠前关键字是性格、孝顺、善良、懂事、结婚、身高、眼缘，而女性心目中的伴侣，排名靠前的关键字是身高、稳重、责任心、上进心、工作、成熟。所以，我现在完全可以理解，为什么女生会对180的身高如此迷恋，因为她们想被男朋友举高高呀，我的一位朋友如是说。 &emsp;&emsp;与此同时，我们发现很多指标譬如孝顺、善良、稳重、责任心、上进心等，其实都是需要两个人在相处久了以后慢慢去验证的，可这些最终会被眼缘和身高这种因素阻挡在外面。或许你会觉得这样浅显的道理，居然值得我花费时间和精力去思考。一个你吸引不到的人，终究是难以拉近两个人心间的距离的。喜欢是两个人的事情，我不是要卑微地乞求你来见我，而是你想要来见我我就主动迎上去。有天在QQ空间看到有人在看《怦然心动》，就忍不住下载下来一个人看。有时候我们喜欢的那个人，或许并没有那么好，你会渐渐发现，那种因为喜欢而附加在对方身上的光环，会随着时光而慢慢变淡。而有那么一瞬间，我只想比她变得更优秀，而不再幻想她会转身回来看我，或许这就是成长吧！ 本文小结&emsp;&emsp;大概没有谁会像我这样，在写一篇技术文章的过程中，掺杂如此多的个人情感。可有时候，一个人做一件事情的动机，的确就是如此简单。我羡慕175以上的身高，可是不是我具备了这样的身高，你就会喜欢我呢？我想应该不会吧，因为你总能找到新的理由来拒绝我。所以，我写这篇文章，通过Python抓取新浪微博数据并对其进行分析，并不是想告诉你，你因为不具备哪些因素而不被人喜欢，而是想告诉你，我们每一个人都是这个世界上独一无二的存在，我们的优点同我们的缺点组合起来，这才是完整的我们。别人喜欢不喜欢我们到底有什么意义呢？就像我们喜欢许嵩、喜欢林依晨，难道就要让人家喜欢我们吗？我可以非常喜欢你，但我一定要骄傲地喜欢你，因为我骄傲时的样子最帅，谁让这是一个看脸的世界呢？","categories":[{"name":"数据分析","slug":"数据分析","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%88%86%E6%9E%90/"}],"tags":[{"name":"Python","slug":"Python","permalink":"https://qinyuanpei.github.io/tags/Python/"},{"name":"微博","slug":"微博","permalink":"https://qinyuanpei.github.io/tags/%E5%BE%AE%E5%8D%9A/"},{"name":"词云","slug":"词云","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%8D%E4%BA%91/"}]},{"title":"冬天来了，春天还会远吗？","date":"2017-11-19T10:16:17.000Z","path":"posts/3111375079/","text":"&emsp;&emsp;接到妈妈打来的电话时，时间已然接近中午时分，从床上爬起来的刹那间，就听见妈妈熟悉的声音。妈妈问我年底公司有没有什么变动，顿时千万种思绪涌上心头，不知道该对电话彼端的妈妈说些什么。我突然想到二十四岁时的我，从第一家公司裸辞时的情景，可如今再度让父母为此焦虑，让身为人子的我感到惭愧不安。电话里妈妈让我照顾好自己，一个人在外不要太委屈自己。当一个人不被这个世界接纳的时候，就像是浑身长满刺的仙人掌。可在最亲近的家人眼里，我们永远是这个世界上独一无二的存在。我是一个不大主动同家里的人，在那一刻我忽然觉得，这个冬天没有那么冷了，即使我身处没有暖气的出租屋里，即使早晨带着体温的被子早已凉透，我想对自己说一句，冬天来了，春天还会远吗？ &emsp;&emsp;发生在年底的release事件，就像这个冬天里的雾霾如约而至，即使早在去年就经历过这样的事情，可当它真实地发生在自己身上时，依然不免让人感到这个冬天的寒冷。纵观二十朝兴废更替，历史对我们而言常常是相似的。诸葛亮为“克复中原”六次北伐出师未捷而身先死的遗憾，唐玄宗宠溺杨玉环终致“安史之乱”而奔走蜀中避祸时的仓皇，这一切大概是我们如今坐西成高铁时无法想到的吧。有时候人的命运像极了历史的兴衰，记得三年前和同学第一次来西安，那个时候我们说，总有一天我们会再来这里的，那时的我或许完全不知道现在会面临这种处境，看着那些年龄比自己大依然碌碌无为的人，看着那些面临中年危机而不得不向生活妥协的人…..我告诉自己，我永远都害怕自己变成这样的人，所以让我内心无法平静下来的，永远是我近乎自责的自我反省式人格。 &emsp;&emsp;在接受被release的事实以后，就开始频繁地去准备面试和跳槽。可年底时找工作注定是一个艰难的过程。其实回头想想今年面试的表现，前端、数据库等相关经验的匮乏，一度让我在面试中非常被动，而外冷内热的性格常常给人一种不自信的表现，特别是去葡萄城面试的这次体验，让我意识到在面试中我无法展示出和职位匹配的能力，我们说面试是双向选择的一个过程，这看起来有点像是找男女朋友一样，有时候我们太在乎对方而导致表现不佳。我花了时间去听知乎上有关面试技巧的Live，甚至找朋友帮我分析如何给出面试官满意的答案，有时候别人会觉得我对严厉到苛刻的程度，是因为我对某些东西太在乎的缘故，可是不在乎这些问题就能解决了吗？矫枉过正至少意味着出发点是好的，总比发现问题后一直无所作为要好很多。 &emsp;&emsp;我一直想找时间整理下这段时间面试遇到的题目，可令人窒息的拖延症让这种想法一直落空。有时候我怀疑，人和人的缘分都在第一眼就注定好了。或许你花时间和精力去追一个女生，但这种关系永远不会发生改变。人类总是肤浅地相信眼睛看到的，固执地认为自己的想法就是正确的，可人这种复杂的动物怎么会一眼就望穿呢，所以试图通过面试完全了解一个人，原本就是不切实际的想法。很多时候人与人接近并不是他们彼此熟悉，仅仅是因为大家的口味比较接近而已。无论多么熟悉的同事，在分开以后都会逐渐变得冷淡。每个人都像一只刺猬，离得太远会感觉到冷，而靠得太近会刺伤对方。大概是遇见小古花光所有运气，此后遇人不淑的厄运纷至沓来。人啊，简直是世界上最麻烦的一种动物。 &emsp;&emsp;有时候我会埋头去做自己的事情，朝着自己内心的目标一点点靠近，即使曾经想要和她分享这点喜悦的人，早已消失在茫茫的人海里。我写爬虫、做数据分析、做聊天机器人，这其中有太多事情，是我对记忆的一种自我延伸，因为在那些曾经灰暗的日子里，陪伴我的人除了她，就是这些我比任何人都要在乎的技术。《嫌疑人X的献身》里，石神说道：“通往山顶的路或许会有很多条，而找出最优雅的那一条，是数学家永恒的追求”。也许他们说得都是对的，即使翻过了2017年，这个季节依然属于冬天，她只会比以前更让你觉得寒冷，可这一切的一切终究是会过去的，冬天来了，春天还会远吗？","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://qinyuanpei.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"工作","slug":"工作","permalink":"https://qinyuanpei.github.io/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"生活","slug":"生活","permalink":"https://qinyuanpei.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"}]},{"title":"迁移Hexo博客到Google渐进式Web应用(PWA)","date":"2017-10-24T23:13:41.000Z","path":"posts/450254281/","text":"&emsp;&emsp;如果说通过TravisCI实现博客的自动化部署，是持续集成这个概念在工作以外的一种延伸，那么今天这篇文章想要和大家分享的，则是我自身寻求技术转型和突破的一种挣扎。前段时间Paul同我聊到Web技术的发展趋势，Paul认为Web应用会逐渐取代原生应用成为主流，我对此不置可否。真正让我陷入思考的是，在这个充满变化的时代，知识的更新速度远远超过你我的学习速度，我们应该如何去追随这个时代的步伐。如同那些淹没在时间河流里的技术名词，当青春不再的时候，我们喜欢把这个过程称之为成长，当发现距离第一次使用FontPage制作网站已过去十年，当发现曾经的网页三剑客在岁月蹉跎里频频改换姓名，当发现那些淹没在历史里的技术来不及学习就成为过往……或许，这个世界真正迷人的地方，就在于它每天都在不断变化。 新一代Web应用——PWA&emsp;&emsp;接着Paul关于Web技术的这个话题，我认为Web技术在短期内会成为原生应用的一种补充。事实上，原生应用和Web应用哪一个会是未来，这个问题的争论由来已久，在业界我们可以看到HTML5、PhoneGap、React/React Native、Electron/NW.js、小程序等方案百家争鸣，每一种方案都可以让我们去Web技术去打破平台间的差异。与此同时，我们注意到移动开发领域对原生技术的需求在缩减，虽然马克·扎克伯格曾表示，“选择HTML5是Facebook最大的错误“，可我们注意到，越来越多的Web技术被运用在原生应用中，Web技术被认为是最佳的打造跨平台应用的技术，可以通过一套代码实现不同平台间体验的一致性。我们注意到知乎和天猫的客户端中都混合使用了一定的Web技术，因为纯粹使用原生技术去开发一个移动应用，其最大的弊端就在于我们要为Android和iOS维护两套不同的代码，从国内曾经疯狂火热的iOS培训就可以看出，单独使用原生技术去开发客户端，其成本实际上是一直居高不下的。 &emsp;&emsp;虽然我们有Xamarin这样的跨平台技术，试图用一种编程语言和代码共享的方式，去开发两种不同平台的应用程序，可是我们注意到，平台间的差异和抗阻是天然存在的，就像SQL和面向对象这样我们再熟悉不过的例子。同样的，Facebook的React Native项目，试图用Web技术去弱化平台间的差异，React Native存在的主要问题是，它依然依赖原生组件暴露出来的组件和方法，所以像DatePickerIOS、TabBarIOS等控件是iOS Only的，这意味着在开发过程中开发者还是要考虑平台间的差异性，其次React本身的JSX(对应HTML)、CSS Layout(对应CSS)本身是具有一定的学习曲线的，虽然底层因为没有使用WebView的原因提高了部分性能，然而整体上是牺牲了扩展性的。总而言之，这是一个介于Web技术和原生技术之间的中间技术，在我看来地位着实蛮尴尬的，因为无论在Web层还是Native层都选择了部分妥协，完美实现跨平台真心不容易啊。 &emsp;&emsp;要掌握一门新技术，最好的方法就是去应用它。我的博客使用的是Indigo主题，这是一个典型的Material Design风格的主题，所以我一直想尝试将其改造成原生应用，我曾经接触过移动端应用开发，如果通过WebView内嵌网页的方式来实现，我需要处理离线状态下页面的显示问题，以及所有混合应用开发都会遇到的一个问题，即原生应用层需要和Web应用层进行通信的问题。而如果采用Hybrid App的思路去开发一个混合应用，意味着我需要去学习Cordova这样的Hybrid开发框架，去了解JavaScript和Native交互的细节。那么有没有一种学习成本相对较低，同时可以提供原生应用体验的思路呢？答案是确定的，这就是我们下面要说的渐进式应用(PWA)。 &emsp;&emsp;渐进式应用(Progressive Web Apps，PWA)是Google提出的新一代Web应用概念，其目的是提供可靠、快速、接近Native应用的服务方案。我们知道传统Web应用有两个关键问题无法解决，即需要从网络实时加载内容而带来的网络延迟和依赖浏览器入口而带来的用户体验，从某种意义上而言，渐进式应用的出现有望让这些问题得到解决，首先，渐进式应用可以显著加快应用加载速度，其提供的离线缓存机制可以让应用在离线环境下继续使用，关键技术为Service Worker和Cache Storage；其次，渐进式应用可以被添加到主屏，有独立的图标、启动页、全屏支持，整体上更像Native App，关键技术为Web.App Manifest；最后，渐进式应用同操作系统集成能力得到提高，具备在不唤醒状态下推送消息的能力，关键技术为Push API和Notification API。 PWA中关键技术解析&emsp;&emsp;Google对外提出PWA这个概念其实是在今天的二月份左右，所以现在我写这篇文章实际上是在赶一趟末班车。我最近比较喜欢的一个男演员张鲁一，在接受媒体采访时媒体称他是一个大器晚成的人，他的确让我找到了理想中成熟男人的一个标准，如果你要问我这个标准是什么，我推荐你去看他主演的电视剧《红色》。那么，好了，为了让大家了解渐进式Web应用(PWA)，相比其它跨平台方案有何优缺点，我们这里来简单讨论下PWA中的关键技术。 ServiceWorker&emsp;&emsp;我们知道，传统的Web应用需要在网络环境下使用，当处在离线环境下时，因为HTTP请求无法被发送到服务器上，所以浏览器通常会显示一个空白页，并告知用户页面无法加载，因此会影响用户在离线环境下的使用体验，与此同时，因为Web页面在打开的过程中需要加载大量资源，因此在页面刚刚打开的一段时间内，用户看到的页面通常都是一个空白页面，考虑到缓存或者是预加载的Web应用，通常都会以预设资源作为占位符来填充页面，因此带来访问者的印象往往会更好。那么渐进式Web应用带给我们最大的惊喜，就是它可以在离线环境下使用，其核心技术就是ServiceWorker，我们来一起看看如何使用SeviceWorker： 12345678if (navigator.serviceWorker) &#123; navigator.serviceWorker.register('service-worker.js') .then(function(registration) &#123; console.log('service worker 注册成功'); &#125;).catch(function (err) &#123; console.log('servcie worker 注册失败'); &#125;);&#125; &emsp;&emsp;我们这里看到一个基本的注册ServiceWorker的代码片段，并且它采用了业界流行的Promise的写法。那么首先第一个问题，ServiceWorker到底是什么？ServiceWorker本质上是一个Web应用程序和浏览器间的代理服务器，它可以在离线环境下拦截网络请求，并基于网络是否可用以及资源是否可用，来采取相对应的处理动作，所以ServiceWorker最基本用法是作为离线缓存来使用，而高阶用法则是消息推送和后台同步。通常来讲，ServiceWorker会经历如下的生命周期： ServiceWorker生命周期 注：配图来自 http://web.jobbole.com/84792/ &emsp;&emsp;按照官方文档中的定义，ServiceWorker同WebWorker一样，是一段JavaScript脚本，作为一个后台独立线程运行，其运行环境与普通的JavaScript不同，因此不直接参与Web交互行为，从某种意义上来说，ServiceWorker的出现，正是为了弥补Web应用天生所不具备的离线使用、消息推送、后台自动更新等特性，我们这里来看一个使用ServiceWorker缓存文件已达到离线使用的目的的例子： 1234567891011121314var cacheStorageKey = 'minimal-pwa-1'var cacheList = [ '/', \"index.html\", \"main.css\", \"e.png\"]self.addEventListener('install', e =&gt; &#123; e.waitUntil( caches.open(cacheStorageKey) .then(cache =&gt; cache.addAll(cacheList)) .then(() =&gt; self.skipWaiting()) )&#125;) &emsp;&emsp;在这里例子中，我们在ServiceWorker的install事件中添加了待缓存文件列表，这将意味着这些静态资源，会在网页中的ServiceWorker被install的时候添加到缓存中，我们在某个合适的时机到来时就可以再次使用这些缓存资源。事实上考虑到安全性的问题，ServiceWorker在设计时被约束为按照路径给予最高权限，即ServiceWorker在指定路径下是有效的。这里简单提下ServiceWorker的缓存策略，因为这个问题在我看来蛮复杂的，例如官方出品的sw-tool中定义的缓存策略就有如下五种： 网络优先:：从网络获取, 失败或者超时再尝试从缓存读取 缓存优先:：从缓存获取, 缓存插叙不到再尝试从网络抓取 最快：同时查询缓存和网络, 返回最先拿到的 仅限网络：仅从网络获取 仅限缓存：仅从缓存获取 &emsp;&emsp;我们刚刚提到被缓存的静态资源会在合适的时机被再次使用，那么什么时候可以称之未合适的时机呢？在这个问题中，我们是指fetch事件，事实上通过拦截fetch事件，我们就可以拦截即将被发送到服务器端的HTTP请求，ServiceWorker首先会检查缓存中是否存在待请求资源，如果存在，就直接使用这个资源并返回HTTP响应，否则就发起HTTP请求到服务器端，此时ServiceWorker担任的是一个代理服务器的角色。至此，我们就会明白，ServiceWorker的作用其实就是在离线条件下利用缓存伪造HTTP响应返回，这样我们就达到了离线使用的目的，传统的Web应用在离线环境无法使用，根本原因是没有这样一个Mock的Server去伪造HTTP响应并返回，因为HTTP请求此时根本就无法发送到服务端。为了让ServiceWorker全面接管HTTP请求以便利用请求，我们这里的实现方式如下： 12345678910111213self.addEventListener('fetch', function(event) &#123; event.respondWith( caches.match(event.request) .then(function(response) &#123; // Cache hit - return response if (response) &#123; return response; &#125; return fetch(event.request); &#125; ) );&#125;); &emsp;&emsp;好了，以上就是ServiceWorker在离线缓存方面的基本用法，希望进行深入了解的朋友，可以参考文末链接做进一步研究。 Web App Manifest&emsp;&emsp;接下来介绍Web App Manifest，它其实是Web开发领域的一个”叛徒”，因为它所做的事情为大家所不齿，基本可以概括为，怎么样假装自己是一个Native App，我们直接看它的定义： 123456789101112131415&#123; \"name\": \"Minimal app to try PWA\", \"short_name\": \"Minimal PWA\", \"display\": \"standalone\", \"start_url\": \"/\", \"theme_color\": \"#8888ff\", \"background_color\": \"#aaaaff\", \"icons\": [ &#123; \"src\": \"e.png\", \"sizes\": \"256x256\", \"type\": \"image/png\" &#125; ]&#125; &emsp;&emsp;这个我确认没有什么好说的，详细的参数可以参考这里，通常我们需要将以上文件命名为manifest.json，并通过以下方式引入到HTML结构中，通常是添加在标签下，我们所期望的图标、启动页、主题色等Native App的特性都是在这里定义的，这里想吐槽的是，随着越来越多的平台开始向标签中注入”新血液”，譬如标签和标签：现在HTML结构变得越来越复杂，更不要说主流的AngularJS和Vue这类MVVM框架，基本上都是通过扩展HTML属性来完成数据绑定的。对PWA应用来讲，我们只需要在标签下引入以下内容： 1&lt;link rel=\"manifest\" href=\"manifest.json\" /&gt; 这里简单介绍下Web App Manifest中常见的参数含义及其作用： name/short_name：表示应用被添加到屏幕上以后显示的名称，当屏幕空间不足以显示完整的name时，将显示short_name。 start_url：表示用户从屏幕启动应用时所加载网页的URL，通常我们将其指向网站的首页。 theme_color：表示应用程序的主题颜色，PWA事实上是建议使用Material Design设计风格的，因此该属性可以控制应用的主题颜色，并在页面加载完成前展示一个过渡动画。 scope：表示PWA应用的作用域，即哪些页面可以以PWA应用的形式呈现。 display：表示PWA应用呈现的方式，可以是fullscreen、standalone、minimal-ui和browser中的任意取值。 orientation：表示PWA应用的屏幕方向，如果你有移动开发的经验，对此应该不会感到陌生。 icons：表示PWA应用在屏幕上的图标，为了适配不同尺寸的屏幕，这里可以设置不同尺寸下的图标。同样地，如果你有移动开发的经验，对此应该不会感到陌生。 Push/Notification API&emsp;&emsp;关于这两个东西，我们简单说一下啊，PWA中的Push机制主要有Notification和Push API两部分组成，前者用于向用户展示通知，而后者用于订阅推送消息。网络上对这块介绍的并不多，关于推送这个问题，一直是国内Android用户和开发者的一块心病，因为Google的推送服务在国内水土不服，因此国内厂商或者是SDK提供商基本上都有自己的一套方案，这就导致在用户的设备上同时开启着若干个消息推送服务，用户手机里的电就是这样一点点被耗尽的，所以这个问题大家看看就好。在PWA中，我们可以通过ServiceWorker 的后台计算能力结合 Push API 对推送事件进行响应，并通过 Notification API 实现通知的发出与处理： 12345678910111213141516// sw.jsself.addEventListener('push', event =&gt; &#123; event.waitUntil( // Process the event and display a notification. self.registration.showNotification(\"Hey!\") );&#125;);self.addEventListener('notificationclick', event =&gt; &#123; // Do something with the event event.notification.close(); &#125;);self.addEventListener('notificationclose', event =&gt; &#123; // Do something with the event &#125;); 移植Hexo博客到PWA应用&emsp;&emsp;现在，我们基本了解了PWA的概念以及实现PWA的关键技术，我们现在考虑将Hexo博客改造成一个PWA应用，我们这里不打算考虑消息推送的相关问题，所以对Hexo这样一个静态博客生成器而言，我们可以做的实际上只有两件事情，即通过Web App Manifest让它更像一个Native应用，通过ServiceWorker为它提供离线缓存的特性。我们从最简单的开始，我们需要在Hexo的根目录中增加一个manifest.json文件，该文件我们可以通过这个网站 manifoldjs.com 来生成。下面给出博主博客中使用的配置： 1234567891011121314151617181920212223242526272829303132333435363738394041&#123; \"name\":\"飞鸿踏雪的部落格\", \"short_name\":\"Payne's Blog\", \"description\":\"人生到处知何似，应似飞鸿踏雪泥\", \"icons\":[ &#123; \"src\":\"assets/images/icons/bird36.png\", \"sizes\":\"36x36\", \"type\":\"image/png\" &#125;, &#123; \"src\":\"assets/images/icons/bird48.png\", \"sizes\":\"48x48\", \"type\":\"image/png\" &#125;, &#123; \"src\":\"assets/images/icons/bird72.png\", \"sizes\":\"72x72\", \"type\":\"image/png\" &#125;, &#123; \"src\":\"assets/images/icons/bird96.png\", \"sizes\":\"96x96\", \"type\":\"image/png\" &#125;, &#123; \"src\":\"assets/images/icons/bird144.png\", \"sizes\":\"144x144\", \"type\":\"image/png\" &#125;, &#123; \"src\":\"assets/images/icons/bird192.png\", \"sizes\":\"192x192\", \"type\":\"image/png\" &#125;], \"background_color\":\"#fff\", \"theme_color\":\"#000\", \"start_url\":\"/\", \"display\":\"standalone\", \"orientation\":\"portrait\"&#125; &emsp;&emsp;好了，现在我们来考虑如何去实现一个ServiceWorker，Google官方提供了一个ServiceWorker的示例项目，以及网友提供的Minimal-PWA，这两个项目都可以帮助我们去了解，如何去实现一个ServiceWorker，甚至于我们有sw-toolbox和sw-precache这样的工具，配合gulp和webpack我们定制缓存策略并生成ServiceWorker。可是你要知道，懒惰对程序员而言是一种美德，在这里我选择了Hexo的插件hexo-offline，该插件可以帮助我们生成ServiceWoker，关于它的使用及配置，大家可以自行去了解，我重点想说说支持ServiceWorker以后，我的博客所呈现出来的变化以及PWA实际运行的效果。 ServiceWorker和Cache Storage &emsp;&emsp;通过这张图，我们可以清楚地看到，ServiceWorker确实在后台工作着，而Cache Storage确实对博客内的静态资源做了缓存处理。事实上对Hexo这样的静态博客而言，整个博客都是静态资源，所以在实际运行中它会对所有内容进行缓存，我们可以在终端中验证这个想法： 在Hexo中监听到的缓存请求 &emsp;&emsp;可我想说这一切并没有什么用，因为我并不能如愿地在离线状态下访问我的博客，甚至因为有了缓存机制，当我在撰写这篇博客时，虽然我改变了markdown文档的内容，但当我刷新博客的时候，因为缓存机制的存在，我不能像从前那样直接看到博客的变化，更重要的一点是，整个缓存大概有8M左右的体积，因此每次请求页面时，我能够明显地感觉到页面加载的延迟，看起来我们费了大量周折最终却一无所获，这听起来实在是讽刺不是吗？ &emsp;&emsp;说完了ServiceWorker，我们再来说说Web App Manifest，我尝试从豌豆荚下载了移动版Chrome，可我自始至终无法将应用添加到主屏幕，貌似这需要Android系统底层的支持，我测试了两部手机，一部OPPO手机和一部小米手机，发现都没有明显的PWA支持，当我访问页面的时候，浏览器更加不会主动提示我”将应用添加到主屏”，像UC浏览器是将网站以应用的形式添加到浏览器首页，这的确没有什么值得令人惊喜的地方，因为在PC端的时候，我们就可以做到类似地实现，这篇文章耗费时间蛮长的啦，大概是因为我不知道，该如何描述这个失败的尝试。最近接触到一位前辈的项目，这是一个需要跨PC端和移动端的项目。目前面临的一个挑战就是，移动端有太多依赖原生接口的功能设计，所以一套代码在全平台适配，真的仅仅是一个美好的理想，离实现永远有一段不可逾越的距离。 本文小结&emsp;&emsp;本文主要以Google提出的渐进式Web应用(Progressive Web Apps)为主线，简单探讨了Google的渐进式Web应用及其关键技术。渐进式Web应用试图解决传统Web应用的两个关键问题，即需要从网络实时加载内容而带来的网络延迟和依赖浏览器入口而带来的用户体验。首先，渐进式应用可以显著加快应用加载速度，其提供的离线缓存机制可以让应用在离线环境下继续使用，关键技术为Service Worker和Cache Storage；其次，渐进式应用可以被添加到主屏，有独立的图标、启动页、全屏支持，整体上更像Native App，关键技术为Web.App Manifest；最后，渐进式应用同操作系统集成能力得到提高，具备在不唤醒状态下推送消息的能力，关键技术为Push API和Notification API。在此背景下，我们对静态博客Hexo进行了改造，尝试将其迁移到一个PWA应用上，虽然最终以失败告终，可是在整个过程中我们依然有所收获，我觉得一件事情能让我们有所思考或者有所感悟的话，这就已然是一种幸运、一种成功啦。 &emsp;&emsp;其实Web应用与原生应用并非彼此水火不容，除了纯粹的Web技术和Native技术以外，在这两者之间我们看到的更多是混合技术的应用，所以我认为开发人员在未来一定要具备两种能力，即跨语言和跨平台开发的能力。比如小程序是在微信原生生态下建立的定制化Web应用，它有着类似HTML/CSS/JavaScript的技术方案，同时提供了统一的应用程序外观和使用体验；而跨平台游戏引擎cocos2d-x，通过JavaScript Bridge等类似技术，则可以实现将Web技术转化为Native技术…..总而言之，在技术选型这个问题上，我们可以选择的方案越来越多，如何让想法可以伴随技术产生优秀的产品，这是我们在这个时代真正该去思考的问题。目前来讲，国内普遍重视iOS，可惜遗憾的是iOS不支持PWA；国内的Android系统经过阉割以后，国内用户无法使用Chrome，以及各个厂商定制的浏览器存在兼容性问题；国内因为政策及现实原因，第三方推送相对GCM推送要活跃很多，厂商并不会太关注对PWA应用推送的支持。虽然现实如此，可Web技术发展到今天为止，我们能做的就是希望它越来越好，在此引用黄玄的一句话： 我们信仰 Web，不仅仅在于软件、软件平台与单纯的技术，还在于『任何人，在任何时间任何地点，都可以在万维网上发布任何信息，并被世界上的任何一个人所访问到。』而这才是 web 的最为革命之处，堪称我们人类，作为一个物种的一次进化。」 PWA 初探：基本特性与标准现状 Service Worker API Using the Push API Service Worker初体验 PWA 入门: 理解和创建 Service Worker 脚本 PWA 入门: 写个非常简单的 PWA 页面 下一代 Web 应用模型 —— Progressive Web App","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://qinyuanpei.github.io/tags/Web/"},{"name":"Hexo","slug":"Hexo","permalink":"https://qinyuanpei.github.io/tags/Hexo/"},{"name":"PWA","slug":"PWA","permalink":"https://qinyuanpei.github.io/tags/PWA/"}]},{"title":"持续集成在Hexo自动化部署上的实践","date":"2017-10-21T22:57:55.000Z","path":"posts/3521618732/","text":"&emsp;&emsp;曾经听到过这样一句话，”不要用战术上的勤奋掩盖战略上的懒惰”，所以战术和战略更像是抽象类和具体类，而面向对象设计实际上是现实等级制度的一种映射。因此我们注意到，决策者通常关注的是战略层面的抽象概念，而执行者通常更关注战术层面的具体实现，正如在代码的架构设计中，处在顶层的代码以发送指令为主要使命，处在底层的代码以实现功能为主要使命。面对日新月异的互联网技术，当我们听到越来越多的新名词，譬如微服务、DevOps、单页面应用、前后端分离等等，这些概念曾让我们迷恋于追寻一个又一个风口，一如曾经的O2O、VR、共享经济和人工智能，那么我们真的懂得如何让这些概念落地吗？在今天这篇文章中，我想和大家一起探讨持续集成相关的话题，并以Hexo结合TravisCI实现自动化部署为例，聊聊我心目中的DevOps。 从DevOps谈谈持续集成&emsp;&emsp;不知从何时起，DevOps开始成为大家竞相追捧的概念，同ThoughtWorks所倡导的微服务、敏捷开发一样，大家仿佛抓住了一根新的救命稻草一般，那么我们在说DevOps的时候，我们到底想要表达什么观点呢？想要搞清楚这个问题，我认为首先要明白，什么是DevOps？从概念上讲，DevOps是一个面向IT运维的工具流，以IT自动化以及持续集成(CI)、持续部署(CD)为基础，目的是优化开发、测试、运维等所有环节，所以DevOps本质上是一组部门间沟通协作的流程和方法，其目的是为了协调开发(DEV)、测试(QA)、运维(OPS)这三种角色，使开发运维一体化，通过高度自动化工具和流程，来确保软件构建、测试和发布更加快捷、频繁和稳定。 &emsp;&emsp;所以，我们在说DevOps的时候，我们想表达的或许是流程和管理、运维和自动化、架构和服务、文化和组织等等的概念，那么在这些观点中，最重要的是什么呢？我认为是持续集成(CI)和持续部署(CD)，这是DevOps中从始至终贯穿的一条主线。通过Git这样的源代码控制工具，我们可以确保项目在一条主干上开发。而自动化测试/部署等周边工具，则为我们提供了实施持续集成/持续部署的必要条件。从公司角度出发，公司普遍更看重项目的交付能力，所以在传统持续集成/部署的基础上，我们时常会听到持续交付这样的声音，这时我们就会意识到，DevOps实则是持续集成思想的一种延伸，它并不是一个新的概念，事实上我们这个行业，每年都喜欢这种“旧酒换新瓶”的做法，持续集成/部署/交付是DevOps的核心技术，如果没有自动化测试和自动化部署，DevOps就是难以落地的空中楼阁。 &emsp;&emsp;由此，我们就引出今天这篇文章的主题，即持续集成。我们提到，DevOps是是一套面向IT的跨部门协作的工作流，它是持续集成思想的一种延伸，所以持续集成首先是一组工具链的集合。从某种意义上来讲，决策者喜欢DevOps，并不是真正喜欢DevOps，而是形式上的DevOps非常容易实现，因为有形的工具资源的整合是非常容易的，真正困难的是无形的流程资源的整合。你可以让两个陌生人在一起假装情侣，但你永远不可能真正拉近两个人心间的距离。通常而言，我们会用到下列工具： 版本控制和协作开发：Github、GitLab、BitBucket、Coding等。 自动化构建和测试：Apache Ant、Maven、Selenium、QUnit、NUnit、XUnit、MSBuild等。 持续集成和交付：Jenkins、TravisCI、Flow.CI等。 容器/服务部署：Docker、AWS、阿里云等。 &emsp;&emsp;从术和道的角度来看待持续集成，我们会发现在术的层面上，我们有非常多的选择空间，所以接下来我们主要从道的层面，来说说持续集成的核心思想。我们提到在实践DevOps的时候，需要有一条项目主干，那么持续集成的基本概念，就是指频繁地提交代码到主干分支，这样做的目的是，保证问题被及时发现以及避免分支大幅度偏离主干。 &emsp;&emsp;在使用Git的场景下来看待持续集成，及时提交代码到主分支，可以避免因为分支改动过大而带来的冲突问题。按照敏捷开发的理论，每个feature通过迭代开发来集成到最终产品中，那么持续集成的目的，就是为了让产品可以在快速迭代的同时保证产品质量。在这里产品质量有两层含义，第一，本次feature提交通过测试；第二，本次feature提交无副作用。我们可以注意到，持续集成的第一个目的，即保证问题被及时发现，对应前者；持续集成的第二个目的，即避免分支大幅度偏离主干，对应后者。 &emsp;&emsp;所谓持续集成，是指代码在集成到主干前，必须要通过自动化测试，只要有一个测试用例失败，就不能集成到主干，所以持续集成和自动化测试天生就是紧密联系在一起的。我们不能只看到持续集成/部署/交付，如果连流程上的自动化都无法实现，这些都是无从谈起的，从开发者的角度来看，理想的状态是编译即部署，我们提交的每一行代码，都是可以集成、交付和部署的代码，所以实际上是对开发者的代码质量提高了要求。所有我们觉得美好的事情，其实核心都在于人如何去运作，想到一位前辈说过的话，“软件开发没有银弹”，所有试图通过某种方法论解决软件工程复杂性的想法，都是天真而幼稚的。 Jenkins持续集成落地实践&emsp;&emsp;博主曾经在公司项目上实践过持续集成，深感持续集成想要真正在团队里落地，受到太多太多的因素制约。我们采取的方案是，使用Git/Github作为源代码版本控制工具，使用Jenkins作为持续集成工具，使用MSBuild作为项目构建工具，使用MSTest/NUnit作为单元测试框架，使用Selenium/UI Automation作为UI自动化测试框架，这些工具可以很好地同Jenkins整合起来。在持续集成工具的选择上，我们并没有太多的选择空间，因为公司需要同时支持Java和JavaScript/Nodejs项目的持续集成，在持续集成落地这件事情上，我们最终选择了妥协，我们不再追求自动化部署，而是选择通过这个过程来快速定位问题，具体原因我们下面来讲。 &emsp;&emsp;首先，我们期望的是开发者在提交代码以后，可以触发编译、构建、测试和部署等一系列操作，我们会通过Git从远程仓库拉取最新代码，然后通过MSBuild来编译整个代码，由于MSBuild提供了定制化的脚本，可以对编译、测试和部署等环节进行精准控制，所以我们在Jenkins上触发的实际上是一系列动作，而这些都是可以在Jenkins上进行配置的，我们通常会将Jenkins上的日志以邮件形式发送给开发者，所以在很长一段时间里，每天到公司第一件事情，就是查看邮箱里的邮件，一旦发现有测试用例没有通过测试，我们就需要重复“修改代码“-&gt;“提交代码“这个过程，直至所有用例都完全通过测试，理论上通过测试的代码就可以直接部署上线，因为MSBuild可以帮助我们生成最终文件，我们只需要将其打包然后上传到服务器即可，可是实际上这是我们假想的一种场景而已，因为现实场景中我们考虑得通常会更多。 &emsp;&emsp;一个关键的问题是，我们没有可以量化的标准去评估，本次提交是否可以集成到主干。我知道你一定会说测试，事实是开发者不喜欢写测试，或者是写了不可测的测试，前一种观点认为写测试会占用开发时间，所以在开发时间相对紧张的时候，这就变成了我们不写测试的借口；后一种观点则是不会写可测试代码的表现，典型的表现是代码耦合度高、依赖大量无法Mock的对象实例、不会合理使用断言，所以在这种情况下，持续集成是没有意义的，我们不知道何时代码可以集成、交付和部署。我承认自动化测试无法全面替代人工测试，但当我们的关注点放在交付和部署上的时候，是否应该考虑先让持续集成落地，这实在是比DevOps更基础、更接地气，因为我相信持续集成是一种思想，它对开发团队中的每一个人都提出了更高的要求，持续集成是为了在保证产品质量的同时快速迭代，如果你心中没有产品质量的概念，DevOps并不能帮你提高产品质量。 &emsp;&emsp;第二个关键的问题是，开发和运维该如何去协作，DevOps是为了促进部门间沟通协作而提出的一套工作流，自动化是这套机制能够良好运行下去的前提，可是在现实场景中一切并没有那么理想。以我们公司为例，开发组和运维组分属两个不同的部门，运维组在上线、部署等关键环节设置了严格的审批流程，即运维组牢牢地控制着线上生产环境，所以即使我们通过MSBuild在Jenkins上为程序打好了包，我们依然需要按照运维组的要求，提交上线请求、人工上传程序以及等待部门审批，通常我们上线只有等到每周五，而上线流程所需的东西，我们需要在一周前准备好，所以你可以注意到一个现象，虽然在流程上开发团队和运维团队是结合在一起的，但实际上两者的工作目标依然是分离的。那是不是将两个团队放在一起工作，就能解决这个问题呢？我想合作的前提是相互理解和信任，如果彼此都不愿意去了解对方的工作流程，DevOps可能仅仅是我们用工具堆积出来的虚幻感。 实现Hexo博客的自动化部署&emsp;&emsp;好了，在公司使用Jenkins实践持续集成，在现实场景中总会受到各种各样的制约，这并不是因为持续集成这个想法不好，而是在现实面前我们都选择了妥协。有句话说，“如果没有见过光明，我本可忍受黑暗”，我们喜欢一个人或者是一样东西，都是因为我们觉得它是美好的，可以让我们觉得这个世界温暖，那么在公司以外的地方，我想更加自由地做些我喜欢的事情。在公司实践持续集成的时候，因为公司对权限的严格控制，我难以实现那种想象中的持续集成，即在成功地在提交代码以后直接触发编译和部署，我想在公司之外做成这件事情。 &emsp;&emsp;为什么想到要给博客做持续集成呢？首先，持续集成和单元测试联系紧密，我自认为我的单元测试刚刚入门，为了写出更好的单元测试，我必须要这样做，来强迫自己努力去写好单元测试；其次，持续集成可以将开发和部署分离，所以我在任何一台计算机上撰写博客，都可以通过TravisCI实现编译和部署，对Hexo这种静态博客而言，部署其实就是推送页面到Github而已，整体难度并没有太高。最后，我平时更新博客都是手动推送页面，因为我不喜欢用Hexo提供的部署功能，现在我想让自己专注在内容写作上，而一切都可以在我的控制范围内。这正是我所想，如果能让一切更好一点，我都愿意去尝试和努力。 &emsp;&emsp;关于Hexo这类静态博客生成器搭建博客的原理，我这里不想在赘述，因为我愿意相信，懂得搭建博客的人，一定是了解Git、Github Pages和Markdown等等的概念的，关于配置相关的细节大家可以参考官网。这里想着重介绍下TravisCI，TravisCI是一个在线的、分布式的持续集成服务，可以用来构建和测试托管在Github上的代码，并且其本身就是开源的。TravisCI提供了主流编程语言如C#、Java、JavaScript、Ruby、PHP、Node.js等的支持，相比Jenkins而言，它是一个轻量级的持续集成平台，它会在每次提交代码后，根据配置文件来创建一个虚拟机，并执行用户定义的Build任务，这个虚拟机提供版本控制(Git)、项目构建(Node.js)等，在此前提下，我们下面着手Hexo的自动化部署。 方案设计&emsp;&emsp;Hexo博客实际上可以分成两部分，即博客源代码和静态页面。其中博客源代码主要是指Hexo及其相关模块、博客内容(source)、博客主题(theme)，而静态页面由Hexo动态生成，通常放置在public目录中。对Hexo来讲，我们最终部署需要的是这些静态页面，所以我们设计得一个方案是，将静态页面存放在master分支，将博客源代码存放在blog分支。当用户提交代码到blog分支后，会触发TravisCI中定义的一系列操作，它会首先从blog分支拉取博客源代码，然后在TravisCI中完成静态页面的生成，最后将其提交到master分支以完成博客的更新，整个过程非常优雅，终于让我彻底摆脱了手动更新博客的过去，而更重要的是，从此写博客不再受地点的制约，因为写博客就是提交代码，生成静态页面以及部署到Github Pages，现在全部交给了TravisCI. 配置TravisCI&emsp;&emsp;TravisCI是一个轻量级的持续集成方案，其轻量级主要体现在它的配置文件，即使用TravisCI并不需要我们安装任何软件，我们仅仅需要提供一个.travis.yml文件即可，该文件通常被放置在项目根目录里。和Jenkins这样的持续集成工具不同，我们在这个文件中即可定制Build任务，下面给出一个基本的配置文件： 12345678910111213141516171819202122232425262728language: node_jsnode_js: stable# S: Build Lifecycleinstall: - npm installscript: - hexo clean - hexo generateafter_script: - cd ./public - git init - git config user.name \"qinyuanpei\" - git config user.email \"qinyuanpei@163.com\" - git add . - git commit -m \"Update Blog\" - git push --force --quiet \"https://$&#123;CI_TOKEN&#125;@$&#123;GH_REF&#125;\" master:master# E: Build LifeCyclebranches: only: - blog env: global: - GH_REF: github.com/qinyuanpei/qinyuanpei.github.io &emsp;&emsp;如果大家熟悉Jenkins的使用，就会发现这里定义的Build任务似曾相识。在这里我们首先指定了项目构建语言，即这是一个node.js的项目，然后我们会通过npm安装所有依赖，我们注意到在根目录里有一个package.json文件，该文件定义了整个项目依赖的项目。如果你使用过Nuget，你会发现这一切都是如此的合理。那么当整个环境准备就绪以后，我们就可以着手博客的构建啦，和平时一样，我们会执行hexo clean和hexo generate命令，这样Hexo会帮助我们生成所有的静态页面，现在我们通过Git将其推送到master分支，通常基于Github Pages托管的页面都是存放在gh-pages分支的，可是对Hexo而言，我们放在master分支是没有问题的，这就是TravisCI构建整个博客的具体过程。 关联TravisCI&emsp;&emsp;到目前为止，我们定义好了TravisCI将会在虚拟机中执行的Build任务。我们知道，这里TravisCI是需要访问我们托管在Github上的代码仓库的，所以我们必须将这个代码仓库和Travis关联起来，这样它就具备了从代码仓库拉取代码(Pull)和向代码仓库推送(Push)代码的能力。印象中公司是给每一个Jenkins服务器关联了一个Github账户，这样需要持续集成的项目只需要添加这个账号，并为其赋予基本的读写权限即可。在这里是类似的，我们有两种方案来关联TravisCI，即为TravisCI虚拟机添加SSH-Key和使用Github提供的Personal Access Token。 &emsp;&emsp;前者和我们平时使用Git时配置SSH-Key是一样的，但考虑到公开密钥产生的安全性问题，TravisCI建议我们使用官方的一个工具来对密钥进行加密，这是一个基于Ruby开发的命令行工具，加密后的内容可以在TravisCI中解密，这种方案需要安装Ruby，博主选择放弃。如果你要问我为什么放弃Ruby，大概是因为我忘不了曾经被Jekyll支配的恐惧感。而后者的原理是将Github生成的Token作为一个环境变量存储在TravisCI中，我们在定义TravisCI中的Build任务时可以引用这些环境变量，我们只需要在执行Git命令时带上这个Token就可以了。显然这种方式更合我的胃口，它的缺点是对此Github采用了粗放式的权限控制，即这个Token时可以访问所有代码仓库的，这一点大家自己可以根据自身情况来决定要使用哪一种方式。 &emsp;&emsp;我们在Github中的Setting-&gt;Developer Settings找到Personal Access Token，然后选择所有repo相关的权限，生成这个token后将其复制下来备用，因为它只有在这个地方是可见的。接下来我们打开TravisCI，在使用Github登录后我们就可以在这里看到所有的项目，如图是我个人的TravisCI界面： TravisCI主界面 大家可以注意到，这里我开启了qinyuanpei.github.io这个仓库的持续集成服务，如果大家没有在这里看到项目列表，可以点击”Sync account”按钮进行同步。好了，现在我们继续配置： 配置TravisCI 在这里我们配置了名为CI_TOKEN的环境变量，该值对应.travis.yml文件中的${CI_TOKEN}。现在我们在本地提交代码到blog分支，就会触发TravisCI执行Build任务，在这里Build任务是从blog分支拉取博客内容及主题，通过npm安装依赖的nodejs模块，最终Hexo生成的静态页面会被推送到master分支，这样就完成了整个自动化构建的流程。下面是TravisCI执行Build过程中的日志界面： TravisCI日志 &emsp;&emsp;从计划写这样一篇文章，到我一边写博客一篇将它发布在网络上，前后花了大概我3天左右的时间。这段时间发生了太多太多的事情，所以写东西受难免受到情绪影响，你现在看到这篇由TravisCI自动生成的博客，大概无法想象屏幕前的我有着怎样复杂的心绪，有时候我告诉自己要沉下心来学点什么，有时候我会觉得此时的我和过去没有什么区别。转眼间忙忙碌碌一年到头，可会想起来顿时觉得时间像虚度一般，有人说，当你对未来不再有什么期许的时候，就是你开始衰老的迹象，可我真的老了吗？我不是只有25岁吗？好啦，夜深人静，该去睡觉了，这篇文章就是这样子啦。","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://qinyuanpei.github.io/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://qinyuanpei.github.io/tags/Hexo/"},{"name":"Travis","slug":"Travis","permalink":"https://qinyuanpei.github.io/tags/Travis/"},{"name":"CI","slug":"CI","permalink":"https://qinyuanpei.github.io/tags/CI/"}]},{"title":"不如归去","date":"2017-10-21T22:31:48.000Z","path":"posts/720539850/","text":"&emsp;&emsp;独自一个人在火车上望着窗外出神，而这种情景我再熟悉不过，或许风景会因为季节而不同，或许时间会因为年龄而不同，但对我而言，这个过程熟悉得就像一个我讲了无数遍的故事，从开篇布局到故事脉络都清楚到严丝合缝。印象中是从初中时候就开始寄宿生活，所以这种漂泊的感觉成为我生命里重要的烙印，而从那一刻起，我最期待的是寒暑假期，因为这象征着一段漂泊旅程的结束。大概是因为双子座属于风象星系，所以每次回家的旅程都伴随着忧愁风雨，我喜欢将这个过程理解为，生命不经意的装点。风有质而无形，或飞沙走石，或拈花弄叶；雨有质而无形，或坠散成珠，或凝聚成流。大概都是在世间漂泊的浪子，每一刻都摇曳不定。 &emsp;&emsp;有人说，放假回家是学生时代做的事情，因为那时我们还没有脱离父母的庇护。可当我工作了以后，当我同他们的距离不再是学校和家的距离，当我同他们打电话不再是因为生活费告拮，我忽然发现我同他们交换了这场漂泊里的角色，从前是我期待着假期，因为我可以见到他们；现在则是他们期待着假期，因为他们可以见到我。我忽然发现我一年中我陪他们的日子屈指可数，从前向往远方觉得在那里能找到我的梦，现在越发地觉得他们一天天老去，想努力长大成熟，让他们能够放心，可更怕因为距离而疏远了他们，古人说『树欲静而风不止，子欲养而亲不待』，这个世界固然不再是古人所认识的世界，这种感情却超越了时间和空间轮回至今。 &emsp;&emsp;国庆本来打算不回家的，因为即使无人可约无人可陪，我一个人同样可以给自己放假。我从来都是这样，如果有人愿意陪我做一件事情，我会很乐意接纳这番好意，并尝试用最好的状态去让彼此享受这个过程。如果没有人愿意陪伴我做一件事情，我不会勉强更不会因此而沮丧，因为当你习惯了一个人去面对所有事情，你会发现你从来不缺乏做一件事情的动力。可当家里人问我国庆要不要回家的时候，我突然心软得像融化了的雪，我意识到是我心底涌出的一股暖流，快速地打开微信买回家的火车票，结果发现15号的时候票就没有了，妈妈发微信给我说，『如果实在买不到火车票，就买机票回来吧，不用太心疼钱，人回来了就好』。 &emsp;&emsp;我记得以前他们都不大会用这类IM产品的，但现在他们学会了怎么发消息发朋友圈。记得过年的时候，我教妈妈怎么样发红包，虽然只有三块钱这样来回发着玩，但她玩得比我都开心，或许父母就是这样，曾经青春期叛逆时觉得他们的世界和自己格格不入，等他们老去的时候依然在努力着融入我们的世界。小时候他们紧紧追逐着我们，是怕我们在成长路上摔倒；长大了他们依然紧紧追逐着我们，是怕我们的世界里没有了他们。可他们在一天天地老去，如果有一天他们追不动了，我们是否愿意停下来等等他们呢？窗外的若明若暗的，像极了我往常回家路上数过的每一盏灯，可是我最喜欢的那一盏，是来自那个叫做家的地方，它或许并不璀璨耀眼，但向来不吝于为你释放光和热，永远为你指示着家的方向。 &emsp;&emsp;早上去北客站取票坐车，就接到朋友从中卫打来的电话，询问我国庆是不是要回家，这种感觉就像家里人一直记挂着你。我经常会想起高中时候，有时同朋友出去玩到很晚回家，常常会到朋友家里借宿，两个人寝则同床食则同桌，到今天我们依然是特别特别好的朋友。我幸运的是一直被朋友这样照顾着，即使我们两个在毕业后天各一方，我这个人不大懂得经营感情，被这样的朋友一直照顾着，我该是有多幸运啊。因为没有买到直达的车票，所以坐动车到兰州去转车，然后遭遇了人生中第一次火车晚点。火车晚点近三个小时，第一次迫切地感觉离家好远好远，每次回家都是披星戴月，或者在夜深人静时，或者在曙光初现时，让家人和朋友等我，我总是过意不去的。大概他们都太了解我，知道我会永远都是这副『长不大』的样子，可我总要长大成熟啊！ &emsp;&emsp;我记得以前还在父母身边时，我脑子里想的是『父母在，不远游，游必有方』，我一位同学曾问我，何谓有方，当时的我真的是不知道该怎么样回答。后来，一个人去西安发展，终于明白，以前公司里一个女生所说的，在哪里都一样。想到父母孤零零地待在家里，想到每年屈指可数的回家次数，曾几何时，我们想去更广阔的世界寻找诗和远方，可父母逐渐蹒跚的步履注定无法，陪伴我们去那些遥远的地方。诗经里说『青青子衿，悠悠我心，纵我不往，子宁不来』，如果他们不能再紧紧追随我们的步伐，我们为什么不停下甚至转身回去去看望他们呢？以前和我徒弟聊天，她说男生都不大喜欢和家里人联络，我本来就是沉默寡言的性格，从初中时候就不主动和家里人联络，现在我想改变这种想法，因为我想有空就陪陪家里人。 &emsp;&emsp;我喜欢在漫长的旅途中看书，这种习惯在我有了Kindle以后变得更为明显。早上看到这样一句话，『你懂得越多，就越觉得自己像这个世界里的孤儿』，人生而孤独，父母总有一天会离开我们，但他们教会我们如何去爱这个世界，我希望我可以用他们教会我的，在他们有生之年做些在他们眼里不再『孩子气』的事情，虽然在他们眼里我们永远都是孩子，我觉得真正的成熟并不是变得冷酷麻木，而是你知道这个世界有黑暗的一面，依然愿意相信那些温暖的事情。我到现在依然不喜欢听别人讲“道理”，因为我觉得人生最奇特的地方就在于，即使别人讲得这些“道理”都对，别人依然无法代替你去体验整个生活。每个人都是生活这片大海里的一朵浪花，为了不被岁月冲上荒凉寂寞的沙滩，我们唯有追逐巨浪努力生存。有那么一瞬间，我想和我喜欢的姑娘生活在一个城市里，等有空了就带上她回家陪陪父母。 &emsp;&emsp;或许有些地方有比故乡更广阔的天空，或许有些地方有比故乡更湿润的土壤，或许有些地方有比故乡更精彩的旅程，我想说的是，不论你是在追求诗和远方，还是在忍受眼前的苟且，如果你觉得累了，请停下忙碌的脚步，找找回家的路，那里永远有人在等你！","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"成长","slug":"成长","permalink":"https://qinyuanpei.github.io/tags/%E6%88%90%E9%95%BF/"},{"name":"回家","slug":"回家","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%9E%E5%AE%B6/"},{"name":"亲情","slug":"亲情","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%B2%E6%83%85/"}]},{"title":"秋风劲似去年时","date":"2017-09-25T00:56:50.000Z","path":"posts/2617501472/","text":"&emsp;&emsp;连续数日的秋雨绵绵，依然固执地不肯转身离开，而之所以选择在国庆节前徘徊，或许是为了让离开家的人，多些同江湖风雨漂泊的味道。印象中这样的日子常常是相似的，譬如穿行在骤雨中被来往车辆溅得一身水，或者行走在上班的路上抬头看见第一场雪，或者是倚靠在公交车窗边上看风景转眼即逝，这些再熟悉不过的场景对我熟悉而又陌生，我惊异于记忆常常像盗梦空间般重叠，我感概于时间常常像钟表指针般流连。我不知道这个世界上是不是有平行世界，但我知道我再回不去曾经某一个时刻，我一直想写下这段时间的状态，可当我准备下笔时才发现，它需要我努力想好多事情，我依然还是曾经的我，风景依稀还是曾经的风景，到底是谁在一直变化呢？ &emsp;&emsp;我不知道要从什么时候回忆这些事情，这种感觉就像是你期待了许久之后，在触碰到她的那一刻都不复存在了。我曾经答应过一个人要去看望她，如果你读过《一个人的朝圣》这本书，或许就会明白这是一种怎么样的执念，即使在明明知道一切再无法挽回的时候，这种执念还是让我想要达成这个愿望。我一直不知道两个人怎么就自然而然地在一起了，那种感觉如果一定要用语言来形容，我觉得是一种熟悉到灵魂里的默契。你想要牵着她的手的时候，她假装挣扎下后就一直让你牵着，那种娇羞中透着可爱的神情，在四目相对的时候眼睛里都是闪着光的。我忘不了在人潮中牵着她的手穿过整条街市，我忘不了抱着她的时候街市两边灯笼通红。有时候觉得人生充满了遗憾，好像错过她花光了我这辈子的好运气，从那以后我总是重复着昨天的故事。 &emsp;&emsp;其实我自己都不清楚，我到底喜欢什么样的女孩子，甚至有时候我喜欢的是，我心中她最美好的样子。一个人少不经事的时候，大概会喜欢对女孩子说甜言蜜语，可当他经历过失去以后，他变得不再轻易许诺，这就好像我小时候是一个特别喜欢说话的人，在经历过因为紧张而变得口吃以后，我终于变成了今天这副沉默寡言的样子。有时候会陡然间觉得自己并没有怎么变，或许是因为她说过她喜欢我这个样子，所以我就固执地不肯改变，因为我怕有一天她回来的时候认不出我来，即使这是我脑补的一个剧情。曾经看过一个电影《这个男人来自地球》，当我们熟知的宗教历史变成一个人的回忆，这种超越哲学意义上的时间我认为是荒凉的。曾经的小伙伴Alex、Sandy、Kent、Andy、Kent、Kavin和Joe都渐行渐远，到底是我停留在原地还是我超越了时间？ &emsp;&emsp;不知道该怎么样描述这种感觉，或许我就是一个不擅长联络感情的人，生命中有太多太多东西，我眼睁睁看它离我远去而又无可奈何，想要安慰我的人总是劝我同昨天告别。但像我这样太看重感情的人，无论外表多么风平浪静，内心永远不肯残忍地删除回忆。所以，我记得Jackson、Lynn、Candy他们陪我度过的二十五岁生日，我记得Candy问我当时暗自许了什么样的愿望，坦白来讲，我没有想着脱单这样离我很遥远的愿望，我只想时间能够永远定格在那一刻，大家都可以开开心心地直到永远。你一定觉得我幼稚或者是不成熟啦，我问过人家要怎么样变得成熟，人家说你去找一个女朋友就好啦，然后就会在喜欢的人面前紧张甚至自卑，我曾一度很讨厌下雨天，因为我怕两个人遇到一起，我既没有伞亦没有外套。 &emsp;&emsp;二十五岁的我，喜欢一个人还是和从前一样无所顾忌，我还是学不会那些复杂的套路，不喜欢单方面付出，不喜欢卑微地爱一个人，每一次都会因为喜欢某个女孩子而尝试改变，想和她站在一起的时候不会被她的光芒完全覆盖，想和她待在一块的时候不让她觉得我这个人枯燥，想和她抱在一起的时候给她讲我从书里看到的某个故事……我一直在想，如果我们的感情不是以异地恋这种方式会不会有不一样的结局，我喜欢《星月神话》这首歌，是因为我们的确呼吸着同一片天空的气息而注定无法再相遇，就像两条相交的直线一样从陌生到熟悉再到陌生。我现在再看《嫌疑人X的献身》这部电影，我总在想，如果那天我们看的是这部电影会怎么样，此时的我比上大学时候胖了许多，大概一开始我在她心目中的样子，应该是张鲁一这样温润如玉的谦谦君子吧！生命就是这般离奇玄妙，你不能假设更无从假设应该发生什么，因为每一天都是无法重现的Case，你觉得它相似，仅仅是因为相似而已。 &emsp;&emsp;我喜欢穿裙子的女孩子，这一点完全是因为受到她的影响，虽然她一再告诉我，是我喜欢这样的女孩子，而她恰好喜欢穿裙子而已，可这些淹没在风声里的话语，谁会去盘问孰是孰非呢，如果她此刻愿意同我争论这个问题，我直接认输就好啦，我对输赢看得并不重要，这就像在工作中，没有人在意做的产品是不是好用，大家关注的是始终是它能节省多少个FTE，所以为了达到这些光鲜亮丽的指标，没有人会在意工程师的代码被改成什么样子，我们所追求的东西是否显得舍本逐末，我们所在意的东西到底是否真正发自你我的本心。以前觉得两个人在一起简单，是因为我们没有想那么多；现在觉得两个人在一起困难，是因为我们习惯性想太多。你有没有在脑海中设想过，和一个人走完一生是种什么样的体验，我想说那是一个很美好的想象。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"},{"name":"回忆","slug":"回忆","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%9E%E5%BF%86/"},{"name":"年华","slug":"年华","permalink":"https://qinyuanpei.github.io/tags/%E5%B9%B4%E5%8D%8E/"}]},{"title":"从React专利事件看开源软件许可","date":"2017-09-20T23:06:45.000Z","path":"posts/1166840790/","text":"&emsp;&emsp;各位朋友，我是Payne，大家好，欢迎大家关注我的博客，我的博客地址是https://qinyuanpei.github.io。最近前端技术圈因为React专利事件再次被大家关注，印象中Angular和Vue的纷争刚刚过去不久，果然前端技术圈对”造轮子”和”搞事情”有着近乎执著的追求。作为一个在知乎吃瓜的伪前端工程师，我对这凑热闹这种事情从来都是是颇为喜欢的。如果说Angular和Vue冲突主要来自大漠穷秋和尤小尤的个人战场，那么这次React专利事件则是商业公司之间对社区主导力量的一次争夺和抗衡。开源是一种近似乌托邦般的理想社会，它倡导的”人人为我，我为人人”这种近乎大同社会的观念，在面临商业化浪潮洗礼的时候难会和商业利益发生冲突，譬如Google因为使用Java而和甲骨文纠纷不断，最终不得不选择Kotlin作为Android开发的主力语言。所以这篇文章我想和大家通过React专利事件来聊聊开源软件许可，以及我们如何在商业化和开源社区间找到一个平衡点。 事件始末&emsp;&emsp;其实React专利事件由来已久，如果不是在知乎上看到“百度要求内部全面停止使用React/React Native”的问题，我是完全没有意识到事态居然发展到如此严重的。每次前端技术圈”搞事情”的时候，基本上都会在我的知乎首页刷屏，可是对我这样的伪前端工程师而言，我仅仅是关注了”Web开发”这个话题而已。忽略知乎首页推荐算法的缺陷，这的确动侧面说明了目前前端领域非常热门的事实，可它不能说明某些前端工程师的技术水平有多高，在引入前后端分离和前端构建工具以后，前端开发的基础设施渐渐地丰富起来了，可是前端开发目前经历着的一切，无一不在后端开发中涉及到，我没有想要成为全栈工程师的野心，在讨论这个事件以前我认为有必要了解下整个事件的始末： 2016年7月，Facebook在React.js的开源许可协议中添加的附加专利条款首次在社区中引发广泛讨论。 2016年11月，Facebook发布官方问答，对附加专利条款进行了澄清，强化了其BSD许可证 + 专利许可证的概念。 2017年4月，Apache Cassandra项目正在考虑是哟过Facebook开源的数据库RocksDB作为存储引擎，可是考虑到专利授权的问题，Jeff Jirsa向Apache法律社区寻求帮助。 2017年6月，Apache 法律社区开始讨论Facebook Patents License协议专利授权的不对称问题，且该协议与Apache Software License，即Apache 2.0等不兼容。 2017年7月15日，Apache软件基金会正式发表声明称：Facebook BSD + Patense License正式被列入”Category X”列表，因此Apache项目中将不能含有或者依赖任何该协议的代码，而已发布的代码必须在8月31日前完成替换。 2007年8月19日，Facebook对Facebook BSD + Patense License有了新的解释，解释指出，专利许可证的存在是为了防御无量的专利诉讼，Facebook增加专利许可证是为了保护核心技术。 2017年9月16日，百度内部全面禁止使用React/React Native的消息在知乎上引发热烈讨论。 2017年9月17日，Wordpress官方称因为React专利问题而停止在博客程序Wordpress中使用React技术。 2017年9月23日，Facebook迫于社区压力对外宣称将在数周后将React授权许可修改为MIT。 主流软件许可&emsp;&emsp;其实作为一名软件工程师，这些和法律息息相关的内容，原本是不需要我们去关注的，因为即使公司在使用这些开源软件中发生法律纠纷，通常都会有法务人员协助公司去解决相关事宜，无论如何都轮不到我们这些人来关心的。不过这个事件的现实意义是，我们在做技术选型时，专利等可能引起法律纠纷的问题，一样是需要纳入考虑范围的。因为如果是个人性质或者纯玩性质的项目，我们的确无需在意太多。而如果你是商业性质项目、或者是公司自营项目，或者是服务于甲方，那么你必须考虑你使用开源软件的方式是否符合相关的软件许可。国内因为盗版软件盛行的原因，大家在心底里好像都不认同软件许可，但是像外企或者是对信息安全比较重视的企业，通常要么对许可证书比较看重，要么对开源软件不太感冒，所以像最近的WePhone创始人自杀这种事件，都在告诉我们一个道理，程序员不要整天都关注技术层面上的东西，虽然技术世界有很多纯粹而美好的事情，但当它和人类联系在一起、和政治联系在一起的时候，它就完全不在我们的控制之中了，所以我觉得我们有必要了解些法律相关的事情，那么从何处开始呢？我们不妨就来说说主流的开源软件许可吧！ &emsp;&emsp;这个世界上的开源软件许可证书大约有上百种，我们不可能也没有必要了解所有的开源软件许可证书。对于主流的开源软件许可，我们有GPL、BSD、MIT、MPL、Apache和LGPL，相信大家都没有兴趣去阅读这些晦涩深奥的License，所以我们不打算在这里逐一介绍它们，事实上搞清楚它们在具体限制上的差异是件非常困难的事情。我们希望用最简洁的语言来描述这些开源软件许可： GPL： 即GNU通用公共授权(GNU General Public License)，其出发点是代码的开源/免费使用和引用/修改/衍生代码的开源/免费使用，但是不允许修改后和衍生的代码做为闭源的商业软件发布和销售。这就是为什么我们能用免费的各种包括商业公司在内的Linux版本，以及Linux上各种各样的由个人、组织和商业软件公司开发的免费软件。 BSD： 即Berkly Software Distribution， 基本上是一个给予使用者极大自由空间的一种开源协议，使用者可以自由地对代码进行使用、修改和二次发布，该协议鼓励代码共享，其出发点是尊重代码作者的著作权，要求保留原代码中的BSD协议，保留创作者署名权利，即不得以开源软件作者/机构的名义进行市场推广。 MIT： 即Massachusetts Institute of Technology，这是一个完全给予使用者自由空间的 简短而宽泛的授权协议，作者唯一的诉求是保留版权，使用者可以复制、修改、合并、发布、分、授权和销售软件副本，并根据程序的需要适度修改授权条款，唯一的要求是必须在发行版里附加原许可协议的声明，无论是以源代码还是二进制形式发布。 MPL：即The Mozilla Public License，该协议同GPL和BSD基本一致，差异主要体现在：源代码提供者不能提供已经受到专利保护的源代码、要求再发布者必须提供对代码程序修改的说明、允许通过MPL许可获得的源代码同其他类型源代码进行混合(第二条献给那些不好好在Git里写注释的同学)。 Apache：即著名的非盈利开源组织Apache采用的协议，该协议和BSD类似，同样鼓励代码共享和尊重原作者的著作权，同样允许代码修改，作为开源或商业软件再发布，主要关注点有：（1）需要给代码的用户一份Apache License；（2）如果改动代码需要在被修改文件中做出说明；（3）衍生代码必须保留原有协议、商标、专利或者说明等；（4）不得对Apache协议进行修改。 LGPL：LGPL，即GPL V2，是GPL的一个为主要为类库使用设计的开源协议，和GPL要求任何使用/修改/衍生之GPL类库的的软件必须采用GPL协议不同。LGPL 允许商业软件通过类库引用(link)方式使用LGPL类库而不需要开源商业软件的代码。这使得采用LGPL协议的开源代码，可以被商业软件作为类库引用并发布和销售的同时，保障作者的知识产权，避免有人利用源代码复制并开发类似产品。 &emsp;&emsp;好了，相信到这里大家就能够明白，为什么这次React专利事件能在社区里引起轰动。我认为主要的原因有两点： &emsp;&emsp;第一，React在BSD协议许可的基础上增加的专利许可，对许可证书授权方和被授权方而言，存在待遇上的不对等性。实际上在React为前端带来虚拟DOM、单向数据流和不可变对象等一系列函数式编程的概念的同时，Facebook在开源社区中的话语权同样越来越大，Facebook在开源协议中夹藏私货的确让人有种”挟天子以令诸侯”的感觉，曾几何时，社区指责微软没有开放全部的OpenXML标准，因为大家都觉得按照这个标准实现的Office文档和微软家的存在差异，可是面对这种和自家产品紧密联系的项目要开源，我觉得这不单是Facebook会有所提防，恐怕所有的商业公司都会有类似的想法吧，所以在这个事件中，隐含的一个点就是，一旦当使用React的公司和Facebook发生业务上的竞争，React将成为Facebook获得诉讼胜利的一个重要筹码，因为根据React的专利协议，Facebook有权在开展诉讼时从被授权方手中收回React的使用权，所以我们不难理解为什么百度和Wordpress都宣称要停止使用React，除了不想受制于人以外，像百度这种未来可能会和Facebook在AI等领域发生竞争的公司，宁可自己造一套轮子而不愿让自家专利被对方使用的做法，我觉得是可以理解的。 &emsp;&emsp;第二，React在开源协议中附加专利许可的做法，从商业公司自我保护的角度来看，的确是无可厚非，不过这种做法未免会给开源社区带来不好的风气。我们都知道开源软件并不等同于免费软件，因为开源软件通过许可证书来保证开源软件代码是以一种合理的方式被使用。在很久很久以前，MySQL是我非常喜欢的一个数据库，因为它可以让我摆脱SQLServer臃肿的体积。什么？你说.NET技术体系中怎么会出现MySQL？可这正是.NET选择开源、选择了跨平台，我们才有机会在更广阔的世界里去做些有趣的事情不是吗，我们必须承认开源对这个世界的重要意义，当你发觉你身边的同事都在重复写些垃圾的代码时候，你或许就会意识到，其实在这个世界上有很多东西，我们是可以站在巨人的肩膀上看得更远的。当你因为目光短浅而小心谨慎地维护着那些破旧的代码的时候，我们除了一天天老去别无所获。自从MySQL被甲骨文收购以后，我觉得这个世界开始缺少些有趣的东西，甲骨文和Google关于Java的官司让Google最终选择了Kotlin，所以你可以看到开源这件事情对这个世界是绝对有利的，很多人担心这些代码开源到互联网上对商业公司不利，其实我们都清楚，没有环境和生态的代码基本不会有人关心，我们是不是该重新审视下开源？ &emsp;&emsp;OK，我知道现在大家都在思考一件事情，既然开源对这个世界的进步是有利的，那么是否开源就不应该成为我们思考的问题，我们真正应该考虑的问题是，如何选择一个合适的开源软件许可证书，在商业化和开源间找到一个平衡点。对于这个问题，我想大家一定会犯选择困难症，不过没有关系啦，我想下面这张图可以帮到大家： 如何选择开源软件许可证书 何去何从&emsp;&emsp;或许在数日前，你还在为React专利事件而苦恼，或者考虑在Preact的基础上实现一个新的React，或者考虑转向Angular和Vue这两个框架，此时此刻Facebook宣布将React的开源协议修改为MIT，或许这算是开源社区的一次胜利，或许这算是整个专利事件的尘埃落定，或许有人继续担心Facebook搞其他事情，可是这个世界原本就是在每天都发生变化着的，对于未来我们常常是无从得知它的足迹会在哪里。人生本来就是一个人的逆旅，要想在这充满变化的世界里获得安全感，唯有努力让自己处于不败之地，技术何尝不是这样呢，想想这20年间我们经历了多少技术的变革，从来没有一门框架可以让我们一劳永逸，所以对于小公司而言，大可不必担心Facebook会因为专利问题和你产生法律上的纠纷，该用什么就用什么框架，因为没有绝对完美的框架，能结合业务场景选择合适的框架，为这个世界带来一点点微小的变化，这样子我们就足够开心啦！而对于BAT这样的互联网大厂，则应该考虑走自主研发的差异化路线，因为如果你不想受制于人，最好的方法就是让别人依赖你，而不是去努力依赖别人。作为一个伪前端工程师，我觉得不管什么时候，我们都要努力打好基础，而不是在一堆框架中疲于奔命，对热衷于搞事情和造轮子的前端技术圈来说，下一次的讨论热点会是什么，你我都未必能想到，这个时候还有什么比努力更重要的事情呢。好了，这篇文章就是这样了，希望大家能够喜欢，我们下一篇见。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"前端","slug":"前端","permalink":"https://qinyuanpei.github.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"React","slug":"React","permalink":"https://qinyuanpei.github.io/tags/React/"},{"name":"开源","slug":"开源","permalink":"https://qinyuanpei.github.io/tags/%E5%BC%80%E6%BA%90/"}]},{"title":"Redis缓存技术学习系列之Lua脚本","date":"2017-09-17T10:49:07.000Z","path":"posts/4197961431/","text":"各位朋友，大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是https://qinyuanpei.github.io。想起来大概有一个月没有更新博客啦。或许是因为这中间发生了太多的事情，想来人生原本就充满曲折和变数。在微信群里得知家中舅爷去世的消息，突然意识到时间早已摧毁你我的一切。那个曾经同你有千丝万缕联系的人，会在某一刻同你彻底失去联系。所以我更珍视彼此在一起的时光，因为在这个世界上每天都面临着改变。有时候工作上遇到不开心的时候，会想着一个人去一个陌生的地方，我们就在不断地相聚和离别中慢慢老去。这段时间一直在学习做饭，为此特意买了本菜谱，结果发现，最难的并不是如何去做好一道菜，而是你为了做好一道菜需要准备各种食材，就像人与人交流并没有什么困难，真正困难的地方，是你找不到一个可以一直陪你说话的人。熟悉的店面会被拆迁转让，熟悉的人事会被错过改变，上帝想把世界煮成一锅粥，可味道的调配却由我们来掌控。 好了，所谓“如人饮水，冷暖自知”，人生奇就奇在你没有办法用三言两语去描述它。这段时间面试过两三家公司，整体上感觉自己的生活太安逸了些，虽然我现在依然住在租来的房子里，转眼间2017年接近尾声啦，可是回想起来今年年初制定的计划，在广泛阅读和提升技术上都是不及格的状态，印象中打算研究Redis和MonogoDB这两种数据库的(因为没有购买为知笔记会员导致部分笔记损坏或者丢失)，然而到现在为止我还有研究完Redis。尤其当我面试的时候，我发现好多我写在简历上的内容，都会成为某种意义上的呈堂证供，这让我更加确信好多东西需要不断地去巩固，所以尝试在实际项目上使用Moq、考虑怎么写出更好的测试方法以及时刻保持自我的不可替代性，这些都是我最近在考虑的事情，有时候发脾气是因为觉得自己在浪费生命，可越是被这种无力感笼罩的时候，就越是要对自己狠一点儿，所以在这篇博客中，让我们重新拾起对Redis的学习兴趣，今天我们来说说Redis中的Lua脚本。 熟悉我博客的朋友一定都知道，我曾经开发过Unity3D相关的项目，而Lua脚本正是Unity3D中主流的热更新方案。关于Lua脚本相关的文章，大家可以通过下面的链接来了解，在这里我们不再讲述Lua的基础内容，本篇文章所讲述的是如何通过Redis内置的Lua解释器来执行脚本，我们为什么使用脚本语言进行开发呢，因为这样可以降低开发的难度啊。 脚本语言编程：Lua脚本编程入门 在Windows下使用Visual Studio编译Lua5.3 Unity3D游戏开发之Lua与游戏的不解之缘(上) Unity3D游戏开发之Lua与游戏的不解之缘(中) Unity3D游戏开发之Lua与游戏的不解之缘(下) Unity3D游戏开发之Lua与游戏的不解之缘终结篇：UniLua热更新完全解读 好了，既然我们已然了解到Redis是通过内置的Lua解释器来执行脚本，所以Redis中的Lua脚本其实可以理解为Lua语法 + Redis API。为了写作这篇文章，我不得不将我的操作系统切换到Linux，因为这样我可以随时在写作过程中使用终端，我写作的一个重要特点，就是所有的内容都尽量保证有测试覆盖，我知道有许多人都不喜欢写测试，测试虽然不能保证你没有BUG，可是有了BUG以后可以直接在测试中定位问题，这就是我们为什么要重视测试的原因所在。在Redis中我们有两类命令用以处理和脚本相关的事情： Eval系列 熟悉JavsScript的朋友应该会更熟悉这个方法，因为Eval在JavaScript是个神奇的存在，它可以执行任何合法的JavaScript代码，我和我的同事就曾经在一个项目中写过两层嵌套的Eval方法，显然这是为了实现某种奇怪的需求。那么在Redis中有EVAL和EVALSHA两个命令可以使用，这两个命令是从Redis2.6.0版本开始的，通过内置的Lua解释器来实现对脚本求值。EVAL命令的基本格式如下： 1EVAL script numkeys key [key ...] arg [arg ...] 我们可以注意到在这里EVAL命令由三部分组成，即第一个部分，表示一段Lua脚本程序，并且这段脚本不需要更不应该定义函数；第二部分，表示参数列表，指在脚本中需要用到的键，因为Redis是一个键值数据库，这些键名可以通过全局变量KEYS来访问，默认索引将从1开始，事实上我们更推荐你使用这种方式来访问键名；第三部分，表示除建键名参数以外的附加参数，和第二部分类似，这里我们可以通过全局变量ARGV来访问，这里就不再赘述啦。我们一起来看下面的例子： 1EVAL \"return &#123;KEYS[1],KEYS[2]&#125;\" 2 ab cd 此时我们会返回一个由KEYS[1]和KEYS[2]组成的集合，集合中的两个元素分别是ab、cd，注意到这里有一个参数2,它表示我们这里将有两个参数，事实上Redis将从这个位置开始解析参数，所以我们必须告诉Redis参数解析到什么位置结束，因为主要参数(KEYS)和附加参数(ARGV)是从解析的角度上是无法区分的，所以我们期望的结果会是： 121) \"ab\"2) \"cd\" 现在我们来增加点难度，显然你明白我在说什么，请注意我要引入附加参数(ARGV)啦！ 1EVAL \"return &#123;KEYS[1]..ARGV[2] ,KEYS[2]..ARGV[1] &#125;\" 2 ab cd ab cd 这里我们尝试对KEYS和ARGV进行拼接，需要说明的是Lua中连接字符串使用的是. .，所以这里将得到结果： 121) \"abcd\"2) \"cdab\" 好了，现在大家应该理解EVAL这个命令的使用方法啦，那么对EVALSHA命令来说，顾名思义，它就是使用了SHA1验证的EVAL方法，我们注意到现在脚本都是定义在EVAL命令的第一个参数上，假如我们需要复用一个脚本，而该脚本可以为我们提供Sum这样的功能，即它可以返回一组参数的和给我们，显然参数的个数是不同的，那么这个时候我们总不能每次都重复写这个脚本吧，所以Redis会为脚本创建一个指纹，我们使用EVALSHA命令来传入一个指纹，Redis将从缓存的脚本中找到这个脚本，并结合我们的参数来调用它，这样我们就可以获得脚本执行以后的结果，关于指纹的这种说法，大家可以结合Git提交代码时的感受进行理解，除此以外，它和EVAL在使用方法上是完全一致的，所以不再举例子说明啦。 Script系列 好了，下面我们来介绍第二类和Lua脚本相关的API，相比Eval给人云里雾里的感觉，Script系列的命令处处洋溢着规范命名的美好气息，我们通过这些命令的名字基本上就可以知道它是做什么事情的，这告诉我们平时写代码的时候如何去写出优雅的代码。我们通过下面一组命令来了解Script系列命令的具体用法： 1234567891011121314/* 载入一个脚本到缓存中 */SCRIPT LOAD \"return 'Hello Redis'\" /* Redis返回该脚本的指纹信息 */\"e509eb0869056563287758d23146eb00e0518da5\"/* 查询脚本是否存在于缓存中 */SCRIPT EXISTS \"e509eb0869056563287758d23146eb00e0518da5\"/* Redis返回1表示脚本存在，反之不存在 */1) (integer) 1/* 从缓存中清空所有脚本 */SCRIPT FLUSHOK/* 此时脚本在缓存中是不存在的 */SCRIPT EXISTS \"e509eb0869056563287758d23146eb00e0518da5\"1) (integer) 0 至此，我们了解到了Redis中对Lua脚本支持的主要特性，坦白地讲，我认为Lua脚本在这里的应用极其薄弱，完全达不到我们印象中Lua脚本的强大，甚至我对Redis中的KEYS和ARGV依然有些模糊，大概越想搞明白的事情有时候就越搞不清楚。这里我没有提到的一个SCRIPT系列的命令是SCRIPT KILL，这个命令的作用是杀死当前正在运行的脚本，并且当且仅当这个脚本没有执行过任何写操作时，这个命令才会生效，所以这个命令主要用于杀死长时间运行的脚本，执行完这个命令后，执行这个脚本的客户端将从阻塞的EVAL命令中退出，并收一个错误作为返回值，所以我们可以理解为这是一个强行终止脚本执行的方法，因为我这里这个脚本非常的简单，所以它执行起来非常快，而我没有这样一个足够长的脚本去验证这个命令，所以在上面的脚本示例中我没有去验证这个命令，对此感兴趣的朋友可以自行去研究啦。 Lua脚本应用 通过本文前面两个部分，我们基本了解了Redis中Lua脚本是如何工作的，在演示示例脚本的时候，我是直接在终端下运行redis-server和redis-cli的，并且所有的命令都是在终端下手动键入的，难道在实际的使用中我们要这样子玩Redis吗？想起来都觉得好可怕是不是？所以我们下面来通过一个具体的案例，来演示Redis怎么去和一个Lua脚本脚本进行交： 首先，我们来定义一个简单的Lua脚本文件script01.lua，该脚本将对集合中的元素进行求和： 1234567891011local sum = 0;local key = KEYS[1]local length = redis.call(\"LLEN\",key)local index = 0while (index &lt; length)do sum = sum + redis.call(\"LINDEX\",key,index) index = index + 1endreturn sum 现在我们在终端中执行这个脚本，为了方便起见，我们这里将其放在redis-3.2.8目录下的scripts目录。我们首先在Redis中准备些数据来做好准备，在终端中执行命令： 1234LPUSH data 2 4 6 8 10(integer) 5src/redis-cli --eval ~/文档/redis-3.2.8/scripts/script01.lua data(integer) 30 好了，我们下面来解释下这段脚本，我们向Redis中键名为data的集合中添加了5个元素，注意这句脚本是在执行src/redis-cli后执行的，这部分内容我们在前面讲解Redis中的数据结构的时候提到过，博主表示在写这篇文章的时候依然要去看文档，总之现在我们有一个集合，并且这个集合中有5个元素，与此同时呢，我们编写了一个Lua脚本文件script01.lua，这个脚本的作用是对集合中的元素进行求和。在这里我们注意到，我们可以通过redis.call()这个方法来调用redis中的命令，具体到这里我们使用LLEN命令获取了集合的长度，使用LINDEX命令获取了集合中的元素。我们在前面提到两个全局变量KEYS和ARGV，可以完全当作Lua脚本中的两个变量来处理，从编程角度来讲，我们可以将其直接在脚本中写死。可是考虑到Redis是一个键值数据库，所以我们很容易想到键名应该对外暴露出来，以满足复用Lua脚本的目的。这里我们直接用redis-cli来运行EVAL命令，所以我们注意到它的传参方式有点不一样，事实上KEYS和ARGV中间使用逗号隔开即可。 所以我们可以想到一种Lua脚本自动管理的思路，即通过命令行读取指定目录下的Lua脚本文件，通过SCRIPT LOAD方法获得其在Redis中的SHA1指纹，然后我们将脚本名称或者ID和这个指纹关联起来并将其存储在Redis中，此时我们只需要传入脚本名称和参数即可返回脚本执行后的结果，这样是不是感觉非常优雅呢？虽然Redis是一个键值性数据库，它不具备传统关系型数据库的查询能力，但是现在我们有了Lua脚本以后一样可以通过脚本来定制出查询，而到此时此刻我或许才真正明白Redis中Lua脚本是一种怎样神奇的存在。我们心怀敬畏，同时对这个世界永远充满期待，因为我们从来不知道人类潜能开发的极限在哪里。我们创造了太多不可思议的事情，有时候甚至连我们自己都怀疑，为什么我们会走到今天这一步。在脚本语言里我最喜欢的编程语言是Lua和Python，如果说我喜欢Lua源于我对游戏开发的兴趣，喜欢Python源于我对编写网页爬虫的兴趣，那么我很庆幸今天我又多了一个使用Lua的原因。世上美好的事情莫过于，你喜欢一样东西，恰好有人和你一样喜欢，可惜那是很久以前的事情啦。 我们现在可以了解到，Redis提供了一种机制可以让Lua脚本同Redis进行交互。可是事实上Redis和Lua在数据结构定义上存在一定差异。所以，下面我们来了解下这两种数据结构是如何进行转换的，了解完这些我认为这篇文章就可以结束啦，因为现在接近1点钟啦而明天还要上班。在Lua脚本中调用call()或者pcall()方法来执行Redis命令时，Redis命令执行的结构会被转换为Lua中的数据结构。同理，当Lua脚本在终端中执行时，Lua脚本的返回值会被转化为Redis的协议并经由EVAL返回给客户端。关于call()和pcall()这两个方法，一个显著的区别是前者在出错时返回的是错误信息，而后者返回的是经由Lua table包装后的结果。我们知道table在Lua语言中是一个非常强大的数据结构，显然后者对调用者更为友好些啦。通常在处理类型转换时我们有以下原则： Lua table结构中不能含有nil，否则Redis将从第一个为nil的位置返回 Lua number结构中不能区分浮点类型，默认会转换为整型并舍弃小数部分，如果需要保留小数部分请返回string类型 Lua boolean结构在Redis中会被转换为0和1的取值 Redis提供了redis.error_reply()和redis.error_status()两个辅助方法来完成Lua-&gt;Redis的转换 好了，这篇博客就是这样子啦，关于为什么使用Lua脚本这个问题，我认为可以从减少网络开销、原子性和脚本复用三个角度来考虑，尤其是第二点，因为Redis执行脚本的时候是整体的、阻塞的执行，中间不会被插入新的命令，因此它完全可以不用担心出现竞态或者事务相关的问题，可是即使这样我们还是建议编写短小精悍的Lua脚本。以上就是这篇博客的全部内容啦，感谢大家关注，欢迎在博客留言及讨论相关技术问题，谢谢大家。 参考文章 Xbynet - Redis与Lua及Redis-py应用Lua 一路向前走 - 【原】Redis基本操作 小咚 - Redis Lua 总结 Redis中文网 - Redis 脚本","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"笔记","slug":"笔记","permalink":"https://qinyuanpei.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Redis","slug":"Redis","permalink":"https://qinyuanpei.github.io/tags/Redis/"},{"name":"缓存","slug":"缓存","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"基于特性(Attribute)的实体属性验证方案设计","date":"2017-08-21T14:25:41.000Z","path":"posts/3873710624/","text":"&emsp;&emsp;各位朋友，我是Payne，大家好，欢迎大家关注我的博客，我的博客地址是https://qinyuanpei.github.io。在这篇文章中，我想和大家探讨下数据校验的相关问题，为什么我会对这个问题感兴趣呢？这其实是来自最近工作中相关需求场景，而这篇文章其实是我在去年就准备要写的一篇文章，这篇文章一直存放在草稿箱里没有发布出来，所以结合这段时间项目上的思考，对当初的设计方案进行了改进，所有就有了大家现在看到的这篇文章，我始终认为思考是一个持久的过程，就像我们对这个世界的理解，是会随着阅历的变化而变化的。我们知道现实通常都会很残酷，不会给我们太充裕的时间去重构。可是思考会是人生永远的功课，当你忙碌到无暇顾影自怜的时候，不妨尝试慢下来抬头看看前方的路，或许原本就是我们选择了错误的方向呢，因为有时候作出一个正确的选择，实在是要比埋头苦干要重要得多啊。 &emsp;&emsp;好啦，既然我们提到了思考，那么我们来一起看一个实际项目中的业务场景，在某自动化项目中，用户会将大量数据以某种方式组织起来，然后藉由自动化工具将这些数据批量上传到一个系统中，该系统实际上是一个由各种表单组成的Web页面，并且这些Web表单中的控件都有着严格的验证规则，当数据无法满足这些验证规则时将无法上传，因此为了提高自动化工具上传的成功率，我们必须保证用户组织的这些数据是合法的，假设我们的用户是一个仅仅会使用Office三件套的普通人，他们可以想到的最好的方式是将这些数据录入到Excel中，而Excel中的数据有效性验证依附在单元格上，一旦验证规则发生变化，我们就不得不去维护这个Excel文件，这绝对不是一个软件工程师该做的事情好吗？我们当然是需要在提交数据前做验证啦，然而我看到Excel中100多列的字段时，我瞬间就不淡定了，这么多的字段难道我们要逐个写if-else吗？不，作为一个提倡少写if-else的程序员，我怎么可能会去做这种无聊的事情呢？下面隆重推出本文的主角——Attribute。 你的名字是？&emsp;&emsp;如你所见，本文的主角是Attribute，那么当它出现在你面前的时候，你是否会像《你的名字。》里的泷和三叶一样，互相问候对方一句：你的名字是？因为我们实在不知道应该叫它特性还是属性。可事实上这篇文章的标题暴露了这个问题的答案，这里我们应该叫它特性。好了，按照数学理论中的观点，任何问题都可以通过引入一个中间层来解决，现在我们有了一个新的问题，Attribute和Property到底有什么区别？虽然这两者都可以翻译为”属性”，可实际上它们表达的是两个不同层面上的概念，一般我们倾向于将Attribute理解为编程语言文法上的概念，而将Property理解为面向对象编程里的概念。 Attribute/特性&emsp;&emsp;我们将Attribute称为特性，那么我们在什么地方会用到特性呢？两个个非常典型的例子是超文本标记语言(HTML)和可扩展标记语言(XML)。首先这两种标记语言都是结构化、描述性的标记语言。结构化表现在节点间可通过父子或者兄弟的关系来表示结构，描述性表现在每个节点都可以附加不同的描述来丰富节点。例如下面的XML文件中，我们使用了描述性的特性来提高元素间的辨识度，即特性为元素定义了更多的额外信息，而这些额外信息并不作为元素数据结构的一部分： 1234567891011121314&lt;bookstore&gt;&lt;book category=\"COOKING\"&gt; &lt;title lang=\"en\"&gt;Everyday Italian&lt;/title&gt; &lt;author&gt;Giada De Laurentiis&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;30.00&lt;/price&gt; &lt;/book&gt;&lt;book category=\"CHILDREN\"&gt; &lt;title lang=\"en\"&gt;Harry Potter&lt;/title&gt; &lt;author&gt;J K. Rowling&lt;/author&gt; &lt;year&gt;2005&lt;/year&gt; &lt;price&gt;29.99&lt;/price&gt; &lt;/book&gt;&lt;/bookstore&gt; &emsp;&emsp;在这个例子中，bookstore节点由两个book节点组成，而每个book节点则由title、author、year和price四个节点组成，显然这些节点描述的是一种结构化的数据，而这些数据同时附加了相关描述性的信息，例如book节点有category信息，title节点有lang信息。在XML中最基本的一个内容单元我们称之为元素，即Element，而描述这些元素的最基本内容单元我们称之为特性。所以，这种在语言层面上进行描述而与实际抽象出的对象无关的概念就称为”特性”，人们认知和描述一个事物的方式会有所不同，所以在XML中会有这样一个历史遗留问题，我们应该使用Element还是Attribute，而产生这个问题的根源在于我们认识这个世界，是通过语言描述还是通过概念抽象。 &emsp;&emsp;如果我们了解GUI相关技术的演进过程，就会发现历史总是如此的相似。为什么微软会在XML的基础上扩展出XAML这种专门为WPF而设计的界面设计语言呢？因为历史告诉我们GUI中的大量特性都应该使用声明式的、描述式的语法来实现，从苹果的Cocoa、微软的XAML、Qt的QML、Android的XML等无一不证明了这个观点，而采用过程式的MFC、WinForm、Swing等，我们常常需要为它们编写大量的交互性的逻辑代码，今天我们会发现前端领域的声明式编程、MVVM、组件化等技术点，其实都是这种思想的无限延伸，我们可以使用jQuery去直接操作DOM，但面向过程的命令式代码一定不如声明式容易理解。虽然在面向对象编程的世界里，我们最终还是需要将这些描述性的语法结构，转化为面向对象里的类和属性，可这已然是一种进步了不是吗？ Property/属性&emsp;&emsp;我们认识这个世界的过程，恰恰折射出这两者截然不同的风格，从孩提时代理解的“天空是蓝色的”到学生时代认识到“大气是由氮气、氧气和稀有气体组成”，这种转变从本质上来看其实是因为我们认识世界的角度发生了变化。《西游降魔篇》里玄奘寻找五行山，第一次是风尘仆仆“看山是山”，第二次是由“镜花水月”启发“看山不是山”，第三次借“儿歌三百首”降伏孙悟空后“看山还是山”。面向对象编程(OOP)的一个重要思想是抽象，而抽象即是我们从描述性的语言中对事物属性进行构建的一个过程。例如现实生活中的汽车会有各种各样的数据信息：长度、宽度、高度、重量、速度等等，而与此同时汽车会有启动、刹车、减速、加速等等的行为，所以将事物的“数据”和“行为”提取出来进行抽象和模拟的过程，就是面向对象编程，我们在这个过程中可以注意到一点，所有的这一切都是针对对象而言的，所以Property是针对对象而言的。 &emsp;&emsp;这里提到的一个重要概念是抽象，什么是抽象呢？我认为它恰好和具体相对的一个概念。所谓具体，即相由心生，你看到什么就是什么，与此同时通过一组描述性的语言将其描述出来，我以为这就是具体。例如”火辣辣的太阳挂在天上”，这是具体到太阳颜色和温度的一种描述；所谓抽象，即返璞归真，我们看到的并非世间阴晴圆缺的月亮，而是这浩瀚宇宙中国一颗遥远的行星，此时此刻我们将行星具备的特点概括出来，推而光之，我以为这就是抽象，所以对我们而言，属性是事物抽象后普遍具有的一种特征，它首先要达到一种抽象的层次，其次它要能表现出事物的特性，我更喜欢将Property称之为属性，它和我们在面向对象编程中的概念是完全统一的。 方案设计及其实现设计目标 免除配置开箱即用：无需任何配置文件，直接在实体上添加Attribute即可实现验证 非侵入式验证设计：验证与否对实体结构无任何副作用，可以随时添加验证或卸载验证 扩展灵活高度复用：可以自由派生自定义特性，通过泛型来支持不同实体类型的验证 设计思路&emsp;&emsp;所有校验相关的Attribute都派生自ValidationAttribute这个父类，其核心方法是Validate()方法，该方法被声明为一个虚方法，因此所有的子类都必须对这个方法进行重写，它将返回一个叫做ValidationResult的结构，这是一个非常简单的数据结构，它仅仅包含Success和Message两个属性，前者表示当前校验是否成功，后者表示验证失败时的错误信息。显然，一个实体结构中将包含若干个不同的属性，所以在对一个实体结构进行验证的时候，会通过反射遍历每一个属性上的ValidationAttribute并调用其Validate()方法，所以最终返回给调用者的应该是由一组ValidationResult组成的集合，为此我们设计了ValidationResultCollection这个类，该类实现了ICollection接口，在此基础上我们增加了一个Success属性，当集合中所有ValidationResult的Success属性为true时，该属性为true反之为false。我们将数据校验的入口类EntityValidation设计成了一个静态类，它提供了一个泛型方法Validate()方法，所以对整体设计而言，它的灵活性和扩展性主要体现在：(1)通过派生自定义特性来增加验证规则；(2)通过泛型方法来支持不同类型的校验。下面给出UML类图供大家参考，最近刚刚开始学习UML，有不足之处请大家轻喷哈： UML类图 技术要点&emsp;&emsp;首先，在.NET中特性的基类是Attribute，Attribute从表现形式上来讲类似Java中的注解，可以像标签一样添加在类、属性、字段和方法上，并在运行时期间产生各种不同的效果。例如[Serializable]标签表示一个实体类可以序列化，[NonSerializable]标签则可以指定某些属性或者字段在序列化的时候被忽略。而从本质上来讲，Attribute是一个类，通常我们会将派生类以Attribute结尾，而在具体使用的时候可以省略Attribute，所以[Serializable]标签其实是对应.NET中定义的SerializableAttribute这个类。在我们定义Attribute的时候，一个需要考虑的问题是Attribute的作用范围，在.NET中定义了AttributeUsageAttribute这个类，它可以是Class、Property、Field、Method等，所以Attribute本质上是在运行时期间为元素提供附加信息的一种机制，即Attribute可以添加元数据。我们知道元数据是(MetaData)实际上是程序集(Assembly)中的一部分，显然这一切都是在编译时期间定义好的，所以Attribute的一个重要特征是在运行时期间只读(Readonly)。Attribute必须依附在指定目标上，当当前目标与AttributeUsage定义不符时，将无法通过编译。Attribute的实例化依赖于目标实例的实例化，无法直接通过new完成实例化。通常我们需要配合反射来使用Attribute，在运行时期间做些有意义的事情，例如ORM中实体字段与数据库字段的绑定、Unity中配合AOP使用的ExceptionHnadler等等，都是非常典型的Attribute的应用。 &emsp;&emsp;了解了Attribute是什么东西，接下来我们要考虑的就是如何访问Attribute，在.NET中主要有两种方式来获取Attribute，即通过Attribute类提供的静态方法获取Attribute和通过Attribute依附的对象实例的元数据来获取Attribute。下面我们来看一段简单的代码实例： 123456public static T GetAttribute&lt;T&gt;(this PropertyInfo propertyInfo)&#123; var attrs = propertyInfo.GetCustomAttributes(typeof(T), false); if(attrs == null || attrs.Length&lt;=0) return null; return atts[0] as T;&#125; &emsp;&emsp;这段代码展示了如何通过反射访问附加在属性上的Attribute，事实上除了PropertyInfo以外，它还可以从任何支持附加Attribute的元素，例如MethodInfo、FieldInfo、ConstructorInfo等。Attribute类提供了类似的静态方法，第一个参数可以是这些元素中的任何一个，第二个参数和第三个参数和这里的示例代码一致，分别是返回的Attribute的类型，以及是否要搜索父类的Attribute，它的返回值类型为Attribute[]。在这个方案中，我们通过下面的方式来对实体属性进行验证： 123456789101112131415161718192021222324252627282930313233public static ValidationResultCollection Validate&lt;T&gt;(T entity)&#123; var type = entity.GetType(); var properties = type.GetProperties(); var results = new ValidationResultsCollection(); foreach(var property in properties) &#123; var propertyValue = property.GetValue(entity,null); var validationAttributes = property.GetCustomAttributes(typeof(ValudationAttribute),fasle); if(propertyValue == null &amp;&amp; (validationAttributes == null || valudationAttributs.Length &lt;= 0)) continue //优先验证RequiredAttribute var requiredAttributes = property.GetCustomAttributes(typeof(RequiredAttribute),false); if(requiredAttributes.Length &gt; 0) &#123; var requiredResult = (requiredAttributes[0] as ValidationAttribute).Validate(propertyValue); results.Add(requiredResult); if(propertyValue == null) continue; &#125; //其次验证ValidationAttribute foreach(var validationAttribute in validationAttributes) &#123; if(propertyValue != null &amp;&amp; !validationAttribute.GetType().Equals(typeof(RequiredAttribute))) &#123; var validationResult = (validateAttribute as ValidationAttribute).Validate(propertyValue); results.Add(validationResult); &#125; &#125; &#125; return results;&#125; &emsp;&emsp;在这里我们注意到在对ValidationAttribute进行处理的时候，优先验证了RequiredAttribute，因为如果它验证失败意味着下面的验证都不需要了，所以当一个Property上附加了RequiredAttribute并且它的值为null的时候，我们将不会进行下面的验证，这是在设计过程中发现ValidationAttribute的优先级不同而做出的一个简单地调整。关于ValidationAttribute，我们提到这是所有自定义特性的基类，实际在使用中我们会有各种各样的派生类，我们这里以RegexAttribute为例来看看它具体怎么实现： 12345678910111213141516171819202122232425public class RegexAttribute : ValidationAttribute&#123; private string regexText; private string defaultMessage = \"value is required to match a Regex rule &#123;$regex&#125;; public RegexAttribute(string regexText,string message = null) &#123; this.regexText = regexText; this.message = message == null ? defaultMessage : message; &#125; public VelidationResult Validate(object value) &#123; var regex = new Regex(regexText); var match = regex.match(value.ToString()); var success = match.Success; if(!success) &#123; message = message.Replace(\"&#123;$regex&#125;\",regexText); return new ValidationResult()&#123;Success = success, Message = message&#125;; &#125; return new ValidationResult()&#123;Success = success&#125;; &#125;&#125; &emsp;&emsp;好了，以上就是整个校验设计中关键的技术点啦，我认为整体上没有多少难点，因为这是我在项目上造的一个简单的轮子，相比ASP.NET MVC 中的校验要简单很多，相信大家可以根据这些内容轻松地实现一个自己的版本，虽然不主张”重复造轮子”，可博主在很多时候都是通过”造轮子”来学习的啊，哈哈。 数据校验示例&emsp;&emsp;下面我们来通过一个简单的示例来了解，如何在实际项目中使用这个验证方案： 12345678910111213public class Foo&#123; [Required] [Regex(\"(\\d+)&#123;3&#125;-(\\d+)&#123;1&#125;-(\\d+)&#123;6&#125;\")] public string CardNumber &#123;get; set;&#125; [Required] [MaxLength(20,\"AccountNumber is required within 20 characters\")] public string AccountNumber &#123;get; set;&#125; [Values(\"FCY,DCP,ATM\")] public string TransactionType&#123;get；set;&#125;&#125; &emsp;&emsp;这里使用了三种验证规则，Required表示该字段不可以为空，Regex表示字段值要匹配指定的正则表达式，MaxLength表示字段长度不能超过指定长度，Values表示字段允许的取值范围，在实际使用中我们可以通过派生定义更多的验证规则，每一种验证规则都可以设置一个验证失败的信息，例如当AccountNumber的长度超过20时，将会返回指定的错误信息。我们可以通过下面的代码来验证Foo这个实体中的属性： 12345678910var foo = new Foo();foo.CardNumber = \"234-7-4567\";foo.AccountNumber = \"12345678900\";foo.TransactionType = \"DCP\"var results = EntityValidation.Validate&lt;Foo&gt;(foo);if(!result.Success) results.ToList().Foreach(r =&gt; &#123; Console.WriteLine(r.Message);&#125;); #本文小结&emsp;&emsp;本文首先讲述了特性和属性两者在概念上的不同，即特性是编程语言文法上的概念，而属性是面向对象编程里的概念。接下来，我们针对.NET中的Attribute的表象和具象进行了讨论，Attribute从表象上看是和Java中的注解类似，可以像使用标签一样附加在类、方法、属性或者字段等元素上，而从具象上看Attribute提供了一种在运行时期间通过元数据访问附加信息的能力，Attribute是附加在类、方法、属性或者字段等元素上的一个类，需要继承自Attribute，它的实例化必须依赖这些附加对象的实例化，并且Attribute在运行时期间是Readonly的，Attribute通常需要配合反射来使用。在具备这些基础知识以后，我们开始和大家分享这个验证方案的设计思路及其技术要点，所谓抛砖引玉，本文的目的是想让大家借鉴这种思路，努力让业务代码更干净些，因为只有我们在乎这件事情，我们才会努力去将它做好。好了，今天这篇文章就是这样啦，谢谢大家关注！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"C#","slug":"C","permalink":"https://qinyuanpei.github.io/tags/C/"},{"name":"校验","slug":"校验","permalink":"https://qinyuanpei.github.io/tags/%E6%A0%A1%E9%AA%8C/"},{"name":"特性","slug":"特性","permalink":"https://qinyuanpei.github.io/tags/%E7%89%B9%E6%80%A7/"}]},{"title":"《大护法》—— 花生镇里的成人童话","date":"2017-07-30T20:38:22.000Z","path":"posts/1684318907/","text":"猛然间驻足回首这些错落的旧时光，我渐渐意识到我已经有三个月没有写博客了。如果一定要我说出这是种什么样的感觉，大概就是你永远都不会知道永远到底有多远。或许你会喜欢上一个陌生的人，源自不经意间的惊鸿一瞥；或许你会开始厌倦一个熟悉的人，源自不经意间的怅然若失。时间如风起云涌，一边熟悉着一边陌生着，永远像极了一场你追我赶的拉力赛。从办公室里走出来被热风吹袭的一瞬间，我居然有种久违的暖人肺腑的感觉。每个人都像一粒炭火，都知道要通过抱团来取暖，可是有谁会愿意燃烧自己呢？所以孤独是人类如宿命一般的社会属性。我一位朋友曾向我讲述过，这种若即若离的感觉，而此时此刻，我想将这种感觉结合一部电影来说出来。 这段时间好像看了挺多电影的，借我一位朋友的话说就是，“两只单身狗跑到电影院里去找刺激”。而对于《大护法》这部电影，我是选择了一个人去看的，因为我觉得这部电影的主题是“反乌托邦式”的，所以我宁愿自己独自去消化这些内容，而不是将消极悲观的情绪在观影时传播给别人。对这部电影我将其看作是一个成人童话，因为它的确不适合带小孩子去观看，而这部电影恰恰采用了PG-13的影片分级。我喜欢这个电影，某种意义是因为它在现有体制内，讲述一群被奴役的“花生人”，如何在外人的帮助下，从愚昧麻木转变为意识清醒，并最终产生自我意识推翻统治者暴政的故事，所以这其实是一个关于觉醒和反抗的故事。 而这基本上是人类历史里永恒的话题啦，熟悉苹果公司历史的朋友一定知道，乔布斯当年曾经拍摄过一部名为《1984》的广告片，这部广告片取材自乔治.奥威尔的同名小说，该书中刻画了一个令人窒息的恐怖世界，在假想的 未来社会中，独裁者以追求权利为最终目标，自由被彻底剥夺，思想被严酷控制，人民被迫屈从于“老大哥”的统治。而将书中这个背景对应到苹果公司，我们就部难理解乔布斯是在用“老大哥”来影射当时的IBM公司，在这则广告片中“老大哥”被铁锤击碎后缓缓消失，此时旁白平静地念道：“1月24日，苹果电脑公司将推出麦金塔电脑，你将明白为什么1984不会变成《1984》”，这段传奇故事在《硅谷传奇》和《乔布斯》两部电影中均有反映，对此感兴趣的朋友可以自己去了解，显然乔布斯在当时试图向世界证明，苹果公司是唯一一家有希望打败IBM的公司。 因此在很长一段时间里，我一直有想要通读《1984》的愿望，这种行为在某些人看来是矫情和装逼，可事实上连周星驰都表示没有读完《演员的自我修养》这本书，我就不明白这个想法为什么会遭人厌恶。这个世界上最令人厌恶的事情就是，我们所有人都生活在一个被道德和法律约束的世界，我们从出生就在适应接受某一种意识形态或者社会法则，可总有人试图告诉你生活是这样或者那样，并且出自尊重你必须接受和感谢这种建议，因为这些人最后会说我是为了你好。那么在导演不思凡的视角里，这种回归哲学意义上的最为追根溯源的问题，即我是谁，是如何通过电影表现出来的呢？欧阳吉安，即花生镇村名眼中的老神仙，他说鬼蘑菇是一种可怕的传染病，一旦花生人长了鬼蘑菇就必须被立即处死，花生人不能开口说话，即使他们都贴着假眼睛和假嘴巴，花生人不能拥有意识和思考，一旦说出事实就会被认为染了疯病必须被立即处死，所有的村民都循规蹈矩地听着老神仙的话，可事实上鬼蘑菇根本就不是传染病，它是花生人成熟的标志，老神仙这样一个统治者，从来不会将花生人视为人，它们活着的唯一意义就是等死后，由庖卯从脑袋里取出黑石头。古话说：流言止于智者，可在这个荒诞诡异的世界里，流言会因为恐惧而掩盖真相，村民始终生活在一种令人窒息的恐怖阴影里。 故事开篇即点明主旨，即奕卫国大护法，即故事主角“红冬瓜”为寻找太子下落，而来到了充斥着腐烂气息的花生镇，虽然主角对这些像人而又不像人的“花生人”表示了反感，因为在大护法沿着山路来到小镇的时候，经过了一个类似拱门的建筑，可细思恐极的是这个拱顶堆满了花生人的头颅，而且头颅上的眼睛是真正的眼睛，而散落在地面上的贴纸其实是假的眼睛，联想整个故事情节，在花生镇敢于揭露真相、寻找真相的人都被杀鸡儆猴地处理掉了，这可以说是故事开篇埋下地一个伏笔了，可是为了寻找太子的下落，大护法不得不去向这些村民打探消息。可是大护法很快就发现，在花生镇这样一个奇怪的地方，随时随地都会有人杀戮村民和外来者，这些人被称为刑法者，负责帮助老神仙欧阳吉安杀死“该死”地村民，所以在故事一开始大护法在村子里就遭到了袭击，可是说起大护法来，这是一个战斗力爆表的反差萌系设定，而通过故事我们知道，这些刑法者由一个称为罗单的人管理，他不属于花生镇，和欧阳吉安这些人类不一样，他对彩这个神秘女子有种强烈的占有欲，他偷看她洗澡被发现便转身离开，可当他发现下属产生感情的时候，他毫不留情地杀死了他们，所以大概到现在为止，我们所认识的世界存在着严格的等级区分，整个故事从此定性，罗单压抑着自己的情欲，却不允许下属产生情欲，所以当他杀死欧阳吉安的时候，我们不会感到太意外，因为他心里隐藏了太多东西。 太子是整个故事里，唯一一个清楚知道自己想要什么的人。他不喜欢朝廷里的纷争，便遁走江湖寄情山水，去寻找自己真正喜欢的事情。从来没有人将花生人当作人，他却视小姜为花生镇里最好的朋友。可我们都知道这样一句话：哪有什么岁月静好，不过是有人负重前行。在整个故事设定中，大护法的爷爷的爷爷起就一直是弈卫国的大护法，所以大护法的职责就是要保护太子，在故事安排上这部电影相对枯燥，因为后期基本上一直在找太子，所以太子有这样的机会，去选择做自己想做的事情，其实是因为有大护法在一直保护他，相反普通人可能不会有这样的机会，这一点我们稍后会提到。太子除了承担整部电影的笑点以外，我个人认为最出彩的地方是，他在被庖卯打得头破血流时，亲眼目睹了小姜的死，从那一刻开始，我相信他终于明白了身为帝王的那种担当，他不再是以前那个避世逃脱的太子，所以这种成长的感觉会非常好，他在看到大护法以后重复了两次“杀了他”，而在此之前他是坚决反对杀人的。 小姜是唯一一个自我意识觉醒的花生人，他通过隐婆了解到自己是怎么来到这个世界上的，了解到毒蘑菇到底是怎么一回事情，了解到花生人来自蚁猴子却又以蚁猴子为食的真相，这里有一个有趣的设定，花生人是以蚁猴子作为食物的，这就好像喂猪的泔水里会有猪肉一样，想通了这一点，或许人吃猪肉和人吃人并没有本质的区别。小姜会说话这件事情，让欧阳吉安和疱卯都感到异样，前者是担心危及到自己的统治，后者是对自己的职业产生了怀疑。小姜最终还是死了，就像被庖卯杀死的那些花生人一样，不同的是那颗石头不再是黑石头，而是晶莹剔透的宝石。这让我想起蚌这种可以孕育出珍珠的海洋生物，普通的砂砾经过时间的磨洗可以变成美丽的珍珠。或许答案会是什么，更多的是因为你想要什么，内心贫瘠的土壤寸草不生，内心肥沃的土壤鲜花遍地。小姜内心善良所以懂得回报太子，但现在这个世界善良越来越被人忽视，小姜被老神仙视作圈养的猪啰，可太子会把他当作好朋友，所以说选择非常重要啦，遵从内心的选择更重要。 庖卯这个角色其实挺悲哀的，他代表是那一类被理想绑架而失去自我的人。“庖”在古代就是指厨师这一类职业，我们熟悉的庖丁解牛这个词就是出自这里。可在影片中颇为讽刺的是，一个想成为厨师的人的最大理想，居然是想要一刀取人心脏，我们不能说这种想法不是一份理想，用大护法的话说就是“你的理想，杀气这么重，怕是实现得一天，会是你的终年”。我们注意到卯和丁一字之差，所谓“丁是丁，卯是卯”，当你被仇恨蒙蔽双眼的时候，看到的东西和实际相比大概会相差很多吧！庖卯在听见花生人说话以后就开始呕吐，这种感觉让他开始思考，自己每天屠杀的到底是些什么东西。试想我们每天吃的这些食物开口说话的话，我们同样会感到恐惧的吧，或许我们想和疱卯一样成为一名绝世大厨，但现实给我们的却是一份杀人的差事，我想坚持初心，知道自己从哪里来要到哪里去，就不会在路上迷失方向，他的死作为一种解脱，在这个故事里算是善终了吧。 说了这么多，始终没有提到我们的大护法，个人感觉这个角色给我的印象确实不够深刻，它是一个古龙式的侠客形象，拥有和外表极不相称的武力值，这是一个用生命在战斗的人，从故事开头一直战斗到故事结尾，主角光环让它在断了数根肋骨后依然可以活到最后一刻，它是什么样子的呢？一个喜欢朗诵诗歌、自带莎士比亚腔调的文艺大护法，从台词的角度来讲，整部电影深刻中带着些许中二，但这部电影吸引的我，恰恰是这些硬伤很突出的地方，它整体的画风给人一种怪诞和虚无，可它的故事在国内审查体制下让人耳目一新，电影里说“假眼睛、假嘴巴都说贴着难受为什么还要贴？都摘掉它们会怎么笑话我？就因为怕被笑话，所以我们活成了笑话”，或许这是一部给成人看的童话，但透过这部电影多一点思考、多一点想象，大概是我们回报导演不思凡的最好方式之一，因为他想说的或许就是我们想说的。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"随笔","slug":"随笔","permalink":"https://qinyuanpei.github.io/tags/%E9%9A%8F%E7%AC%94/"},{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"大护法","slug":"大护法","permalink":"https://qinyuanpei.github.io/tags/%E5%A4%A7%E6%8A%A4%E6%B3%95/"},{"name":"童话","slug":"童话","permalink":"https://qinyuanpei.github.io/tags/%E7%AB%A5%E8%AF%9D/"}]},{"title":"基于过滤器实现异常处理的探索","date":"2017-05-20T20:10:28.000Z","path":"posts/570888918/","text":"&emsp;&emsp;正如你所看到的那样，今天我想和大家聊聊异常处理这个话题。对于异常处理这个话题，我相信大家都有各自的方法论。而我今天想和大家探讨的这种异常处理方案，我将其称之为基于过滤器的异常处理。我不知道这种定义是否准确，我们的项目上在要引入AOP的概念以后，我们对异常处理的关注点就从try-catch转向Interceptor。虽然首席架构极力推荐，使用Unity框架来拦截代码中的各种异常，可从我最初纠结于”return”和”throw”的取舍，到现在我可以灵活地使用和捕捉自定义异常，对我而言老老实实地实践异常处理的经典做法，比使用AOP这样一种高大上的概念要有意义地多，因为我相信在某些情况下，我们并不是真正地了解了异常处理。 异常和错误 或许是因为人类对机器时代充满了近乎苛刻的憧憬，我们的计算机程序在开始设计的时候，就被告知不允许出现错误，甚至我们的教科书上会用一种充满传奇色彩的口吻，来讲述一个因为粗心的工程师计算错了小数点而导致航天飞行器机毁人亡的故事。可是人类常常会对自己选择宽容，而对他人则选择严格，这种观点在整个数字时代更为凸显，当我们无法容忍一个糟糕的应用程序的时候，无论曾经人们为此付出过多少努力，在这一瞬间他们的价值都将不复存在。我们的这种苛刻迫使我们不允许软件出现错误，我们尝试通过各种各样的测试来避免错误发生，可是事实上软件工程实践最终会演变为一个妥协的产物，这意味着我们任何的形式化方法最终都会失败，没有人可以保证一生都不会犯错，而软件工程师同样是人，为什么我们一定要求他们不可以犯错呢？ 我们不得不承认软件产品是一个持续演进的过程，如果抛开商业意义上的Deadline来说，实际上软件是永远没有写完的那一天的，这就是为什么工程师都有点理想主义的原因，不考虑外界环境因素的变化，而期待软件永远不会有新的问题产生，这实在是一种苛刻地要求。好了，我们在这里频繁地提到错误，那么在软件工程学意义上的异常和错误分别是指什么呢？具体来讲，异常是指我们可以明确预测到它会发生并且需要我们进一步处理的流程，而错误是指我们无法明确预测到它会发生并且它会程序流程中断而导致程序崩溃，所以我认为区分”异常”和”错误”最直观、最简单粗暴的方法就是，如果你捕捉到了一个异常并处理了这个异常，那么它就是异常。反之，如果任由异常导致程序Crash，那么它就是错误。如果我们因为畏惧异常而给所有方法增加try-catch，我不得不遗憾得告诉你，你还没有真正明白什么是异常。 &emsp;&emsp;在早期的Win32 API中，微软大量使用了错误码来表示方法执行过程中发生的错误，这样就引出异常处理中的第一个问题，我们到底是应该是使用错误码还是异常来表示方法执行中发生的错误？事实上这两者在程序的表达能力上等价的，它们都可以向调用者传达”异常发生“这个事件，譬如我们在集合中查找一个元素，如果元素不存在则返回-1，这其实就是一个使用错误码来表示”错误“的经典案例，显然这种从C/C++时代遗留下来的传统解释了Win32 API为什么会选择这样的设计方式，换言之，选择哪种方式，本质上是一种从API风格、代码风格和性能指标等方面综合考虑后的结果，错误码这种方式的缺陷主要在于，错误码不能明确地告诉调用者到底发生了什么错误，除非我们定义更多的错误代码，而且在没有引入可空类型以前，我们没有办法避免错误码污染返回值的值域，比如在这个例子，如果集合中恰好有一个元素-1，那么通过-1这个返回值我们是没有办法判断出，这个-1到底是不是因为方法内部发生了错误而返回-1. &emsp;&emsp;好了，现在我们来说说异常，异常在主流的编程语言里基本上是一个标配。异常可以保存从异常抛出点到异常捕获点间的相关信息，所以异常相比错误码可以持有更多的信息，或许你可以尝试去设计一种数据结构来让返回值更丰富:)。我们常常听到”使用异常会降低程序性能”这样的说法，可这部分性能上的差异仅仅是因为，我们需要在抛出异常的时候给调用者更多的信息，所以这是一个非常公平的事情。第二个问题，我们是不是在所有情况下都使用异常？使用异常的好处是它可以让我们以一种更安全的方式去处理异常，可一旦发生了异常程序的性能就会降低，所以我们可以看到.NET中提供TryParse这样的方法，这其实是在告诉我们：如果预测到异常一定会发生，正确的策略不是去捕捉它而是去回避它。在《编写高质量的C#代码》一书中曾建议：不要在foreach内部使用try-catch，就是这个道理，即采用防御式编程的策略来回避异常，而不是总是抛出异常。 &emsp;&emsp;那么，总结下行文至此的观点：异常是强类型的，类型安全的分支处理技术，而错误码是弱类型的，类型不安全的分支处理技术。元组等可以让函数返回多个返回值的技术，从理论层面上可以模拟异常，即将更多的细节信息返回给调用者，可是这种方式相比由运行时提供支持的异常机制，在性能指标和堆栈调用上都存在缺陷。异常在被运行时抛出来的时候，程序性能是下降的，这是因为调用者需要更多的细节信息，所以不建议在所有场合都抛出异常，建议使用防御式编程的策略去回避异常，直到确定程序没有办法处理下去的时候再抛出异常。理论上所有自定义的异常都应该去捕捉并处理，否则定义这些自定义异常是没有意义的。异常处理应该拥有统一的入口，在代码中到处try-catch和记日志是种非常丑陋的做法，理论上应该坚决摒弃。 Checked Exception 最近垠神写了一篇新的文章《Kotlin和Checked Exception》，在这篇文章中垠神提到了Checked Exception这种针对异常处理的设计，而恰好我这篇文章写的同样是异常处理，并且我在下面提到的基于过滤器的异常处理方案，实际上就是为了解决这种Checked Exception的问题，虽然在.NET中不存在Checked Exception。 要了解什么是Checked Exception，要从Java中的异常机制说起。Java中的异常类全部继承自Throwable，它有两个直接子类Error和Exception，通常情况下Error是指Java虚拟机中发生错误，所以Error不需要捕捉或者抛出，因为对此表示无能为力；而Exception则是指代码逻辑中发生错误，这类错误需要调用者去捕捉和处理。那么在这样的分类下，Java中的异常可以分为Checked Exception(受检查的异常)和Unchecked Exception(未受检查的异常)，前者需要需要方法强制实现throws声明或者是使用try-catch，如果不这样做编辑器就会直接报错，后者就相对宽容啦，没有这样霸道的条款，可是诡异的是RuntimeException是一个UncheckedException，可它居然是继承自Exception而不是Error，这实在令人费解，Java的设计模式果然博大精深。 那么对一个Checked Exception，Java的处理方式是十分地霸道的，我们一起来看下面这段代码： 1234void Foo(string fileName) throws FileNotFoundException&#123; if(...) throw new FileNotFoundException();&#125; 我们可以注意到Java强制让Foo()方法实现了throws声明，原因是在该方法内部可能会引发FileNotFoundException，如果我们不遵从这一”霸王条款”，那么我们的代码将无法通过编译，而在调用者层面上，Java的霸道则体现在要求调用者使用try-catch结构处理这种异常，或者继续使用throws声明来使异常继续向上传递，我更喜欢将这种设计称之为一种理想状态下的异常处理机制，比如我们读写一个文件的时候，除了FileNotFoundException以外，可能还会遇到FileLoadException、PathTooLongException、EndOfStreamException等等的异常，如果这些异常在业务层面上是无差别的，那么我认为将异常细分到如此精细的程度是没有意义的，因为对用户而言这个时候它关心的是否成功读写了这个文件，具体的异常原因用户并不想真的知道，可是Java的Checked Exception在面对这种处境的时候，整体而言是显得力不从心的，因为我们不得不在方法从声明该方法会引出哪些异常，这对方法的编写者和方法的调用者来说都很痛苦。 &emsp;&emsp;垠神这篇文章其实在说一个问题，Checked Exception鼓励开发者主动告知调用者来捕获特定异常，这种思路完全是没有问题的，问题是调用者如何能够知道它需要捕获哪些异常，我们不可能每次都通过”转到定义”功能去看一个方法会引发哪些异常，垠神从PL的角度出发，想到了通过代码静态分析的方法来处理异常，垠神吐槽的其实是不分青红皂白滥用try-catch的做法，实际上Java标准库里对异常处理相当混乱，虽然官方鼓励使用Checked Exception，但是标准库实现和工程实践上不乏将异常包装为RuntimeException来规避Check的做法，我认为Checked Exception在工程学意义上最大贡献是，在开发阶段该抛出什么异常就应该抛出异常，因为这样可以方便我们快读定位问题，而到了发布阶段则应该将这些异常都catch住即可，这样用户就不会看到这些奇葩的异常。换句话说，我们不必在程序中去处理所有的异常，而是将异常机制作为我们定位问题的工具，去捕获那些有可能出现的异常即可。 &emsp;&emsp;C#中其实是由类似Checked Exception的概念存在的，不过所有的Check都不是强制去实现的，我们知道.NET中一个方法会抛出哪些异常完全是由注释来说明的，XML注释中的exception节点表示该方法会引发何种异常，我们一起来看下面的例子： 12345678910/// &lt;exception cref=\"MasterFileFormatCorruptException\"&gt;&lt;/exception&gt;/// &lt;exception cref=\"MasterFileLockedOpenException\"&gt;&lt;/exception&gt;public static void ReadRecord(int flag) &#123; if (flag == 1) throw new MasterFileFormatCorruptException(); else if (flag == 2) throw new MasterFileLockedOpenException(); // …&#125; 可以注意到C#采用的是一种相对温和的策略，即文档会明确告诉你，某个方法是否会引发异常以及引发哪些异常，但是是否要捕获这些异常则完全由调用者决定，我认为这是C#之父Hejlsberg在权衡后在工程实践上选择的一种妥协，因为Java的Checked Exception理想主义色彩稍重，并不是在所有场景下我们都需要去处理所有的异常，所以Checked Exception带来的问题是，即使在只需要捕获基类异常的情况下，我们依然不得不去捕获各种子类异常，这难道不有点矫枉过正的感觉吗？事实上所有工程实践中，不分青红皂白直接捕获Exception父类的做法，就是因为调用者完全不想关注发生得异常细节，这是垠神在文章中吐槽的”糟糕的代码”，C#相对Java在异常处理上好的一点就是，优秀的工程师会自觉地处理异常，如果他们清楚地知道异常会发生就一定会去捕获异常。你不能强迫他们去做他们不喜欢做的事情。 让异常处理更优雅&emsp;&emsp;好了，现在我们来考虑这样一个问题，设计Checked Exception的初衷是为了让我们处理业务逻辑中不同的具体的异常，当这些异常在业务逻辑层面上无差别的时候，其实我们可以完全忽略这些异常的细节，因为不管是哪种具体的异常，在业务逻辑层面都被认为是任务执行失败，这种情况下我们直接捕获基类异常即可，例如在读写文件的例子中我们关注IOException即可。那么如果这些具体异常在业务逻辑层面上存在差异呢？这种情况下我们就应该向Checked Exception方向靠拢，下面我们来一起听一个实际的故事。 &emsp;&emsp;我们的项目上需要从多个相互独立的系统中抓取数据并生成报表，因为这些系统在设计上都存在缺陷，所以在抓取数据的过程中非常容易出现错误，所以我们必须非常谨慎地处理这些异常，用户要求我们必须一种视觉友好的方式将报表输出出来，当异常发生时我们需要将抓取失败的数据高亮显示出来，并输出相关的错误信息来提醒用户来Check这些信息，而事实上每种异常发生的时候其处理逻辑是完全不同的。为此我们定义了将近10种的自定义异常，并为用户设计了完善的操作日志记录机制，这一切听起来非常不错，最终写出来的代码大概是下面这个样子： 12345678910111213try&#123; Foo()&#125;catch(ExceptionA ex)&#123; &#125;catch(ExceptionB ex)&#123; &#125;catch(ExceptionC ex)&#123; &#125;carch(ExceptionD ex)&#123; &#125;// ... 相信在Java的相关工程实践中，这种教科书般的代码基本上是异常处理的金科玉律啦，可是这种代码实现写起来会让人感觉头重脚轻，因为我们所有重要的逻辑都写在了catch块里，这让我非常不喜欢这种”臃肿”的代码，而且事实上在这个案例中catch块里的代码具备可重用的可能，所以我决定以一种更优雅的方式来重构这段代码。数学领域中有一个不变的真理，即任何问题都可以通过引入一个新的问题来得到解决，这个理论在编程中同样适用，因为在公司里受到同事Wesley的影响，我对Ioc和AOP都从思想上有了一定认识，公司在推行Unity的过程中我并没有看到多少实际的意义，所以我对”道”的重视远远超过对”术”的追求，因为我相信框架学习起来并不会花费多少实践，可怕的是你从来不试图去了解框架背后的秘密，所以我借由AOP中拦截器和MVC中过滤器的概念，想到了我接下来要说的这种异常处理的方案。 其实我们在这里的核心目的是为了消除分支，所以采用多态是我们重构这部分代码的第一步。我们首先定义一个针对Foo方法的异常基类ExceptionBase，然后让这里的ExceptionA、ExceptionB、ExceptionC等全部继承自ExceptionBase，这样我们就可以将这些具体的异常子类向上转型为ExceptionBase统一进行处理。与此同时，我们注意到处理各种异常子类的逻辑各不相同，虽然我们可以直接将处理异常的逻辑写到异常中(通过一个虚方法来实现)，可这样会造成异常子类里的职责负荷，我更希望异常子类是一个朴素的贫血模型，所以我们这里引入过滤器的概念(不知道这样叫是否合适)，Filter全部继承自FilterBase，它有一个Invoke的方法，我们最终会在这里实现异常处理的方法，为此我们需要定义各种各样的Filter，然后通过Attribute将每一种Filter和特定的Exception关联起来，比如我们希望在所有异常的地方打日志，那么我们只需要实现一个LoggerFilter，然后给所有的Exception添加Attribute，这可以显著改善我们的代码。 现在，我们只需要给ExceptionBase类提供一个GetFilter()方法，该方法的返回值类型为FilterBase，我们将通过反射来创建一个Filter并将其返回，所以我们写出来的代码会是下面这个样子： 12345678[ExceptionFilter(FilterName = \"FilterA\")]class ExceptionA : ExceptionBase &#123; &#125;[ExceptionFilter(FilterName = \"FilterB\")]class ExceptionB : ExceptionBase &#123; &#125;[ExceptionFilter(FilterName = \"FilterC\")]class ExceptionC : ExceptionBase &#123; &#125; 此时此刻，我们的关注点就从一堆catch块中转移到了不同的filter中，虽然我们编写代码的工作量没有减少，但这样的做法无疑增强了代码的可维护性，因为我们只需要到不同的Filter里去修改逻辑即可，我在书上看到这样一句话，无论什么时候合并代码总是比拆分代码要容易，当你不确定某个功能是否要放在特定模块中的时候，最好的解决方案就是将他们完全独立设计。降低代码的耦合度是一件我们常常挂在嘴边的事情，可是如何去真正地降低代码耦合度，这件事情需要我们一直思考下去。好了，现在我们完成了分支结构上的精简，而最终调用的代码会是： 12345678try&#123; Foo()&#125;catch(ExceptionBase ex)&#123; var filter = ex.GetFilter(); filter.Invoke();&#125; 现在的代码是不是比原来清新了好多呢？虽然这相比真正的AOP还是稍显稚嫩，可它的出现成功地让一段”丑陋”的代码变得优雅起来，我们不必再担心修改异常处理流程时会原来的代码产生副作用，如果需要增加新的处理逻辑我们继续派生异常类和过滤器即可，这就是代码设计上以不变应万变的道理，你要相信程序员都是非常懒惰的，如果有可以不用修改代码就适应变化的设计，他们是一定会喜欢的，因为这个世界对程序员并不友好，如果你不想你的代码被这个世界修改得面目全非，最好的选择就是不给它们这样的机会，他们说人长大一定会变成自己讨厌的样子，我想告诉这个世界永远不要忘记初心。 好了，这篇文章唠叨到现在，写了大概5000多字，花了我整整两个下午的时间，我在向Paul和John询问这个问题的看法时，他们都告诉我这个问题没有好的解决方案或者是劝我不要做这样探索，可是事实上我只用了半天时间就完成了这个设计，在去年的时候我曾向房燕良前辈请教好异常处理的问题，当时我的关注点主要在使用错误码还是使用异常。在上一个项目中，我对于异常处理其实实践得并不好，因为我一直不知道哪里是捕获异常的入口，我个人并不认同直接捕获到异常直接throw这种做法，因为你在自定义异常的时候就应该想清楚，哪些异常是需要捕获并处理的，哪些异常时可以直接让它Crash的，如果每个人都仅仅是抛出异常而不去拦截异常，那么异常机制设计得再好又有什么用呢，关于Java的异常有一个梗，是说Java的异常给出了详细的堆栈信息，可就是不直接告诉你到底是哪里异常了，事实证明我设计的这个方案运行的很好，其实我很想吐槽操作日志真的有存在的必要吗？很多时候，我们要学会遵从自己内心的声音，所谓世间难道不就是我们吗？真正绑架我们的永远都只有别人，让我们时刻谨记：万物为虚，万事皆允。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"异常","slug":"异常","permalink":"https://qinyuanpei.github.io/tags/%E5%BC%82%E5%B8%B8/"},{"name":"设计","slug":"设计","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%BE%E8%AE%A1/"},{"name":"架构","slug":"架构","permalink":"https://qinyuanpei.github.io/tags/%E6%9E%B6%E6%9E%84/"}]},{"title":"异步Lambda表达式问题的探索","date":"2017-04-15T21:10:47.000Z","path":"posts/187480982/","text":"各位朋友，大家好，欢迎大家关注我的博客，我是Payne，我的博客地址是:http://qinyuanpei.com。今天博主想和大家探讨的是，.NET中异步Lambda表达式的问题。为什么要讨论这个问题呢，这或许要从公司首席架构推广内部框架这件事情说起。我其实很久以前就有这种在团队内部做技术演进的想法，即通过公共类库、团队Wiki和技术交流等形式逐步地推进和完善团队整体架构的统一，因为一个团队在业务方向和技术选型上基本是一致的，因此团队内的技术演进对提高开发效率和交付质量意义重大，所以我能理解首席架构在内部推广公共类库这件事情，因为除了KPI这种功利性的目标以外，从长远来看这些东西对一个团队来说是积极而有利的，可是我们都知道工程师是这个世界上最傲慢的人，如果一个东西设计得不好，他们一定会尝试去改进甚至重新设计，所以架构并非是一种虚无缥缈的、凭空想象出来的东西，它的存在必须是为了解决某种问题。 所以我始终认为，架构设计必须由一线开发人员来提炼和抽象，因为只有真正经历过”坑”的人，才会清楚地知道团队里最需要解决的问题是什么，一个良好的架构绝对不是由某些所谓”专家”闭门造车的结果，你只有真正了解了一个问题，懂得如何去定义一个问题，你才会知道目前这个团队中最迫切需要去解决的问题是什么，虽然说团队里技术层次存在差异，一个技术选型必然会和普通社会学问题一样存在众口难调的情形，可是一个东西设计得不好它就是不好，你不能强迫团队成员必须去使用它，因为这实在有悖于”自由”和”分享”的黑客文化。我相信软件开发没有银弹可言，这意味着它没有一种一劳永逸的解决方案，即使它的抽象层次再高、代码鲁棒性再好，所以团队内部技术演进应该采取”自下而上”的方式，对待工程师最好的方式就是给他们充分的自由，”自上而下”的行政命令不适合工程师文化，自计算机文明诞生以来，那种来自内心深处的”极客思维”决定了我们的基因，所以啊，”请原谅我一生不羁放纵爱自由”。 好了，现在回到这个问题本身，问题产生的根源来自ICommand接口，而我们都知道该接口主要承担命令绑定作用。通过ICommand接口的定义我们可以知道，ICommand接口的Execute方法是一个同步方法，因此常规的做法如RelayCommand或者DelegateCommand，基本上都是传入一个Action来指向一个具体方法，最终ICommand接口中的Execute方法执行的实际上是这个具体方法。截止到目前为止，这个策略在主流的场景下都实施得非常好，可是我们在引入Task、async/await这些新的概念以后，我们突然发现ICommand接口存在一个亟待解决的问题，即它缺乏一个支持异步机制的Execute方法，显然这是一个历史遗留问题。 我开始关注这个问题是当我在同事John和Charles的项目中看到类似下面的代码，事实上他们都是非常优秀的高级工程师，在对这个问题理解和探讨的过程中，我要特别感谢他们愿意分享他们的想法。我们一起来看看下面的代码： 123456789public RelayCommand RunCommand&#123; get &#123; return new RelayCommand(async ()=&gt;&#123; /* await awaitable */ &#125;); &#125;&#125; 请相信你的眼睛，因为你没有看错，让我倍感纠结的的正是这样一段简单的代码。这段代码让我迷惑的地方有两处，第一，RelayCommand实现了ICommand接口，而ICommand接口的Execute方法是一个同步的方法，为什么我们可以在这个里传入一个异步方法，并通过Action这种委托类型来对其进行包装；第二，Action是一个void类型，即无返回值的委托类型，我们这里显然使用async关键字修饰了一个无返回值的方法，因为我们在这个匿名方法内部使用了await语法。可是我们知道微软官方的建议是，使用async关键字来修饰一个返回值类型为Task或者Task的方法。在我了解到async关键字还可以这样使用以后，对第二处疑惑我稍稍有些许释怀，因为事实上Charles就是正式通过这种思路来启发我，可我始终无法理解，为什么我们可以在一个同步的方法里执行一段异步代码，并试图去安慰自己说这段代码是异步的，在执行一个非常耗时的任务时界面不会阻塞。 我们的项目需要在整个任务执行过程中输出操作日志，这意味着消息会实时地输出到界面上并且不会阻塞界面。我们在为此设计了一个基于观察者模式的消息队列，所有需要发送实时消息的模块被抽象为一个消息主题，而界面模块、日志模块等被抽象为消息观察者，所有订阅过的消息主题都会将消息推送到消息队列中，这一切目前在设计上是符合业务需求的。可是很快我们就会发现一个问题，使用await或者Wait()方法时，消息并不是实时地发送到界面上去的，因为我们知道await或者Wait()方法会一直等待一个异步任务执行完成，所以消息会在任务结束的一瞬间被全部发送到界面上，这显示是不符合我们的期望的，所以Execute()方法里执行的必然是一个同步方法，它不会因为我们传入了一个异步方法而改变，况且同步和异步是相对而言的，如果我们将await语法修改为Task.Run()，我们就会发现在异步任务执行完成前同步方法就开始执行了，而这正是我们想要的结果。 在这里我更感兴趣的一个问题是，.NET框架中的委托、匿名方法、Lambda表达式和Task是不同时期.NET的产物，那么我们在这里使用一个async关键字来修饰一个匿名方法，编译器在处理它的时候到底会怎么做呢？因为我们知道委托会被编译成一个包装类，那么现在在这篇文章中的提到的这个问题背景下，它会有什么不同呢？我们一起来看下面的代码： 12345static void Main(string[] args)&#123; Action action1 = async () =&gt; await DoWorkAsync(); Action action2 = () =&gt; DoWork();&#125; 我们注意到这里声明了两个Action，即两个没有返回值的委托类型，它们的不同点在于前者使用了async/await这两个关键字，而后者则是一个普通的同步方法，那么这两者生成的IL代码是否有区别呢？我们可以通过IL DASM或者是IL Spy这两个工具来查看IL代码： 查看IL代码 我们可以注意到两点，第一，两个委托类型生成的中间代码完全一致，都是CachedAnonymousMethodDelegate，这在某种程度上说明不管Action里包装的是一个同步方法还是一个异步方法，最终生成的IL代码应该都是相同的。第二，同匿名方法和扩展方法一样，async/await并未引入新的IL指令，async/await内部应该是在维护一个状态机，这一点和yield关键字应该是相似的，并且对于异步的匿名方法(指voild类型)，通过IL代码可知它是由AsyncVoidMethodBuilder类来生成的，而对于异步的方法(指Task和Task类型)，则是由AsyncTaskMethodBuilder类来生成，需要说明的是这两者在功能上相差无几，唯一的区别就在于异常处理。 关于异步编程中异常的处理，老赵在其博客关于C#中async/await中的异常处理（上）和 关于C#中async/await中的异常处理（下）这两篇博客中做了非常详细的解释，建议大家有时间的话去阅读这两篇文章，我们在这里关注结论就好。 具体来讲，async Task或者async Task方法引发异常时，会捕获异常并将其放置在Task对象里，并且只有Task对象被await时会引发异常。特别地，在调用Task.WhenAll()方法时，一个Task对象中可能会含有多个异常，此时await仅仅会重新抛出第一个异常，但是在 Task 上使用 Task.Wait 或 Task.Result 同步阻塞时，所有异常都会用 AggregateException 包装后引发。对于嵌套的Task，即含有子任务的Task，应该采用AggregateException来获取和处理所有的异常。Task/Task中未捕获的异常可以通过TaskScheduler.UnobservedTaskException来处理，这些异常不会继续向上抛导致程序异常退出。 async void方法引发异常时，因为它没有Task对象来放置异常，因此它的异常SynchronizationContext上引发，而且因为AsyncVoidMethodBuilder内部并没有使用TaskScheduler，因此对于async void方法来说，线程池中未捕获的异常将会一直向上抛并最终导致程序异常终止，虽然我们可以在AppDomain.UnhandledException这个事件中捕捉到这些”未处理的异常”，但这并不能阻止程序异常终止，通过我们可以通过注册这个事件来记录异常日志，以帮助我们快速定位问题。 好了，现在我们回到这篇文章开始的问题，我们现在知道async Task和async Task引发的异常，都不会是程序立即终止，除非我们显式地去await一个Task对象会引发异常，可是对async void来讲，一旦它引发异常，常规的try-catch时无法捕捉到异常的，这种”未处理的异常”会一直向上抛并最终导致程序异常终止。我为什么要说这个问题呢，因为我们在文章开始的时候写了一个异步的lambda表达式，最终它会被编译为async void，我们现在应该会了解到，async void非常容易引发未处理的异常并导致程序异常退出，所以这是微软官方最佳实践中不推荐使用async void的原因，因为使用async void就意味着我们要去捕获所有的异常。可是对标记为async的lambda表达式来讲，这个问题是非常隐蔽而且蛋疼的，或许不使用async void就是最为正确的选择了吧！ 最后，其实坦白讲，我自己是不清楚在这篇文章里我到底说什么的，因为这样一个在项目开发中遇到的问题，其实并不是一个特别重要的内容，因为它实在是太容易被我们给忽略啦。我最初关注这个问题完全是因为好奇，因为我从来没有见到过这种lambda表达式的写法，虽然纠结这样一个语法上的问题，和孔乙己讨论茴香豆的”茴”字由几种写法一样，都是一个相当迂腐不堪的表现，可我庆幸这份好奇让我了解到了更多的东西。其实总结下这篇文章中关注的点，主要有： 由同步方法和异步方法包装的委托类型在IL层面上是无差别的，委托关注的是参数列表和返回类型，和是否有async关键字修饰没有关系。 匿名方法或者lambda最终依然会被编译为一个方法，在有async关键字修饰的情况下，建议使用Func而不是Action，因为前者可以生成async Task或者async Task，而后者仅仅可以生成async void。 async Task/async Task和async void在异常处理机制上存在差异，前者未处理的异常不会继续向上抛导致程序异常退出，而后者未处理的异常会继续向上抛并导致程序异常退出，因此如果坚持要使用async void，就一定处理各种异常。 参考文章：Microsoft - async/await - 异步编程中的最佳做法TianFang - C# 5.0 async 函的提示和技巧","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"异步","slug":"异步","permalink":"https://qinyuanpei.github.io/tags/%E5%BC%82%E6%AD%A5/"},{"name":"编程","slug":"编程","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E7%A8%8B/"},{"name":"Lambda","slug":"Lambda","permalink":"https://qinyuanpei.github.io/tags/Lambda/"}]},{"title":"Redis缓存技术学习系列之发布订阅","date":"2017-04-15T21:03:57.000Z","path":"posts/1444577573/","text":"各位朋友，大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。最近这段时间的天气可谓是变幻莫测，常常是周一到周五像夏天般热烈，而周六和周天像秋天般冷清。你不知道它到底会在何时下雨，即使你可以一直带着伞等雨落下来。但是对于没有伞的我来说，学会努力奔跑以至于不那么狼狈，或许是在这个世界上我唯一可以去做的事情。可是你知道一个人孤独的时候，即使是下雨这种再平常不过的事情，他都可以从雨声里听出孤独的感觉来，所以这个周末我决定继续研究Redis缓存技术，而今天我想和大家讨论的话题是Redis中的发布-订阅(Pub-Sub)，希望大家喜欢！ 从观察者模式说起 如果你熟悉常见的设计模式，就应该会知道在24种设计模式中，有一种称为观察者模式的设计模式，该模式又被称为发布-订阅模式。在正式讨论Redis中的发布-订阅特性前，我想先花点时间来为大家讲解下这种设计模式。观察者模式定义了一种一对多的依赖关系，让多个观察者同时监听同一个主题对象，当该主题对象在状态发生变化时，会通知所有观察者对象并使其自动更新自己。下面是该模式的UML类图： 设计者模式的UML类图 通常我们提到设计模式的时候，都认为实际模式是非常抽象而晦涩的概念，事实上设计模式是一种经过反复验证的编程经验。我们每天面对这个世界对其进行抽象并认识它，所以设计模式本质上是根植自生活的一种编程思想。以观察者模式为例，我们或许会在微信里订阅各种各样感兴趣的公众号，当这些公众号的内容发生更新时，就会主动向我们推送新的内容。在这里，我们订阅的公众号称为”主题”，而我们则称为”观察者”或者”订阅者”，而这正是观察者模式又被称为”发布-订阅模式”的原因所在，这种定义了一种一对多的依赖关系，让多个观察者同时监听同一个主题对象，当该主题对象在状态发生变化时，会通知所有观察者对象并使其自动更新自己的设计模式就被称为”观察者模式”。而通过这张图我们可以了解到，观察者模式试图解决的问题是，在不同的实例对象间相互协作的时候，如果在降低其各自耦合度的同时，维持这些示例对象间的一致性。在该模式中，主要存在四种角色，即： 抽象主题(Subject)：抽象主题将所有观察者对象的引用保存到一个集合里，每个主题都可以有任何数量的观察者。抽象主题提供一个接口，可以增加(Attach方法)和删除(Detach方法)观察者对象。 具体主题(ConcreteSubject)：具体主题将在其内部定义相关状态，并将相关状态存入具体观察者对象。在具体主题内部状态发生变化时，通知所有注册过的观察者发出通知，即UML类图中定义的Notify()方法。 抽象观察者(Observer)：抽象观察者将为所有具体的观察者定义一个接口，在获得主题更新通知时更新自己，即UML类图中定义的Update()方法，执行该方法后观察者与主题的状态实现同步。 具体观察者(ConcreteObserver)：具体观察者将实现抽象观察者所定义的更新接口，来使得观察者自身的状态与主题状态协调，即具体观察者需要重写Update()方法并维护其内部状态同主题保持一致。 至此我们就从思想上理解了观察者模式，观察者模式本质上是在维护一种一对多的依赖关系，因为观察者与主题都是依赖于抽象而非具体，两者分别属于两个不同层次上的抽象，因此观察者和主题两者间是解耦的。可是当你去实现一个具体的主题或者具体的观察者的时候，你会发现这两者间依然存在一定的依赖，因为观察者和主题在接口设计上需要协调，因为两者分别作为消息的”接收方”和”发送方”存在。观察者模式虽然在解耦上效果显著，可这并不代表它就是完美的。事实上，当观察者数目特别多的时候，为了通知所有的观察者将花费大量的时间；其次，当观察者间存在依赖关系时，观察者模式将导致这些观察者出现循环调用；再者，当主题通过异步的方式来通知观察者时，需要考虑通知本身是以自洽的方式进行的；最后，观察者模式可以确保观察者捕捉到主题的变化，可是观察者模式机制本身不具备知晓主题如何变化的能力。好了，下面我们来讲解如何实现一个基本的观察者模式。 观察者模式的实现 现在，我们已然了解到在观察者模式中主要有四类角色，即抽象主题、抽象观察者、具体主题和具体观察者。因此，要实现观察者模式，实际上就是要实现这四种不同的角色。回到我们最初讨论过的场景，即微信用户订阅公众号，假设博主希望在博客更新的时候，以邮件或者公众号的形式来通知读者朋友博客更新的内容，这是一个典型的一对多的依赖关系维护的问题，显然此时观察者模式是一个最佳的设计思路。在这个设计中，邮件和公众号是两个具体的观察者，而博客是一个具体的主题。参照观察者模式的UML类图，我们应该首先提取出来两个抽象类，即Subject和Observer。 对Subject类而言，首先它需要提供一个订阅(Subscribe的方法和取消订阅(Unsubscribe)方法，这和我们在日常生活中订阅报纸是完全一样的；其次，它需要有一个更新(Update)的方法，该方法负责向所有的订阅者广播消息。为什么叫做广播呢？因为所有的订阅者都会收到这条消息，这种订阅者被动接受主题推送消息的方式我们称为”推送模式”，即在Update的时候，主题会主动推送”参数”给订阅者；而订阅者主动拉取主题消息的方式我们称为”拉取模式”，即在Update的时候，主题并不主动推送”参数”给订阅者，而是由订阅者通过注入的主题来获取消息。这两种方式我们都可以称之为观察者模式，在这里我们选择”推送模式”，代码实现如下： 12345678910111213141516171819public abstract class Subject&#123; private IList&lt;Observer&gt; observers = new List&lt;Observer&gt;(); public void Attach(Observer observer) &#123; observers.Add(observer); &#125; public void Deatch(Observer observer) &#123; observers.Remove(observer); &#125; public void Notify(string message) &#123; observers.ToList().ForEach(o =&gt; o.Update(message)); &#125;&#125; 对Observer而言，它在观察者模式中承担着消息接收者的角色，所以我们需要为其定义好接收消息的接口，需要注意的是该接口必须与具体主题保持一致，这便是我在文章中提到的，主题和观察者存在一定程度依赖的问题。考虑到不同的观察者所做的事情是完全不同的，例如邮件和公众号采取两种不同的方式来推送消息，因此Update方法应该被声明为虚方法，以为不同的观察者提供重写的扩展能力。它的代码实现如下： 1234567public abstract class Observer&#123; public virtual void Update(string message) &#123; &#125;&#125; 对具体观察者而言，我们需要做的就是继承Observer类然后重写Update方法，在这里我们需要实现两个不同的类EmailObserver和WechatObserver，它们分别来实现邮件和公众号接收到主题推送消息以后的逻辑，这里以EmailObserver为例，代码实现如下： 1234567public class EmailObserver:Observer&#123; public override void Update(string message) &#123; Console.WriteLine(\"邮箱接收到订阅消息:&#123;0&#125;\", message); &#125;&#125; 对具体主题而言，我们不再关心如何向所有的观察者发送消息，该功能在Subject父类中已然完成。我们可以为新的主题类添加更多的属性来描述其内部发生变化时的状态，例如文章数目、评论数目或者是内容更改等等。在这个例子中我们选择最简单的方式，即简单通知这两个观察者，因此我们直接继承Subject类即可。此时，完整的调用代码如下： 1234BlogSubject blog = new BlogSubject();blog.Attach(new EmailObserver());blog.Attach(new WechatObserver());blog.Notify(\"Payne更新了Redis缓存技术学习系列文章\"); 好了，现在通过下面的截图，我们就可以看到两个观察者EmailObserver和WechatObserver，都接收到了来自主题Blog的消息推送。这就是观察者模式啦，看起来是不是非常简单。可是相信大家使用公众号以后就会发现一个问题，随着你订阅的内容越来越多，你的微信消息列表里出现的消息推送就越来越多，这个时候如果你不想接收消息推送该怎么办呢？答案好像只有一个，那就是取消订阅。这个场景可以看出”推送模式”让订阅者饱受消息骚扰，而为了解决这个问题，我们就有了”拉取模式”，此时主题仅仅是告诉观察者博客内容有更新，而更新的内容需要观察者自己去处理，这种模式大同小异，大家可以参照”推送模式”来自己实现。 观察者模式基本实例 这些就是观察者模式的核心内容啦，观察者模式的优点是它解除了主题和观察者间的耦合，并且使得这两者各自都依赖于抽象而非具体，观察者模式适用的场景是当一个对象的改变需要给变其它对象时，而且它不知道具体有多少个对象有待改变时。在C#中我们可以通过委托、事件以及Observable接口这三种方式来更好、更快的实现观察者模式，自然这些都是后话啦，如果以后有机会我们可以继续进行探讨。 Hey Redis Pub-Sub 好了，了解完观察者模式即发布-订阅模式以后，我们现在就可以开始学习Redis中的发布-订阅模式啦。为什么我们要在开始学习Redis中的发布-订阅模式前，了解设计模式相关的概念呢？这是因为Redis中的发布-订阅模式和Gof设计模式一脉相承，譬如事件机制、消息机制等概念其实都是观察者模式的一种实际应用，一旦我们掌握了观察者模式的核心思想，即使这个世界充满了套路，可是这对你我而言又有什么不同呢？我们学习设计模式不是为了记住这些类图，而是能在最恰当的场景中合理使用这些模式来解决问题，这是我们学习的最终目的。 Redis中的发布-订阅模式是一种消息通信模式，即发布者发布消息，订阅者接收消息。在Redis中客户端可以订阅任意个频道，当该频道内接收到一个新消息时，所有订阅该频道的客户端都会收到这条新消息。我们可以这样理解这种消息通信模式，我们每个微信账号都是一个客户端，每个客户端都可以订阅任意个微信公众号，当微信的后台服务上接收到某个微信公众号的请求消息时，所有订阅了该微信公众号的客户端都会收到该推送。一个简单的图示如下： Redis中的消息模式 我们可以注意到这和我们在文章中提到的”观察者模式”非常相似，在这个通信模式下，客户端作为消息的订阅者，即观察者。而频道作为消息的发布者，即主题。在Redis中频道是一个字符串类型的值，你可以将其理解为一个Id。虽然我们在这篇文章中花费大量时间来讲观察者模式，事实上Redis中的发布-订阅是非常轻量并且强大的，下面是常见的命令： PSUBSCRIBE：该命令用于订阅一个或者多个符合模式匹配的频道 PUBSUB：该命令用于返回由活跃频道组成的列表，即可以查询订阅与发布系统的状态 PUBLISH：该命令用于发送消息到指定的频道 PUNSUBSCRIBE：该命令用于退订所有符合模式匹配的频道 SUBSCRIBE：该命令用于订阅一个或多个频道 UNSUBSCRIBE：该命令用于退订一个或多个频道 以上这些就是和发布-订阅相关的命令啦，从整体上而言它是相当简洁和紧凑的。在这篇文章中我们通篇都在说观察者模式，事实上Redis的发布-订阅从本质上来讲还是观察者模式，Redis内部会维护一个频道的字典，首先它会从频道字典中查找所有的客户端，如果字典中不存在该频道，则将订阅该频道的客户端列表添加到字典中，否则它会返回字典中已经存在的客户端列表。在获取到所有客户端列表以后，Redis将会遍历客户端列表中的客户端，然后给每个客户端发送消息，这部分代码的解读可以参考这篇文章：15天玩转redis —— 第九篇 发布/订阅模式。好了，这篇文章暂时就是这样子啦，为什么感觉最近学习Redis没有动力了呢？这篇文章没有实际的命令演示，这是因为我是在Windows系统下写完的这篇文章，深夜啦，睡吧！ &emsp;&emsp;现在我们一起来看一个简单的示例，在这个示例中我们让两个客户端A和B，订阅同一个频道News，然后由客户端C来向这个频道News广播一条消息，理论上客户端A和客户端B都将会收到这条消息，需要注意此时服务端是开启的。首先，对于客户端A和客户端B，我们在两个不同的终端窗口中打开redis-cli，然后输入命令： 1&gt; SUBSCRIBE News 在按下回车后，我们可以看到下面的信息： 1231) \"subscribe\"2) \"News\"3) (integer) 1 好了，现在我们在客户端C中来广播一条消息： 1&gt; PUBLISH News \"This is a message sent by 127.0.0.1:6379\" 此时我们可以看到下图中所示的结果： Redis中发布订阅模式","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"笔记","slug":"笔记","permalink":"https://qinyuanpei.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"设计模式","slug":"设计模式","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"Redis","slug":"Redis","permalink":"https://qinyuanpei.github.io/tags/Redis/"},{"name":"缓存","slug":"缓存","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"Redis缓存技术学习系列之事务处理","date":"2017-04-08T21:46:40.000Z","path":"posts/335366821/","text":"&emsp;&emsp;在本系列的第一篇文章中，我们主要针对Redis中的“键”和“值”进行了学习。我们可以注意到，Redis是一个C/S架构的数据库，在我们目前的认知中，它是通过终端中的一条条命令来存储和读取的，即它是一个非常典型的“请求-响应”模型。可是我们知道在实际的应用中，我们要面对的或许是更为复杂的业务逻辑，因为Redis中不存在传统关系型数据库中表的概念，因此在使用Redis的过程中，我们要面对两个实际的问题，即如何更好的维护数据库中的”键“、如何在高效执行命令的同时保证命令执行成功。对于前者，我认为这是一个设计上的问题，而对于后者，我认为这是一个技术上的问题。所以，这篇文章的核心内容就是找到这两个问题的答案。带着这样的问题出发，我们就可以正式进入这篇文章的主题：Redis中的事务处理。 从数据库事务说起​&emsp;&emsp;通常我们提及数据库都不可避免的要提到事务，那么什么是事务呢？事务是指作为单个逻辑工作单元执行的一系列操作。所以，首先事务是一系列操作，这一系列操作具有二态性，即完全地执行或者完全地不执行。因此事务处理可以确保除非事务单元内的所有操作的成功完成，否则不会永久更新面向数据的资源。我们这里举一个例子，数据库中除查询操作以外，插入(Insert)、删除(Delete)和更新(Update)这三种操作都会对数据造成影响，因为事务处理能够保证一系列操作可以完全地执行或者完全不执行，因此在一个事务被提交以后，该事务中的任何一条SQL语句在被执行的时候，都会生成一条撤销日志(Undo Log)，而撤销日志中记录的是和当前擦作完全相反的操作，比如删除的相反操作是插入，插入的相反操作是删除等。我们通常所说的事务回滚其实就是去执行这些插销日志里的相反操作，这同样告诉我们一个道理，只有事务中的一系列操作完全执行的情况下可以回滚，如果是在意外情况下导致事务中的一系列操作没有完全执行，这个时候我们是不能保证数据一定可以回滚的。 ​&emsp;&emsp;在数据库相关理论中，一个逻辑工作单元想要成为事务，就必须满足ACID，即原子性、一致性、隔离性和持久性。(1)：原子性这个概念其实就是指，一个事务内的所有SQL操作都是一个整体，因此只有所有的SQL操作都完全执行成功，该事务方可以认为提交成功。如果在提交事务过程中某一条SQL语句执行失败，则整个事务必须回滚到事务提交前的状态。(2)：而一致性这个概念则是指，事务在完成的时候，必须要保证所有的数据都保持一致的状态，而落实到数据库的各个组成部分上，则要求开发人员能够保证数据、索引、约束、日志等在事务前后具备一致性。(3)：隔离性这个概念主要针对并发，其核心思想就是不同的并发事务对数据产生的修改必须是相互隔离的，假设有两个不同的事务A和B并发执行，那么对A来讲，它在执行前的状态只有两种，即B执行前和B执行后。同理，对B来讲同样是如此，这样的特性我们就称为隔离性。(4)：持久性相对简单，是指事务完成以后它对数据的影响是永久性的。 Redis中的事务处理​&emsp;&emsp;好了，截止到目前为止，我们对数据库中事务处理的相关理论有了一个基本的认识，或许这个世界上的数据库系统千差万别，但我相信在事务处理这个问题上它们最终会殊途同归，就像我们解决并发过程中的冲突问题，常规的做法依然是加锁一样，这是我之所以要花费精力去理解和解释这些理论知识的原因，技术可谓是日新月异，如果我们总是一味地为新技术而疲于奔命，那么或许我们会渐渐地失去对这个行业的热爱，我相信原理永远比框架更为重要，没有系统学习过计算机专业的课程，这件事情让我至今都颇为遗憾。Redis中的事务是可以视为一个队列，即我们可以通过MULTI开始一个事务，这相当于我们声明了一个命令队列。接下来，我们向Redis中提交的每条命令，都会被排入这个命令队列。当我们输入EXEC命令时，将触发当前事务，这相当于我们从命令队列中取出命令并执行，所以Redis中一个事务从开始到执行会经历开始事务、命令入队和执行事务三个阶段。下面是一个在Redis中使用事务的简单示例： 123456789101112127.0.0.1:6379&gt; MULTIOK127.0.0.1:6379&gt; SET Book_Name \"GIt Pro\"QUEUED127.0.0.1:6379&gt; SADD Program_Language \"C++\" \"C#\" \"Jave\" \"Python\" QUEUED127.0.0.1:6379&gt; GET Book_NameQUEUED127.0.0.1:6379&gt; EXEC1) OK2) (integer) 43) \"GIt Pro\" 我们可以注意到Redis中的事务和通常意义上的事务基本上是一致的，即 事务是由一系列操作组成的单个逻辑工作执行单元。特别地，因为在Redis中命令是存储在一个队列中，所以，事务中的所有命令都会按顺序执行，并且在执行事务的过程中不会被客户端发送的其它命令中断。 事务是一个原子操作，事物中的命令只有两种执行结果，即全部执行或者全部不执行。如果客户端在使用MULTI命令开启事务后因为意外而没有执行EXEC命令，则事务中的所有命令都不会执行。同理，如果客户端在使用MULTI命令开启事务后执行EXEC命令，则事务中的所有命令都会执行。 Redis中的事务可以使用DISCARD命令来清空一个命令队列，并放弃对事务的执行。如果命令在入队时发生错误，Redis将在客户端调用EXEC命令时拒绝执行并取消事务，但是在EXEC命令执行后发生的错误，Redis将选择自动忽略。 &emsp;&emsp;我们知道，常见的并发控制方案主要有悲观锁和乐观锁两种方案，这里首先来解释下这两种概念。所谓悲观锁，顾名思义是一种悲观的策略，悲观锁认为：在对任何记录做修改前都应该加锁，如果加锁失败则表明该机录正在被修改，此时应该抛出异常；如果加锁成功则修改记录并在事务完成后解锁；如果有其它人修改则应该等待当前修改解锁或者是抛出异常。而所谓乐观锁，顾名思义是一种乐观的策略，乐观锁认为：每次从记录中查找数据别人都不会修改，因此这个过程中不需要加锁，但是在更新记录的时候，会通过版本号来判断别人是否修改过当前记录。 &emsp;&emsp;通常来讲，乐观锁适合在写冲突相对较少的场合下，悲观锁适合在写冲突相对较多的场合下。Redis中提供了一种称为check-and-set的机制，该机制主要通过WATCH命令来实现，其原理正是基于乐观锁的策略，Redis会在执行EXEC命令前检查被监视的键对应的值是否发生变化，如果该值发生变化表明有人修改过这个键中存储的值，此时Redis将会自动取消当前事务。我们来看这个简单的例子： 123456WATCH Record_Countval = GET Record_Countval = val + 1MULTISET Record_Count $valEXEC &emsp;&emsp;在这个例子中，我们尝试在事务中对Record_Count做一个自增操作，这段代码在非并发的情况下是没有问题的，可是在并发的情况下，如果在执行EXEC命令前有一个用户修改了Record_Count的值，那么我们此时的结果就会比期望的结果小1，现在我们有了WATCH，Redis就会对Record_Count进行监听，当Redis监听到该值发生变化的时候，这个事务就会被自动取消，进而避免造成冲突。 如何管理Redis的键​&emsp;&emsp;其实从切题的角度来讲，这篇博客基本上说清楚了事务处理问题，因此这篇博客虽然没有给大家带来多少惊喜，却依然可以非常恰到好处的结题，可是因为之前有朋友在博客中留言并问到Redis的键管理的问题，所以博主决定在这里简单的讨论下这个问题，鉴于博主和大家一样都是感刚接触Redis，所以下面的观点仅仅是一家之言，如果有疑问可以在博客中留言，欢迎大家批评指正。我认为Redis中的键的管理，基本上有两种策略，即惰性删除和定期删除，而实际上这正是Redis默认的键删除策略： redis使用惰性删除和定期删除两种策略来删除过期的键：惰性删除策略在碰到过期键时方进行删除操作，定期删除策略则每隔一段时间主动查找并删除过期键。 所以，基于这两种键删除策略，我们可以想到的做法有： 对于临时变量可以采用临时键来存储，在数据库全局设定一个过期时间，由Redis在键过期后自动删除。 对于持久化数据可以采用普通键来存储，通过服务器和客户端间定义协议来由客户端主动删除键。 对于不同模块中的键采取统一规范的命名规则来命名键，从而解决Redis中键管理混乱的问题。 设计合理的键回收机制，避免Redis使用超过95%以上的内存，或者通过设置Redis中的最大内存容量及其内存策略来主动触发Redis对键的淘汰。具体可以参考：Sunnyxd - Redis学习笔记-事务、键空间的维护与性能 &emsp;&emsp;好了，这篇文章就是这样了，希望大家喜欢，下篇见！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"笔记","slug":"笔记","permalink":"https://qinyuanpei.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Redis","slug":"Redis","permalink":"https://qinyuanpei.github.io/tags/Redis/"},{"name":"缓存","slug":"缓存","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"时间如灰烬般遥远","date":"2017-04-03T00:25:21.000Z","path":"posts/1357715684/","text":"&emsp;&emsp;春天，常常是万物复苏的日子，是以这段时间喜欢去各种地方赏花阅景。相比起三月中旬里裹挟着清冷的青龙寺，此刻到处人山人海的景象，仿佛洋溢着某种热闹的气息。从前读朱自清的《荷塘月色》，一直不明白“热闹是他们的，我什么都没有”这句话该做何解。当你面对梨花胜雪、桃花人面的景致的时候，心中却是如灰烬一般孤独的时候，大概终于明白，为何在熙熙攘攘的人群中会感到一丝清冷，因为唯有行走在人群里的时候，你会发现原来你一个人走了这么久。天地间万事万物更迭交替，本来是自然界中最普通的规则，可是如果每年的这个时候，你都是一个人去看这山山水水，相比时空上的孤寂感，人的孤寂感会更为强烈，“良辰美景奈何天，赏心乐事谁家院”，外面的世界再纷繁多变，对你而言不过是活着的时间。 &emsp;&emsp;我常常像一个淡漠世情的路人，这个世界上发生什么都和我无关，路人纷纷成双入对，而我依然孑然一身，或许这就是我的生活。每天你会和不同的人相处，可每个人都在忙着自己的事情，我们和这个世界息息相关，与此同时，我们和这个世界毫无关联。我记得周五我帮Kent办理离职手续的时候，我一个人从七楼到十三楼再到十六楼，反复地奔波着。同事让他帮忙向公司归还一台笔记本，结果这台笔记本让整个过程都充满了落寞感。部门与部门间的相互推脱，同事与同事间的相互推诿，让我感到从未有过的窒息感：有一群人每天都坐在一起，每个人都看起来在努力工作，然而在你真正需要帮助的时候，你不能完全指望任何一个人。或许这和我外冷内热的性格有关，可是有那么一瞬间，我突然好想离开那个地方。 &emsp;&emsp;组里的人都走得差不多啦，现下终于剩下我一个人。自此项目上全凭我一个人做主，可对我而言却没有多少欢喜。我还是喜欢和大家在一起，虽然我时常让他们生气，像个孩子一样，可你知道我从来都不是无理取闹的。『射雕英雄传』我看了不下十遍，世人都道东邪黄药师行事乖张、狂傲不羁，可他对妻子冯蘅的深情世间谁人能及，夜夜笙箫相伴墓前，打造花船赴死沧澜，及闻爱女葬身大海，悲痛之际以玉箫扣舷而歌，其深情亦如此。没有人可以一直像个孩子，可以永远都不长大。前段时间看韩寒的电影《乘风破浪》，电影的主题曲从发布就被人吐槽直男癌，其实那仅仅是丈夫在妻子面前“撒娇”的心态，有句话说『在你身边我是个孩子，可你需要了，我就是无坚不摧的勇士』，人人都在说情商如何如何重要，可在真性情面前它的确有点虚伪。 &emsp;&emsp;Kent是坐周五晚上的火车离开，晚上两个人一块儿吃饭，聊到了家里的琐事，聊到了工作的想法，唯独没有提到离别，大概是我不愿意说起。结账的时候，两个人抢着付钱，老板娘笑着说两个人谁付都是一样的，反正以后还有的是机会。可是未来的事情有谁能够说得准呢？或许期望越高，失望就越大，就像我答应了她许多事情，即使我常常在脑海里想起，她现在都不会在乎了吧。可我总是很怀念那些日子，在这世上有那么一个人，绘画、舞蹈、诗文、书法无所不通，我如果能学会吹奏洞箫，为她跳舞时伴奏一曲可好？人生相识不易，或许不是我不愿意去认识别人，而是我知道知音难觅、知己难求，得不到的永远都是最好的。对Kent来说，他有根可寻，回去是最好的选择。而我则是无根枯蓬，风吹到哪里就在哪里。我知道我再难遇见那样的人，人生与我而言，离别总是常态，孤独是种绝症。 &emsp;&emsp;或许Kent说得是对的，这个世界上并没有那么多，真正看重技术的公司，这个世界上普通如你我的人，无一不在做着普通的事情。寻找一家新的公司，对目前的我来说，是件极具挑战的事情。虽然邹老师最后帮我推荐了简历，但是对方并没有适合的项目，这种处境既危险而困窘，我不能再像以前一样，我必须让自己拥有自信的生活，一个人如果不能做到爱自己，又怎么能够做到爱别人呢？可她永远不会再出现了，看到路人成双入对的时候，或许爱对我而言是件太困难的事情，佛门有“贪嗔痴”三戒，求而不得是为执，一个人孤零零地在这个城市里，从明天开始，我会经历更多的一个人，一个人吃饭，一个人工作，一个人游曳……长夜听雨，自今日始，你知道一个人数梅花该是何等的寂寞，你就会知道一个人听雨滴下该是何等的孤独，当然这对我而言是没有区别的。 &emsp;&emsp;有时候会在B站上看以前的影视剧，忽然发现原来一切都已然过去那么久。可当时的心性却不再回复，取而代之的是无限的回想，人生总是如此匆忙的别离，你每天都会认识不同的人，你每天都会错过不同的人，光影恍惚间，一切都仿佛是时间的灰烬爬上了镜子，这像什么呢？或许这就是世事无常，如白云苍狗；或许这就是人生不见，动如参商……时间啊，像极了爬满窗台的灰烬，我却还惦念着窗台外的爬山虎…… Payne, 于4月3日夜","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"心情","slug":"心情","permalink":"https://qinyuanpei.github.io/tags/%E5%BF%83%E6%83%85/"},{"name":"孤独","slug":"孤独","permalink":"https://qinyuanpei.github.io/tags/%E5%AD%A4%E7%8B%AC/"},{"name":"别离","slug":"别离","permalink":"https://qinyuanpei.github.io/tags/%E5%88%AB%E7%A6%BB/"}]},{"title":"Redis缓存技术学习系列之邂逅Redis","date":"2017-03-30T23:31:40.000Z","path":"posts/3032366281/","text":"&emsp;&emsp;作为一个反主流的开发者，在某种程度上，我对传统关系型数据库一直有点“讨厌”，因为关系型数据库实际上和面向对象思想是完全冲突的，前者建立在数学集合理论的基础上，而后者则是建立在软件工程基本原则的基础上。虽然传统的ORM、序列化/反序列化在一定程度上解决了这种冲突，但是软件开发中关于使用原生SQL语句还是使用ORM框架的争论从来没有停止过。可是实际的业务背景中，是完全无法脱离数据库的，除非在某些特定的场合下，考虑到信息安全因素而禁止开发者使用数据库，在主流技术中数据库是一个非常重要的组成部分。为了弥补这个技术上的短板，从这篇文章开始，我将会学习一个经典的缓存技术：Redis。我们这里将Redis定性为一门缓存技术，这说明Redis和MySQL等主流的数据库存在本质上的区别，那么这些区别到底在哪里呢？或许在看完这个系列文章以后，你心中自然就会有了答案。 Redis是什么?&emsp;&emsp;Redis是什么?这是本文第一个问题。Redis是一个开源的使用ANSI C语言编写的、支持网络、 基于内存的、支持持久化的日志型、Key-Value数据库。从如此丰富的修饰语中，我们基本可以抽离出这些信息： Redis是一个Key-Value存储系统 Redis的数据全部缓存在内存里 Redis可以通过网络实现主从同步 Redis支持丰富的数据类型可实现持久化 那么该如何给Redis一个准确的定义呢？或许这个定义可以帮助我们更好的理解Redis，即Redis是一个高性能的Key-Value数据库。我们知道主流的数据存储方案，可以分为关系型数据库和非关系型数据库两大类。传统的Oracle、MySQL和SQLServer都是关系型数据库，关系型数据库将复杂的数据结构归结为二元关系，即二维表形式，而对数据的操作则建立在一个或多个关系表格中，并通过这些表格间的分类、合并、连接和选取等运算实现数据处理。如同天地万物，有阴影的地方就会有阳光。和关系型数据库相对应的，我们称之为非关系型数据库，这是一个泛指的概念。实际上非关系型数据库，根据设计原理的不同，具体可分为：键-值存储数据库、列存储数据库、文档数据库和图数据库四种。我们通常称非关系型数据库为NoSQL，即”Not Only SQL”，从这个概念我们或许可以明白，SQL和NoSQL并非是完全对立的两个世界，它们各自在其擅长的应用场景中发挥着重要的作用。 所以我选择Redis这样一个非关系型数据库，从某种意义上来说，我是想说明一件事情，数据库技术并非绝对代表着关系型数据库和SQL，实际上SQL这门语言存在一定缺陷，就像我们提及Web技术常常想到是如何去做一个网站(MVC)，可你同样会意识到Web API是更为重要的Web技术。这个世界并非是一成不变的，每一天都是新的挑战。 开始使用Redis 好了，在了解了Redis是一个什么东西以后，现在我们来正式开始使用Redis。Redis作为一个开源的键-值数据库，我们可以从它的官方网站或者是从Github来获取。这里推荐从官方网站下载相对稳定的版本，这里博主选择的是3.2.8版本，需要注意我们这里从官方网站下载的是源代码版本，所以首先第一件事情就是编译源代码。如果你非常擅长在Window下编译类似项目，可以尝试在Windows下进行编译。博主这里推荐大家使用Linux或者MacOS来编译，因为主流开源项目使用的Makefile都是Unix世界里的产物，所以使用Linux或者MacOS能够为我们节省大量的时间。博主这里使用的是Elementary OS这个Linux发行版(对应Ubuntu14)，编译方法如下： Redis的编译与安装1234$ wget http://download.redis.io/releases/redis-3.2.8.tar.gz$ tar xzf redis-3.2.8.tar.gz$ cd redis-3.2.8$ make 在这里，除了make的步骤严格依赖命令行以外，其余的步骤都可以手动完成，所以因为惧怕命令行而不愿意接触Linux的世界，事实证明，对一个真正的程序员来讲，命令行是一个唯一可以让人不被外界所干扰的高效地工具，Git是这个世界上最好没有之一的版本控制工具，如果你喜欢Git，那么你更应该尝试去喜欢Linux。好了，在完成对Redis的编译后，我们就可以开始使用Redis了。Redis是一个C/S架构的键-值数据库，这意味着我们需要Redis的服务端程序和客户端程序。在完成编译以后，我们将得到redis-server和redis-cli这两个内置服务端程序和客户端程序。实际使用中我们会接触到不同语言下的redis客户端，在这里我们直接使用Redis内置的客户端： 1234//开启Redis服务$ src/redis-server//开启Redis客户端$ src/redis-cli 需要注意的是在这里服务端和客户端，是在两个不同的终端窗口中运行的，当我们看到下面的窗口时，即表明Redis服务开启就绪，此时我们就可以通过客户端来输入各种命令来完成数据的存取，默认情况下Redis每次会随机分配一个端口，这里Redis采用6379端口进行通信： Redis服务 Redis是一个采用键-值存储方案的数据库，因而传统关系型数据库里的SQL在这里将不再适用。你可以将Redis理解为一个字典，我们可以向这个字典中储存任何Redis支持的数据类型，并通过键名来获取字典中存储的对应数值。我们来看下面的例子，以下命令均在redis-cli中执行： 1234SET foo barOKGET foo\"bar\" Redis中支持的数据类型 这个例子演示了如何在Redis中存储和读取一个简单的字符串类型的值，看起来这一切都非常简单啊，的确Redis就是这样一个简单而高效的键-值数据库。我们在前面提到Redis支持各种各样的数据类型，那么它到底支持哪些数据类型呢？具体来讲，Redis支持5种基本的数据类型： 字符串(Strings)：最基本的数据类型，使用SET/GET命令来存储和读取字符串类型的值。在Redis中最多可支持512兆字节的字符串长度，这意味着我们可以常见的数据类型序列化后再存储到Redis中。 散列/哈希(Hashes)：专门用来表示对象的数据类型。散列/哈希是键-值对的集合，可以维系字符串字段和字符串值间的映射关系，因此它主要用来表示对象。在Redis中可以使用HMSET、HMGET、HGET、HGETALL四种命令来存储和读取散列类型的值。 列表(Lists)：指按照插入顺序排序的字符串元素的集合，特别地，Redis中的列表是采用链表实现的，因为对数据库系统而言，一个非常重要的特性是可以支持在含有大量元素的集合中快速添加元素。常见的应用于列表的命令主要有LPUSH、RPUSH、LPOP、RPOP和LRANGE。 集合(Sets)：指不重复且无序的字符串元素的集合。针对列表，常见的命令主要有：SADD、SPOP、SCARD、SMEMBERS和SISMEMBER。例如SADD命令可以向集合中添加元素，SPOP命令可以从集合中删除元素，SCARD命令可以返回集合内元素个数，SMERMERS命令可以枚举集合的所有元素，SISMEMBER命令可以判断指定元素是否在指定集合内。 有序集合(Sorted Sets)：有序集合与集合相似，不同点在于集合中的每一个元素都会关联一个浮点型的数值，该数值称为score，事实上Redis正是根据score来对集合内的元素进行排序的。集合内的元素是不允许重复的，但是score是可以允许重复的。常见的命令有：ZADD、ZCARD、ZCOUNT、ZREM、ZSCORE等。 Redis中和键有关的命令 我们知道Redis是一个键-值数据库，所以在了解了Redis中支持的数据类型，即“值”以后，现在让我们将关注点回归到“键”上面来，这是因为作为一个键-值数据库，键是我们从数据库中获取值的唯一方式，因此在这里说说Redis中那些和键有关的命令，这些命令基本都遵循下面的命名格式，常见的命令有： 1COMMAND KEY_NAME DEL：该命令将在键名存在时从数据库中删除指定键，成功则返回1，否则返回0。 DUMP：该命令将序列化指定键，并返回被序列化的值。 EXISTS：该命令用以判断指定键是否存在。 EXPIRE：该命令用以给指定键设置过期时间。 KEYS：该命令用以返回所有满足匹配模式的键。 PERSIST：该命令用以移除指定键的过期时间。 RENAME：该命令用以重命名指定键。 ​ 好了，这就是这篇博客的内容了，自我感觉Redis中的内容相对分散，这种细小的知识点都隐藏在命令中，最初在介绍不同的数据类型的时候，在文章中均做了详细的介绍并辅以终端脚本，可是最后发现这样写下去还不如去看官方文档，像Redis这种即使学习了都不见得有机会使用的技术，当然我并不是说Redis不好啊，关系型数据库目前依然是主流的技术驱动力量，所以我觉得我们学习的时候最好是“观其大略”、“不求甚解”，首先注重整体知识体系上的理解，微枝末叶上的细节问题可以在使用的时候去查阅文档。在下面的文章中，我重点关注的内容是Redis的事务、脚本、发布/订阅及不同语言下Redis的使用，希望大家继续关注我的博客，本篇结束！","categories":[{"name":"数据存储","slug":"数据存储","permalink":"https://qinyuanpei.github.io/categories/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/"}],"tags":[{"name":"数据库","slug":"数据库","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"笔记","slug":"笔记","permalink":"https://qinyuanpei.github.io/tags/%E7%AC%94%E8%AE%B0/"},{"name":"Redis","slug":"Redis","permalink":"https://qinyuanpei.github.io/tags/Redis/"},{"name":"缓存","slug":"缓存","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%93%E5%AD%98/"}]},{"title":"使用C#开发HTTP服务器之支持HTTPS","date":"2017-03-05T14:01:39.000Z","path":"posts/2734896333/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。本文是“使用C#开发HTTP服务器”系列的第六篇文章，在这个系列文章中我们实现了一个基础的Web服务器，它支持从本地读取静态HTML页面，支持GET和POST 两种请求方式。该项目托管在我的Github上，项目地址为https://github.com/qinyuanpei/HttpServer，感兴趣的朋友可以前往了解。其间有朋友为我提供了HTTPS的PR，或许这偏离了这个系列开发HTTP服务器的初衷，可是我们应该认识到普及HTTPS是大势所趋。所以在今天这篇文章中，我将为大家带来HTTPS相关知识的普及，以及如何为我们的这个Web服务器增加HTTPS的支持。 &emsp;&emsp;2017年我们听到这样一个声音，苹果将强制实施ATS，即App Transport Security。首先我们要了解的是ATS，它是苹果为了保证应用数据在网络中安全地传输而制定的一种规则，其核心是鼓励开发者使用安全的HTTPS协议和服务器进行通讯。在此之前考虑到大量的应用还在使用HTTP协议，所以苹果并未强制要求应用遵守这个规范，而此时苹果发出这样一种声音，我们终于意识到苹果这是在推广HTTPS啊！无独有偶，同样作为科技巨头之一的Google，宣布在新发布的Chrome 56中会将仅支持HTTP协议的网页标记为“不安全”。HTTPS到底是什么呢？为什么科技巨头纷纷开始对它青眼有加呢？这或许要从HTTPS协议说起。 &emsp;&emsp;HTTPS，即Hyper Text Transfer Protocol Over Secure Socket Layer的简称，是指以安全为目标的HTTP协议。我们可以将其理解为在HTTP协议的基础上增加了安全机制，这里的安全机制是指SSL,简单来讲HTTPS协议依然采用HTTP协议，不过它在HTTP和TCP间增加了加密/身份验证层，因此在保证数据传输安全的同时，为服务器提供了身份校验机制。任何采用HTTPS协议的网站，均可通过浏览器地址栏中的“锁”标志来查看网站的认证信息，或者是通过CA机构颁发的数字证书来查询。下图展示的是HTTPS协议中客户端和服务器端通信过程： HTTPS协议中客户端和服务器通信过程 从图中我们可以看出，在HTTPS协议中客户端和服务器端分为六步： 客户端请求服务器，发送握手消息给服务器。 服务器端返回客户端加密算法、数字证书和公钥。 客户端对返回的数字证书进行验证，如果验证通过则产生一个随机数，否则提示验证失败。 客户端使用公钥对产生的随机数进行加密，然后将其发送给服务器端。 服务器对该随机数进行解密，并以此作为密钥发送握手信息给客户端。 客户端收到消息后对消息进行解密，如果解密成功则表示握手结束。 &emsp;&emsp;这恰恰印证了我们最初的观点，即HTTPS协议依然采用HTTP协议(三次握手)进行通讯，不同的地方在于中间环节增加了加密处理，例如在客户端和服务器端相互验证的环节采用的是非对称加密，在客户端验证通过以后双方采用随机数作为密钥是对称加密，而三次握手以后验证消息是否被篡改则是采用HASH算法。所以我们应该可以注意到，HTTP协议和HTTPS协议的一个显著的区别是，前者采用明文来传输消息，而后者采用密文来传输消息，因此HTTPS协议比HTTP协议在通讯上更为安全。而详细来说，两者的区别主要有： HTTPS需要证书，而HTTP则不需要证书，证书由CA机构颁发。 HTTP采用明文来传输消息，C/S端无身份验证；HTTPS采用密文来传输消息，C/S端有身份验证。 HTTP默认采用80端口进行通信，而HTTPS默认采用443端口进行通信。 &emsp;&emsp;好了，现在我们对HTTPS协议有了一个基本的认识：HTTPS协议相比HTTP协议增加了身份验证和消息加密的机制，因此HTTPS协议能够保证通讯过程中的数据传输安全。在今天这样一个数字时代，当个人隐私安全彻底地暴露在浏览器、应用程序面前，能够提供更安全的互联网服务无疑会让人更有安全感，我想这是苹果和谷歌这样的科技巨头公司，之所以要去努力推广HTTPS协议的原因吧！因为客户端需要对服务器的证书进行验证，所以这意味着在客户端拥有访问所有受信证书的能力，例如我们在使用传统网银产品时都需要安装网银证书，这其实就是为了让客户端在向服务器端发起请求时方便对服务器进行验证，因此如果客户端请求的URL遭遇劫持，被重定向到某个不被信任的站点上，那么客户端发起的请求就会被拦截。同样的道理，服务器端会对客户端的请求进行验证，所以这里就不再详细展开去说啦。 &emsp;&emsp;我们最初设计这个HTTP服务器的时候，没有考虑过要支持HTTPS协议。可是当我们了解了HTTPS协议后，我们发现，如果要让最初设计的Web服务器支持HTTPS协议，我们需要关注的是Security，即身份验证和数据加密，我们知道这里的Security指的是SSL，所以需要了解SSL相关的内容。其次，我们需要提供一个数字证书给服务器端，目的是在客户端发起请求的时候，将数字证书、加密算法和公钥返回，保证客户端可以完成证书校验。从这两点可以看出，我们首先需要从CA机构购买证书，这一点毋庸置疑。关于证书的购买及服务器的设置，我们通过搜索引擎可以找到相关参考。目前主流的服务器如Apache、IIS、Tomcat和Ngnix都可以非常方便地支持HTTPS，这些问题更像是一种基础设施，所以我会在文章末尾列举出相关文章供大家查阅。 &emsp;&emsp;这篇文章的核心是开发一个服务器，所以在保证这些基础设施完备的前提下，让我们将关注点落实到代码上面来。我们提到，HTTPS除了证书以外关键点是SSL，而在.NET中提供SSL相关的API，所以这里我们直接使用这些API就可以完成证书的创建、加载等工作。下面是相关的代码示例： 12345678910111213141516171819202122232425262728293031// 使用OpenSSL.NET生成密钥RSA rsa = new RSA();BigNumber number = OpenSSL.Core.Random.Next(10, 10, 1);rsa.GenerateKeys(1024, number, null, null);CryptoKey key = new CryptoKey(rsa);//创建X509证书，Subject和Issuer相同 X509Certificate x509 = new X509Certificate();x509.SerialNumber = (int)DateTime.Now.Ticks;x509.Subject = new X509Name(\"CN=DOMAIN\"); //DOMAIN为站点域名 x509.Issuer = new X509Name(\"CN=DOMAIN\");x509.PublicKey = key; //指定公钥 x509.NotBefore = Convert.ToDateTime(\"2011-1-1\"); //起始时间 x509.NotAfter = Convert.ToDateTime(\"2050-1-1\"); //失效时间 x509.Version = 2;//使用私钥签名x509.Sign(key, MessageDigest.MD5);//生成CRT证书BIO x509bio = BIO.File(\"CA.crt\", \"w\");x509.Write(x509bio);//生成PFX证书var certs = new OpenSSL.Core.Stack&lt;X509Certificate&gt;();PKCS12 p12 = new PKCS12(\"PASSWORD\", key, x509, certs); //PASSWORD为保护密钥 BIO p12Bio = BIO.File(\"CA.pfx\", \"w\");p12.Write(p12Bio);//加载证书var certifiate = X509Certificate.CreateFromCertFile(\"CA.crt\"); &emsp;&emsp;在我们获得证书以后，我们就可以通过SSL对Socket通信过程中传递的消息进行加密了，一个基本的示例代码如下： 12345SslStream sslStream = new SslStream(clientStream);sslStream.AuthenticateAsServer(serverCertificate, false, SslProtocols.Tls, true);sslStream.ReadTimeout = 10000;sslStream.WriteTimeout = 10000;return sslStream; &emsp;&emsp;个人感觉加密相关的问题深奥而晦涩，这篇文章中涉及到的相关概念和技术，都大大地超出了我目前的认知范围。不过既然这位朋友热心地提交了这个PR，我就将这个过程视为向别人的一次学习吧！我会继续去完善这个项目：https://github.com/qinyuanpei/HttpServer。这篇博客终于算是写完了，周末开心！ ** 参考文章 ** Zery - HTTPS原理解析 阮一峰 - SSL/TLS协议运行机制的概述 维基百科 - 超文本传输安全协议 猫尾博客 - HTTPS工作原理 MSDN - 如何在 IIS 中设置 HTTPS 服务 Dudu - 给IIS添加CA证书以支持https 温柔易淡 - Apache配置HTTPS功能 王浩宇 - 配置Tomcat使用https协议","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"服务器","slug":"服务器","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"C#","slug":"C","permalink":"https://qinyuanpei.github.io/tags/C/"}]},{"title":"愿浮萍乘风破浪","date":"2017-02-04T22:31:33.000Z","path":"posts/2314414875/","text":"或许是今年的贺岁档电影全部遭遇“滑铁卢”的缘故，在这种情况下，电影《乘风破浪》或许会成为拯救整个贺一个岁档的奇迹。同往常一样，我依然选择一个人去看电影，而庆幸的是韩寒真的没有让我们失望。虽然前期在微博上经常看到韩寒在为这部电影做宣传，但我一直想知道它会一种什么样的方式来讲述这个故事，我隐隐约约觉得徐太浪(邓超饰)、徐正太(彭于晏饰)、小花(赵丽颖饰)三个人之间的关系非同寻常，我甚至臆想这是一部俗套的三角恋的故事。可结果却是完全出人意料的，我很喜欢这个故事。 &emsp;&emsp;首先，电影一开头就项我们展示了一个非常常见的矛盾冲突，从小喜欢赛车的儿子徐太浪和坚决反对儿子以赛车作为职业的父亲徐正太。我们从小到大或许都会有这样的经历，我们曾经执著地喜欢过什么或是热爱过什么，可这种喜欢在父母眼中常常被视为叛逆。我大学四年里最反感的一件事情就是我的本科专业，我一直很喜欢计算机技术，确切地说是通过编程来理解这个世界，可是因为我高考成绩并不理想，当时在父亲的建议下选择了一个我不喜欢的专业，在这四年里我做过最多的事情，就是极力想要摆脱这个专业。我从那个时候开始将编程视为我主要的兴趣，我从大学时候就开始研究自己感兴趣的技术，开始在技术社区里撰写博客。 &emsp;&emsp;这段经历让我至今都难以忘怀，这件事情教会我一个道理，当你认准去做一件事情的时候，其实没有任何一个人可以左右你的选择，2016年上半年我经历了一段时间的失业。虽然周围人都在告诉我，考公务员或者选择我本专业或许会比我的选择更为光明，但那个时候我一直找不到喜欢的工作，我常常在心里问我自己：难道我注定不能去做我喜欢的事情吗？后来我独自一个人来到西安，我畏惧逃离北上广的那种无力感和孤独感，可其实一个人在西安同样是孤独的。父母自然是为了我们好，可这种两代人的矛盾不管什么时候都会持续下去，当徐太浪面对着镜头大声说出那些压抑在心底的话的时候，我们所看到的那个懦弱而苍老的父亲，或许在每个人身上都可以找到影子吧！ &emsp;&emsp;或许是因为太想在父亲面前证明自己，所以当徐太浪取得赛车比赛冠军时，他迫不及待地让父亲坐在自己的副驾驶位上，一如电影开头那呼啸而过的一抹车影，当赛车穿过蜿蜒的山路、穿过废旧的城镇，在恍惚间我好像看到了，在《平凡之路》中一直蔓延着的无尽的长路，当镜头和画面频繁切换着，你以为是时间穿越了历史，其实时间就静止在那里，我们所看到的不过是那些转瞬即逝的风景，所听到的不过是那些呼啸而过的风声。我特别喜欢徐太浪的赛车与货车擦肩而过时，一切变得支离破碎的那组慢镜头，它就像一层层地褪去外表华丽的油漆，直接让斑驳的纹理一点点地裸露出来，当车窗玻璃破碎并跌落在空气里，当庆祝成功的香槟和奖杯混杂在空气里。或许此时此刻所有的一切都不再重要了吧，我们说洗去铅华返璞归真，大概只有在这种情况下，当我们的灵魂完全变得纯净的时候，或许穿越这种影视表现手法才会真正起作用，我们注意到徐太浪在医院病床上醒来的时候，眼角是带着泪水的，所以对这个电影里所叙述的故事，我宁愿将其当作是徐太浪的一个梦吧！他因为从小没有见过母亲，所以想要努力知道母亲长什么样子，在死亡边缘成为了他的一种执念。影片为了刻意制造笑点，让徐太浪身上多了许多“穿越”的特质，其实对观众而言这仅仅是一种代入的符号，换句话说，“穿越”以后的这个人是不是徐太浪本身已经不再重要了，重要的是我们通过这个人了解了整个故事。 &emsp;&emsp;整个故事其实是一个解惑的过程，所有的线索都是为了让徐太浪明白，自己的父亲为什么会变成这个样子，而围绕这些线索，整理的冲突发生在以徐正太、六一、阿浪、小马为代表的“正太帮”和黄志强、罗力为代表的“黑社会”，双方的利益冲突交织在一间歌舞厅。我们知道徐正太的一个梦想是“歌舞厅里只唱歌，桑拿房里就洗澡”，而这是一种近乎乌托邦的存在，所以年轻的徐正太有理想和抱负，想成为杜月笙那样的老大，而这一切的初衷是为了让自己的妻子做歌舞厅的老板娘。而通过阿浪夜寻小花这个事情，我们同时知道，徐正太是一个可以因为朋友一句话就等对方一个晚上的人，这说明他是一个守信用的人，而导致徐正太坐牢的直接原因是他为朋友六一报仇，这是一个重义气的表现，那么他的局限性在哪里呢？他认为录像厅比电影院有前途，就大量购买录像带；他认为BP机代表了通信行业的未来，就大量囤积BP机。所以这个时候我们就会明白，他后来会对阿浪采取“棍棒教育”，其实是因为他的眼界就局限在这里，他在对待新事物上存在局限性，所以看不到世界的变化，他在天台上说的那句“世界是不会变的”就是最好的证明。六一代表了那种并不聪明但愿意为朋友两肋插刀的“傻气”，小马则代表了那种愿意去追逐梦想的“执着”，当OICQ这个名字从他口中说出来的时候，我就知道这个人的一生都将注定不平凡。黄志强代表的是商业利益既得者，而罗力则代表的是失去一切后迷途知返的回头浪子。 &emsp;&emsp;如果说男人们的故事都是这般粗犷的话，那么这部电影里女性角色则显得细腻。首先从小花说起，小花和阿浪一样，都是对自己的父亲怀有敌意的，因为作为飞行员的父亲舍弃了和家人在一起的时间，投入全部身心到飞行事业上去，以至于在她婚礼的时候，父亲都没有来参加。影片中一个细节是，最后徐正太和阿浪杀死黄志强以后，怀有身孕的小花匆匆赶来，将满身血污的徐正太紧紧抱在怀里，小花说徐正太有时候像个孩子，其实男人都会有像孩子的一面，所以小花其实代表的是一种母性的关怀吧！值得一提的是电影里佳怡和松子这个女性角色，虽然六一喜欢佳怡，可依琳说她有喜欢的人的时候，他默默地选择放手，即使他心里依然有她，而最终六一躺在太平间里，此时陪伴在他身边的，不过是哭成泪人地佳怡和那条巡回犬，大概我们都习惯了忽视身边人的爱吧，从父母到伴侣，影片中正太和小花从四岁结识从始自终，这大概就足以令人唏嘘了吧。顶风作案的罗力，承诺要给松子一方天地，然而等他从狱中出来，见到的却是坐在黄志强车上神色复杂的那个人，你说这个世界是会变的，可它会变成什么样我们永远无从得知，小马希望的是那个拨号上网频频掉线的时代诞生一款OICQ的软件，徐正太希望的是像杜月笙那样收“物业费”……我们期望着什么，我们等待着什么，其实都不重要，世界一直都在变化，而我们如浮萍，或随风漂泊，或乘风破浪，一切都在我们的选择。 &emsp;&emsp;电影结尾，阿浪和正太在同一个平行宇宙，一如影片开始，两个人坐在同一辆车上一样，阿浪问正太：“你的车技这么好是跟谁学的？”，正太回答：“天赋来的”。同样，正太问了阿浪相同的问题，阿浪说：“遗传来的”。其实到这里，我们看到的是父子间真正的握手言和，最终两个人互相理解了对方，电影开头两个人的矛盾冲突，以这样一种形式化解，是件让人欣慰的事情，如果那些被时代抛弃的BP机，或许你我都不再认同它们的价值，但那曾是父母眼中给我们的最好的爱，世界每天都在变化，而起风了，唯有努力生存。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"电影","slug":"电影","permalink":"https://qinyuanpei.github.io/tags/%E7%94%B5%E5%BD%B1/"},{"name":"韩寒","slug":"韩寒","permalink":"https://qinyuanpei.github.io/tags/%E9%9F%A9%E5%AF%92/"},{"name":"青春","slug":"青春","permalink":"https://qinyuanpei.github.io/tags/%E9%9D%92%E6%98%A5/"}]},{"title":"函数式编程常用术语","date":"2017-02-02T19:21:12.000Z","path":"posts/2171683728/","text":"&emsp;&emsp;近年来函数式编程这种概念渐渐流行起来，尤其是在React/Vuejs这两个前端框架的推动下，函数式编程就像股新思潮一般瞬间席卷整个技术圈。虽然博主接触到的前端技术并不算深入，可这并不妨碍我们通过类似概念的延伸来理解这种概念。首先，函数式编程是一种编程范式，而我们所熟悉的常见编程范式则有命令式编程(Imperative Programmming)、函数式编程(Functional Programming)、逻辑式编程(Logic Programming)、声明式编程(Declarative Programming)和响应式编程(Reactive Programming)等。现代编程语言 在发展过程中实际上都在借鉴不同的编程范式，比如Lisp和Haskell 是最经典的函数式编程语言，而SmartTalk、C++和Java则是最经典的命令式编程语言。微软的C#语言最早主要借鉴Java语言，在其引入lambda和LINQ特性以后，使得C#开始具备实施函数式编程的基础，而最新的Java8同样开始强化lambda这一特性，为什么lambda会如此重要呢？这或许要从函数式编程的基本术语开始说起。 什么是函数式编程？&emsp;&emsp;我们提到函数式编程是一种编程范式，它的基本思想是将计算机运算当作是数学中的函数，同时避免了状态和变量的概念。一个直观的理解是，在函数式编程中面向数据，函数是第一等公民，而我们传统的命令式编程中面向过程，类是第一等公民。为什么我们反复提到lambda呢？因为函数式编程中最重要的基础是lambda演算(Lambda Calculus)，并且lambda演算的函数可以接受函数作为参数和返回值，这听起来和数学有关，的确函数式编程是面向数学的抽象，任何计算机运算在这里都被抽象为表达式求值，简而言之，函数式程序即为一个表达式。值得一提的是，函数式编程是图灵完备的，这再次说明数学和计算机技术是紧密联系在一起的。虽然在博主心目中认为，图灵这位天纵英才的英国数学家，是真正的计算机鼻祖，但历史从来都喜欢开玩笑的，因为现代计算机是以冯.诺依曼体系为基础的，而这一体系天生就是面向过程即命令式的，在这套体系下计算机的运算实则是硬件的一种抽象，命令式程序实际上是一组指令集。因此，函数式程序目前依然需要编译为该体系下的计算机指令来执行，这听起来略显遗憾，可这对我们来说并不重要，下面让我们来一窥函数式编程的真容： 12squares = map(lambda x: x * x, [0, 1, 2, 3, 4]) print squares 这是使用Python编写的函数式编程风格的代码，或许看到这样的代码，我们内心是完全崩溃的，可是它实现得其实是这样一个功能，即将集合{0, 1, 2, 3, 4}中的每个元素进行平方操作，然后返回一个新的集合。如果使用命令式编程，我们注定无法使用如此简单的代码实现这个功能。而这个功能在.NET中其实是一个Select的功能： 12int[] array = new int[]&#123;0, 1, 2, 3, 4&#125;;int[] result = array.Select(m =&gt; m * m).ToArray(); 这就是函数式编程的魅力，我们所做的事情都是由一个个函数来完成的，这个函数定义了输入和输出，而我们只需要将数据作为参数传递给函数，函数会返回我们期望的结果。好了，下面再看一个例子： 12sum = reduce(lambda a, x: a + x, [0, 1, 2, 3, 4])print sum 即使我们从来没有了解过函数式编程，从命名我们依然可以看出这是一个对集合中的元素求和的功能实现，这就是规范命名的重要性。幸运的是.NET中同样有类似的扩展方法，我喜欢Linq，我喜欢lambda： 12int[] array = new int[]&#123;0, 1, 2, 3, 4&#125;;int result = array.Sum(); 考虑到博主写不出更复杂的函数式编程的代码示例，这里不再列举更多的函数式编程风格的代码，可是我们从直观上来理解函数式编程，就会发现函数式编程同lambda密不可分，函数在这里扮演着重要的角色。好了，下面我们来了解下函数式编程中的常用术语。 函数式编程的常用术语&emsp;&emsp;函数式编程首先是一种编程范式，这意味着它和面向对象编程一样，都是一种编程的思想。而函数式编程最基本的两个特性就是不可变数据和表达式求值。基于两个基础特性，我们延伸出了各种函数式编程的相关概念，而这些概念就是函数式编程的常用术语。常用的函数式编程术语有高阶函数、柯里化/局部调用、惰性求值，递归等。在了解这些概念前，我们先来理解，什么是函数式编程的不可变性。不可变性，意味着在函数式编程中没有变量的概念，即操作不会改变原有的值而是修改新产生的值。举一个基本的例子，.NET中IEnumerable接口提供了大量的如Select、Where等扩展方法，而这些扩展方法同样会返回IEnumerable类型，并且这些扩展方法不会改变原来的集合，所有的修改都是作用在一个新的集合上，这就是函数式编程的不可变性。实现不可变性的前提是纯函数，即函数不会产生副作用。一个更为生动的例子是，如果我们尝试对一个由匿名类型组成的集合进行修改，会被提示该匿名类型的属性为只读属性，这意味着数据是不可改变的，如果我们要坚持对数据进行“修改”，唯一的方法就是调用一个函数。 高阶函数(Higer-Order-Function)&emsp;&emsp;高阶函数是指函数自身能够接受函数，并返回函数的一种函数。这个概念听起来好像非常复杂的样子，其实在我们使用Linq的时候，我们就是在使用高阶函数啦。这里介绍三个非常有名的高阶函数，即Map、Filter和Fold，这三个函数在Linq中分别对应于Select、Where和Sum。我们可以通过下面的例子来理解： Map函数需要一个元素集合和一个访问该元素集合中每一个元素的函数，该函数将生成一个新的元素集合，并返回这个新的元素集合。通过C#中的迭代器可以惰性实现Map函数：12345IEnumerable&lt;R&gt; Map&lt;T,R&gt;(Func&lt;T,R&gt; func, IEnumerable&lt;T&gt; list)&#123; foreach(T item in list) yield return func(item);&#125; Filter函数需要一个元素集合和一个筛选该元素结合的函数，该函数将从原始元素集合中筛选中符合条件的元素，然后组成一个新的元素集合，并返回这个新的元素集合。通过C#中的Predicate委托类型，我们可以写出下面的代码：12345678IEnumerable&lt;T&gt; Filter&lt;T&gt;(Predicate&lt;T&gt; predicate, IEnumerable&lt;T&gt; list)&#123; foreach(T item in list) &#123; if(predicate(item)) yield return item; &#125;&#125; Fold函数实际上代表了一系列函数，而最重要的两个例子是左折叠和右折叠，这里我们选择相对简单地左折叠来实现累加的功能，它需要一个元素集合，一个累加函数和一个初始值，我们一起来看下面的代码实现：1234567R Fold&lt;T,R&gt;(Func&lt;R,T,R&gt; func, IEnumerable&lt;T&gt; list, R startValue = default(R))&#123; R result = startValue; foreach(T item in list) result = func(result, item); return result;&#125; 相信现在大家应该理解什么是高阶函数了，这种听起来非常数学的名词，当我们尝试用代码来描述的时候会发现非常简单。相信大家都经历过学生时代，临近期末考试的时候死记硬背名词解释的情形，其实可以用简洁的东西描述清楚的概念，为什么需要用这种方式来理解呢？为什么我这里选择了C#中的委托来编写这些示例代码呢？自然是同样的道理啦，因为我们都知道，在C#中委托是一种类似函数指针的概念，因为当我们需要传入和返回一个函数的时候，选择委托这种特殊的类型可谓是恰如其分啦，这样并不会影响我们去理解高阶函数。 柯里化(Curring)/局部套用&emsp;&emsp;柯里化(Curring)得名于数学家Haskell Curry，你的确没有看错，这位伟大的数学家不仅创造了Haskell这门函数式编程语言，而且提出了局部套用(Currin)这种概念。所谓局部套用，就是指不管函数中有多少个参数，都可以函数视为函数类的成员，而这些函数只有一个形参，局部套用和部分应用息息相关，尤其是部分应用是保证函数模块化的两个重要技术之一(部分应用和组合(Composition)是保证函数模块化的两个重要技术)。众所周知，在C#中一个函数一旦完成定义，那么它的参数列表就是确定的，即相对静态。它不能像Python和Lua一样去动态改变参数列表，虽然我们可以通过缺省参数来减少参数的个数，可是在大多数情况下，我们都需要在调用函数前准备好所有参数，而局部套用所做的事情与这个理念截然相反，它的目标是用非完全的参数列表去调用函数。我们来一起看下面这个例子： 1Func&lt;int,int,int&gt; add = (x,y) =&gt; &#123;return x + y;&#125;; 这是一个由匿名方法定义的委托类型，显然我们需要在调用这个方法前准备好两个参数x和y，这意味着C#不允许我们在改变参数列表的情况下调用这个方法。而通过局部套用： 1234Func&lt;int,int,int&gt; curriedAdd =&gt; (x) =&gt;&#123; return (y) =&gt; &#123; return x + y;&#125;;&#125;; 实际上在这里两个参数x和y的顺序对最终结果没有任何影响，我们这样写仅仅是为了符合人类正常的认知习惯，而此时我们注意到我们在调用curriedAdd时会发生质的的变化： 1234//x和y同时被传入addadd(x,y)//x和y可以不同时被传入curriedAddcurriedAdd(x)(y); 而如果我们将这里的函数用Lambda表达式来表示，则会发现： 12Func&lt;int,int,int&gt; add = (x,y) =&gt; return x + y;Func&lt;int,Fucn&lt;int,int&gt;&gt; curriedAdd = x = &gt; y =&gt; x + y; 至此，对一般的局部套用，存在： 12Func&lt;...&gt; f = (part1, part2, part3, ...) =&gt; ... 可转换为：Func&lt;...&gt; cf = part1 =&gt; part2 =&gt; part3 ... =&gt; ... 则称后者为前者的局部套用形式。 惰性求值&emsp;&emsp;我们在前文中曾经提到过，在函数式编程中函数是第一等公民，而这里的函数更接近数学意义上的函数，即将函数视为一个可以对表达式求值的纯函数，所以我们这里自然而然地就提到了惰性求值。首先，博主这里想说说求值策略这个问题，求值策略通常有严格求值和非严格求值两种，而对C#语言来讲，它在大多数情况下使用严格求值策略，即参数在传递给函数前求值。与之相对应的，我们将参数在传递给函数前不进行求值或者延迟求值的这种情况，称为非严格求值策略。一个经典的例子是C#中的“短路”效应： 1bool isTrue = (10 &lt; 5) &amp;&amp; (MyCheck()) 因为在这里表达式的第一部分返回值为false，因此在实际调用中第二部分根本不会执行，因为无论第二部分返回true还是false，实际上对整个表达式的结果都不会产生影响。这是一个非常经典的非严格求值的例子，同样的，布尔运算中的”||”运算符，同样存在这个问题。所以，至此我们可以领会到惰性求值的优点，即使程序的执行效率更好，尤其是在避免高昂运算代价的时候，我们要牢记：懒惰是程序员的一种美德，使用更简洁的代码来满足需求，是一名游戏程序员的永恒追求。我们可以联想那些在代码片段中优先return的场景，这大概勉强可以用这种理论来解释吧！例如我们强大的Linq，原谅我如此执著于举Linq的例子，Linq的一个特点是当数据需要被使用的时候开始计算，即数据是延迟加载的，而在此之前我们所有对数据的操作，从某种意义上来讲，更像是定义了一系列函数，这好像和数据库中的事务非常相近啦，其实这就是在告诉我们，懒惰是一种美德啊，哈哈！ 函数式编程的利弊探讨&emsp;&emsp;好了，现在让我们从函数式编程的各种术语中解放出来，高屋建瓴般地从更高的层面上探讨下函数式编程的利弊。当你讨论一种东西的利弊时，一种习惯性的做法是找一种东西来和它作比较，如果Windows和Linux、SQL和NoSQ、面向对象和函数式…等等，我们常常关注一件事物的利弊，而非去寻找哪一个是最好。可惜自以为是的人类，常常以此来自我设限，划分各自的阵营，这当真是件无聊的事情，就像我一直不喜欢SQL和正则表达式，所以我就去了解数据库的设计、模式匹配相关内容，最终感觉颇有一番收获，我想这是我们真正的目的吧！好了，下面我们说说函数式编程有哪些优缺点？首先，函数式编程极大地改善了程序的模块化程度，高阶函数、递归和惰性求值让程序充分函数化，函数式让编程可以以一种声明式的风格来增强程序语义。当然，函数式编程的缺点是，我们这个现实世界本来就不是纯粹的，函数式编程强调的数据不可变性，意味着我们无法去模拟事物状态变化，因此我们不能为了追求无副作用、无锁而忽视现实，这个世界上总有些肮脏的问题，无法让我们用纯函数的思维去解决，这个时候我们不能说要让设计去适应这个世界，任何技术或者框架的诞生归根到底是为了解决问题，而函数式编程或者是面向对象编程，本质都是一种编程思想，我们最终是为了解决问题，就像这个世界有时候并不是面向对象的，我们用面向对象来描述这个世界，或许仅仅是我们自己的理解，这个世界到底是什么样子的，大概只有上帝会知道吧！ 本文小结&emsp;&emsp;本文主要对函数式编程及其常见术语进行了简要讨论，主要根据《C#函数式程序设计》一书整理并辅以博主的理解而成。首先，函数式编程中强调无状态、不可变性，认为函数是一等公民，并且在函数式编程中每一个函数都是一个纯函数，它是数学概念咋计算机领域的一种延伸，和冯.诺依曼计算机体系不同，函数式编程的核心思想是以lambda演算为基础的表达式求值，并且函数式编程强调无副作用。本文对函数式编程中的常见术语如高阶函数、局部套用/柯里化、惰性求值等结合C#语言进行了简单分析。或许对我们而言，函数式编程是一个新鲜事物，可正如我们第一次接触面向对象编程时一样，我们并不知道这样一种编程思想会持续到今天。我不认为函数式编程会彻底替代面向对象编程，就像Web开发无法彻底替换原生开发一样，函数式编程会作为面向对象的一种延伸和补充，所以本文对函数式编程的理解实际上是非常肤浅的，可这个世界本来就是在不断变化的，希望我们可以在恰当的场景下去权衡选择什么样的技术，对这个世界而言，我们永远都是探索者，或许永远都不存在完全能满足现实场景的编程范式吧！","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"编程","slug":"编程","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E7%A8%8B/"},{"name":"读书","slug":"读书","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"函数式编程","slug":"函数式编程","permalink":"https://qinyuanpei.github.io/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/"}]},{"title":"基于Mono和VSCode打造轻量级跨平台IDE","date":"2016-11-18T20:23:44.000Z","path":"posts/3568552646/","text":"&emsp;&emsp;最近Visual Studio推出Mac版本的消息迅速在技术圈里刷屏，当工程师们最喜欢的笔记本电脑Mac，邂逅地球上最强大的集成开发环境Visual Studio的时候，会碰撞出怎样精彩的火花呢？在微软新任CEO纳德拉的“移动为先、云为先”战略下，微软的转变渐渐开始让人欣喜，从.NET Core、VSCode、TypeScript再到近期的Visual Studio For Mac，这一系列动作让我们感觉到，微软的技术栈越来越多地向着开源和跨平台两个方向努力。我们曾经固执地认为，微软的技术栈注定永远无法摆脱Windows的束缚，而事实上这个世界每天都在发生着变化。或许这次Visual Studio推出Mac版这件事情，本质上是微软收购的Xamarin公司旗下产品Xamarin Studio的一次改头换面。可是这件事情说明，微软正在努力让.NET技术栈融入更多的应用场景。对我而言，我是没有钱去买一台Mac的，所以在这篇文章中，我们将在Linux下通过Mono和VSCode来打造一个轻量级的IDE。而据说Mono会和Xamarin一样，将来会成为.NET基金会的一部分。 &emsp;&emsp;好了，我们首先在Windows世界里进行彩排，在开始下面的内容以前，请保证你的计算机上安装了Mono和VSCode。假如你经常关注我的博客，你应该会知道Mono在这里的作用是什么？，简而言之，Mono为我们提供了编译器环境和运行时环境，在这个基础上VSCode这个天生带着Visual Studio基因的编辑器，则可以为我们提供基础的代码调试功能，这是我们这篇文章写作的关键因素。如果你还对Mono一无所知，下面的两篇文章可以帮助你快速了解： 使用Mono让.NET程序跨平台运行 使用Mono打造轻量级的.NET运行时 &emsp;&emsp;在我们了解了Mono以后，就可以考虑将Mono作为VSCode的运行时环境，这意味着我们可以在使用VSCode的同时直接编译代码。目前在VSCode中内建的运行时支持为Node/Node2，所以如果我们希望在VSCode中调试更多的语言，我们就必须要为VSCode安装相应的插件。因为事实上在VSCode中编译代码我们可以直接通过Task来完成编译，但当我们希望在VSCode中对代码进行调试的时候，我们就必须借助插件来完成调试任务，这或许从侧面印证了VSCode的产品定位就是一个文本编辑器。 &emsp;&emsp;而对于微软推出的这样一款产品，我们或许会疑惑，为什么这个编辑器提供的内建支持居然是Node，而不是我们所熟悉的.NET技术体系。这个原因非常容易理解，如果你听说过Github出品的编辑器Atom，或者是使用过Electron/Node-Webkit相关技术，那么你一定会深刻地理解，VSCode本质上和Atom一样，都是采用Web技术来构建跨平台应用，而Node天生就具备Web属性加成，所以我们就不难理解为什么VSCode内建的支持是Node而非.NET技术体系。同样地，为了实现跨平台的目标，在对C#语言的支持这个问题上，微软选择了OminiSharp这样一个跨平台的代码自动补全工具，而非我们在Visual Studio中所熟知的Intellisense技术。在.NETCore推出以后.NET跨平台不再是梦想，我们对技术的探索就不应该再局限在Windows平台上。 &emsp;&emsp;博主关注Mono始于Unity3D引擎，因为Mono真正实现了.NET技术的跨平台，而Unity3D引擎最为人所称道的当属其强悍的跨平台能力，在这一点上Mono功不可没。在此之前收费的Xamarin让人望而却步，所以Mono自然而然地就成为了我的选择。因为博主的计算机上安装了Mono，所以在一开始使用VSCode的时候，就先入为主地认为在不安装插件的情况下，应该就可以直接在VSCode中编译和调试代码了。首先我们在VSCode中创建一个C#代码文件，既然在程序世界里万事万物都从Hello World说起，那么我们这里依然遵循这个原则。在创建该代码文件以后，我们将其所在的目录在VSCode中打开，这是因为： 在VSCode中仅支持以目录方式打开的文件的编译和调试 所以这个时候我们在VSCode中的界面应该是如图所示： 在VSCode中编写代码 好了，下面我们直接按下Ctrl+Shift+B来编译代码，此时VSCode将提示我们“配置任务运行程序”，这里需要说明的是，在VSCode中你可以感受到微软对命令行和配置文件的偏执，这让适应了Visual Studio这样功能强大的我们相当不习惯，按照VSCode的提示或者是通过Ctrl+Shift+P打开命令面板，VSCode将在当前工作目录下为我们创建.vscode目录和tasks.json文件，在VSCode中任何和项目相关的配置信息都会存储在这里啦。此时我们配置tasks.json: 12345678910111213&#123; // See https://go.microsoft.com/fwlink/?LinkId=733558 // for the documentation about the tasks.json format \"version\": \"0.1.0\", // 该命令需要在系统变量内定义 \"command\": \"mcs\", // 或者使用完整的可执行路径 // \"command: \"C:\\Program Files\\Mono\\bin\\mcs.exe\" \"isShellCommand\": true, \"args\": [\"*.cs\"], \"showOutput\": \"always\"&#125; 在这里需要说明的是一个tasks.json中可以通过tasks属性来配置多个任务运行程序，例如我们的项目中有Python和C#两种代码需要编译，那么我们就可以配置两个task，VSCode将在运行程序的时候让用户由哪一个task来编译代码。如果你看过我在前面介绍过的两篇文章，就应该知道这里的mcs.exe其实是Mono提供的C#编译器，它负责将我们的C#代码编译为IL文件，然后IL文件再交由CLR来转换为本机代码。Mono提供的C#编译器可以将C#代码编译为.exe或者是.dll，可是在VSCode中好像默认都是编译为.exe，所以如果有知道如何在这里配置编译输出项的朋友，希望可以告诉我怎么去实现。 &emsp;&emsp;现在，我们应该会得到一个MainClass.exe的文件，最初博主尝试直接去配置launch.json，发现直接填写type为mono在VSCode中是无法识别的，最后决定去安装mono-debug的插件，安装插件在VSCode中是非常简单的，按下Ctrl+Shift+X打开插件界面，可以在这里查看最流行的插件列表、官方推荐的插件列表等等，我们直接搜索mono-debug然后安装插件即可。可是我不曾想到的是，我猜中故事的开头，却没有猜中故事的结尾，这个插件是不支持Window平台的，这个插件是不支持Windows平台的，这个插件是不支持Windows平台的。 &emsp;&emsp;好吧，现在看起来Linux是我唯一可以去尝试的平台了，博主这里选择的是颜值最高的Elementary OS，这是一个衍生自Ubuntu的Linux发行版。在VSCode正式版发布以后，在Linux下用VSCode来编程是我一直在尝试的事情，请不要说Linux系统使用起来会非常困难，博主在安装这些软件的过程中可以说是相当顺利。建议大家在Linux平台下安装C#、Mono-Debug和Python这3个插件，需要说明的是C#和Mono-Debug在第一次使用的时候，需要在网络环境下下载相关依赖。下面是博主目前的插件安装情况： VSCode中插件安装界面 &emsp;&emsp;我们现在按F5进行调试，和编译时一样，如果用户没有为当前项目配置“任务调试程序”，VSCode会提示我们去创建一个配置文件launch.json，我们这里选择mono，该选项在安装Mono-Debug插件以前是没有的，该配置文件如下，我们注意到这里需要修改program属性为MainClass.exe: 123456789101112131415161718192021222324&#123; \"version\": \"0.2.0\", \"configurations\": [ &#123; \"name\": \"Launch\", \"type\": \"mono\", \"request\": \"launch\", \"program\": \"$&#123;workspaceRoot&#125;/MainClass.exe\", \"args\": [], \"cwd\": \"$&#123;workspaceRoot&#125;\", \"preLaunchTask\": \"\", \"runtimeExecutable\": null, \"env\": &#123;&#125;, \"externalConsole\": false &#125;, &#123; \"name\": \"Attach\", \"type\": \"mono\", \"request\": \"attach\", \"address\": \"localhost\", \"port\": 5085 &#125; ]&#125; &emsp;&emsp;这里有一个小插曲，在博主运行这个简单的程序的时候，提示Mono的版本和Mono-Debug插件的版本要求不一致，因为Mono-Debug插件使用的是最新版本的Mono。所以，果断卸载目前的mono，然后安装最新的mono，安装方法为： 1sudo apt-get install mono-complete 这样我们就可以看到眼前的成果啦，我们成功地在VSCode运行了一个C#程序： VSCode中调试代码 &emsp;&emsp;虽然我很想在这篇博客中搞点干货出来，但是当我折腾数天以后，我大概就能够写出这样一篇相当零碎的文章，到目前为止我还是没有搞明白，为什么我在调试地过程中，VSCode不会在我设置了断点地地方停下来，希望知道这个原因的朋友可以告诉我啊。这个过程最有意义的地方在于让我进一步熟悉了Linux，在不一样的地方，会有不一样的风景，这个世界很大，不要给自己设限。后续我会去研究VSCode中的调试技巧以及.NETCore相关内容，能看到C#跨平台运行是件幸福的事情，而跨平台开发是我一直在探索的方向之一。夜晚已然来临了，而这篇文章就是这样了，谢谢大家的关注，晚安！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Mono","slug":"Mono","permalink":"https://qinyuanpei.github.io/tags/Mono/"},{"name":"跨平台","slug":"跨平台","permalink":"https://qinyuanpei.github.io/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/"},{"name":"VSCode","slug":"VSCode","permalink":"https://qinyuanpei.github.io/tags/VSCode/"}]},{"title":"在Kindle上阅读Markdown文档","date":"2016-11-13T13:58:35.000Z","path":"posts/1152813120/","text":"&emsp;&emsp;其实我一直希望Kindle能够成为我知识管理的一部分，我们此刻所处的这个时代实则是一个信息爆炸的时代。我们每天都不得不去面对各种各样的信息，可这些信息中有多少是我们真正需要的呢？在一个信息碎片化的时代，有人说我们要懂得如何去利用碎片化的时间，有人说我们要懂得如何去高效查找需要的信息，微信和微博这类社交产品加速了信息的碎片化，或许当我们发现自己无法再集中精力去做一件事情的时候，我们就应该停下来反思如何去做好个人知识管理，我一直希望Kindle可以成为我知识管理的一部分，因为Kindle的阅读体验完全超越主流的电子设备，而且它可以让我们更加专注地去关注内容本身，Kindle的同步机制为了提供了良好的知识管理契机，所以这篇文章我主要想分享我在以Kindle作为知识管理载体这件事情上的想法，希望对大家有所启发。 记录，成为更好的自己&emsp;&emsp;相信大家都有在阅读中收集和整理内容的习惯，尤其是当我们需要在写作过程中参考大量资料的时候。对博主而言，写博客其实是我学习和理解技术的一种方式，我始终相信：写作是一种自我鞭策式的学习方法。当我们通过描述来向别人传达一种概念时，如果连自己都没有想清楚其中的关节，那么我们必然无法想别人清晰地传达这种概念。或许我们会畏惧犯错，畏惧向别人传达出错误的概念，可是如果你永远不愿意迈出那一步，那么我们就永远无法知道自己的弱点在什么地方。所以，当我们尝试对自我进行知识管理的时候，我们就需要一种良好的方式来管理这些零散的知识，在这里Markdown和Kindle会成为我们的强力工具，来帮助我们收集和整理各种各样的信息，正如我在写这篇博客的时候，我需要Markdown文档撰写和Kindle电子书格式的相关内容，我可以快速地从我的为知笔记中找到参考内容。 &emsp;&emsp;我最早一直使用网易的“有道云笔记”来做笔记，选择“有道云笔记”更多的原因是我使用着“网易云音乐”、“网易邮箱”和“网易云阅读”等众多的网易旗下产品。虽然国内不乏有OneNote、为知笔记、有道云笔记、EverNote、马克飞象等众多笔记类产品，可是选择一款适合自己的笔记产品非常困难的。让我逐渐想要放弃有道云笔记的一个重要原因是，有道云笔记在推出“云协作”功能后，整体上显得非常臃肿，即使在后来推出了我喜欢的Markdown功能，我还是决定渐渐地从这个产品中过渡出来，或许是网易公司这样的大厂更注重产品线的全面化，“有道云笔记”在一段时间里产品定位一直相对尴尬，而且“有道云笔记”不支持导出笔记到同类产品这个举动，让我觉得这不符合网易相对国内厂商一贯良心的风格，所以我不得不去寻找一款它的替代产品。 &emsp;&emsp;而最终我选择了为知笔记，它整体天蓝色的风格让我非常喜欢，虽然没有“有道云笔记”功能强大，而且内置付费模板，但对我来说，因为大部分记录都是在手机上，所以对我来讲，其实免费的功能基本足够我使用了，当然选择为知笔记的一个重要理由是它可以支持Markdown，而且它的笔记存储格式为.zip和.html，这意味着我们可以将笔记从云端同步到本地以后，我们可以将其导出到其它笔记产品中，这是我非常喜欢的特性。对为知笔记来说，它提供了类似Kindle通过邮箱传输电子书的功能，因此我们可以通过这个机制来将喜欢的资料推送到为知笔记中，目前主流笔记类产品在微信公众号中都提供了发送文章到笔记的功能，显然亚马逊官方公众号提供的Send To Kindle可以为我们提供类似的体验。即使微信公众号的出现让信息变成了新的信息孤岛，可我们通过这种方式来让我们感兴趣的内容被收集到笔记中，这是否在说明笔记类应用和Kindle阅读器冥冥之中就存在某种联系呢？ 使用Markdown来写作&emsp;&emsp;可能你想象不到，你眼前看到的这篇博客，正是我通过Markdown这种“语言”来完成撰写的。而事实上，我使用Markdown超过三年了，对我而言Markdown是一种能让我专心写作的一种利器，不要告诉我Word是这个世界上标准的文档编写工具，如果我告诉你，使用Markdown你仅仅需要的是一个记事本，你是否还会对它的强大产生怀疑呢？事实上Word作为文档编制标准，对我们使用Markdown并没有太多影响，因为写作本来就应该是一件让自己开心的事情，如果我们不喜欢它，为什么不尝试更好的方式呢？一种让你可以关注核心内容的撰写，而非字体、段落或者是排版这种和样式息息相关的事情，我并不是说这些东西不重要，仅仅是因为从此时此刻开始，它开始变得不再重要起来。 &emsp;&emsp;或许对普通人而言，Markdown是一种陌生的语言，因为Markdown天生就有着极客的基因，我们最早接触Markdown或许是从Github上的某种一个开源项目开始，这种与生俱来就在全球最大的同性交友网站上活跃的语言，或许会被人们下意识地打上“程序员”的标签，这个世界从来不乏因为一知半解而肆意猜度的人，其实Markdown在写作领域是一种非常时尚的语言，我经常被别人问一个问题，Markdown到底能为我们提升多少效率呢？这让我们从Markdown的语法说起。虽然我们称Markdown为一种语言，事实上Markdown是由John Gruber设计的一种标记语法，它的基本元素有： 标题&emsp;&emsp;Markdown中定义标题采用#来完成，按照标题的级别，我们在需要提升为标题级别的内容前面，添加指定数目的#就可以了。例如我们可以定义下面的标题，以此类推总共有6级标题： 123# 一级标题## 二级标题### 三级标题 列表&emsp;&emsp;熟悉HTML的朋友都知道，在HTML中存在有序列表和无序列表两种，而在Markdown语法中无序列表采用-或者*来完成，有序列表采用1.、2.等来完成。我们来看一个简单的示例： 123456789//这是一个无序列表* 无序列表元素1* 无序列表元素2* 无序列表元素3//这是一个有序列表1. 有序列表元素12. 有序列表元素23. 有序列表元素3 引用&emsp;&emsp;我们在写作时经常需要引用相关观点来作为辅证，我们学习一种知识通常是一种由内而外的方式，我们从这个世界吸收知识和思想，通过内化来形成我们独立的世界观，世界原本就不是非此即彼的，就像自然界中的熵增定律一般，永远处在一种动态的平衡中。对Markdown来说，它采用&lt;来完成引用的定义。例如，愿洞察之父指引我等： 1&gt; 万物皆虚，万事皆允。当其它人盲目追寻真相的时候，记住万物皆虚；当其它人被道德和法律约束的时候，记住万事皆允。 图片与链接&emsp;&emsp;互联网的重要精神是分享，我们说没有人是一座孤岛，对互联网来讲，没有链接就意味着没有一切。在Markdown语法中图片和链接的定义方式是非常接近的： 12[Google](http://www.google.com)![这是一张图片](http://mouapp.com/Mou_128.png) 加粗与倾斜&emsp;&emsp;我们通常会在文档中将重要信息加粗或者倾斜以表示其重要性，这种习惯在工作以后写邮件的时候得到了进一步的强化，虽然我们说Markdown更关注内容本身，即认为内容是写作的核心，可是这并不代表Markdown就此黯淡无光，相反地通过定义CSS样式，我们可以让Markdown文档更加美观和优雅。在Markdwn语法中，我们使用两个来表示加粗，一个表示倾斜。比如下面这个例子： 12**这是一个加粗的文本***这是一个倾斜的文本** 代码高亮&emsp;&emsp;没有什么比看到一段支持代码高亮的代码片段更让人开心的了，所以你至此就会明白，为什么Markdown会如此深受工程师们的喜爱，尤其当我们需要撰写一篇技术文章并且需要在文章中展示代码的时候，如你所见，这个博客中所有的代码片段都支持代码高亮，这样可以给阅读者更好的阅读的体验，我想吐槽的一件事情是公司内部的Jira居然不支持Markdown语法，虽然公司的第一架构经常会在这里Share技术文章，可是糟糕的代码片段完全让人没有继续看下去的冲动。在Markdown中定义一个代码块的语法使用三个`符号： 123456789using System;class MainClass&#123; public static void Main(string[] args) &#123; Console.WriteLine(\"Nothing is true, Everything is permitted.\"); &#125;&#125; 表格&emsp;&emsp;表格在Markdown中使用频率相对较低，因为如果没有编辑表格内容的需求，通常采用图片来展示表格内容会是一个更好的选择，而表格在Markdown中的表示同样是最复杂的，当然更复杂的是Markdown中的LeTex和FlowChar，这些均属于Markdown的扩展语法，因为违背Markdown语法简洁的原则，所以我们在这里简单说下Markdown中的表格： 12345| Column1| Column2| Column3||:-------|:------:|-------:|| Left | Center | Right || Left | Center | Right || Left | Center | Right | 这里我们定义了一个四行三列的表格，我们这里使用:符号来表示表格中的对齐方式，显然这三列分别表示左对齐、居中对齐和右对齐，我们说表格这种元素复杂，主要是因为当表格中内容特别复杂的时候，这个表格定义就会降低可读性，而且它无法处理在单元格内换行的情况，所以它主要适用于表格内数据相对简单的情况下。 &emsp;&emsp;好了，这些就是基本的Markdown语法所定义的元素啦，我觉得这是一种非常优雅的标记语言，如果你觉得纯文本的内容太单调，如果你觉得Word使用起来太复杂，那么Markdown就在这两者间找到一个平衡点，我没有劝大家放弃Word然后转而投身Markdown写作，可是作为一个经常码字的博客作者，我可以负责任的说，Markdown是一种可以让你专注写作的工具，而且作为一名工程师，你会发现StackOverflow、Segmentfault、Github等知名技术社区，无一例外地都在支持Markdown语法，所以Markdown其实是开源社区里除了英语以外的第二大通用语言，所以如果你喜欢写作或者是喜欢开源，Markdown都会是你不错的选择，而它的语法相信你此时已然学会了。 从Markdown到Kindle&emsp;&emsp;有人说，Markdown是一个人的狂欢，因为即使你再喜欢Markdown语法，如果你身边的同事都在使用Word等不同的工具，那么你该如何和他们写作呢？这听起来好像是一个严重的缺陷，所以Markdown注定是一种小众的写作语言。Markdown可以转化为HTML或者PDF，相比HTMLPDF相对会好些，因为HTML需要依赖CSS样式文件，没有样式文件的HTML是无论如何都不能彰显Markdown的优雅的。那么，难道我们就要坐以待毙接受这种妥协，Markdown注定要被人们抛弃吗？不，让我们勇敢地说不，下面我们介绍常见的Markdown导出/转换工具： 文档转换神器Pandoc&emsp;&emsp;如果说Markdown是这个世界上最为简洁、优雅的书写语言，那么Pandoc就是标记语言转换领域的瑞士军刀。我们知道Markdown是一种轻量级的标记语言，它可以允许写作者使用纯文本标记来来编写文档。通常我们会在Markdown编辑器中完成Markdown文档的编辑，然后将其发布到支持Markdown语法的站点上。以博主为例，博主会在Sublime中安装了Markdown插件，通常我会在Sublime中编写好文章，然后利用Hexo这个静态博客生成器生成静态HTML页面，利用Github Pages提供的静态网页托管服务，我将这些博客发布到了互联网上，大家此刻所看到的这篇文章就是通过Markdown语法撰写的。可是一旦Markdown语法出现在一个不被支持的场合，Markdown的简洁、优雅都将大打折扣，这个时候就该我们的Pandoc登场啦！ &emsp;&emsp;Pandoc是一个采用Haskell语法编写的命令行工具，或许你对Haskell这样的函数式编程语言闻名已久，但是我相信Panndoc对我们每一个人来说都是一个新颖的事物。Pandoc采用GNU GPL授权协议进行发布，属于Linux世界的自由软件。庆幸的是，Pandoc支持主流的Windows、Mac和Linux三大平台，这里我们以Windows平台为例介绍Pandoc这个工具。Pandoc支持HTML、.docx、Markdown、LaTex、.TXT、.epub等常见格式的转换，以Markdown为例： Markdown转HTML 1pandoc README.md -o README.html Markdown转Word 1pandoc README.md -o README.docx Markdown转Pdf(需要安装LaTex) 1pandoc README.md --latex-engine=xelatex -o README.pdf &emsp;&emsp;好了，现在通过Pandoc我们可以将Markdown转换为可读性更为良好的文档，而我们知道Kindle阅读器是可以支持.pdf格式的文档的，虽然这种格式在Kindle并不能做到尽如人意，可是这对于我们而言，是将Markdown和Kindle紧密联系在一起的重要一步，这意味着我们只要Markdown文档转换为Kindle支持的文档格式，就可以实现Markdown+Kindle的个人知识管理方案。 支持导出HTML/PDF的Cmd Markdown编辑器&emsp;&emsp;下面推荐的是由作业部落出品的Cmd Markdown编辑器，这款自称为国内国内最强大的Markdown编辑器，实现了全平台覆盖，可以在线编辑同步预览，同时支持自动保存文档和云同步，支持一键发布文章到社区，是一个集文档编辑、预览、同步和发布等功能于一身的综合型Markdown编辑器，支持一键切换黑、白两种主题，支持直接导出HTML/PDF，整体上是一个非常出色的Markdown编辑器。我不太喜欢这个编辑器的一个重要原因是，我喜欢在离线环境下写文章，然后将其发布在我的个人博客上面，而这款编辑器和社区耦合过紧，虽然提供了离线版本的Markdown编辑器，但是对我而言功能上略显臃肿，我在这里推荐这个Markdown编辑器的原因是，它提供了HTML/PDF的导出功能，当我们在线编辑Markdown文档时即可通过浏览器导出HTML/PDF，如果你不需要经常导出Markdown为其它的文档格式，我会推荐你使用Sublime、VSCode、马克飞象、为知笔记、小书匠等编辑器，虽然Markdown语法对使用者的要求并不高，但我相信有一个体验良好的Markdown编辑器，会让我们的写作过程更为开心，从而达到事半功倍的效果。我们这篇文章的主题是希望将Markdown和Kindle结合起来形成一套个人知识管理的方案，所以在这里的核心关注点就变成了如何快速、高效的导出Markdown为其它文档格式，而在这一点上，相信Cmd Markdown不会让你我感到失望。 支持导出PDF/Mobi/Epub格式的GitBook&emsp;&emsp;好了，下面我们介绍一个使用Github/Git和Markdown来构建电子书的网站GitBook，请不要误会，这个网站和全球最大的同性交友网站Github没有任何直接的关系，两者的关系可以理解为，GitBook是一个基于Github/Git的静态页面生成器，其本身是一个由NodeJS编写而成的命令行工具，而通过这个工具和Markdown语法，我们就可以创建出足以媲美专业电子书籍的电子书，和Hexo类似，我们可以将这些生成的静态页面部署到Github Pages来供其它人浏览和阅读，除此以外GitBook本身就是一个相当优秀的内容发布平台，截止到今天GitBook上已经有18036本电子书。如果说在此以前，我们讨论的话题，即如何将Markdown转换为Kindle支持的电子书格式，是一个和Kindle电子书没有多少交集的话题，那么此时此刻我们已然和电子书密切地发生着关系，并且我们可以编写一本属于自己的电子书然后将其存放在Kindle上来阅读，这是一件非常酷的的事情，不是吗？如同王力宏在《开讲啦》节目中提到他幼时曾憧憬在广播里听到自己的歌一样，相信每一个喜欢写作的人，都渴望有朝一日看到自己的作品被发布出来，而GitBook就给了你这样一个梦想成真的机会。GitBook提供了epub、moni和pdf等非常Kindle的文档格式导出功能，因此我们可以在编写完Markdown文档后直接导出为Kindle支持的文档格式，这是多么美好的一件事情呀！除此以外，我们还可以使用Calibre这个Kindle电子书管理软件来完成Markdown文件的支持，但这个世界上没有绝对完美的事情，经过博主尝试后发现，使用Calibre转换的电子书在Kindle上阅读体验并没有想象中出色，对此感兴趣的朋友可以自行尝试，这些都是后话啦！ 本文小结&emsp;&emsp;个人知识管理其实是一个非常答案开放的问题，常言道“世事洞察皆学问，人情练达即文章”，当你渐渐地建立个人知识管理的意识，开始经常性地去梳理和完善自我的知识体系，这个时候到底选择什么样的方式来管理，其实是并不重要的，就像我们管理项目可以使用Github，同样可以使用Jira，这并不意味着这其中哪一种就是最好的，只有适合自己的才是最好的，就像我们使用Jira来管理项目并不意味着我们就在践行敏捷开发，我更愿意相信Wesley的观点，当你真正领会一件事情的思想和本质的时候，其实采用什么样的形式反而是次要的，我们从小到大常听到的一句话是，”如果连形式化的东西都不愿意去实践，又有什么资格来妄谈超脱形式化呢？”，我们暂且不管这句话对不对，我们必须认同的一点是，从Git到Github到Markdown到GitBook再到Kindle，一个明显的趋势是，我们这个时代，信息会越来越趋于碎片化，而与此同时，开源让我们每一个人离信息越来越近，当每一个人都成为信息的提供者，我们这个时代是一个百家争鸣、集思广益的时代，所以不管你愿不愿意，不管你有没有意识到这一点，学会去高效地检索信息、学会高效地管理信息、学会高效地利用信息，这是这个时代对我们个人知识管理能力的一种要求。好了，这篇文章就是这样啦，再次谢谢大家的关注！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Kindle","slug":"Kindle","permalink":"https://qinyuanpei.github.io/tags/Kindle/"},{"name":"Markdown","slug":"Markdown","permalink":"https://qinyuanpei.github.io/tags/Markdown/"},{"name":"阅读","slug":"阅读","permalink":"https://qinyuanpei.github.io/tags/%E9%98%85%E8%AF%BB/"}]},{"title":"生命的朝圣者","date":"2016-11-05T21:44:52.000Z","path":"posts/3657008967/","text":"&emsp;&emsp;最初开始读这本书的时候，并没有想到这本书会讲这样一个故事，甚至它不像一本畅销书一样让人充满期待，可是当你逐渐理清整个故事的来龙去脉以后，或许你会喜欢这个故事甚至被这个这个故事所震撼。我从未对宗教意义上的朝圣进行过深入了解，我所知道的朝圣，比如每年伊斯兰教历的第十二月，都会有数以百万计的伊斯兰教徒前往麦加参与朝觐仪式，而国内每年都会有从各地前往布达拉宫下的大昭寺朝佛的佛教信徒，而对藏传佛教信众来说“叩长头”是最为至诚的礼佛方式之一。所以朝圣是一项具有重大的道德或者灵性意义的旅程或者探寻，它关乎对信仰的思考同时注重身体力行，因为朝圣者始终相信前往一个重要的地方，能够从中获得灵性或者是得到治愈。 &emsp;&emsp;本书的主人公哈罗德.弗莱，一个六十岁的老头儿，在酿酒厂工作了四十年后默默无闻地退休。在他平静如水的生活中，不曾经历过升迁的起起落落，他不曾得罪过别人到处树敌，更没有可以亲近到交心的朋友。他和心存隔阂的妻子住在乡下，生活平静却彼此感情疏离，日复一日，年复一年。直到有一天，一封来自二十年未见的老友奎妮地信，让哈罗德原本平静地生活开始发生变化。在信中奎妮告诉他自己患了癌症，哈罗德感到莫名的震惊和悲痛，此时他做了一个疯狂的决定：从英国最西南一路到最东北，徒步跨越整个英格兰去看望她。而让他产生这个想法的原因是他想当然地认为，只要自己去看奎妮她就能够活下来。这听起来确实是一个疯狂的想法，可是谁能够真的预料这个世界下一刻会发生什么呢？ &emsp;&emsp;当哈罗德决定要开始做这件事情的时候，我们或许不会想到，这场以生命的名义发起的朝圣，其实是哈罗德内心深处的一种自我救赎。哈罗德是一个平凡如你我的普通人，甚至从他波澜不兴的人生轨迹中，我们完全找不出他的生命里有过哪些闪光点。当我们以今天这样一个世俗的眼光来审视哈罗德的时候，或许沉默寡言的哈罗德完全就是一个失败者，可当他徒步走完627英里的这段旅程以后，我们或许会明白，我们每一个人都是不完美的，而哈罗德所做的，无非是希望通过一个原始而质朴的方式，找回埋藏在内心多年的善良和温情，他曾经不是一个合格的丈夫、更不是一个合格的父亲，可是在经历过这段旅程以后，他终于找回了一个愈加真实的自己，这是一场关于生命地修行。 &emsp;&emsp;有时候我们完全无法认清自我，因为随着年龄的增长，我们常常会因为这个冰冷的世界而变得麻木，我们开始学会沉默、学会妥协，那份与生俱来的骄傲终于被岁月磨去棱角。我们开始欺骗自己，认为这就是所谓的成熟。我特别喜欢这句话，“知世故而不世故，方为最善良的成熟”。当我们回首哈罗德的生平的时候，我们会意识到，这是一个一生都被挫败感塞满的男人，从小就害怕成为大家关注的焦点;一辈子都弯着腰生活，习惯像影子一样悄无声息，甚至于在他退休的时候，公司都没有为他举行过欢送仪式;他害怕被抛弃，结果因为儿子的死和妻子产生隔阂;他太害怕失去眼前，所以在儿子溺水时犹豫不决选择停下来解鞋带;他太害怕错过美好，所以在新婚之夜躲进厕所而不敢直视美丽的妻子.人们常常无法接纳不完美的自己，或许是因为我们心怀执念，或许是因为我们习惯自卑。可是不管怎么样，生活的意义就是去发现自我，更好地接纳这个世界。 &emsp;&emsp;在这段旅行中，哈罗德遇到了加油站女孩、客店旅人、玛蒂娜等等不同的人，对哈罗德来说，这些人是他旅途中遇到的路人甲，可正是这些路人甲教会了哈罗德很多东西，让他学会了聆听别人的故事，学会了坦陈内心分享自己的故事。我们的人生是一个过程，它的起点和终点都是上天安排好的，我们要做的就是去让这个过程变得丰富起来。所以，试着去接受些你不了解的东西、去争取和相信自己可以改变某些事情。与其踟蹰不前犹豫不决，不如去接受这些来自未来的恐惧，当我们心中坚信自己一定可以做到的时候，其实我们离目标已然接近了一步。我们都还年轻，所以为什么不趁着现在，去做些真正疯狂的事情，如果当我们垂垂老矣的时候，发现生命是如此的苍白，大概我们会更加因为年轻时的碌碌无为而悔恨终生吧。人们都是憧憬着未来，期待着无限美好可能性。当我们明白爱是一种发自本性的情感，我们便真正具备了爱一个人的能力。 &emsp;&emsp;我时常会因为控制不住情绪而伤害到别人，虽然我知道我的本意并不是为了去伤害别人，可是当对别人的伤害已然造成，它就会像钉满篱笆的钉子即使钉子被拔出来，可是永远无法再让篱笆变回它原来的样子。所以，在读这本书的过程中，我有时候会同情哈罗德的妻子莫琳，如果你面对的是一个终日木纳寡言的丈夫，甚至他从来都学不会浪漫或者是哄你开心，你会怎么想呢？最初莫琳对丈夫的困惑不解、担忧愤怒，随着故事的推进逐渐演变为探寻改变、尝试了解，甚至到故事的最后两个人终于重新走到一起，我最喜欢的情节是两个人尽释前嫌，手牵着手走向海边，一边走一边回忆第一次两个人在舞会上认识的情景，这个旅程是一个人的远行，可是它却是两个人的灵魂回归，当哈罗德逐渐接受自己懦弱的一面，开始学会承担责任；当莫琳开始反思过去的种种经历，回想起丈夫曾经温情的一面，我想说，世间所有的相遇都是久别重逢，有什么比相逢一笑泯恩仇更开心的事情呢？不愿意放下过去是执念，不愿意重新开始是执念，我们本来就应该温暖善良的样子，即使生活让我们暂时穷困潦倒、失意落寞，那又怎么样呢？ &emsp;&emsp;一个让我更加感兴趣的地方是，当哈罗德因为独自远行这件事情而声名远播的时候，在那一瞬间形形色色的朝圣者都表示要加入这个旅程，可是很快我们就发现，这些朝圣者或多或少的都各怀心机，有的人是为了追求名利而加入队伍，有的人是为了出一本传奇书籍而加入队伍，有的人是为了挽救一段失败的婚姻而加入队伍，有的人是为了写一篇成为头条的新闻报道而加入队伍……这就像我们这个世界，当所有人都开始尝试按照自己的理解来揣度哈罗德的用意的时候，朝圣这件事情本身地意义就会被无限的忽略，没有一个人尝试去理解哈罗德的本意，当所有人都对此趋之若鹜的时候，或许并不代表这件事情本身为人们所理解所推崇，人们喜欢的仅仅是这种被关注的感觉而已，所以请放下那颗浮躁的心，努力去聆听自己内心的声音，我们生来并不是因为我们需要这样一场添油加醋的作秀，就像我始终相信爱情是两个人彼此吸引自然而然地走到一起，我不擅长刻意的事情，或许是因为我天生就喜欢本色出演。 &emsp;&emsp;哈罗德最初开始旅程的时候，基本上是一无所有的，他腿脚不便同时患有老年痴呆，正是这样的状态让妻子莫琳对他的所作所在困惑而愤怒，可是随着旅途的深入，那些在旅途中遇到的路人们，常常会馈赠给哈罗德如地图、指南针、药物等等这些东西，所以对哈罗德而言，这个过程是一个装备逐渐增加的过程，可是当他离目标越来越近的时候，他不得不将这些东西转赠给其他人或者是不慎在旅途中丢失，我印象比较深的一点是，他在旅途中收留了一条流浪狗，在相处的过程中逐渐培养出了感情，此时的哈罗德想起自己的儿子曾经想要养一条小狗，可是因为他的固执和懦弱，这个愿望最终成为永远的遗憾，正当他为此而费心伤神时，这条流浪狗忽然不知所踪，等哈罗德找到它时，发现它跟上一个年轻女孩儿上了一辆公交车，或许这告诉我们，我们的人生其实就是一个由简至繁再由繁至简的过程，我们曾经年少轻狂、我们曾经迷失方向，可当我们洗净铅华、丢掉一切附庸的时候，我们或许会不由得感谢，那些生命里教会我们某些东西的人。从始至终我们面对的这个世界的悲欢离合其实都是我们自己，可能有些人会在特定的时候出现然后陪伴我们一段时间，可我们最终会发现，有些路只能我们一个人来走。 &emsp;&emsp;我们总要尝试去做一件想做的事情，我们总要学会去放下过去重新开始，这是一个人的涅磐，这是哈罗德的朝圣。“也许当你走出车门真真切切用双腿走路的时候，绵延不绝的土地并不是你能看到的唯一的事物”。我忘记这句话是故事中的哪个人物曾经说过的话啦，我对小说一直没有完全能股投入阅读的感觉，我想人的大脑里有太多的东西我们不明白，但是你想想，如果有信念，你就一定能把事情做成。你是否还记得最初开始这个旅程时说过的话： 我现在马上出发。只要我一天还在走，她一天就要活着。请告诉她这次我不会让她失望。 Payne 于 2016/11/12","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://qinyuanpei.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"读书","slug":"读书","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"朝圣","slug":"朝圣","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%9D%E5%9C%A3/"}]},{"title":"基于C#中的Trace实现一个简单的日志系统","date":"2016-10-25T20:16:13.000Z","path":"posts/1254783039/","text":"&emsp;&emsp;最近在做的项目进入中期阶段，因为在基本框架结构确定以后，现阶段工作重心开始转变为具体业务逻辑的实现，在这个过程中我认为主要有两点，即保证逻辑代码的正确性和容错性、确定需求文档中隐性需求和逻辑缺陷。为什么我说的这两点都和用户需求这个层面息息相关呢？或许这和我这段时间的感受有些关系吧，我觉得当我们在面对用户提出的需求的时候，一个非常让我们不爽的一个地方是，我们总是需要花费大量的时间来和用户确定某些细节，而这些细节无论在BRD或者PRD中都无从体现。固然从用户层面上来讲，我们无法要求用户提供，详尽到每一个细节的需求文档。可我觉得这是一个修养的问题，我们习惯于宽以律己、严以待人，可是如果我们连自己都说服不了，我们该如何尝试去说服别人呢？我不认为我们就应该被用户限制自由，我们共同的目的都是想要好做一件事情，所以我们的关系应该是平等的伙伴的关系，这种上下级的、命令式的主仆关系让我感觉受到了侮辱。 关于最近的碎碎念&emsp;&emsp;其实对我而言，我更希望在工作中能找到一种释放天性的氛围，因为我觉得我们这个世界每天都有新的技术诞生。可是当我发现，我们的用户依然在使用着20多年前的技术的时候，我常常感觉到一种难以言表的紧迫感，或许对银行这类用户而言，它对安全和可靠的需要远远超过对新技术和新工具的需要，可是当我看到身边的同龄人甚至是人到中年的时候，我忽然间发现，原来这一切离我是如此的近，当你看到身边的同龄人对代码开始厌烦，继而将其当作糊口的工具的时候，我有时候就常常在想，我离这种状态会有多远，我讨厌自己不像期望中那样好，因为我曾错失过一个我爱的人，所以我有时候会像强迫症晚期一样，刻意地去追求完美。或许接受平庸会更像一个正常人，可我怕我再没有勇气去轻易喜欢一个人。我承认，我在这件事情上偏执是因为我在某种程度上自卑，可是如果我们能做得更好，为什么不去尝试做得更好呢？ &emsp;&emsp;这段时间，我喜怒无常的性格，或许让我身边的同事受到了伤害，其实我从来都不是针对任何人，我只是对这种无法掌控的现实的一种愤怒，我们常常被用户要求，为他们开发某种自动化的工具，可是我们所有的工具流，都是建立在一套尚未健全的设计上的，甚至用户内部使用的相关系统存在各种各样的设计缺陷，而这些完全不适合做自动化的特性，常常面临被设计到需求文档中的尴尬。虽然工程师喜欢解决问题，可解决问题并不代表要以牺牲技术上的先进性为代价，就像今天我们同样可以使用汇编语言来开发应用程序，可是有谁会选择这样做呢？这是因为汇编作为工具本身就是一种相对低级的编程语言，所以在这种情况下，我不认为花费精力来为落后的工具填坑，是一种值得称赞的事情，我们早已告别了石器时代，可有人因为学会了钻木取火而沾沾自喜，这是一种悲哀。我们既然让计算机来替人们做事情，所以就应该明确告诉计算机到底想做什么。一切没有任何规则可言，同时妄图实现自动化的过程，都是在赤裸裸的耍流氓，而规则和约束常常让人性的缺点暴露无疑。 &emsp;&emsp;所以，这种向现实妥协的做法，常常会让我们编写出肮脏的代码。我们总是想要编写出优雅、通用的代码，可因为工具流的落后、需求频繁变动、设计缺陷等等的原因，我们在面对这些东西的时候，常常感觉被人类的愚蠢的打败，人们说是人类发明了计算机，可是这是否就意味着我们一定会比计算机聪明，难道计算机无法通过深度学习超越人类吗？Google的AlphaGo凭借当今火热的深度学习理论以4:1的战绩打败了韩国棋手李世乭，可是不愿意去学习新知识的人类居然可以自信到能够驾驭计算机，我说将来会有越来越多的工作被计算机代替，我的一位长辈不以为然的说，不管计算机如何智能它总需要人类来控制它吧，我真的很想问一句，如果计算机真的超越了人类它为什么还需要人类来管理，而人类依靠什么样的技术来管理这些计算机。我认为在这个世界上，总是存在某种永恒的规则，它可以超越生与死的界限，而这些规则永远不会被打破，人类就像一个任性的孩子一样，可真理不就是用来敬畏的吗？我们对这个世界了解的越多，发现自己越来越渺小，此时此刻，你是否还有信心说我们可以驾驭计算机？ &emsp;&emsp;写这些碎碎念，其实是想反映我这段时间的心理状态，有人说，摆脱失恋最好的方法就是投入一段新的感情，可是其实你永远都清楚地知道，在你心里最看重什么，所以我对代码有一种特殊地感情，你可以清楚地从代码中读出一个人的所思所悟，因为那就是你独特个性的一种写照，所以每一次或许Alex让我改代码的时候，我都是在和我自己赌气吧，我不愿意让那些奇怪的逻辑破坏它的纯粹性，它必须是统一的、简洁的、纯粹的，它不能掺杂丝毫的丑陋的设计。而这种情况常常是因为用户在设计需求的时候忽略了某些细节，所以对我而言我生气、我愤怒，并非是我觉得这个需求无法实现，而是它在某种程度上是冗余的，即它可能破坏了一致性原则，灵活的人类是比呆板的计算机有趣，可和人相处得久了，你难免会觉得人显得不靠谱，这就是我厌恶的理由，在这个世界上所有一切计算机可以处理的问题，在某种程度上都可以转化为数学问题，一旦我们将设定突破这个规则，就会让代码因为妥协而变得丑陋不堪，我显然不允许这样的事情发生。 花十分钟解锁新技能&emsp;&emsp;好了，现在我们来回到这篇文章的主题，基于C#中的Trace来实现一个简单地日志系统。我们的项目上存在大量和用户内部系统关联的特性，所以我们会在远程计算机上耗费大量的时间来测试代码，这个时候我们会遇到两个问题，第一，我们开发环境中的Visual Studio版本和生产环境中的Visual Studio版本不一致，所以如果直接远程调试，因为项目中使用的相关语法在低版本Visual Studio中不被支持，如果修改代码会非常痛苦，我们实在没有精力去兼容两个版本的开发环境。第二，项目中默认使用的日志系统Log4Net，默认是在指定用户的我的文档目录中产生日志信息，而我们在远程调试时因为权限问题无法访问日志文件，所以虽然我们可以根据界面上反馈的信息，来粗略判断异常发生在什么时候，但这对我们追踪和定位问题来说是非常不利的。我们在研究了Log4Net的文档后，认为这个库的配置文件非常复杂，所以我们在想有没有一种更为简单地方案可以帮助我们解决这个问题。 &emsp;&emsp;我们了解到.NET中实际上提供了两个类Trace和Debug来满足类似的需求，而这两个类位于System.Diagnostics空间下，所以我们完全有理由相信基于这两个类，我们同样可以构建出一个相对简单的日志系统。首先我们通过MSDN了解到官方对它们各自用途的定义： Trace：提供了一组方法和属性，可以帮助您追踪您的代码执行，该类无法被继承。 Debug: 提供了一组帮助调试代码的方法和属性，该类无法被继承。 &emsp;&emsp;显然，我们通过这里给出的定义，可以非常容易的理解这两个类都可以用来追踪和调试代码，那么它们本质的区别在什么地方呢？如果我们的解决方案配置类型为Release，则会忽略Debug类的输出。换句话说，当我们处在开发调试阶段时，使用Debug类能够帮助我们在控制台或者是文件以及任意自定义的输出位置输出相关的调试信息，而当产品上线发布以后这些调试信息则不会输出。而Trace无论是在Debug还是Release模式下都会输出相关的追踪信息。通常我们会在发布以后的产品中部署日志生成模块，这样可以方便开发者定位问题、维护产品，那么在这种情况下，我们采用Trace这种方式来追踪程序的执行情况是非常适合的，而这正是我想写这篇博客的一个原因。 &emsp;&emsp;现在，在确定了使用Trace来开发一个简单的日志系统这样一个技术路线以后，现在我们来了解下Trace都提供了那些东西吧！对Debug和Trace这两个类来说，.NET为它们提供了下面这些相同的方法： WriteLine: 该方法会在输出设备中写入一条调试信息，而通过实现不同的监听器(Listener)并对其中的方法进行重写(OverWrite)，就可以将调试信息以不同的形式输出。例如Debug类产生的调试信息默认输出在Visual Studio中的输出窗口，我们可以通过自定义监听器将调试信息输出到文件或者控制台中。同样地，对Trace类来说，它同样遵循这个原则，这体现出了一种宏观上的统一。所谓“和而不同”，我们可以尊重这个世界的规则、尊重宇宙苍生，可是我们每一个人都是一个完全独立的个体，人可以被打倒，但决不会被打败。 12Trace.WriteLine(\"This is a Debug message!\");Trace.WriteLine(\"This is a Debug message!\",\"Debug\"); WriteLineIf: 该方法是WriteLine的增强版，仅当条件满足时会在输出设备中写入一条调试信息，同样，它支持通过实现不同的监听器(Listener)来完成重写，进而将调试信息以不同的形式输出，该方法在需要根据条件处理不同响应的场景下会非常有用。例如在项目中我们会通过一个窗口来输出程序执行过程中的细节信息，这些信息对我们开发人员来讲是非常重要的，因为我们可以通过这些信息来快速地定位问题。可是这些信息对用户而言是可以完全忽略的啊，难道肤浅的我们要在这里处理这两种情况吗？不，我们只需要定义一个全局开关，从此整个世界都变得安静了。 1Trace.WriteLineIf(i&gt;10,\"This message will only output when i&gt;10\"); Indent/Unindent: Log4Net中提供了对日志输出样式的支持，它被定义在一个Xml形式的配置文件当中，我们发现一件有趣的事情，复杂和简单是矛盾而统一的，就像我对编辑器这类工具，我会喜欢它提供的各种强大的扩展能力，而对集成开发环境这类工具，我会喜欢它提供的简单上手、零配置、开箱即用这种良好特性。当你发现你提供的功能越来越多的时候，就应该停下来思考这种做是否是正确的举动，一个东西的灵活性越强，它的复杂性就会越高，因为这意味着你需要去兼顾各种各样可能的组合。在这里Indent方法可以为输出提供缩进样式，相反Unindent方法可以为输出清除缩进样式。 Assert: 断言不一定就出现在单元测试中，就像骑白马的不一定都是唐僧。严格的来讲，这里的断言相对单元测试中的断言会显得相对薄弱，因为它没有Assert这个类的功能丰富。在这里我想说的是，Assert方法会在条件不满足时显示“断言失败”对话框，在对话框中会显示当前程序堆栈调用的详细情况，这是非常有意思的一个功能。有时候我们或许会因为业务而忽略技术，业务是现实规则的一种映射，所以我们可以理解业务本身地复杂性，可我们从古到今所认识的世界难道都是这样子的吗？或许由人类定义出来的这些规则本身就是错误的呢？ 1Trace.Assert(i&gt;10,\"This message will only output when i&lt;=10\"); Flush: Flush方法可以理解为一个通知监听器的方法，因为在调用Flush方法以后，每一个Listener对象将接收到它的所有输出，我们可以理解为，WriteLine方法执行以后，无论Trace还是Debug，其监听器都不会理解响应输出，只有当Flush方法被调用以后调试信息才会被响应和输出。 &emsp;&emsp;好了，再了解了这些以后，现在我们就可以开始设计一个日志系统了。按照国际惯例，我们当然是从设计接口开始，其实在做一项设计的时候，是不是要从接口开始，完全取决于你对接口持怎样的态度，人生或许有各种各样的套路，可是需不需要遵守这些套路完全是取决你的啊，编程同样是这个道理，我的习惯是在没有理解一个东西以前，永远不要尝试去使用它，可能你会说如果永远都不去尝试，那你就永远失去了了解它的机会，我想说的是，请不要滥用： 1234567interface ILoger&#123; void Warn(object msg); void Info(object msg); void Debug(object msg); void Error(object msg);&#125; 可以注意到在这里，我定义了四种级别的Log，这自然是模仿Log4Net，更重要的是这些不同的级别，我并不清楚他们之间的区别。这听起来好像挺尴尬啊。定义好接口以后，我们就可以考虑具体的实现啦！日志系统对整个应用程序而言哼，是独立且贯穿整个软件开发的生命周期的，所以将其设计为单例模式会更加友好： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class SimpleLoger : ILoger&#123; /// &lt;summary&gt; /// Single Instance /// &lt;/summary&gt; private static SimpleLoger instance; public static SimpleLoger Instance &#123; get &#123; if (instance == null) instance = new SimpleLoger(); return instance; &#125; &#125; /// &lt;summary&gt; /// Constructor /// &lt;/summary&gt; private SimpleLoger() &#123; Trace.Listeners.Clear(); Trace.Listeners.Add(new LogerTraceListener()); &#125; public void Debug(object msg) &#123; Trace.WriteLine(msg, \"Debug\"); &#125; public void Warn(object msg) &#123; Trace.WriteLine(msg, \"Warn\"); &#125; public void Info(object msg) &#123; Trace.WriteLine(msg, \"Info\"); &#125; public void Error(object msg) &#123; Trace.WriteLine(msg, \"Error\"); &#125;&#125; &emsp;&emsp;现在我们来重点关注SimpleLoger的构造函数，显然在这里它应该是私有的，在这里我们首先从Trace类的Listeners中移除所有的监听器，这样做的目的是改变Trace类的输出行为，因为在前面介绍Trace的时候我们了解到，Trace类和Debug类默认将调试信息输出在“输出”窗口中的，而我们现在希望将调试信息输出到日志文件中，所以我们需要改变Trace类的输出行为，改变的方式非常简单啦，移除默认的监听器，然后添加我们自己定义的监听器哇，对对对，就是这样简单粗暴。下面我们来看看如何定义这样一个监听器LogerTraceLitener，它继承自TraceListener这个类，这意味着我们如果要实现一个自定义监听器，只需要继承TraceListener然后重写相关方法即可： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class LogerTraceListener:TraceListener&#123; /// &lt;summary&gt; /// FileName /// &lt;/summary&gt; private string m_fileName; /// &lt;summary&gt; /// Constructor /// &lt;/summary&gt; public LogerTraceListener() &#123; string basePath = AppDomain.CurrentDomain.BaseDirectory + \"\\\\Logs\\\\\"; if(!Directory.Exists(basePath)) Directory.CreateDirectory(basePath); this.m_fileName = basePath + string.Format(\"Log-&#123;0&#125;.txt\", DateTime.Now.ToString(\"yyyyMMdd\")); &#125; /// &lt;summary&gt; /// Write /// &lt;/summary&gt; public override void Write(string message) &#123; message = Format(message, \"\"); File.AppendAllText(m_fileName,message); &#125; /// &lt;summary&gt; /// Write /// &lt;/summary&gt; public override void Write(object obj) &#123; string message = Format(obj, \"\"); File.AppendAllText(m_fileName, message); &#125; /// &lt;summary&gt; /// WriteLine /// &lt;/summary&gt; public override void WriteLine(object obj) &#123; string message = Format(obj, \"\"); File.AppendAllText(m_fileName, message); &#125; /// &lt;summary&gt; /// WriteLine /// &lt;/summary&gt; public override void WriteLine(string message) &#123; message = Format(message, \"\"); File.AppendAllText(m_fileName, message); &#125; /// &lt;summary&gt; /// WriteLine /// &lt;/summary&gt; public override void WriteLine(object obj, string category) &#123; string message = Format(obj, category); File.AppendAllText(m_fileName, message); &#125; /// &lt;summary&gt; /// WriteLine /// &lt;/summary&gt; public override void WriteLine(string message, string category) &#123; message = Format(message, category); File.AppendAllText(m_fileName, message); &#125; /// &lt;summary&gt; /// Format /// &lt;/summary&gt; private string Format(object obj, string category) &#123; StringBuilder builder = new StringBuilder(); builder.AppendFormat(\"&#123;0&#125; \",DateTime.Now.ToString(\"yyyy-MM-dd HH:mm:ss\")); if (!string.IsNullOrEmpty(category)) builder.AppendFormat(\"[&#123;0&#125;] \", category); if (obj is Exception)&#123; var ex = (Exception)obj; builder.Append(ex.Message + \"\\r\\n\"); builder.Append(ex.StackTrace + \"\\r\\n\"); &#125; else&#123; builder.Append(obj.ToString() + \"\\r\\n\"); &#125; return builder.ToString(); &#125;&#125; &emsp;&emsp;在这里我重写了好多好多方法，可是实际上我在SimpleLoger中仅仅用到WriteLine这个方法，大家可以发挥自己的想象力，因为我始终相信编程是一件有趣的事情，我们有时候会感到沮丧，完全是因为这个糟糕的世界里充满了同样糟糕的事情。其实程序员是一个理性与感性并存的职业，如果是操作系统、编译原理和图形学可以并称为程序员的三大浪漫，那么Big Clean Problem将是我们最这个世界最好的敬畏，我们喜欢解决问题本质上是因为我们对这个世界充满好奇，可这并不意味着我们对问题来者不拒，这个世界产生的大部分问题都是因为人类的无知，可人类到此刻依然认为这一切非常合理。 &emsp;&emsp;现在，让我们来检验我们的这个小玩意儿，我们将编写一个非常简单的单元测试案例，我们都知道当除数为0时在数学上是没有任何意义的，所以在计算机中当我们尝试除以0的时候会引发异常，由此我们会写出下面的代码： 12345678910[TestMethod]public void Test()&#123; try&#123; int i=0; Console.WriteLine(5/i); &#125;catch (Exception e)&#123; SimpleLoger.Instance.Debug(e); &#125;&#125; 理论上它会在程序根目录下生成一个Logs的文件夹，然后每天会生成一个以日期命名的文本文件。现在，它看起来工作得很好，我没有想要做出一个更好的日志系统的野心，我更喜欢去探索一种全新的可能性，我更在意在这个过程中我们收获了什么，人生本来就充满了各种各样无意义的事情，我们之所以热爱生命，是因为我们希望它变得有趣，这样就足够了，不是吗？ 效果演示","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"日志","slug":"日志","permalink":"https://qinyuanpei.github.io/tags/%E6%97%A5%E5%BF%97/"},{"name":"Trace","slug":"Trace","permalink":"https://qinyuanpei.github.io/tags/Trace/"},{"name":"调试","slug":"调试","permalink":"https://qinyuanpei.github.io/tags/%E8%B0%83%E8%AF%95/"}]},{"title":"当黑客遇见画家","date":"2016-10-09T18:38:03.000Z","path":"posts/4205536912/","text":"&emsp;&emsp;其实一直想读《黑客与画家》这本书，所以在我买了Kindle以后，这本书就成为我读完的第一本书。本书作者是美国互联网界举足轻重、有“创业教父”之称的哈佛大学计算机博士保罗·格雷厄姆 (Paul Graham )，而这本书是由他的思考整理而成的一本文集，虽然这本书的名字叫做《黑客与画家》，可实际上作者在这本书中观点，并非局限于黑客与画家本身，相反地它涉及编程、软件、创业、财富、设计、研究等等多个领域。我认为这本书带给我的，更多的是一种思想上的提升，当我们沉迷在代码中无法自拔的时候，我们其实应该意识到，这个世界原本是由理性和感性两种认识混合而成的。当科技与人文发生碰撞进而共鸣，这本书会告诉你这一切是如此的美妙。 &emsp;&emsp;我们目前所处的这个时代，本质上是一个机器的时代，这是自工业革命以来，人类历史上又一个革命性的时代。越来越多迹象表明，未来的人类生活不仅是人与人的互动，而且更多的将是人与计算机的互动。所以想要把握这个时代，就必须理解计算机。而理解计算机的关键，则是要理解计算机背后的人。我们的时代是程序员主导的时代，而伟大的程序员就是黑客。 &emsp;&emsp;普通人认为“黑客”就是入侵计算机的“计算机罪犯”，其实“黑客”的本意是指出于兴趣而解决某个难题，不管它有没有用的这类人(出自自由软件基金会创始人理查德·斯托尔曼)，所以黑客从一开始就是有精神追求的，它代表着求解问题过程中产生的精神愉悦或享受，黑客们只是比我们普通人更崇尚分享、开放和民主，他们对任何被禁止的东西都怀有特别强烈的好奇心，他们喜欢去思考那些似乎不应该被思考的问题，他们相信计算机会深刻地改变人们的生活，由此我们可以认识到“黑客伦理”的一个推论：黑客不服从管教，具有叛逆精神。黑客就像一群有知识的海盗。编程与绘画异曲同工，黑客是数字时代的艺术家，他们都是创作者，都试图创造出优秀的作品。 &emsp;&emsp;书呆子之所以不受欢迎，是因为他们不如普通人聪明。可是作为普通人的我们没有意识到，这些书呆子和周围环境显得格格不入，或许从某种程度上说明他们领先了一步，或许书呆子已经在思考的东西，正是真实世界看重的东西，他们并非不想让自己受大家环境，他们只是没有时间来做这些普通人所看重的事情。虽然现实中的图灵并不像电影《模仿游戏》中塑造的那样怪癖、不合群，可是通过这部电影，我们依然能够感受到那种天才般的疯狂，图灵将全部精力都专注在制造“克里斯托弗”，因为不通世故而被同事嘲笑和指责，是琼教会他如何和大家相处。我们可以发现当图灵尝试改变以后，他可以像普通人一样收获友谊，所以所谓天才无非是，他们比常人更专注他们认为重要的事情。 &emsp;&emsp;中国企业更加关注软件作为科学和工程的一部分，即我们都将编程作为一种技术，其实编程同样有它作为人文与艺术的部分，我们必须认识到编程是一种艺术创作。编程语言是用来帮助我们思考程序，而不是用来表达我们已经想好的程序。你只有以一种“设计”软件，而非“实现”软件的思路来应用程序，你才能在这个过程中发现编程的乐趣，这和我们的兴趣相辅相成，因为如果你不爱一件事，你不可能把它做得真正优秀，要是你很热爱编程，你就不可避免地会开发你自己的项目。 &emsp;&emsp;坚持一丝不苟，就能取得优秀的成果，因为那些看不见的细节累加起来，就变得可见了。当一个黑客认为他是一个创作者的时候，他从事的就不再是机械性的工作，因为这就要求他具备灵感。如果编程时与绘画和写作同一类的工作，黑客是否有机会像伟大艺术家一样备受推崇、流芳百世呢？我认为这是有可能的，譬如Linus一生有Linux和Git两个作品就足以彪炳史册，而更重要的是他能让更多的人从中收益，这是黑客精神的价值所在。 &emsp;&emsp;我们总是习惯于，给那些为我们所看不惯的人，贴上各种各样的标签。其实做自己喜欢的事情，是不需要伪装的，我只是我而已，不需要满足你们过高的期望。在我们这个世界里，程序员毫无例外地被人们误解，从阿里月饼事件我们就可以看出，普通人对技术的理解基本保持在白痴这样的水平上，可讽刺的是我们的命运被被掌握在这样的人手里，我们绞尽脑汁来复原产品经理们的脑洞，我们费尽心机来防止白痴用户们的错误……可我们依然被这场无情而可笑的舆论打败，我们对这个世界充满敬畏，因为它的复杂程度远远超过我们能够想象以致于抽象的范围。 &emsp;&emsp;可我们依然在尝试让自己更努力一点，因为我们编写代码的同时，在不断地认识着这个世界，就像这个世界上本来没有算法、数据结构和设计模式，可当我们创造和了解这一切以后，我们对这个世界的看法或许会发生变化。我们不能接受的人类的愚蠢、狂妄和无知，因为当你越接近真理时，你就越会认识到自己的渺小。我们曾自以为是地相信，现代人比古代人更聪明、更高尚，可是当我们了解的历史越多，就会越明白事实并非如此，古人与我们是一样的人，他们不是更勇敢亦或着更野蛮，而是像我们一样的普通人，不管他们产生怎样的想法，都是正常人产生的想法。 &emsp;&emsp;不管你是否愿意去相信，这个时代已经无可避免地，和计算机紧紧地联系在一起，计算机可以帮助人类完成大量工作。可你必须认识到，计算机存在的意义并非是让人类变得更懒惰。相反地，它希望人类向着更好的方向去发展、希望人类更有效率的工作和生活，因为计算机可以做的事情越多，人类面临的这种失业的紧迫感就应该越强烈。我们不应该想当然地认为，人类一定会凌驾于智能机器之上。人类在和大自然抗衡的过程中其无知与愚蠢昭然若揭，我们今天意识到地球环境面临威胁，这难道不是为儿时的任性付出的代价？ &emsp;&emsp;图灵在这个世界上尚未出现计算机的时候，就能够想到有一天机器会比人更聪明，可我们普通人居然狂妄而无知地认为，所有的一切在工程师眼中都是非常简单的事情，工程师们懂得敬畏自然、敬畏真理，可普通人反而不愿意去理解这些原理和事实，更讽刺的事情是，一个软件工程的话语权是掌握在这样的人手中。我们从来不畏惧去挑战艰难的任务，仅仅是因为在这个世界上，有值得我们永远去敬畏和尊重的东西，那就是真理，那是像伽利略、布鲁诺、图灵等等对人类进步做出卓越贡献的人们，愿意用生命去捍卫的东西，现代计算机的理论基础是数学，所以你必须承认计算机是一门科学，其次它是一门艺术。 &emsp;&emsp;我喜欢这种科学和艺术完美融合的感觉，就像现代科技发展到今天，我们面对地不再是冷冰冰的控制台终端，而是注重人性化和用户体验的图形化界面。苹果和微软都曾经窃取过施乐公司的图形化界面技术，这段故事在电影《硅谷传奇》中更是被演绎得淋漓尽致。可为什么乔布斯会一直评价微软的产品没有品味呢？或许这是因为乔布斯站在了一个科技与人文的十字路口。我并非果粉，甚至在某种意义上我一直是软粉，可这并不妨碍我对科技和美的一种热爱，技术本身并不能在商业化策略中起到决定性作用，可是一个优秀的产品一定是将技术和艺术完美地融合在一起，所谓“一张一弛，文武之道”，从这个意义上来说，黑客和画家志同道合，理性与感性相辅相成，即使我们不能这个世界改变什么呢？可那有什么关系呢？","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"程序员","slug":"程序员","permalink":"https://qinyuanpei.github.io/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/"},{"name":"人文","slug":"人文","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%BA%E6%96%87/"},{"name":"黑客","slug":"黑客","permalink":"https://qinyuanpei.github.io/tags/%E9%BB%91%E5%AE%A2/"}]},{"title":"像诗人一样睿智，像天才一样疯狂","date":"2016-10-01T17:12:43.000Z","path":"posts/3653716295/","text":"&emsp;&emsp;我不知道大家如何定义程序员这个工作，在我看来，在某种意义上，程序员和艺术家们具有相同之处，我们都是创作者，和诗人、画家、作家等等这些职业相近，我们都在试图创作出优秀的作品，我们借助编程语言来重构我们对这个世界的认识、借助抽象的概念来创造这个世界上不存在的东西，所以我们对自由和创造的渴望，来源自我们在这个世界上写下的第一行代码，或许这像是一个充满理想主义的臆想，可这并不重要，重要的是你如何看待这个世界、如何看待你自己，我更喜欢将程序员视为造梦者，就像每一个孩子在搭积木的时候，都有一个建筑师的梦一样，你可以选择让代码简洁、优雅，你同样选择让代码肮脏、丑陋，你相信什么，你执着什么，它就会是什么，所以为什么不给我们自己更多创造的机会。 &emsp;&emsp;在这个世界上，伟大的艺术家都是孤独的。从梵高那忧郁而狂野的绘画作品，到永远如童话王国里天真孩子一般的顾城……或许这种与生俱来的孤独感会成为一种宿命般的诅咒吧！程序员同样是孤独的，虽然我们今天的现代文明，高度依赖着程序员们创作的各种程序代码，可程序员就像一个被隐藏在幕后的魔术师，永远被人们忽略甚至是遗忘，同样地，程序代码和程序员一样孤独，当一段代码经过链接和编译，然后转化为可执行程序以后，没有人会再记得它们的样子，这种感觉就像人们需要你，可是人们从来不想了解你，而这种孤独会从心灵上摧毁一个人。“古来圣贤皆寂寞，唯有饮者留其名”，这种感悟在司马迁的《报任安书》里表现得更加玲离尽致：盖文王拘而演周易；仲尼厄而作春秋；屈原放逐，乃赋离骚；左丘失明，厥有国语；孙子膑脚，兵法修列；不韦迁蜀，世传吕览；韩非囚秦，孤愤说难；诗三百篇，大抵圣贤发奋之所为作也。 &emsp;&emsp;所以，我希望，程序员能够将每一行代码，都当做诗歌一样的艺术品，你必须在字里行间折射出明显的个人气质。在这个世界上，没有人会真正在乎这些代码是什么样子，因为人们需要的是一个可以对自己有用的东西，而对于它到底是什么永远没有人关心。我们整天面对着冷冰冰地液晶屏幕，所以我们理所当然地认为这些数字设备、应用程序都没有感情，它们就应该是被我们人类无情嘲弄的数字化工具。可讽刺的是，在一种称为手机的移动设备中，我们所有人的秘密都隐藏在这个我们不愿意去理解的东西里，这就相当于我们将我们的秘密，交给一个我们不愿意去深入了解的人一样，而仅仅是因为我们需要这样的一个人。这听起来像个笑话，所以，我们所有的努力，都是为了让这些代码，看起来不再那么孤独，你可以让它们成为你在这个世界上的烙印，你可以使用注释帮助人类理解代码、理解你自己，你可以创造出一种无限接近真相或者真理的信仰，你可以通过这一行行代码影响历史或者生活，我们不是仅仅为了活着。 &emsp;&emsp;乔布斯曾经引用毕加索的名言：优秀的艺术家复制，伟大的艺术家偷窃，并以此作为理由对施乐公司进行了疯狂的“盗窃”，乔布斯身上最让我着迷的是那灵魂深处那种艺术家的气质，他始终相信任何产品都应该是人的一种自然延伸，而正是这种对质量、理想和心灵的专注，让苹果公司的产品在设计和品味上显得与众不同。在麦金塔电脑这个项目上，他对完美的极致追求，让他对艺术和设计的那种天性得到释放，可与此同时他被斯卡利排挤出苹果公司，或许在这个以成败论英雄的时代，乔布斯是一个失败者，可这个世界依然需要理想主义，多年后，当人们提到苹果电脑总会不由自主地想到Mac这个品牌，我想说这是理想主义的胜利。 &emsp;&emsp;天才与普通人的区别在于，他们会做出在我们普通人眼中显得“疯狂”的事情，在电影《乔布斯》的结尾，乔布斯说：“只有疯狂到相信自己能改变世界的人，才能真正改变世界”，而这里对天才的定义是什么呢？他们特立独行、桀骜不驯、麻烦制造者，他们是格格不入的一群人，习惯用不同眼光看事情的人，不受规则约束的人，对既成事实不屑一顾的人，你可以引用他们，亦可反驳他们，或赞颂或诋毁他们，你唯一做不到的就是忽视他们，因为他们带来变革，他们推动人类向前，或许有些人将他们视作疯子，而我们将其视为天才。对大部分而言，我们都是普通人，可这并不代表我们就要停止努力，因为大部分的努力都尚未达到拼天赋的程度，何况我们可能连天赋都没有呢？ &emsp;&emsp;这意味着我们需要去做些疯狂的事情，我们追求极致和完美，是因为我们想在这个世界上，留下属于我们自己的印记，没有人会明白，为什么乔布斯天生就有一种想要和IBM抗衡的想法，这种想法促成了让人们印象深刻的”1984”广告，其创意来自乔治·奥威尔的小说《一九八四》，并借助小说中的“大佬”映射当时的蓝色巨人IBM，这个举动让苹果公司、让Mac成为人们心中理想主义的化身，这个举动相当地疯狂，不是吗？甚至在《硅谷传奇》这部电影中，这种疯狂被表现得更加淋漓尽致：我们正在创造一个新的信仰，你应该这样来认识，像艺术家或者诗人一样，我们正通过我们的所作所为，重写人类思想的历史。所以，当我们极力追求代码的优雅、性能的出众以及架构的良好，这一切都是因为我们想要做些，真正可以让我们在乎的事情。因为我们的生活常常被需求和问题左右，如果我们都不在乎我们所做的事情，我相信这个世界上不会有第二个人更加在乎。 &emsp;&emsp;天才在某种意义上来讲是孤独的，因为天才的想法，注定会超越时间和空间。古往今来，无数仁人志士，为这个世界所付诸的努力，其实都是为了帮助我们更好的认识这个世界而已。遥想太古时期，在这个世界上尚流传着诸神创造世界的传说，地球上或许还没有人类出现，最早的古猿还没有学会直立行走，这段时间对我们人类来说非常漫长，可它对整个宇宙、整个地球来讲，或许是短暂到可以忽略的一段时间，甚至当我们将视野放大到整个宇宙的时候，我们可能会突然意识到，我们所处的世界，可能仅仅是宇宙中的时光，曾经驻足过的，一个小城镇，因此我们对这个世界既熟悉又陌生，所以我们有什么理由不去发现更多的事情呢？对这个世界永远保留好奇心，是天才的基本要求，我们必须认识到，相对整个宇宙，我们每个人都显得狭隘而无知，所以我们有什么理由不去探索这个陌生的世界呢？我们目前所处的这个时代，大量的开源项目和第三方SDK，为我们提供了前人所不能想象的丰富的资源，无疑我们是幸福的，我们仅仅需要再努力一点。 &emsp;&emsp;一位同事给我推荐了《模仿游戏》这个电影，在此之前我对图灵这个人物的了解，无外乎他对整个计算机行业做出的革命性的贡献，以及他像谜一样的人生经历，可是通过这部电影，我看到的是一种天才般的疯狂和执著，图灵在被通知去接受破解德国加密装置“恩尼格玛”的任务时，军方对其进行了一个简单的面试，在面试中我们发现图灵或许不懂得什么是幽默，这种被我们称为“书呆子”的性格，在实际生活中是不讨喜的，在《黑客与画家》中作者明确地指出，“书呆子”不受欢迎是因为他们比普通人聪明，可是图灵很快就能发现，团队中有哪些人是不合格的解密者，而在这个过程中他因为不太懂得如何和别人相处，而被团队里的成员指责和谩骂，可他从来没有放弃过制造他的机器，而最终的结果的确是依靠他的机器计算出来的，天才的孤独在于常常不被常人理解，可是当图灵被强迫关闭他的机器的时候，团队中的成员愿意站在这一边，这一幕是让我感受到温情存在的，而这一切来自一个走进他生命中的女孩子：琼。 &emsp;&emsp;或许我们普通人穷尽一生都无法达到天才的万分之一，甚至有人想要告诫我，不要在一件事情上投入大量的热情，因为我们都期望获得成功，可现实难免会在这个时刻，无情地为我们浇下一盆凉水，这种感觉就像你对一个女孩子投入了大量感情，结果最后被她伤心到心灰意冷……可是人生其实本来是没有意义的，你从出生到走向死亡早已安排好，你需要做的就是“重写”这个过程，所以我们来到这个世界上，无非是想要认识些有趣的人、经历些有趣的事情，所以如果你对一件事情的成与败、一件东西得与失，都能做到坦然处之，或许你就不会再畏惧失败，当我们不再愿意为一件事情投入热情的时候，其实我们已经习惯了为自己的懒惰找到一个借口，你必须要相信你做的事情是最正确的事情，你必须要有一种敢于突破自我的激情，否则你注定只能做出平庸而普通的产品。如果我们不能比别人做得更好，那么就努力和别人做得不同;如果我们可以和别人做得不同，那么就努力比别人做得更好，即使普通如你我一般的人，我们依然可以选择像天才一样疯狂。 &emsp;&emsp;在《模仿游戏》里，艾伦的“初恋”克里斯托弗告诉他，有时候正是人们以为的无用之人，成就了无人感想之事。同样地，在劝说琼参与到解密工作中时，他同样对琼说出了这句话，或许是因为琼因为迟到而无法参加测试时，她说的一句漫不经心的话“你凭什么认为我自己不可以解决呢”，让图灵想到了自己，所以他破例让迟到的琼参加测试，虽然图灵是一个同性恋，可他和琼两个人的感情依然让人动容，即使两个人都不是完美的彼此，即使他们按照各自不同的生活方式生活，可他们同样能按照各自不同的方式去爱对方，在这种情形下，世俗中理解的爱是否会显得平淡无奇？图灵的死亡，在我看来是一个国家甚至整个世界的巨大损失，从伽利略、布鲁诺再到图灵，在这个世界上人类自以为是地创造了各种“教条”，并以此来伤害这些本应该在历史中绽放异彩的天才们，图灵提出的“图灵测试”是人工智能领域的一个重要概念，而计算机领域最高的奖项以他的名字定义，甚至英国女王都曾经公开为其恢复名誉，所以同样都是活着，为什么我们不能给自己一种新的选择？ &emsp;&emsp;或许你我的努力不会为人们所歌颂，或许你我的坚持不会为人们所理解，可我们来到这个世界，就是为了给这个世界留下我们的印记，不然我们来这里做什么呢？因为你要相信，你学过的每一样东西，你遭受过的每一次苦难，都会在你一生中的某个时刻派上用场。其实你我的生命都很短暂，我们没有多少时间值得去浪费。像诗人一样睿智，去了解我们的生活；像天才一样疯狂，去掌控我们的生活。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"黑客","slug":"黑客","permalink":"https://qinyuanpei.github.io/tags/%E9%BB%91%E5%AE%A2/"},{"name":"画家","slug":"画家","permalink":"https://qinyuanpei.github.io/tags/%E7%94%BB%E5%AE%B6/"},{"name":"诗人","slug":"诗人","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%97%E4%BA%BA/"}]},{"title":"你了解爱的艺术吗？","date":"2016-09-24T22:42:44.000Z","path":"posts/2275646954/","text":"&emsp;&emsp;或许我不是一个懂得如何去爱人的人，我时常陷入一种自我否定的焦虑当中，当我发觉自己喜欢上一个人的时候，从某种意义上它会让我身上的缺点被无情地放大，我并不畏惧在喜欢的人面前暴露这些缺点，因为这就是真实的我，因此我从来不喜欢去塑造别人，让别人成为我心目中期待的样子，可是我会忍不住去塑造我自己，尤其是在和别人相处的过程中，发现我身上的缺点或者问题的时候，我习惯了对自我严格，虽然我知道这个过程注定痛苦，可是你能告诉我，爱到底是什么吗？如果爱不足以让我们改变，我们喜欢的究竟是一个怎样的自己、怎样的别人？ &emsp;&emsp;弗洛姆这本《爱的艺术》是我自己为自己挑选的一本书，在我买了Kindle以后，我将我的时间安排在看书和学习上，因为我的确很喜欢读书，而我这种理性的性格有时候难免让人讨厌，所以读书特别是选择去读人文类书籍，从某种意义上来说是我在刻意地稀释这种理性思维造成的影响，《黑客与画家》里告诉我们一件事情，聪明人不被周围人喜欢是因为他们比周围人聪明，当谈恋爱越发地被人们改造成一种套路，我们对爱的定义或许会越来越模糊，可是爱作为一种大自然间普遍存在的情感，我坚信它是一种相当原始而简单的事情。 &emsp;&emsp;弗洛姆认为，爱情是对人类生存问题的回答，人们在这个世界上逐渐意识到生不由己、意识到死的必然、意识到孤独和与世隔绝、意识到面对社会和自然的威力时的无能为力，所以，所有生活在不同文化和时代里的人，都面临着一个同一个问题，即：如何克服这种孤独感。古人说“古来圣贤皆寂寞，唯有饮者留其名”，其实何止是古来圣贤，我们生活在这个地球上的所有人，从出生到死亡都不可避免地被一种孤独感包围者，曾经和别人 讨论过这个问题，我对人情颇为淡漠，因为我觉得除了能够真正将彼此联系起来的两个人，在这个世界上你永远无法找到真正能让你灵魂皈依的地方，这种感觉并非是由血缘或者金钱这样的关系来维系，一个人的孤独与一群人的孤独，在整个宇宙间看起来，其实没有什么不同。 &emsp;&emsp;爱的确是一门艺术，可对我们每个人而言，它像是某种缥缈甚至是难以揣测的情绪，你不能用一种非常理性的眼光来审视和定义它的存在，弗洛姆说：“不是拥有财物的人是富裕的，而是给予他人东西的人才是富裕者”，可现实是并非你不顾一切地对一个人好，就能赢得一份让你感动的爱情，所以在经历过挫折以后，我不再考虑一味地索取或者付出，我喜欢将这个过程叫做分享，人们在分享的过程中认识彼此、丰富彼此、提高彼此的生命感，这是我认为在爱情中我们需要去挖掘的一种潜质，如果一个人没有生命力，就不会有创造爱情的能力，所以当我们试图爱一个人之前，我们首先要学会爱我们自己，而弗洛伊德将这种人的自我欣赏叫做“自恋”，除了爱情自身积极性的因素以外，爱情具有所有爱的形式所共有的因素，如：关心、责任心、尊重和理解。 &emsp;&emsp;爱情不是自私地占有对方或者是放弃除对方以外人的更为广泛意义上的博爱，“爱情是自由之子，永远不会是控制的产物”。或许我们穷极一生来认识自己、认识别人，可我们最终还是不认识自己、不认识别人，可我们无法阻止这种深入了解人的灵魂的秘密、了解人的核心，即“自我”的愿望将继续存在。毫无疑问，德尔斐的人箴言“认识你自己”表达了我们认识自己和他人的愿望。白昼和黑夜表面看起来是敌人，但它们却都是为了一个目标，因为相爱就是为了完成共同的事情。而从广义的爱的定义来看，中国古代先哲孟子的“老吾老以及人之老，幼吾幼以及人之幼”就很好的表达了这种观点，弗洛姆说：“一切爱的形式都以博爱为基础，我指的博爱就是对所有的人都有一种责任感，关心、尊重和了解他人，即愿意提高其他人的生活情趣”。以前以为爱是自私地占有一个人，是对除对方以外的人表现得漠不关心，可后来逐渐发现，我们对自己的爱远远超过别人，这或许不能叫做爱吧！ &emsp;&emsp;我们来到这个世界上，更本质的意义在于我们希望认识些有趣的人，做些有趣的事情而已，这意味着我们常常试图在这个世界上留下自己的印记，我们习惯了在朋友圈里晒美食、晒旅游、晒自拍等等约定俗成的处事方法，亦如我们生来就渴望被人理解、被人喜欢一样，而这一切更本质的原因，我们现在称为“刷存在感”，恰恰迎合了这个观点，我们想要在这个世界上留下我们的印记，即使这些方式方法看起来并不是我们最初喜欢的样子，弗洛姆将在这个观点理解为“超越自己”的追求，这一追求属于人的最基本要求，即“人对自己的纯生物作用不满，他不能忍受自己仅仅是被扔进这一世界的小卒。他一定要感到自己是创造者，是能超越处于被创造者消极地位的生命。满足这一要求有许多可能性，最自然和最基本的途径就是母亲对自己创造物的关怀和爱”。所以，我们渴望被人喜欢、被人理解都是因为我们希望生来独特、生来不同，而这一切都源于父母对爱的一种创造力。 &emsp;&emsp;我们常常表现出，一种试图要要证明比别人过得更好的心态，仿佛在朋友圈或者微博这种社交平台上，我们能找到更多的自豪感，可我同样知道，这个世界上最大的社交网站Facebook，背后却是由一个有社交障碍的人创造出来的，我们都渴望让别人了解自己、认识自己，这不同于社交场合里那种客套的场面话，对此，弗洛姆认为，人与人之间可以通过讲述这种方式来打破人与生俱来的这种孤独感，“讲述自己的生活，叙述自己的希望和恐惧，谈出自己幼稚的或者不成熟的梦想，以及找到面对世界的共同利益——所有这一切都是克服人与人之间隔离的途径，甚至表露自己的愤怒和仇恨，毫无顾忌地交心也都被看作是亲密的表现”，我们对爱的终极理解其实应该是，我们通过爱一个人，进而爱全人类，爱一切生命，我们从自我的生命的本质出发去爱对方，并且去体验对方的本质，爱情是意志的行为，是人作的一项把全部生命交付对方的决定。 &emsp;&emsp;圣经中“爱他人如同爱己”的说法，说明了对自己的完整性和独特性的尊重，爱自己，理解自己同尊重、爱和谅解别人是不可分割的，爱我同爱他人是紧密相连的。中世纪德意志神秘主义哲学家和神学家，爱克哈特有一句关于自爱的格言：“你若爱己，那就会爱所有的人如爱己。你若对一个人的爱少于爱己，如果你不是爱所有的人如同爱己，如果你不是在一个人身上爱所有的人——因为这个人就是上帝和人。一个既爱自己又爱他人如同爱己的人就是这样的人，一个值得这样评价的人”。我们来到世界上学会与人相处、学会如何去爱一个人，其实是在寻找一种探索生活所需要的信仰，因为生存或许会非常容易，可是学会生活或许会非常困难，我们努力提高生活质量，源于我们对自己和伴侣的一种爱，希望让彼此变得更好。 &emsp;&emsp;或许对弗洛姆本人而言，这本《爱的艺术》更像是 他对自我的一种内省，因为他的爱情基本上在持续地遭遇着失败，他曾经和四个不同的女人结过婚，所以他在这本书里提出的大量观点都来源自他自己的感情经历，他早期研究过弗洛伊德的相关理论，而事实上，因为对爱的无能为力让他真正找到了爱的能力，我们在年轻的时候总会遇到一个非常喜欢，可我们却无法给她想要的生活的女孩子，或许我们都需要用一生去领悟爱的真正含义吧，就像弗洛姆这本书是建立在将理论和实践结合起来的基础上的，我不认为我此刻已经读懂了这本书，可是它对我的确非常重要，我总要学着去爱别人，让自己变得更好！","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"读书","slug":"读书","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"爱情","slug":"爱情","permalink":"https://qinyuanpei.github.io/tags/%E7%88%B1%E6%83%85/"},{"name":"Kindle","slug":"Kindle","permalink":"https://qinyuanpei.github.io/tags/Kindle/"}]},{"title":"一个关于概率的问题的思考","date":"2016-09-24T20:06:45.000Z","path":"posts/3247186509/","text":"&emsp;&emsp;最近需要给公司内部编写一个随机生成人员名单的小工具，在解决这个问题的过程中，我认识到这是一个概率相关的问题，即使在过去我曾经设计过类似转盘抽奖这样的应用程序，可我并不认为我真正搞清楚了这个问题，所以想在这篇文章中说说我对概率问题的相关思考。首先，我们来考虑这个问题的背景，我们需要定期在内部举行英语交流活动，可是大家的英语水差异悬殊，所以如果按照常规的思路来解决这个问题，即认为每个人被选中的概率是相等的话，实际上对英语不好的人是显得不公平的。其次，作为一个内部活动它需要的是营造一种氛围，让每个人参与到其中，所以它要求英语好的人有一个相对高的优先级，这样能够方便在活动开始前“破冰”，可是同时它需要让英语不好的人能够参与其中，所以这个问题该如何解决呢？这就是我们今天想要讨论的话题！ 今天吃什么？&emsp;&emsp;虽然我的确是一个对穿衣吃饭没有太多追求的人，可是作为这尘世间芸芸众生里最为普通的一个人，我们每天不可避免地会遇到这个问题。如同哲学家会从“认识你自己”这样一个基本命题发散出无数哲学问题一样，“今天吃什么”在某种意义上可能是比哲学问题还要重要的问题，尤其是对一个喜欢美食的吃货来讲，“今天吃什么”可能是整个世界里优先级最高的事情。 &emsp;&emsp;好了，我们从这个问题出发想要说明什么呢？通常我们解决这个问题最简单粗暴的方式是，罗列出附近所有的餐馆然后从中随机选择一家，现在主流的地图类APP基本上都有这样的功能，在每个餐馆被选中的概率相同的情况下，这种方案是没有什么问题的。可是我们都知道，人类作为这个世界上最复杂的一种动物，怎么会甘心让这个问题如此的简单呢？因为我们在选择的时候存在一个优先级的问题，例如我今天想吃红烧肉而明天想吃水煮鱼，显然因为个体偏好的差异每个餐馆被选中的概率是不相同的，因此在这种情况下，经典的概率理论是无法满足我们的要求的，那么此时该如何解决这个问题呢？ &emsp;&emsp;考虑到个人偏好对餐馆是否被选中的影响比较明显，因此实际上不同的餐馆拥有不同的优先级，这里我们假定有A、B、C三家餐馆，以你的个人喜好作为优先级评价标准，其优先级分别为2、3、5，则根据概率知识可知，P(A)=0.2、P(B)=0.3、P(C)=0.5。我们这里采用一种累加的思路来处理，令P(A)=P(A)=0.2、P(B)=P(A)+P(B)=0.5、P(C)=P(B)+P(C)=1，此时我们将P(A)、P(B)、P(C)三个概率值标注在数轴上，根据几何概型的相关理论，我们很容易地可以知道，00.2范围内可以表示餐馆A被选中的概率、0.20.5可以表示餐馆B被选中的概率，0.51可以表示餐馆C被选中的概率，此时我们可以借助各种编程语言提供的随机数功能来生成01间的随机数，然后根据随机数落在哪个区间内来处理结果。 &emsp;&emsp;我认为这个方案是比较不错的一种思路，在数学里有一种思想称为归一化，我们这里是将概率值从离散状态变为连续状态，而计算机更擅长我们生成一定范围内的随机数，所以这个方案为我们解决这类问题找到了一个不错的契合点，联想到转盘游戏其实是将01范围内的数字转换为0360度范围内的角度，这一切就显得更加有趣啦！ 概率与累积概率&emsp;&emsp;在解决了“今天吃什么？”这样一个终极命题后，下面我们来从理论上对这个问题进行解释。第一个问题，什么是概率呢？根据百科全书中的定义，概率是概率论中的一个基本概念，它是度量随机事件发生的可能性的一个量，通常使用0~1间的实数来表示一个随机事件发生的可能性的大小，当其值越接近0时表示该随机事件越不可能发生，当其值月接近1时表示该随机事件越有可能发生。经典的古典概型理论指出，如果一个实验满足同时下列两个条件，则这样的实验就是古典实验： 实验只且只有有限个基本结果 每个基本结果出现的可能性相同 &emsp;&emsp;此时，对古典实验中的事件A，其概率定义为：P(A)=m/n，其中m为事件A包含的基本结果的数目，n为该实验中所有可能出现的基本结果的数目，这种概率定义的方法称为概率的古典定义。人们在重复实验的基础上进一步提出，在一定条件下，重复做n次重复实验，虽然实验次数的增加，如果某个事件的频率逐渐稳定在某一个数值p附近，则认为数值p即为事件A在该条件下发生的概率。这是建立在统计基础上的概率定义。显然我们发现这里存在问题，即古典概型是建立在所有事件发生的可能性相同这样一个基本假设的基础上的，于此同时我们可以注意到，概率是客观的而频率则依赖经验。对于概率甚至数学，人们一度认为它们都是严格的科学，对这种观点，我想引用庞加莱的一段话： 概率仅仅是我们无知程度的度量，据定义，我们不晓得其定律的现象，都是偶然现象。 &emsp;&emsp;好了，下面我们来关注一个新的概念，即累积分布函数(CDF，Cumulative Distribution Function)，它能够完整描述一个实数随机变量X的概率分布，是概率密度函数(pdf，probability density function)的积分。其数学定义是F(X)=P(X&lt;=x)，表示随机变量小于或者等于某个数值的概率。为什么我们需要连续的随机变量呢？因为计算机产生的随机数通常都是指某个范围内的随机变量，而通常意义上的古典概型实际上是一种离散分布的数学模型，显然这两者间需要某种形式上的转换，所以我们需要累积分布函数，并且对连续函数而言，所有小于或者等于某个数值x的概率都可以认为，它等于数值x处的概率，因为我们能够保证累积分布函数严格递增，印象中诸如正态分布、均匀分布、泊松分布都是可以采用这种思路来处理的。好啦，更多理论层面的内容大家有兴趣的话可以自己去探索，这里我们想在这种理论的基础上设计一个基本的抽奖系统。 一个抽奖系统的设计&emsp;&emsp;首先，我们必须指出计算机产生的随机数都是伪随机数，因此我们无法编写出100%随机的程序，而且事实上这种“随机”程度对我们来讲应该是完全足够了，所以在排除了这个因素的影响以后，我们基本上不能再为我们的应用程序寻找任何的借口，在这里我认为重要的一点是，我们能够有一个在理论和实践上都相对可行的方案，我们这里选择以一个简单的抽奖系统的设计为例来探讨这个问题。 随机概率公平吗？&emsp;&emsp;抽奖系统最重要的是什么呢？是公平合理，那么怎样保证每次抽奖对所有用户来讲都是公平的呢？我认为首先要能够指定一个公平合理的规则，因为规则就如同人世间的法律正义、就如同璀璨夜空中的星辰宇宙一样，当它被确定下来以后就会一种永恒的真理。我们现在来考虑这样一个概率问题，假设我们有A、B、C、D四种不同的物品，它们各自被选中的概率分别为10%、20%、30%和40%，我们应该如何解决这个问题呢？通常可以想到的一种方案是，因为这四种物品被选中的概率之和为100%，因此我们将0~100范围内的数划分为[1,11)、[11,31)、[31,61)、[61,101)，我们注意到这四个区间都是左闭右开的，因此每个区间的长度和概率完全对应，此时我们产生一个(0,101)间的随机数，然后根据随机数落在那个区间内来判断抽取物品的结果，这种方法称为随机概率，我们来看看它是如何实现的： 1234567891011121314151617static void Main(string[] args)&#123; List&lt;Prize&gt; prizes = new List&lt;Prize&gt;() &#123; new Prize(\"奖品A\",0.1d,1,11), new Prize(\"奖品B\",0.2d,11,31), new Prize(\"奖品C\",0.3d,31,61), new Prize(\"奖品D\",0.4d,61,101) &#125;; var seed = Guid.NewGuid().GetHashCode(); Random random = new Random(seed); int rand = random.Next(1, 101); var prize = prizes.Where(p =&gt; rand &gt;= p.RangeStart &amp;&amp; rand &lt; p.RangeEnd).FirstOrDefault(); Console.WriteLine(\"随机选取的物品为:\" + prize.ID); &#125; &emsp;&emsp;这段代码是非常简单的，可我想要问的一个问题是，我们这样的做法到底对不对呢。面对一个概率学的问题，如果要检验我们的算法是否正确，一个最简单的方式是判断其是否符合我们的预期，因为从概率的定义中我们已经可以了解到，概率是一种数学定义中的概念，我们可以通过大量重复试验的客观性来证明概率的确是存在的，并且我们可以合理地解释它为什么这样，可是这样到底对不对，我相信没有人能够给出确定的答案。现在我们来借助计算机通过大量的重复实验来证明我们的方法是否正确，根据频率和概率的关系，我们知道频率应该会在概率的某一个范围内上下波动，但是它整体上会越来越接近于概率。下面的表格给出了我在这个问题上的试验结果： 10次 1000次 1000000次 物品A 0.2 0.109 0.10066 物品B 0.4 0.199 0.19977 物品C 0.3 0.311 0.300071 物品D 0.1 0.381 0.399499 &emsp;&emsp;这里因为博主在尝试做1亿次重复试验时电脑运行时间非常漫长，就像在电影《模仿游戏》中艾伦.图灵制作的计算机器在破解德国加密设备“恩格尼玛”时，常常需要长达数月的运算周期一样，这种类比可能不是非常恰当，因为现代计算机的硬件水平是图灵所处的二战时期难以企及的，可是我们忽然发现一个非常沮丧的事实，我们在这里处理1亿次左右的循环，依然需要一段我们感觉上非常“漫长”的时间，而根据电影中的情节，图灵制作的计算机器需要完成159亿次的运算来尝试各种可能的组合，所以此时此刻我们是应该向这些推动人类进步的杰出人物诚恳地致敬，因为我们今天的一切都是来自这些人在当时看似疯狂的举动，或许人们曾将他们视为疯子而我更喜欢将其视为天才。 &emsp;&emsp;结果的确如我们所预期的那样，这里每组试验都是3次平行试验后的平均值，可以看到随着重复次数的增加，试验结果更加趋向我们理论上设计的概率值，因此这种情况下我们认为这个设计是合理的，即这个算法是公平的。可是这个世界让人头疼的一点是，我们每个人都理所当然地认为，只要是别人能得到而我们自己得不到地，就一定是有内幕、是不公平地，可是这个世界本来就是不公平的啊，谁掌握更多的社会资源、谁掌握绝对的话语权，“正义”的天平就会向谁倾斜，我们能做的无非是让自己变得更好，努力避免陷入某种被动的局面。 &emsp;&emsp;好了，言归正传，现在我们会发现一个问题，这种方案在奖品种类非常多的情况下，调整概率会是一件非常困难的事情，这就像工程师不喜欢产品经理和游戏策划，其真实原因并非是工程师无法实现特定需求，而是在整个建筑完成规划和设计以后，频繁的需求变更让一座伟大的建筑变成了临时的脚手架，你必须认识到这是工程师经过创作以后的某种产出，你可以不在乎这些无人问津的代码，可是我作为工程师我一定要比任何人都要在乎啊。 &emsp;&emsp;可是一个新的问题是，你永远无法为用户提供一种通用的解决方案，一个简单的抽奖在引入各种“自定义”规则以后，就注定不会再成为一个简单的抽奖，因为揣测一个人会说什么，对我这样一个不喜欢说话的人来说简直是种灾难，同样地，用户让计算机来做什么就应该明确地告诉计算机，而不是让工程师用各种各样的if-else来揣测用户想要做什么，我们常常说“优雅接口、肮脏实现”，在某种意义上就是指这种东西在永远浪费工程师的时间，用户愚蠢、用户懒惰，可是他们居然可以凌驾于工程师之上，这是对这个世界最大的恶意。好了，我们现在来动手解决新的问题，当用户需要在抽奖的时候对各种条件进行筛选同时还要考虑优先级和公平性这样一个问题吧！ 让一切可复用&emsp;&emsp;首先我们来考虑，如何设计一个可以复用的抽奖系统，在这个问题中我们关注两点，第一，这个抽奖系统可以支持不同类型的“奖品”；第二，这个抽奖系统可以支持不同类型的“抽取”方式。因为在这个问题中，按照某种优先级随机抽取人员或者物品其实应该是一类问题，而抽取我们都知道应该有可放回抽取和不可放回抽取两种，所以我们可以考虑通过泛型和接口来实现这样的需求。我们在这里定义一个IRankable接口，所有的“奖品”都要实现该接口，其定义如下： 1234interface IRankable&#123; int GetRank();&#125; 我们可以发现该接口中只有一个GetRank()方法，这是因为我们这里的概率算法的基础是权重，所以我们只要为不同类型的“奖品”建立其相应的权重模型，就可以实现对不同类型奖品的支持。现在我们需要编写一个随机生成“奖品”的随机生成器，我们应该可以想到通过接口来约束泛型的思路，所以下面我们来实现一个随机生成器RandomGenerator。 &emsp;&emsp;首先我们可以想到的一点是，因为这里的泛型类型T需要实现IRankable接口，因此我们可以通过IRankable接口中定义的GetRank()方法来获取不同奖品的权重，在此基础上我们对奖品按照权重进行分组，则我们可以计算出每种权重在整个奖品权重中占到的百分比，我们以此作为每种权重奖品的概率，利用累积概率的思想可以非常容易地获得各种权重奖品对应的概率范围。其代码实现如下： 12345678910111213141516171819202122232425262728/// &lt;summary&gt;/// 计算概率/// &lt;/summary&gt;private void CalculateProbability(IEnumerable&lt;T&gt; source)&#123; this.m_groups = source.GroupBy(e =&gt; e.GetRank()); //计算总权重 var totalRank = 0; m_source.ToList().ForEach((item) =&gt; &#123; totalRank += item.GetRank(); &#125;); //计算每个权重对应的概率 m_probs = new Dictionary&lt;int, double&gt;(); foreach (IGrouping&lt;int, T&gt; group in m_groups) &#123; var p = (double)(group.Key * group.Count() / (double)totalRank); m_probs.Add(group.Key, p); &#125; //计算每个权重对应的累积概率(递增） var totalProb = 0d; m_totalProbs = new Dictionary&lt;int, double&gt;(); foreach (KeyValuePair&lt;int, double&gt; kv in m_probs) &#123; totalProb += kv.Value; m_totalProbs.Add(kv.Key, totalProb); &#125;&#125; &emsp;&emsp;好了，现在我们就获得了不同权重物品所对应的累积概率，即其概率范围，因此我们可以利用随机生成[0,1)范围内的随机数，然后判断随机数所在哪个概率范围内，我们就可以知道要对哪个权重分组中的奖品进行抽取，而对每个权重分组来说，因为其权重都是一样的，所以这里抽取试验可以认为是符合随机概率的，我们只需要从该分组中随机选取一个奖品返回就可以啦。那么这里该如何查找概率范围内，我们这里选择经典的“二分查找”算法： 1234567891011121314/// &lt;summary&gt;/// 返回概率所在的区间索引/// &lt;/summary&gt;private int GetProbablityRange(Dictionary&lt;int, double&gt; totalProbs, int begin, int end, double value)&#123; if (begin &gt;= end) return begin; int mid = (begin + end) / 2; if (totalProbs.ElementAt(mid).Value &gt;= value) return GetProbablityRange(totalProbs, begin, mid, value); else return GetProbablityRange(totalProbs, mid + 1, end, value);&#125; &emsp;&emsp;那么好了，现在我们该怎么从这些奖品中随机抽取一个奖品呢，我们这里提供了随机生成1个奖品和随机生成指定数目个奖品的方法重载，我们以前者为例来看看它的实现过程: 1234567891011121314151617181920212223242526272829/// &lt;summary&gt;/// 随机抽取一个奖品/// &lt;/summary&gt;public T Generate()&#123; //初始化随机数 var seed = Guid.NewGuid().GetHashCode(); var random = new Random(seed); //生成0到1间的随机数 double rand = random.NextDouble(); T result = default(T); //计算随机数落在哪个区间内 int index = GetProbablityRange(m_totalProbs, 0, m_totalProbs.Count - 1, rand); switch (m_option) &#123; case GenerateOption.CanReplace: result = GenerateCanReplace(index, random); break; case GenerateOption.NoReplace: result = GetnerateNoReplace(index, random); break; &#125; return result;&#125; &emsp;&emsp;在这里我设计了两种不同的抽取方式，即可放回抽取和不可放回抽取，两者的区别在于前者奖品池中奖品的数目保持不变，而后者奖品池中奖品的数目会发生变化，而更本质的区别在于前者奖品概率保持不变，而后者概率会发生变化。后者在每次抽取完以后需要将抽中的奖品从奖品池中取出，重新计算概率后方能进行下一轮抽取，所以这里我们直接给出这两两种抽取方法的代码实现，这里需要考虑的一个问题是，在抽取指定数目个“奖品”的时候我们通常不希望出现重复的元素，前者需要我们判断已抽取的奖品列表中是否存在指定元素，而后者因为抽取的奖品会被取出，所以不需要考虑这种情况的处理。 12345678910111213141516171819202122232425262728293031323334/// &lt;summary&gt;/// 可放回抽取/// &lt;/summary&gt;private T GenerateCanReplace(int index, Random random)&#123; int rank = m_totalProbs.ElementAt(index).Key; var group = m_groups.Where(e =&gt; e.Key == rank).FirstOrDefault(); if (group == null) group = m_groups.ElementAt(random.Next(0, m_groups.Count())); return group.ElementAt(random.Next(0, group.ToList().Count));&#125;/// &lt;summary&gt;/// 不可放回抽取/// &lt;/summary&gt;/// &lt;returns&gt;&lt;/returns&gt;private T GetnerateNoReplace(int index, Random random)&#123; int rank = m_totalProbs.ElementAt(index).Key; var group = m_groups.Where(e =&gt; e.Key == rank).FirstOrDefault(); if (group == null) group = m_groups.ElementAt(random.Next(0, m_groups.Count())); T result = group.ElementAt(random.Next(0, group.ToList().Count)); //从集合中移除当前抽取的元素 var list = m_source.ToList(); list.Remove(result); //更新集合、重新计算概率 m_source = list; CalculateProbability(m_source); return result;&#125; &emsp;&emsp;在此基础上实现指定数目的奖品就会变得非常简单啦，因为我们只需要重复调用这个方法就可以啦，那么现在我们该如何使用这个随机生成器呢？一起来看一段示例代码： 123456789101112131415161718192021222324252627282930//模拟优先级和员工级别对随机数的影响List&lt;Contract&gt; contracts = new List&lt;Contract&gt;();contracts.Add(new Contract() &#123; Name = \"People0\", Level = \"Senior\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People1\", Level = \"Senior\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People2\", Level = \"SSE\", Priority = 10 &#125;);contracts.Add(new Contract() &#123; Name = \"People3\", Level = \"SSE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People4\", Level = \"SSE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People5\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People6\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People7\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People8\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People9\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People10\", Level = \"Senior\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People11\", Level = \"Senior\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People12\", Level = \"SSE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People13\", Level = \"SSE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People14\", Level = \"SSE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People15\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People16\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People17\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People18\", Level = \"SE\", Priority = 1 &#125;);contracts.Add(new Contract() &#123; Name = \"People19\", Level = \"SE\", Priority = 1 &#125;);RandomGenerator&lt;Contract&gt; generator = new RandomGenerator&lt;Contract&gt;(contracts,GenerateOption.NoReplace);var list = generator.Generate(10);foreach (var contract in list)&#123; Console.WriteLine(contract.Name);&#125;&#125; 在这里Contract实现了IRankable接口，每个Contract的权重由Level和Priority两个属性来计算，示例中我们一次从集合中随机抽取了10个Contract，而我们的算法能够保证它们都是不重复的，这个程序可以满足各种各样的抽取规则，比如按照Contract的口语、职位等不同的维度进行概率模型的建立即可，只要它实现了IRankable接口就可以使用这篇文章中的方法来随机抽取，这其实是一个业余时间的小项目啦，可我还是想让自己认真地考虑下这个问题，所以我花时间写了这篇文章，我对它的期望并没有太高，我喜欢将这些想法写下来而已。 小结&emsp;&emsp;或许有些时候我们对一个事情的态度，对事情最终的走向起不了决定性的作用，尤其是在我们没有掌握话语权的时候。可我在考虑这个方案的时候，是明显地意识到程序永远无法满足人类的脑洞的需要，所以当我们在做一件事情的时候，就应该有意识地让自己想到它可能会有扩展性上的需求，我认为这是我们在做项目开发过程中需要去关注的一个点，如何让你的代码具备扩展性和可维护性，虽然有时候你想得太多会造成过度设计，可是如果你在项目前期做出了一个糟糕的规划，到了后期遭遇项目需求变更的时候就会非常痛苦，可不幸的是我在最近同时遭遇了这两种情况，或许这就是我想要强迫自己写完这篇文章的原因吧，这篇文章足足花了我两周的时间，我的拖延症啊什么时候能好啊！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"概率","slug":"概率","permalink":"https://qinyuanpei.github.io/tags/%E6%A6%82%E7%8E%87/"},{"name":"数学","slug":"数学","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"算法","slug":"算法","permalink":"https://qinyuanpei.github.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"一见钟情，无疾而终","date":"2016-09-10T19:29:57.000Z","path":"posts/21112647/","text":"&emsp;&emsp;昨天下午，当她从公司办理完离职手续的时候，她在内部聊天工具上告诉我：“师父，我在公司的离职手续都办理完了，我要走了”。在那一瞬间，我突然非常平静地走过去对她说：“那就走吧”。我不知道她是不是想让我在她离开之前做些什么，或许这完全就是我的一厢情愿，因为她在此之前就明确地告诉我，她不喜欢我，所以这注定是一个悲伤的故事。一个月前，当她的同学从公司离职的时候，她就告诉我或许某一天她就离开这里了，当时我说我会想她的，而当她真正要离开的时候，我甚至都想不明白自己为什么会如此平静。下班路上同事Kent若有所思的告诉我，在我这个年龄“一见钟情”这种满足初恋情结的机会会越来越少，与其在感情的创伤中持续失落不如努力去争取一段新的开始。我惊诧于他突然间发现我隐藏在心底的秘密，我更加纠结于我丧失了喜欢一个人的能力。 &emsp;&emsp;我像是忽然间发现我在感情上的天赋基本为负值似的，从我开始喜欢她开始，在这个过程中我感觉自己非常自卑，甚至当我真正站在她面前的时候，我常常会变得非常笨拙以至于完全不知道要说什么，我和她说我在她面前的时候有点儿“怕”她，她回复给我一个笑脸说：你可是我师父啊。你知道吗？当一个男生接受女生“成为朋友”这种现实的时候，从某种意义上来讲，他是将对她的喜欢以一种新的方式重新输出，就像她不在公司里的时候，她愿意委托我帮她处理某些事情，这对我而言是非常开心的一个时刻，因为你永远都期待着，她在有事情的时候能够第一个想到你，即使她曾经拒绝过你两次，即使她明确告诉你她不喜欢你，我曾经告诉过自己，喜欢是占有而爱是克制，至少曾经有很多很多的瞬间，我们两个人因为坦露心声而变得非常开心，这是我最让我怀念的瞬间。 &emsp;&emsp;我承认我喜欢她是明显的“套路”感的，而我恰恰不是一个演技派，所以当我发现我在她面前变得笨拙的时候，我意识到我的情绪随时都可能因为她的一举一动而受到影响。我曾经因为她和某个男生一起而生她的闷气，可讽刺的是她告诉我在她心目中我比这个男生更受欢迎。同样地，这是一个悲剧的开始：你人挺好的，可我觉得我们不适合，我们还是继续做朋友吧！男人在年轻的时候，最难以接受而不得不接受的一个现实是，你非常喜欢一个人，可你此时此刻完全没有能力给她想要的生活，就像古古说她可能再遇不到我这样对她好的人，可她始终觉得我们两个人是没有未来的，而这一次，我忽然发现这一切是如此的相似，虽然我清楚地知道她们是完全不同的两个人，当她们同时对我说出“你会找到真正适合你的那个人”这句话的时候，我已无心分辨这句话的真假，我只知道我会陷入无休止的纠结，就像一个死循环导致的精神分裂。 &emsp;&emsp;我是一个双子座男生，虽然我不是特别相信星座这种东西，可是通过知乎上的相关问题，我意识到双重人格可能是每一个双子座的终身宿命。同事说我走路的时候身体前倾、双手呈合拢状态，我承认这是因为我受到阿什顿.库彻主演的乔布斯同名传记电影的影响，在某种程度上我是在刻意模仿他的动作，所以当时我戏诩地回答道：因为我是风一样的男子啊。可事实是，无论是她还是我，我们都像风一样彼此走进各自的生命历程，然后又像风一样遁迹于无形，可是这一切真实存在过不是吗？她说我无法控制情绪生闷气的时候显得挺逗比的，所以从那个时候开始，我决定学会管理情绪。可我时常对自己产生怀疑， 比如我怀疑我是不是一个不懂得聊天的人，比如我怀疑我是不是自从古古离开我以后就失去了爱人的能力，比如我怀疑是不是太专注于技术而忽略了更多技术以外的东西等等，事实上这些问题确实存在，当你喜欢上一个人以后，你会发现你更加你身上的缺点会在瞬间被方大，大概这是我在她面前自卑的原因吧！ &emsp;&emsp;所以双子座内心深处像是上帝打开了一扇新窗户，它是天使与魔鬼的结合。而更多的时候，我都被内心深处的两个灵魂左右者，我时常温柔、时常暴戾，就像阴晴不定的天气一样，我虽然讨厌这种严重分裂的性格，因为它常常让我在小事情上举棋不定，而一个成熟的男人是要学会当机立断的，可我同样知道，这是真实的我，不管它是好是坏，当你学会接受这一切的时候，你的灵魂和你的身体是完全同步的，所以这是我为什么讨厌虚伪的原因，因为它像藏在套子里的一个人你永远都不知道它哪一句话是真的。当你发现一个双子座男生对你忽冷忽热的时候，如果你信任他就让他自生自灭，当他安静下来像个孩子的时候，你会发现他的快乐和忧愁就像风一样转瞬即逝，所以我说：“我是风一样的男子”。而当他对你失去关注和热情的时候，他会使用最直接的话语告诉你他的真实想法，而这一切在我这里从来发生过，我希望所有被我这种阴晴不定的性格不经意间伤害过的朋友都能够原谅我，我从来都不是一个坏人，只是我的心里一直有两个人在打架。 &emsp;&emsp;当我此时此刻写这篇博客的时候，我常常问自己，我还喜欢她吗？我确认我依然喜欢她，尤其是当我知道，她年龄比我大1岁以及她拥有硕士学位，这样两个事实以后，我更多的纠结和痛苦是来自来自我的否定，我们常常说爱情一半靠缘分一半靠争取，可当你真正试图走进一个人的生活的时候，你是否认真地考虑过两个人的未来，因为我不想重蹈覆辙。喜欢一个人并没有错，关键是你如何让两个人的世界巧妙地融合为一个世界，我时常自卑因为我对未来还没有确定。我喜欢过的人永远都会在我心底占据一片地方，因为我有严重的依赖性和怀旧心理，我可以去经常去的地方吃同样的东西，我可以和经常遇见的人说同样的话，对我而言，忠诚度和稳定性比新鲜感更为重要。或许我在生活和情感上的的确确存在弱点，很多时候我主观意识薄弱，对待事物的态度随意而温和，这在女生心目中可能会变成没有主见吧，其实在这些小事情上我一直都不怎么上心的，或许我需要改变吧！ &emsp;&emsp;昨天晚上，不知道为什么突然特别难过，或许是因为被同事说中心事，或许是因为想到我喜欢过的女孩而心存不甘，或许是因为憎恶现在这个状态的自己……总而言之，有那么一瞬间我感到我的心像是被挖去了一块，原来喜欢一个人可以让我如此难过，想到种种过往我以为自己会泣不成声，结果我声音哽咽着眼睛却是干的，或许我们最喜欢使用的那个“破涕为笑”的表情最能形容我当时的心境，我想了很久，一个人跑出去散步，当风轻轻地划过我的脸庞的时候，当秋天的寒意让我猝不及防的时候，我忽然觉得，当这个世界越发地充满“恶意”的时候，你更需要一个坚强地理由去生活，她们都教会我很多，和这个相比，悲伤和痛苦都显得微不足道，我想努力学好英语、我想努力练习写字、我想努力培养兴趣、我想努力克服恐惧，我是一个骄傲的人，在技术上是在生活上更应该是，如果我不能像编程一样掌控世界，我愿意在这纷繁的世界里不忘初心，喜欢和爱这种美好的情感，是不该让悲伤来消化的奢侈品。对未来的期望是让我变得优秀，如果在感情问题上做不了演技派，那我只好选择本色出演，真诚比套路更重要。 &emsp;&emsp;下午坐公交回来的时候，看着窗外像风一样飞驰的风景，我的思绪越飘越远，我不知道我想要表达什么，在那一刻我突然很想给她写一首诗，当别的女孩儿嫉妒我对她如宠溺一般的耐心时，我常常告诉她们，我曾经有一个不笨的徒弟，即使各种羡慕嫉妒恨，可我想说，这是我的心自己选择的啊，我不过是遵从它的意志，让这一切变得温暖美好起来： 你像一阵风/我伸开手抓到的只有/花落后的芬芳我离你/时而很近/时而很远像天上的云/舒卷成蝶我不想去采摘它啊月亮静待着它怒放我愿意守护它一刻即使它一直当月亮是太阳 2016年9月10日 Payne","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"},{"name":"成长","slug":"成长","permalink":"https://qinyuanpei.github.io/tags/%E6%88%90%E9%95%BF/"},{"name":"爱情","slug":"爱情","permalink":"https://qinyuanpei.github.io/tags/%E7%88%B1%E6%83%85/"}]},{"title":"浅析WPF中MVVM模式下命令与委托的关系","date":"2016-07-21T14:27:07.000Z","path":"posts/569337285/","text":"&emsp;&emsp;各位朋友大家好，我是Payne，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。最近因为项目上的原因开始接触WPF，或许这样一个在现在来讲显得过时的东西，我猜大家不会有兴趣去了解，可是你不会明白对某些保守的项目来讲，安全性比先进性更为重要，所以当你发现银行这类机构还在使用各种“复古”的软件系统的时候，你应该相信这类东西的确有它们存在的意义。与此同时，你会更加深刻地明白一个道理：技术是否先进性和其流行程度本身并无直接联系。由此我们可以推论出：一项不流行的技术不一定是因为它本身技术不先进，或许仅仅是因为它无法满足商业化的需求而已。我这里的确是在说WPF,MVVM思想最早由WPF提出，然而其发扬光大却是因为前端领域近年来比较热的AngularJS和Vue.js，我们这里表达的一个观点是：很多你以为非常新潮的概念，或许仅仅是被人们重新赋予了新的名字，当你理清这一切的来龙去脉以后，你会发现这一切并没有什么不同。这符合我一贯的主张：去发现问题的实质、不要被框架束缚、通过共性来消除差异，所以在今天这篇文章里，我想说说WPF中MVVM模式下命令与委托的关系。 什么是MVVM?&emsp;&emsp;既然提及MVVM，那么我们就无可避免的需要知道什么是MVVM。我们在本文开篇已经提到，MVVM这个概念最早由微软提出，具体来讲是由微软架构师John Gossman提出的。我个人更喜欢通过将MVC、MVP和MVVM这三者横向对比的方式来加强理解，因为这从某种意义上来讲，这是一个逐步改进和演化的过程。我们常常谈及软件的三层架构，我们常常对MVC耳濡目染以致将其神化，可事实上它们是某种在思想上无限接近的理念而已。 MVC模式示意图 &emsp;&emsp;首先，我们从最简单的MVC开始说起，作为最常用的软件架构之一，我们可以从上面的图示中看到，MVC其实是非常简单的一个概念，它由模型(Model)、视图(View)和控制器(Controller)三部分组成，建立在一个单向流动的通信基础上，即View通知Controller响应用户请求，Controller在接到View的通知后会更新Model内的数据，然后Model会将新的数据反馈给View。我们发现这个设计可以使软件工程中的关注点分离，我们注意到通过MVC模式，我们实现了视图和模型的分离，通过控制器这个胶水层让两者间接联系起来，所以MVC的优点是让各个模块更好的协作。那么，它的缺点是什么呢？显然，视图和控制器是高度耦合的，因为控制器中无可避免地要访问视图内的元素，所以控制器注定无法在这尘世间独善其身。要知道最早的MVC架构是基于观察者模式实现的，即当Model发生变化时会同时通知View和Controller，所以我们很快就可以认识到：我们从古至今的所有努力，都是为了让视图和模型彼此分离，我们在这条路上越走越远，幸运的是一直都不忘初心。 MVP模式示意图 &emsp;&emsp;接下来，我们为了彻底地让视图和模型分离，我们发明了新的软件架构：MVP。虽然从感性的认识上来讲，它是将Controller改名为Presenter，然而从理性的认识上来讲，它在让视图和模型分离这件事情上做得更为决绝果断。通过图示我们可以发现，视图和模型不再发生直接联系，它们都通过Presenter相互联系，而且各个部分间的通信都变成了双向流动。我们可以很快意识到，现在全新的控制器即Presenter会变得越来越“重”，因为所有的逻辑都在这里，而视图会变得越来越“轻”，它不再需要主动去获取模型提供的数据，它将被动地接拥抱变化，因为现在在视图里基本上没有任何业务逻辑。现在我们可以预见，人类会在隔绝视图和模型这件事情上乘胜追击，人们会尝试让Controller/Presenter/ViewModel变得越来越臃肿，我想说的是，求它们在得知这一切真相时的心理阴影面积，我们试图让每一个模块各司其职、通力协作，结果脏活累活儿都交给了Controller/Presenter/ViewModel，我想说这件事情做的真是漂亮。 MVVM模式示意图 &emsp;&emsp;历史总是如此的相似，人类在作死的道路上匍匐前进，继续发扬改名的优良传统，这一次是Presenter被改名为ViewModel，在命名这件事情上，我认为程序员都是有某种强迫症因素在里面的，所以当你发现一个事物以一个新的名字出现在你的视野中的时候，通常它会有两种不同的结局，第一，陈酒换新瓶，我们贩卖的不是酒是情怀；第二，看今天的你我怎样重复昨天的故事，我这张旧船票还能否登上你的客船。幸运的是，MVVM相对MVP的确发生了些许改变，一个重要的特性是双向绑定，View的变化将自动反映在ViewModel中，而显然ViewModel是一个为View打造的Model，它可以容纳更多的普通的Model，因此从某种意义上来说，ViewModel依然作为连接View和Model的桥梁而出现，它是对View的一种抽象，而抽象有两层含义，即数据(Property)和行为(Command)，一旦你明白了这一点，ViewModel无非是一个特殊而普通的类而已，特殊是因为它需要实现INotifyPropertyChanged接口，普通是因为它继承了面向对象编程(OOP)的基本思想。 更像MVC的MVVM&emsp;&emsp;到现在为止，我们基本上理解了MVC、MVP和MVVM这三者间的联系和区别，可是这样真的就是最好的结果吗？我们首先来思考一个问题，即什么样的代码应该写在控制器里。比如我们在对项目进行分层的时候，到底应该让控制器负责哪些任务？我们可以让Controller处理单独的路由，同样可以让Controller参与视图逻辑，甚至我们在编写Model的时候，我们可以有两种不同的选择，第一，编写一个简单的数据聚合实体，具体逻辑都交给控制器来处理，我们将这种方式称为贫血模型；第二，编写一个持有行为的数据聚合实体，控制器在业务逻辑中调用这些方法，我们将这种方式称为充血模型。所以，在这里我们纠结的地方，其实是选择让控制器更“重”还是让模型更“重”，我曾经接触过1年左右的Android开发，我认为Android工程是一个相对符合MVC架构的设计，可是我们难免会发现，作为控制器的Activity中的代码非常臃肿，因为我们在这里需要和视图、模型关联起来，所以综合现有的这些软件架构思想，我们发现模型和视图相对来讲都是可以复用的，可是作为连接这两者的Controller/Presenter/ViewModel是非常臃肿而且难以复用的，所以我怀疑我们是否是在真正的使用MVVM。 &emsp;&emsp;我不知道MVVM架构正确的使用方法是什么样的，因为这是我第一次接触到这样一个新的概念，就如同很多年前，我在学校图书馆里看到的一本讲Web开发的书中描写的那样：当我们不了解MVC的时候，我们理所当然地认为通过文件夹将项目划分为Model、View、Controller，这样好像就是MVC啦。可是事实真的是这样吗？以我目前公司项目的情况而已，我认为它更像是使用了双向绑定的MVC，因为你经常可以在ViewModel中看到，某个属性的Get访问器中各种被if-else折磨的“脏”代码，而在ViewModel中我基本上看不到Model的身影，并且因为使用了Binding的概念严重弱化了ViewModel作为类的基本属性，因此它没有构造函数、没有初始化，我们可以在Get访问器中看到各种硬编码，因为视图上的需求经常变动，所以当整个项目结束的时候，我本人是非常不愿意去看ViewModel这部分的代码的，因为项目上要求避免写Code-Behind代码，所以大量的事件被Command和UIEventToCommand代替，这样让ViewModel变得更“重”了。原本我们希望的是让这三者各司其职，结果现在脏活累活儿全部变成了ViewModel一个人的。虽然双向绑定可以避免去写大量赋值语句，可是我知道ViewModel内心深处会表示：宝宝心里苦。 &emsp;&emsp;如果说WPF对技术圈最大的贡献，我认为这个贡献不在双向绑定，而是它真正意义上实现了设计和编程分离，我们必须承认设计和编程都是一项创造性活动，前者趋向感性，而后者趋向理想，在没有实现这两者分离的时候，程序员需要花费大量时间去还原设计师的设计，可是对程序员来讲，一段程序有没有界面设计在某些场合下是完全不重要的，在没有界面设计的情况下，我们可以通过单元测试来测试代码的可靠程度，相反地在有了界面设计以后我们反而不容易做到这一点，所以你问我WPF对技术圈最大的贡献是什么，我会回答它解放了程序员，可以让理性思维去做理性思维更适合的事情。我不太喜欢声明式编程，这里是指WPF中XAML这种继承自XML的标记语言，因为Visual Studio对XAML没有提供调试的支持，所以当你发现视图显示出现问题的时候，你很难分清楚是前台视图绑定出现错误还是后台ViewModel出现错误，只要你输入符合XML规范的内容程序都会编译通过而非引发异常，因为它是用反射所以性能问题广为人所诟病，其次ViewModel中通知前台属性发生变化时需要使用OnPropertyChanged，该方法需要传入一个字符串类型的值，通常是指属性的名称，可是如果你定义了一个字符串类型的属性，当你在这里传入这个属性的时候，因为它是字符串类型所以不会引发编译错误，可是我觉得这个东西还是比较坑。 委托与命令&emsp;&emsp;好了，现在我想说说WPF中的命令和委托，事实上在我计划写这篇文章前，我对这里无比好奇，可当我发现这东西的实质以后，我忽然觉得花费如此大的篇幅来讲解这样一个概念，这是不是会显得特别无聊。我们的项目上使用的是一个叫做MVVM light的框架，当然我们没有使用它的全部功能，公司的前辈们非常猥琐地从这个开源项目中挑了些源代码出来，这里我不想提及关于这个框架本身地相关细节，因为我认为理解问题的实质比学会一个框架更加重要。首先，WPF为每一个控件都提供了一个Command的依赖属性，因为任何实现了ICommand接口的类都可以通过绑定的方式和前台关联起来，我们这里对比下命令和路由事件的区别可以发现，路由事件必须写在Code-Behind代码中，而命令可以写在ViewModel里，所以直观上来讲命令更加自由灵活。下面我们以一个简单的例子来剖析这两者间的关系。 &emsp;&emsp;我们知道使用Command需要实现ICommand接口，所以实现起来是相对容易的，我们这里继续沿用MVVM light中的RelayCommand这个名字： 1234567891011121314151617181920212223242526272829303132333435public class RelayCommand : ICommand&#123; private readonly Action&lt;object&gt; m_execute; private readonly Predicate&lt;object&gt; m_canExecute; public RelayCommand(Action&lt;object&gt; execute) &#123; this.m_execute = execute; &#125; public RelayCommand(Action&lt;object&gt; execute, Predicate&lt;object&gt; canExecute) &#123; this.m_execute = execute; this.m_canExecute = canExecute; &#125; public bool CanExecute(object parameter) &#123; if (m_canExecute == null) return true; return m_canExecute(parameter); &#125; public event EventHandler CanExecuteChanged &#123; add &#123; CommandManager.RequerySuggested += value; &#125; remove &#123; CommandManager.RequerySuggested -= value; &#125; &#125; public void Execute(object parameter) &#123; this.m_execute(parameter); &#125;&#125; 我们可以看到这里有两个重要的方法，Execute和CanExecute，前者是一个void类型的方法，后者是一个bool类型的方法。当我们需要判断控件是否应该执行某一个过程的时候，CanExecute这个方法就可以帮助我们完成判断，而Execute方法显然是执行某一个过程的方法，可以注意到通过委托我们让调用者更加自由和灵活地传入一个方法，这是我喜欢这种设计的一个地方，因为我的一位同事就对普通的路由事件表示无法理解。 &emsp;&emsp;这里需要说明的是CanExecuteChanged这个事件，这个和INotifyPropertyChanged接口中的PropertyChanged成员类似，是在当CanExecute发生变化的时候通知视图的，我对这里的理解是CanExecute本身就具备对某一个过程是否应该被执行的支持，可是遗憾的是在，在我参与的项目中，人们更喜欢声明大量的布尔类型变量来处理这里的相关逻辑，因此无论是对Property还是Command而言，在ViewModel里都是看起来非常丑陋的代码实现。 &emsp;&emsp;好了，现在对我们而言，这是一个非常愉快的旅程，因为在完成对RelayCommand的定义以后，我们绑定命令和定义命令的过程是非常简单的。除此以外，WPF提供了一个RoutedCommand类，该类实现了ICommand接口，我怀疑MVVM light中的EventToCommand正是通过这种思路实现了路由事件到命令的转换，因为只有RoutedCommand具备访问UI事件的能力，这里我们仅仅提出问题，进一步的思考和验证我们可以留到以后去做。下面我们来看看如何声明和绑定命令： 12345678910public RelayCommand ClickCommand&#123; get &#123; return new RelayCommand((arg)=&gt; &#123; MessageBox.Show(\"Click\"); &#125;); &#125;&#125; 显然这个ClickCommand将作为一个属性出现在ViewModel中，我选择了一个我最喜欢用的方法，或许这样看起来非常低端。可是在调试界面的过程中，它要比断点调试更为直接和直观。当我们的ViewModel中出现这样的只读属性的时候，直接在Get访问器中定义它的返回值似乎是最直接有效的方案，可问题是Get访问器应该是非常“轻”的，因为大量业务逻辑的渗透，现在连这里都不能保留其纯粹性了吗？这让我表示非常郁闷啊。 123456789&lt;Window x:Class=\"WPFLearning.Window1\" xmlns=\"http://schemas.microsoft.com/winfx/2006/xaml/presentation\" xmlns:x=\"http://schemas.microsoft.com/winfx/2006/xaml\" Title=\"Window\" Height=\"300\" Width=\"300\"&gt; &lt;Grid&gt; &lt;Button Content=\"Button\" HorizontalAlignment=\"Center\" VerticalAlignment=\"Center\" Command=\"&#123;Binding ClickCommand &#125;\"/&gt; &lt;/Grid&gt;&lt;/Window&gt; 现在你可以发现，委托和命令结合得非常好，当你发现这一切如此美妙的时候，回归本质或许是我们最喜欢的事情，就像纯粹的你我一样，在这个世界上，我们彼此装点着各自生命里美好的风景，执著而勇敢、温暖而明媚，那些周而复始的日子里，总能听到梦想开花的声音。 小结&emsp;&emsp;在这篇文章里我们讨论了MVC、MVP、MVVM各自架构变迁的前因后果，由此我们知道了软件设计中，一个典型的设计目标是让视图和模型分离，可我们同样发现，带着这个目标去设计软件的时候，我们基本鲜有更换视图的时候，虽然从理论上来讲，所有的业务逻辑都是在ViewModel中，视图和模型应该是可以进行更换的，可是你告诉我，有谁会为同一个软件制作不同的界面呢？难道我们还能期望通过一个静态工厂，来为不同的平台返回不同的视图，然后理论上只要适配正确的控制器就可以实现软件对不同平台的“自适应”，可是软件开发领域发展至今，最有可能提供完整跨平台方案的Web技术目前都无法满足这个需求，所以我们是否应该去怀疑这个设计的正确性呢？同样的，以Java的SSH三大框架为代表的“配置文件”流派，认为应该将数据库的相关信息写在配置文件里，这样可以满足我们随时切换到不同数据库产品上的需要，可是你告诉我，这样的应用场景多吗？所以，技术本身的设计并没有问题，我们需要思考的是，是否应该被框架和架构束缚，说到底我们是为了设计出更棒的软件产品，以此为目标，其实框架和架构更应该衍生为一种哲学意义上的思想，我们想让每一行代码都充满智慧的光芒，它骄傲却不孤独，因为总有人理解它、懂它。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"MVVM","slug":"MVVM","permalink":"https://qinyuanpei.github.io/tags/MVVM/"},{"name":"委托","slug":"委托","permalink":"https://qinyuanpei.github.io/tags/%E5%A7%94%E6%89%98/"},{"name":"命令","slug":"命令","permalink":"https://qinyuanpei.github.io/tags/%E5%91%BD%E4%BB%A4/"}]},{"title":"在Unity3D中使用uGUI实现3D旋转特效","date":"2016-07-10T14:29:33.000Z","path":"posts/1150143610/","text":"&emsp;&emsp;各位朋友大家好，欢迎大家关注我的博客，我是Payne，我的博客地址是http://qinyuanpei.com。最近一位朋友问我，如何在Unity引擎中实现类似《英雄联盟》中选择皮肤时的3D滚动视图效果，虽然我非常不喜欢这个游戏，可是大学四年在宿舍里被周围同学们耳濡目染，对这个游戏中常见英雄的口头禅还是颇为熟悉的，曾经在周围同学的“硝烟”和“噪杂”中熬夜编程，此时此刻想起来大概是最能让我怀念和骄傲的记忆了。剑圣说“你的剑就是我的剑”，伊泽瑞尔说“是时候表演真正的技术了”，杰斯说“为了更美好的明天而战”……或许曾经的某一瞬间，我们曾经有过类似的让你我疯狂着迷的人生信条，可是不管怎样，我希望我们可以将这些永远地铭刻在心里，如同心中栽种下一棵红莲，在黑夜中静静地等待开放，这样当此去经年亦或时过境迁的时候，我们不会说是时光抹去了你我年轻的棱角，因为我相信真正的棱角会因为磨砺而变得更加明亮，绝对不会因为此刻的苟且就变的麻木甚至迷茫。好了，喝完我这碗心灵鸡汤，下面我们来一起学习如何在Unity3D中使用uGUI实现3D滚动视图效果。 需求分析&emsp;&emsp;首先，我们先来对这个需求进行分析，从这篇文章的题目我们获得的一个关键信息是，希望通过某种方式实现3D滚动特效。因此我们首先要解决的一个问题是，我们应该采用2D方式来实现还是采用3D方式来实现这种界面效果。我们假定这里希望实现的效果如下图所示，我们可以注意到从这张图片的设计初衷来看，它更像是一种介绍产品特性的文案设计，我们这里仅仅是想通过这张图告诉大家，我们需要实现一个什么样的效果。软件开发过程中最大的成本在我看来主要来自沟通。因为事实上对普通用户而言技术并不重要，重要的是能否实现用户想要的功能，可是大部分情形是用户并不知道自己想要什么，除非你将实际的产品放到用户眼前甚至手中。好了，在对需求有了一个基本的印象以后，我们来思考如何实现这个需求。 &emsp;&emsp;具体来讲，我们有两种思路： 其一是采用真实的3D来制作，即我们通过一个圆柱体或者是多棱柱将图片”粘贴”在不同的面上，通过对圆柱体或者多棱柱进行旋转，然后以真实的3D的形式来呈现给用户。 其二是采用伪3D来制作，即我们通过在2D平面内对图片的层次进行合理化调整实现伪3D效果，配合插值、缩放等技巧来实现2D平面上的旋转，然后给用户一种视觉上的3D效果。 需求设定 核心原理&emsp;&emsp;在这里我们选择采用伪3D来制作，为什么选择这种方案呢？因为它简单啊，哈哈。好了，我们现在将实际的需求进行抽象，我们会发现什么呢？我们注意到这本质上是一个曲线问题，我们可以将每个图片的中心用平滑的曲线连接起来，然后我们就得到了一条抛物线或者是圆锥曲线或者是贝塞尔曲线，在这里我们将其理解为什么样的曲线并不重要，因为这最终影响到的是曲线的平滑度问题，即细节上的调整。沿着这个思路，我们就意识到，这是一个根据曲线平均分布坐标点的过程，假设我们这里5张图片，并且曲线在中间位置可以找到一条垂直的对称轴，那么我们只需要将这5个点在水平方向上平均分布即可，事实上根据人类视觉的特点，这个距离应该是越来越小的，就像我们看到的一排并列的树木，越远的地方它们的间距会越来越小，而事实上它们的间距是一样的，根据这个特性我们可以表现出这种视觉上的纵深的感觉，在实际项目中它取决于美术设定和策划设定，我们这里就从最简单的情况开始分析。 &emsp;&emsp;好了，在解决了精灵放置的这个问题以后，我们接下来要解决的是什么呢？答案是精灵的层级，因为层级能够帮助我们营造一种视觉上的层次感和立体感，比如在跑酷游戏中我们常常使用视差滚动这种技术来表现3D效果，以及传统的斜45度瓦片地图来实现2.5D效果都是使用2D来模拟3D效果的经典案例。所以在这里除了确定每个精灵的放置位置以外，我们还有一个问题，如何对这些精灵进行排序，所幸的是在uGUI中我们可以通过SetSiblingIndex方法来设置一个精灵的深度，当每次通过按钮切换精灵的时候，我们都需要对所有精灵重新计算坐标和深度，而为了更好的视觉表现力，我们可以在切换的时候做一个简单的位移动画，至此我们就可以开始动手实现功能啦。 具体实现&emsp;&emsp;首先我们来搭建一个基本的场景，我们这里将一切浮华褪尽，我们可以看到在场景中有两个按钮，它们可以让我们当前选中的卡片，而界面底部的标签会显示我们当前选择的角色名称。虽然在这里采用触屏滑动的效果更好，可我们这里主要的目的是为了说明如何实现我们的思路，当引入这部分功能的设计以后，会增加大家在整体理解上的难度，所以我们这里以快速实现功能为主。注意到场景中的卡片此时都是相当“任性”地放置在界面上，这是因为我们稍后会采用算法计算每个卡片的实际位置，所以在这里完全可以忽略其“美观性”。 场景展示 &emsp;&emsp;这里，我们设定场景的大小为800x460，那么在这种情况下，我们可以按照下面图中所示的曲线轨迹来构造一条曲线，考虑到椭圆方程比贝塞尔曲线更加简单易用，所以我们这里选择椭圆方程来作为场景中这些卡片排列的曲线方程。 曲线方程 &emsp;&emsp;此时以屏幕中心为原点构建平面直角坐标系，则这个椭圆是一个以长轴2A=400、短轴2B=640、中心在(0,320)上的椭圆。根据这个原理，我们可以将其代码实现分为三个步骤来实现。首先，我们将场景中的所有卡片存储在GameObject数组中，这里我们这里规定卡片的数目必须为奇数，然后我们从左到右依次计算每个卡片的位置和深度，这样就可以让卡片按照我们期望的方式进行排列啦。下面一起来看代码如何实现： 123456789101112//初始化精灵数组int childCount = transform.childCount;//计算两侧精灵数目halfSize = (childCount-1)/2;//初始化精灵sprites = new GameObject[childCount];for(int i=0;i&lt;childCount;i++)&#123; sprites[i] = transform.GetChild(i).gameObject; SetPosition(i); SetDeepin(i);&#125; 这里sprites显然是一个GameObject[],因为卡片的数目为奇数个，所以halfSize是指中间位置卡片的索引，这里需要两个辅助方法，SetPosition和SetDeepin，从名字我们就知道这两个方法分别是设置卡片位置和设置卡片深度。当我们提到代码注释的时候，好多人以代码自注释为理解逃避注释，孰不知这建立在命名规范的基础上，如果你连这点基本的要求都做不到，我建议你还是多写点注释、少写点代码。好了，这两个方法的实现细节如下： 1234567891011121314151617181920212223/// &lt;summary&gt;/// 设置精灵位置/// &lt;/summary&gt;private void SetPosition(int index)&#123; //计算第index个精灵的角度 float angle = 0.0f; if (index &lt; halfSize) &#123; angle = startAngle - (halfSize - index) * DeltaAngle; &#125; else if (index &gt; halfSize) &#123; angle = startAngle + (index - halfSize) * DeltaAngle; &#125; else &#123; angle = startAngle; &#125; //计算第index个精灵的坐标 float x = A* Mathf.Cos((angle/180) * Mathf.PI) + Center.x; float y = B* Mathf.Sin((angle/180) * Mathf.PI) + Center.y; Vector3 v3 = Camera.main.WorldToScreenPoint(new Vector3(x,y,0)); v3 = Camera.main.ScreenToWorldPoint(v3); Vector2 v2 = new Vector2(v3.x,v3.y); sprites[index].GetComponent&lt;RectTransform&gt;().anchoredPosition = v2;&#125; 可以注意到，在这里我们根据精灵索引index和两侧精灵数目halfSize的关系，按照DeltaAngle这个增量来计算每个精灵实际的角度，在此基础上结合椭圆的参数方程，我们可以非常容易地计算出每个精灵实际的位置，这样就可以保证精灵中心都在椭圆曲线上。好了，接下来我们会遇到一个新的问题，这些精灵的层级应该是从中间位置向两边依次递减的，所以为了解决这个问题，我们还需要对每个精灵的层级进行计算，这部分代码的实现细节如下： 12345678910111213141516/// &lt;summary&gt;/// 设置精灵深度/// &lt;/summary&gt;private void SetDeepin(int index)&#123; //计算精灵深度 int deepin = 0; if(index&lt;halfSize)&#123; deepin = index; &#125;else if(index&gt;halfSize)&#123; deepin = sprites.Length-(1+index); &#125;else&#123; deepin = halfSize; &#125; sprites[index].GetComponent&lt;RectTransform&gt;().SetSiblingIndex(deepin);&#125; 事实上，我在这里并不清楚SetSiblingIndex这个方法的真正作用:)，可是它的确能够实现我们想要的功能。有时候在维护一个古老的项目的时候，可能你会在代码中看到各种有趣的注释，而这些注释中有相当一些都充满了一种“形而上学”的味道在里面，我们不知道这个世界为什么会是这样，可是看起来它们都运行地非常良好。或许这就是这个世界的奇妙之处，无论我们是否想要尝试打破这些规则，这个世界上总是有些我们难以理解的东西存在，可是存在即合理，不是吗？理性思维的缺陷在于想要为一切问题找到一个答案，所以这次苏格拉没有底，我们就感性一次又何妨呢，这个问题就让它没有答案吧！ &emsp;&emsp;现在，显然我们需要解决一个新的问题，就像上帝在我们关上一扇门的同时，会为我们开启一扇窗口。理论上任何问题都可以通过引入一个中间层来解决，而引入中间层的同时毫无疑问地引入了一个新的问题。在这里我们已经完成了让所有精灵按照椭圆曲线进行排布以及精灵的层级关系这两个问题，可是我们这是一个静态的过程啊，我们需要的是让它能够滚动起来，所以怎么解决这个问题呢？我们可以注意到的一点是，精灵的这种“滚动”效果，实际上是将数组中的第一个元素sprites[0]或者最后一个元素sprites[sprites.Length-1]，依次和数组中的第i个元素进行交换。比如精灵整体向右侧“滚动”，我们只需要从第一个元素开始依次和最后一个元素进行交换就可以啦，所以这里的实现实际上是： 12345678910111213141516171819/// &lt;summary&gt;/// 向后翻页/// &lt;/summary&gt;public void OnNext()&#123; int length = sprites.Length; for(int i=0;i&lt;length;i++) &#123; GameObject temp = sprites[i]; sprites[i] = sprites[length-1]; sprites[length-1] = temp; &#125; for(int i=0;i&lt;length;i++) &#123; SetPosition(i); SetDeepin(i); &#125;&#125; 我们在对数组内的元素重新组织后，需要重新计算每个精灵的位置和深度。我这里在思考的一个问题是：精灵的位置和深度实际上是确定的，所以我们可以考虑将它们存储起来“复用”，这样可以减少每次的重复计算。其实，代码的优化和重构是一个需要时间来酝酿的过程，没有人能够在写代码的时候，就可以意识到代码中的瑕疵，而这种发现问题的眼光通常需要长时间的培养，这是我们之所以提倡不要过早优化的原因，除非你能够快速地找到代码中的优化点。好了，现在采用类似的思路，我们可以实现向前翻页的逻辑啦，这里的代码非常简单不再赘述。 &emsp;&emsp;好了，现在我们可以看看到目前为止我们实现了一个怎样的功能吧！ 效果展示 其实这篇文章我还想继续再往下写的，可是因为我比较懒一直拖着不写，以及接下来相当多的内容都是和界面相关的东西，所以我决定这篇文章就暂时写到这里，目前这个方案可以实现一个简单的“3D”滚动的效果，按照这个思路，接下来我们要做的事情是让滚动更加平滑以及支持鼠标或者触屏操作，毕竟这个需求的出发点是来自一个游戏，所以我们可以考虑在“滚动”的时候增加插值特性，与此同时，为了让它更加具有“3D”的感觉，可以在设置精灵层级的时候为不同的精灵设置不同的缩放比例，这样会更加符合美术中的透视关系，效果应该会更好吧！我认识的一位朋友使用uGUI中原生控件ScrollRect实现了类似的功能，感觉她还是非常厉害的啊，果然我不再从事Unity开发以后，我在这块的技术完全跟不上整个技术圈的节奏啊。 小结&emsp;&emsp;本文介绍了一种基于曲线方程来构建伪3D效果的思路，主要借助椭圆的参数方程来计算精灵位置，使其实现按照椭圆曲线进行排布的效果，在此基础上配合层级调整、插值、缩放等技巧，在一定程度上可以实现2D平面内的伪3D旋转效果。因为博主身患拖延症晚期，所以这篇文章在拖延了很久以后，终于成功的成为了一个没有填完的坑，不过我相信掌握原理比获取代码更为重要，所以这篇文章更多的是希望能给大家提供相关思路，博主在这篇文章中没有实现的功能，各位读者有兴趣的话可以考虑自行实现，写完这篇文章表示心好累，好了，就这样吧,各位晚安！","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"uGUI","slug":"uGUI","permalink":"https://qinyuanpei.github.io/tags/uGUI/"}]},{"title":"Unity3D游戏开发之在uGUI中使用不规则精灵制作按钮","date":"2016-07-08T21:58:39.000Z","path":"posts/1190622881/","text":"&emsp;&emsp;各位朋友大家好，欢迎关注我的博客，我的博客地址是http://www.qinyuanpei.com。最近因为受到工作上业务因素影响，所以博主在Unity引擎上的研究有所停滞。虽然目前的工作内容和Unity3D没有直接的关联，可是我觉得工程师应该有这样一种情怀，即工作和兴趣是完全不同的两个概念。编程对我而言，首先是一种兴趣，其次是一份工作。所以我宁愿在每天下班以后继续研究自己感兴趣的东西，而非为了取悦这个世界、为了加班而加班。最近广电总局让整个游戏行业都坐立不安了，因为其新发布的一系列规定，让中国的独立游戏开发者怨声载道。可是我们更应该看到积极的一面是，无数的小游戏公司会在最近数月内大量消失，或许对中国野蛮生长的游戏行业这是一次“形式”上的整顿，可对我们开发者来说，在这个过程中努力提升自我、巩固基础永远比追求时髦、流行的技术或者框架有意义的多，因为热闹的从来都是昙花一现般的璀璨，而永恒的永远都是历久弥新的真理。好了，闲言少叙，今天我们的话题是在uGUI中使用不规则精灵制作按钮。 从用户体验说起&emsp;&emsp;我们都知道在现代应用程序设计中，用户体验(UX)和用户界面(UI)是两个非常重要的内容。为什么用户体验(UX)和用户界面(UI)会显得如此重要呢？这是因为从普通用户的角度来讲，用户界面(UI)是其接触到一个产品时最先看到的最直观的东西，而在这个过程中产生的直观感受就是用户体验(UX)，所以说到底这是一个产品给用户的“第一印象”。 UX和UI &emsp;&emsp;最近百度UE总监刘超在IXDC峰会上的演讲引起了大家的关注，抛开百度在人才选拔机制中存在的问题以及刘超本人在设计领域是否具备专业能力这两个问题，这件事情真正让大家吐槽的是什么呢？答案是用户体验。虽然IXDC并非国际级别的大型会议，但是我相信大家组织这样的活动，其本意是为了探讨交互、设计领域内的新方法和新思维，因为随着互联网行业的发展，交互和设计这个领域越来越被人们所关注，所以在这样一个场合下，当与会嘉宾都在试图向人们输出干货的时候，刘超以一个非常糟糕的“用户体验”来给大家讲什么是用户体验，这件事情起源自刘超的一个个人行为，结果牵一发而动全身，最终升级为百度继“魏则西事件”以后的又一次公关危机。 什么叫设计 &emsp;&emsp;我到底想说什么呢？我说的本质上就是用户体验的问题，在这个事件中，刘超穿着上的不得体(短裤搭配拖鞋?)、PPT制作的粗制滥造(校招时所用修改)、演讲过程的敷衍糊弄(说相声、猜谜语)等因素，让刘超在与会者心目中的地位瞬间滑落到冰点，进而引发人们对百度在交互设计领域内的能力的怀疑，联想到百度最近这些年内出现的问题，这件事情难免会被人作为指责百度这家企业价值观问题，我想这是这个事情为什么会让大家如此关注的一个原因吧。 WTF! &emsp;&emsp;那么，我们说这些到底和今天的主题有什么关系呢？我想说这当然有关系啊，因为我们提出的这个问题就是一个用户体验的问题。我们知道游戏行业对美术资源高度依赖，不管是2D游戏还是3D游戏，一个项目组中前期主要的工作量其实都在美术这边，虽然不同的游戏引擎、GUI框架都为我们提供了标准的控件样式，然而在这样一个注重多样性的时代，默认样式、系统字体都会让人觉得这个产品缺乏新意，因此这种要求体现在游戏项目中就变成了，我们使用大量的图片资源来解决界面和字体的问题。 &emsp;&emsp;例如，我们通常使用BMFont来制作位图字体，这是为了同时满足字体的多样性和资源的容量这两个要求。再比如我们在使用cocos2d-x和Unity3D引擎开发游戏的时候，我们将大量的时间花费在了UI的制作上，这一切的一切从本质上来讲都是为了提升产品的童虎体验。这样我们就会遇到一个问题，UI中的按钮默认情况下都是规则的矩形，而实际上美术提供的素材常常是不规则的，因此如果继续使用以矩形为标准的这套机制，在实际使用中可能出现“用户点击在不该响应的区域结果程序响应了用户操作”这样的问题，为了解决这个问题，提升这一点点细微的用户体验，我们需要花费时间和精力来了解下面这些内容。 两种不同的方案&emsp;&emsp;目前，关于这个问题如何，解决通过搜索引擎我们能找到两种不同的方案： 多边形碰撞器: 该方法是指给精灵(Sprite)添加一个多边形碰撞器(Rolygon Collider)组件，利用该组件来标记精灵的边界，这样通过比较鼠标位置和边界可以判断点击是否发生在精灵内部。这种方法的详细说明可以参考宣雨松的这篇文章：UGUI研究院之不规则按钮的响应区域（十四） 精灵像素检测: 该方法是指通过读取精灵(Sprite)在某一点的像素值(RGBA)，如果该点的像素值中的Alpha&lt;0.5则表示该点处是透明的，即用户点击的位置在精灵边界以外，否则用户点击的位置在精灵边界内部。这种方法的详细说明可以参考这里 多边形碰撞器&emsp;&emsp;多边形碰撞器这种方案从本质上来讲，其核心思路是验证某一点是否在任意多边形内部，因为在这里RolygonCollider2D组件的作用体现在：第一，它可以在编辑器下进行可视化编辑对用户友好；第二，它可以在帮助我们标记精灵边界的同时保留顶点信息。所以在这里RolygonCollider2D组件相当于为我们提供任意多边形的顶点信息，而接下来我们要做是将鼠标位置转化为屏幕坐标，这样我们就获得了某一点的坐标。整体思路看起来是没有问题的，但我个人以及网友AwayMe都认为宣雨松这个算法存在问题，具体的理由如下： 1、uGUI中的元素采用的是以屏幕中心为原点(0,0)的平面直角坐标系，而普通屏幕坐标采用的是以左下角为原点(0,0)的平面直角坐标系，所以多边形顶点数组和鼠标位置不在一个坐标系内，使用AABBB这样的碰撞检测算法存在问题。 2、RolygonCollider2D中的points属性即多边形顶点数组存储的是相对于UI元素的相对坐标，在进行计算的时候应该统一转化为绝对坐标，这个过程在宣雨松的代码中有所涉及，但我认为对UI元素来讲，应该使用transform.GetComponent().position而非transform.position，因为transform.position最初是给3D物体使用的，而实际上这里是存在误差的。 3、我怀疑宣雨松提供的这个ContainsPoint方法的正确性，因为按照我的理解修改这个方法以后，发现界面响应的情况和实际情况是有所出入的，如下图所示，在整个区域内该方法都返回false。为了排除因为我的方法而对结果产生的影响，我使用宣雨松的代码进行了测试，结论是这个方法不管进行坐标系的转换与否，它在整个区域内的返回值都是false，因此我认为这个方法是错误的，虽然从理解算法的角度来看，它应该是根据线性差值来判断点在多边形中每条边的哪一侧的。 响应区域说明 &emsp;&emsp;在评论中网友AwayMe指出可以使用多边形碰撞器的OverlapPoint方法来判断一个点是否在多边形内部，可是经过我测试，这种方式和宣雨松提供的方法有着类似地问题，无论是否对坐标系进行转换，这个方法都返回false，响应区域与上图完全一致。 &emsp;&emsp;所以不管网络上有没有高质量的内容，一个核心的问题是你能否从中找到答案。如果你可以直接找到解决方案这可能是最好的结局；如果找不到直接的解决方案，却能够有所启发并独立解决问题，这是我们希望看到的结果。可是有时候人们并不这样想啊，人们想得到的是可以运行的代码而非解决问题的思路，因为可能人们并不想解决这个问题。 &emsp;&emsp;好了，经过知乎上相关答案我找到了这篇文章，文章中提到了判断一个点是否在任意多边形内部的两种方法，分别为Corssing Number和Winding Number。这两种方法在理论层面的相关细节请大家自行阅读这篇文章，我们这里选择的是前者，其基本思想是计算从该点引出的射线与多边形边界橡胶的次数，当其为奇数时表示该点在多边形内部，当其为偶数时表示在多边形外部。这里有一个有意思的事情是宣雨松选择的方法应该是著名的Ray-Crossing算法，可是为什么在这里会出现这样的问题呢？ &emsp;&emsp;孰是孰非，一切都交给实践来证明吧！下面是我根据文章中提供的算法改写的一段C#代码： 123456789101112131415161718192021222324252627282930313233bool ContainsPoint2(Vector2[] polyPoints,Vector2 p)&#123; //统计射线和多边形交叉次数 int cn = 0; //遍历多边形顶点数组中的每条边 for(int i=0; i&lt;polyPoints.Length-1; i++) &#123; //正常情况下这一步骤可以忽略这里是为了统一坐标系 polyPoints [i].x += transform.GetComponent&lt;RectTransform&gt; ().position.x; polyPoints [i].y += transform.GetComponent&lt;RectTransform&gt; ().position.y; //从当前位置发射向上向下两条射线 if(((polyPoints [i].y &lt;= p.y) &amp;&amp; (polyPoints [i + 1].y &gt; p.y)) || ((polyPoints [i].y &gt; p.y) &amp;&amp; (polyPoints [i + 1].y &lt;= p.y))) &#123; //compute the actual edge-ray intersect x-coordinate float vt = (float)(p.y - polyPoints [i].y) / (polyPoints [i + 1].y - polyPoints [i].y); //p.x &lt; intersect if(p.x &lt; polyPoints [i].x + vt * (polyPoints [i + 1].x - polyPoints [i].x)) ++cn; &#125; &#125; //实际测试发现cn为0的情况即为宣雨松算法中存在的问题 //所以在这里进行屏蔽直接返回false这样就可以让透明区域不再响应 if(cn == 0) return false; //返回true表示在多边形外部否则表示在多边形内部 return cn % 2 == 0;&#125; 这段代码说实话我理解的不是很透彻，而且令人费解的是实际结论和算法结论完全相反，因为按照我现在这样的设计，当cn为偶数时返回为true，此时应该表示该点再多边形外部啊，可是事实上我测试这段代码的时候，它居然是可以正常工作的，即当该方法返回true的时候我的点击确实是在多边形内部，所以这是一段可以正常工作同时让我感到费解的代码，而且当我屏蔽了cn为0的这种情况以后，现在它已经可以完美的工作了 正五边形精灵 同样的，我们这里使用一张正五边形的精灵图片，然后编写下面的代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677/* * 基于多边形碰撞器实现的不规则按钮 * 作者：PayneQin * 日期：2016年7月9日 */using UnityEngine;using System.Collections;using UnityEngine.UI;using UnityEngine.EventSystems;public class UnregularButtonWithCollider : MonoBehaviour,IPointerClickHandler&#123; /// &lt;summary&gt; /// 多边形碰撞器 /// &lt;/summary&gt; PolygonCollider2D polygonCollider; void Start() &#123; //获取多边形碰撞器 polygonCollider = transform.GetComponent&lt;PolygonCollider2D&gt;(); &#125; public void OnPointerClick(PointerEventData eventData) &#123; //对2D屏幕坐标系进行转换 Vector2 local; local.x = eventData.position.x - (float)Screen.width / 2.0f; local.y = eventData.position.y - (float)Screen.height / 2.0f; if(ContainsPoint(polygonCollider.points,local)) &#123; Debug.Log (\"这是一个正五边形!\"); &#125; &#125; /// &lt;summary&gt; /// 判断指定点是否在给定的任意多边形内 /// &lt;/summary&gt; bool ContainsPoint(Vector2[] polyPoints,Vector2 p) &#123; //统计射线和多边形交叉次数 int cn = 0; //遍历多边形顶点数组中的每条边 for(int i=0; i&lt;polyPoints.Length-1; i++) &#123; //正常情况下这一步骤可以忽略这里是为了统一坐标系 polyPoints [i].x += transform.GetComponent&lt;RectTransform&gt; ().position.x; polyPoints [i].y += transform.GetComponent&lt;RectTransform&gt; ().position.y; //从当前位置发射向上向下两条射线 if(((polyPoints [i].y &lt;= p.y) &amp;&amp; (polyPoints [i + 1].y &gt; p.y)) || ((polyPoints [i].y &gt; p.y) &amp;&amp; (polyPoints [i + 1].y &lt;= p.y))) &#123; //compute the actual edge-ray intersect x-coordinate float vt = (float)(p.y - polyPoints [i].y) / (polyPoints [i + 1].y - polyPoints [i].y); //p.x &lt; intersect if(p.x &lt; polyPoints [i].x + vt * (polyPoints [i + 1].x - polyPoints [i].x)) ++cn; &#125; &#125; //实际测试发现cn为0的情况即为宣雨松算法中存在的问题 //所以在这里进行屏蔽直接返回false这样就可以让透明区域不再响应 if(cn == 0) return false; //返回true表示在多边形外部否则表示在多边形内部 return cn % 2 == 0; &#125;&#125; 我们可以发现现在它可以正常工作啦！我们必须意识到的一点是，这个方法的空间复杂度为O(n-1)，所以随着多边形顶点数目的增加，这个方法的执行效率会越来越低，如果对不规则精灵的边界没有十分苛刻的要求的话，我的建议是我们使用多边形碰撞器标记出一个相对模糊的边界即可，因为现在我们这个方法主要依靠数学计算，没有涉及到摄像机相关计算，所以宣雨松博客中有朋友指出他的方法仅仅适用于Canvas的模式为Screen-Space Camera这种情况，而我目前这个方法对除了World Space以外都是可以使用的，我最大的疑虑来自对鼠标位置进行转化的时候是否应该使用Screen.width和Screen.height，因为我担心可能会出现屏幕适配这种需求。 演示效果1 精灵像素检测&emsp;&emsp;精灵像素检测这个方案的灵感来自Image组件，我们在MonoDevelop或者Visual Studio中通过”转到定义”这个功能可以获得Image组件的内部细节。我们发现uGUI在处理控件是否被点击的时候，主要是根据IsRaycastLocationValid这个方法的返回值来进行判断的，而这个方法用到的基本原理则是判断指定点对应像素的RGBA数值中的Alpha是否大于某个指定临界值。例如，我们知道半透明通常是指Alpha=0.5，而对一个.png格式的图片来说半透明甚至完全透明的区域理论上不应该被响应的，所以根据这个原理我们只需要设定一个透明度的临界值然后对当前鼠标位置对应的像素进行判断就可以了，因此这种方法叫做精灵像素检测。 &emsp;&emsp;下面我们来一起看这段uGUI的代码，这段代码通过MonoDevelop或者Visual Studio的”转到定义”功能可以找到，这里我做了简单的注释帮助大家理解代码： 123456789101112131415161718192021222324252627282930313233343536373839public virtual bool IsRaycastLocationValid(Vector2 screenPoint, Camera eventCamera)&#123; //当透明度&gt;=1.0时，表示点击在可响应区域返回true if(this.m_EventAlphaThreshold &gt;= 1f)&#123; return true; &#125; //当没有指定精灵时为什么要返回true? Sprite overrideSprite = this.overrideSprite; if(overrideSprite == null)&#123; return true; &#125; //坐标系转换 Vector2 local; RectTransformUtility.ScreenPointToLocalPointInRectangle(base.rectTransform, screenPoint, eventCamera, ref local); Rect pixelAdjustedRect = base.GetPixelAdjustedRect (); local.x += base.rectTransform.get_pivot ().x * pixelAdjustedRect.get_width (); local.y += base.rectTransform.get_pivot ().y * pixelAdjustedRect.get_height (); local = this.MapCoordinate(local, pixelAdjustedRect); Rect textureRect = overrideSprite.get_textureRect (); Vector2 vector = new Vector2(local.x / textureRect.get_width (), local.y / textureRect.get_height ()); //计算屏幕坐标对应的UV坐标 float num = Mathf.Lerp(textureRect.get_x (), textureRect.get_xMax (), vector.x) / (float)overrideSprite.get_texture().get_width(); float num2 = Mathf.Lerp(textureRect.get_y (), textureRect.get_yMax (), vector.y) / (float)overrideSprite.get_texture().get_height(); bool result; //核心方法：像素检测 try&#123; result = (overrideSprite.get_texture().GetPixelBilinear(num, num2).a &gt;= this.m_EventAlphaThreshold); &#125;catch(UnityException ex)&#123; Debug.LogError(\"Using clickAlphaThreshold lower than 1 on Image whose sprite texture cannot be read. \" + ex.Message + \" Also make sure to disable sprite packing for this sprite.\", this); result = true; &#125; //返回结果 return result;&#125; 从这段代码中我们可以看出，这个方法核心在第31行代码，即传入一个UV坐标返回一个RGBA数值并将其和临界值相比较。可是在此之前，我们看到在引入uGUI及其专属组件RectTransform以后，现在Unity中的坐标系转换变得更加复杂了，我个人看到这部分代码是相当凌乱的，或许我应该找时间补习下矩阵变换了吧。所以现在我们就有思路啦，我们有两种方式，第一种基于这个思路重新定制一个Image组件;第二种直接修改Image组件的eventAlphaThreshold属性。考虑到坐标系转换这里非常复杂，显然第二种方式更容易接受，为什么这里可以直接修改eventAlphaThreshold属性呢，因为它在Image组件内部和代码中的m_EventAlphaThreshold相关联，这就是这篇文章的完整解释啦！ 圆形精灵图片 &emsp;&emsp;好了，现在我们来一个简单的测试，我们这里准备一张圆形的精灵图片(如上图)，然后编写下面的代码： 1234567891011121314151617181920212223242526272829303132333435363738/* * 基于精灵像素检测实现的不规则按钮 * 作者：PayneQin * 日期：2016年7月9日 */using UnityEngine;using System.Collections;using UnityEngine.UI;using UnityEngine.EventSystems;public class UnregularButtonWithPixel : MonoBehaviour,IPointerClickHandler&#123; /// &lt;summary&gt; /// Image组件 /// &lt;/summary&gt; private Image image; /// &lt;summary&gt; /// 透明度临界值 /// &lt;/summary&gt; [Range(0.0f,0.5f)] public float Alpha; public void Start() &#123; //获取Image组件 image = transform.GetComponent&lt;Image&gt;(); //设定透明度临界值 image.eventAlphaThreshold = Alpha; &#125; public void OnPointerClick(PointerEventData eventData) &#123; Debug.Log(\"这是一个圆形!\"); &#125;&#125; 这里我为了让大家在学(复)习(制)的时候更容易理解，我在Click事件的响应上，使用的是实现IPointerClickHandler接口这种方法，希望通过动态绑定这种方式添加事件响应的可以自己解决，我是不会为了满足你们的好(懒)奇(惰)而奉献出我的EventTriggerListener的代码的。好了，现在我们要做的就是为需要响应点击的不规则精灵附加该脚本，这样就可以解决不规则精灵响应的问题了。这种方法使用起来非常简单，需要注意的是：图片的类型必须是Advance且保证可读可写。因为我们在脚本中访问了像素，而简单伴随着的代价就是我们无法使用图集、该图片在内存中会复制一份，所以在项目性能上允许的情况下这种方法还是可以考虑使用的。 演示效果2 小结&emsp;&emsp;本文通过对网络上两种比较通用的不规则按钮制作方案进行对比和研究，解决了基于多边形碰撞器实现不规则按钮这个过程中存在的问题，剖析了基于精灵像素检测实现不规则按钮 这个过程的内部原理，从易用性角度来讲，后者要优于前者，而这种方法的缺陷主要来自于它对图片类型的限制以及允许像素可读写这两个方面，它必须是Advance类型，所以普通的Texture或者Sprite拥有的特性在这里它都无法享受，比如我们无法为其做颜色渐变这类Tween动画、无法使用精灵特有的图集特性等等，于此同时它必须允许像素可读写，因此在实际使用中它会在内存中复制一份，在执行效率上可能会受到影响。而从技术性角度来讲，我个人更推推崇前者，因为在这个过程中我们学到了新的知识，明白了如何利用一个算法来解决实际的问题，而且它不会限制我们对精灵的使用，所有精灵拥有的特性在这里我们都可以使用，无非是在寻找算法、解决问题的过程中我们耗费了大量精力，可是这是值得的啊，不是吗？这就是我们做这件事情的意义所在。从昨天开始研究这两个问题到今天写完整篇文章，整个人是非常疲惫的，欢迎大家继续关注我的博客，今天的内容就是这样啦，谢谢大家！","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"uGUI","slug":"uGUI","permalink":"https://qinyuanpei.github.io/tags/uGUI/"}]},{"title":"使用C#开发HTTP服务器系列之实现Get和Post","date":"2016-06-11T15:01:35.000Z","path":"posts/1700650235/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。在我们这个Web服务器有了一个基本的门面以后，我们是时候来用它做点实际的事情了。还记得我们最早提到HTTP协议的用途是什么吗？它叫超文本传输协议啊，所以我们必须考虑让我们的服务器能够接收到客户端传来的数据。因为我们目前完成了大部分的工作，所以对数据传输这个问题我们这里选择以最简单的GET和POST为例来实现，这样我们今天的重点就落实在Get和Post的实现这个问题上来。而从原理上来讲，无论Get方式请求还是Post方式请求，我们都可以在请求报文中获得其请求参数，不同的是前者出现在请求行中，而后者出现在消息体中。例如我们传递的两个参数num1和num2对应的数值分别是12和24，那么在具体的请求报文中我们都能找到类似“num1=12&amp;num2=24”这样的字符结构，所以只要针对这个字符结构进行解析，就可以获得客户端传递给服务器的参数啦。 实现Get请求&emsp;&emsp;首先我们来实现Get请求，Get是HTTP协议中默认的请求类型，我们平时访问网页、请求资源实际上都是通过Get方式实现的。Get方式请求需要通过类似“?id=001&amp;option=10”这样的形式附加在URL上，因此Get方式对浏览器来说是透明的，即用户可以通过浏览器地址栏知道，这个过程中传递了哪些参数以及这些参数的值分别是什么。而由于浏览器的限制，我们通过这种方式请求的时候能够传递的参数数目和长度都是有限的，而且当参数中存在中文数值的时候还需要对其进行编码。Get方式请求相对简单，我们下面来看看它的请求报文： 12345678GET /?num1=23&amp;num2=12 HTTP/1.1Accept: text/html, application/xhtml+xml, image/jxr, */*Accept-Language: zh-Hans-CN,zh-Hans;q=0.5User-Agent: Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2486.0 Safari/537.36 Edge/13.10586Accept-Encoding: gzip, deflateHost: localhost:4040Connection: Keep-AliveCookie: _ga=GA1.1.1181222800.1463541781 此时我们可以注意到在请求报文第一行，即请求行中出现了“/?num1=23&amp;num2=12”这样的字样，这就是客户端传递给服务器的参数，我们很容易想到只需要将这个字段串中的“键”和“值”都解析出来，服务器就可以对这些数据进行处理然后返回给客户端了。所以下面我们通过这样的方式来实现，我们为HtttpRequest类增加了一个Parms属性，它是一个键和值均为字符串类型的字典，我们使用这个字典来存储和管理客户端传递来的参数。 123//获取请求参数if(this.Method == \"GET\" &amp;&amp; this.URL.Contains('?')) this.Params = GetRequestParams(lines[0].Split(' ')[1].Split('?')[1]); 显然我们首先需要判断请求类型是否为GET以及请求中是否带有参数，其方法是判断请求地址中是否含有“?”字符。这里的lines是指将报文信息按行分割以后的数组，显然请求地址在第一行，所以我们根据“?”分割该行数据以后就可以得到“num1=23&amp;num2=12”这样的结果，这里我们使用一个方法GetRequestParms来返回参数字典，这样作做是为了复用方法，因为在处理Post请求的时候我们会继续使用这个方法。该方法定义如下： 1234567891011121314151617181920212223242526272829 /// &lt;summary&gt;/// 从内容中解析请求参数并返回一个字典/// &lt;/summary&gt;/// &lt;param name=\"content\"&gt;使用&amp;连接的参数字符串&lt;/param&gt;/// &lt;returns&gt;如果存在参数则返回参数否则返回null&lt;/returns&gt;protected Dictionary&lt;string, string&gt; GetRequestParams(string content)&#123; //防御编程 if(string.IsNullOrEmpty(content)) return null; //按照&amp;对字符进行分割 string[] reval = content.Split('&amp;'); if(reval.Length &lt;= 0) return null; //将结果添加至字典 Dictionary&lt;string, string&gt; dict = new Dictionary&lt;string, string&gt;(); foreach(string val in reval) &#123; string[] kv = val.Split('='); if(kv.Length &lt;= 1) dict.Add(kv[0], \"\"); dict.Add(kv[0],kv[1]); &#125; //返回字典 return dict;&#125; 实现Post请求&emsp;&emsp;Post请求相对Get请求比较安全，因为它克服了Get请求参数长度的限制问题，而且由于它的参数是存放在消息体中的，所以在传递参数的时候对用户而言是不可见的，我们平时接触到的网站登录都是这种类型，而复杂点的网站会通过验证码、Cookie等形式来避免爬虫程序模拟登录，在Web开发中Post请求可以由一个表单发起，可以由爬虫程序如HttpWebRequest、WebClient等发起，下面我们重点来分析它的请求报文： 12345678910POST / HTTP/1.1Accept: text/html, application/xhtml+xml, image/jxr, */*Accept-Language: zh-Hans-CN,zh-Hans;q=0.5User-Agent: Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2486.0 Safari/537.36 Edge/13.10586Accept-Encoding: gzip, deflateHost: localhost:4040Connection: Keep-AliveCookie: _ga=GA1.1.1181222800.1463541781num1=23&amp;num2=12 我们可以注意到此时请求行的请求方法变成了POST，而在报文结尾增加了一行内容，我们称其为“消息体”，这是一个可选的内容，请注意它前面有一个空行。所以，当我们处理一个Posst请求的时候，通过最后一行就可以解析出客户端传递过来的参数，和Get请求相同，我们这里继续使用GetRequestParams来完成解析。 12if(this.Method == \"POST\") this.Params = GetRequestParams(lines[lines.Length-1]); 实例&emsp;&emsp;现在我们来完成一个简单地实例，服务器自然由我们这里设计的这个服务器来完成咯，而客户端则由Unity来完成因为Unity有简单的WWW可以使用。首先来编写服务端，这个继承HttpServer就好了，我们主要来写这里的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162using System;using System.Collections.Generic;using System.Linq;using System.Text;using System.Threading.Tasks;using HttpServerLib;using System.IO;namespace HttpServer&#123; public class ExampleServer : HttpServerLib.HttpServer &#123; /// &lt;summary&gt; /// 构造函数 /// &lt;/summary&gt; /// &lt;param name=\"ipAddress\"&gt;IP地址&lt;/param&gt; /// &lt;param name=\"port\"&gt;端口号&lt;/param&gt; public ExampleServer(string ipAddress, int port) : base(ipAddress, port) &#123; &#125; public override void OnPost(HttpRequest request) &#123; //获取客户端传递的参数 int num1 = int.Parse(request.Params[\"num1\"]); int num2 = int.Parse(request.Params[\"num2\"]); //设置返回信息 string content = string.Format(\"这是通过Post方式返回的数据:num1=&#123;0&#125;,num2=&#123;1&#125;\",num1,num2); //构造响应报文 HttpResponse response = new HttpResponse(content, Encoding.UTF8); response.StatusCode = \"200\"; response.Content_Type = \"text/html; charset=UTF-8\"; response.Server = \"ExampleServer\"; //发送响应 ProcessResponse(request.Handler, response); &#125; public override void OnGet(HttpRequest request) &#123; //获取客户端传递的参数 int num1 = int.Parse(request.Params[\"num1\"]); int num2 = int.Parse(request.Params[\"num2\"]); //设置返回信息 string content = string.Format(\"这是通过Get方式返回的数据:num1=&#123;0&#125;,num2=&#123;1&#125;\",num1,num2); //构造响应报文 HttpResponse response = new HttpResponse(content, Encoding.UTF8); response.StatusCode = \"200\"; response.Content_Type = \"text/html; charset=UTF-8\"; response.Server = \"ExampleServer\"; //发送响应 ProcessResponse(request.Handler, response); &#125; &#125;&#125; 因为这里需要对Get和Post进行响应，所以我们这里对OnGet和OnPost两个方法进行了重写，这里的处理方式非常简单，按照一定格式返回数据即可。下面我们来说说Unity作为客户端这边要做的工作。WWW是Unity3D中提供的一个简单的HTTP协议的封装类，它和.NET平台下的WebClient、HttpWebRequest/HttpWebResponse类似，都可以处理常见的HTTP请求如Get和Post这两种请求方式。 WWW的优势主要是简单易用和支持协程，尤其是Unity3D中的协程（Coroutine）这个特性，如果能够得到良好的使用，常常能够起到事倍功半的效果。因为WWW强调的是以HTTP短链接为主的易用性，所以相应地在超时、Cookie等HTTP头部字段支持的完整性上无法和WebClient、HttpWebRequest/HttpWebRespons相提并论，当我们需要更复杂的HTTP协议支持的时候，选择在WebClient、HttpWebRequest/HttpWebResponse上进行深度定制将会是一个不错的选择。我们这里需要的是发起一个简单的HTTP请求，所以使用WWW完全可以满足我们的要求，首先我们来看在Unity3D中如何发起一个Get请求，这里给出一个简单的代码示例： 1234567//采用GET方式请求数据IEnumerator Get()&#123; WWW www = new WWW (\"http://127.0.0.1:4040/?num1=12&amp;num2=23\"); yield return www; Debug.Log(www.text);&#125; 现在我们是需要使用StartCoroutine调用这个方法就可以啦！同样地，对于Post请求，我们这里采用一个WWWForm来封装参数，而在网页开发中我们通常都是借助表单来向服务器传递参数的，这里给出同样简单的代码示例： 12345678910//采用POST方式请求数据IEnumerator Post()&#123; WWWForm form = new WWWForm (); form.AddField (\"num1\", 12); form.AddField (\"num2\", 23); WWW www = new WWW (\"http://127.0.0.1:4040/\", form); yield return www; Debug.Log (www.text);&#125; 而运行这个实例，我们可以得到下面的结果： 测试结果 都是谁告诉你做服务器开发一定要用Java的啊，现在我们可以写出自己的服务器了，本篇结束，下期见！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"服务器","slug":"服务器","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"C#","slug":"C","permalink":"https://qinyuanpei.github.io/tags/C/"}]},{"title":"使用C#开发HTTP服务器系列之更简单的实现方式","date":"2016-06-11T15:01:35.000Z","path":"posts/3603924376/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。到目前为止，我已经发布了3篇HTTP服务器开发的系列文章。对我个人而言，我非常享受这个从无到有的过程，或许我现在写的这个Web服务器有各种不完美的因素，可是当有一天我需要一个轻量级的服务器的时候，我在无形中是不是比别人多了一种选择呢？我们常常提到“不要重复造轮子”，可事实上这并不能成为我们“不造轮子”的理由，虽然我们有各种各样的服务器软件、有各种各样的服务端框架可以供我们选择，可是在动手写这个系列文章前，我对Web服务器的印象无非是因为我是用LAWP(Linux + Apache + MySQL + PHP)搭建过Wordpress博客而已。虽然在对动态页面(如.aspx、.jsp、.php等)的处理上，可能会和静态页面有所不同，但是我庆幸我了解了这个过程以及它的内部原理，这种跨语言、跨平台的设计思路是任何框架或者标准都无法告诉我的。或许有人会问我，为什么不在最开始的时候就选择更简单的实现方法，那么在这篇文章中你将会找到答案。 从原理说起&emsp;&emsp;我们知道HTTP服务器其实是一个“服务端循环监听客户端请求然后响应客户端请求”的请求/响应模型，在这个模型中请求通常是由浏览器来发起的，而服务端负责响应客户端的请求。这是我们通常意义上的认识，可是当我们了解到HTTP协议的实质以后就会明白，不管是客户端还是服务端，从本质上来讲都是Socket通信，只要我们能够发送符合HTTP协议规范的报文就可以啦。 &emsp;&emsp;所以我们立刻就能够想到无论是Unity引擎中的WWW还是.NET平台下的WebClient，它们之所以能够向服务器发起请求，无一例外地是它们都遵循了HTTP协议的规范。从这个角度来讲，人类社会存在各种各样的问题，本质上都是存在游离于规范以外的不公平的现象。还记得我们在这个系列中提到的请求报文和响应报文的结构是什么样的吗？此时此刻我们发自内心地向创造HTTP协议的先驱们致敬，因为这个协议我们构建起了连接人与人的社交网络，可是同样因为这个协议我们和人越来越远、和手机越来越近。 &emsp;&emsp;HTTP协议是一种无状态的应用层协议，这个无状态该怎么理解呢？我这里想借助聊天机器人这个实例来解释这个问题，我们都知道聊天机器人是一种问答型的程序，程序每次都可以根据提问者的问题给出，一个从人类角度来看完全合理的答案。然而从目前我了解到的聊天机器人的技术现状来看，具备自然语言理解的机器人程序基本没有，所以在这样的大背景下，机器人程序实际上是没有上下文理解的能力的。 &emsp;&emsp;好了，现在我们回到HTTP协议，首先聊天机器人的问答模式是不是和HTTP协议中的请求/响应模式非常相似呢？其次，我们在设计HTTP服务器的时候，每次在向客户端返回响应报文以后，我们就关闭了Socket连接，这意味着每次的请求和响应完全都是独立的，那么这样是不是就和聊天机器人不能理解上下文非常相似了呢？所以综合下来，我们理解的无状态其实就是说HTTP请求和响应完全独立，即在客户端中不会存储服务端的响应，在服务端中同样不会存储客户端的请求。 &emsp;&emsp;这样难免引发一个问题，如果我需要在不同请求和响应中保持状态该怎么做呢？这个在不同的服务器软件中有不同的技术实现，这里我们说一种最通用的Cookie。Cookie是存储在客户端中的一个数据，在发起下一轮请求时这个参数会被加入到参数列表中然后传递给服务器，服务器会对客户端传递的参数进行验证，以此来判断本轮请求和上轮请求间是否存在上下文联系。 两种不同的实现&emsp;&emsp;到目前为止我们了解的HTTP服务器开发，实际上由两部分组成，即Socket通信和请求-响应模型。基于这两点考虑，我们这里提供两种快速实现Web服务器的具体思路，这是在我们理解了HTTP协议实质以后，从原理出发想到的解决方案，为什么我不建议在刚开始就学习这些东西呢？因为我觉得学习有时候其实就是一个不断开阔视野和思路的过程吧。好了，下面我们来说说这两种不同实现方式的具体思路吧！ 基于TcpListener/TcpClienr改进Socket&emsp;&emsp;如果说使用Socket从头开始编写HTTP服务器是一个“刀耕火种”时代的缩影，那么使用TcpListener/TcpClient则是让我们开始进入“青铜铸犁”的农耕时代。和Sokcet相比，TcpListener/TcpClient是.NET对Socket的进一步封装，在这个体系下，TcpListener负责监听和接收传入的连接请求，在该类中仅需要传入一个网络终端信息就可以完成服务端的初始化，而无需设置网络通信协议等细节性的内容。调用Start方法后即可以开始监听，这里我们使用AcceptTcpClient方法来阻塞进程直到接受到一个客户端请求为止，该方法将返回一个TcpClient对象，我们可以借助它完成和客户端的通信。下面我们来一起看基本的代码实现： 123456789101112131415161718192021222324252627282930public void Start()&#123; if(isRunning) return; //创建TcpListener serverListener = new TcpListener(IPAddress.Parse(ServerIP), ServerPort); //开始监听 serverListener.Start(10); isRunning = true; //输出服务器状态 Console.WriteLine(\"Sever is running at http://&#123;0&#125;:&#123;1&#125;/.\", ServerIP, ServerPort); while(isRunning) &#123; //获取客户端连接 TcpClient acceptClient = serverListener.AcceptTcpClient(); //获取请求报文 NetworkStream netstream = acceptClient.GetStream(); //解析请求报文 byte[] bytes = new byte[1024]; int length = netstream.Read(bytes, 0, bytes.Length); string requestString = Encoding.UTF8.GetString(bytes, 0, length); //以下为响应报文(略) &#125;&#125; 我个人感觉这种形式和原生的Socket在实现上区别不是非常大，按照这种思路继续往下设计，我的HttpRequest和HttpResponse可能都需要进行改进，因为在我的设计中，我是在尽可能地隐藏Socket通信的细节，因为我不想让使用者觉察到他这是在使用Socket进行通信，这里细心的朋友可能会发现，这里的TcpListener/TcpClient都保留了常见的Socket用法如同步通信和异步通信的支持等，所以在使用cpListener/TcpClient其实没有必要纠结它的这套流程，如果你喜欢继续使用Socket通信的经验和方法就可以了。这里我们仅提供一种延伸思路。具体的代码实现大家顺着这个思路继续下去就好啦。 基于HttpListener实现请求-响应模型&emsp;&emsp;下面我们再来说说基于HttpListener实现请求-响应模型，它和改进Socket不同，它对我们编写一个Web服务器的意义主要体现在它提供了一个非常规范的接口，类似我这里的HttpResponse和HttpRequest以及OnPost、OnGet等接口这些设计。这个让我不喜欢的一点是它在设置服务器IP地址和端口的时候非常别扭，其思路和我的设计是非常相似的，下面我们来一起看代码： 1234567891011121314151617181920212223242526272829303132public void Listen()&#123; if(!HttpListener.IsSupported) throw new InvalidOperationException( \"请确保使用WindowsXP以上版本的Windows!\"); //初始化Http监听器 listener = new HttpListener(); //初始化服务器URL string[] prefixes = new string[] &#123; address &#125;; foreach(string prefix in prefixes) &#123; listener.Prefixes.Add(prefix); &#125; //开启服务器 listener.Start(); //监听服务器 while(isActive) &#123; HttpListenerContext context = listener.GetContext(); HttpListenerRequest request = context.Request; HttpListenerResponse response = context.Response; if(request.HttpMethod == \"GET\")&#123; OnGetRequest(request, response); &#125;else&#123; OnPostRequest(request, response); &#125; &#125;&#125; 好了，现在这个东西就非常简单了，因为我们只需要继承HttpServerBase这个类然后重写相关方法就可以了，而请求报文和响应报文中的相关属性都在HttpListenerRequest和HttpListenerResponse这两个类中封装好了，我们直接使用就好了。在没有写这个系列文章前，可能我会对这种方案充满好奇，可是当我了解到这一切的实质以后，我反而更加喜欢使用我设计的HTTP服务器了，因为这些东西在我看来区别真的可以忽略。 One More Thing&emsp;&emsp;关于今天本文中提到的两种方案，我都是作为HTTP服务器开发延伸出来的内容来写出来给大家看,所以这块儿内容我都是点到为止不打算给出完整的实现，如果有兴趣的朋友可以顺着我这个思路区继续改进。这个系列文章中的示例代码主要来自我的项目HttpServer，大家到我的GIthub上去了解更多细节。到目前为止我觉得HTTP服务器快发这块儿我能写的内容都基本上写完了，因为是一边写代码一边写博客，所以有时候博客中如果有写得不好或者写的不明白的地方，希望大家能够谅解，同时希望大家在博客中给我积极留言，下一篇我想简单写一下RESTful API的相关问题，写完这一篇整个系列就结束了，我还是想说写文章真的很累啊，希望大家继续支持，下期见。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"服务器","slug":"服务器","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"C#","slug":"C","permalink":"https://qinyuanpei.github.io/tags/C/"}]},{"title":"使用C#开发HTTP服务器系列之构建RESTful API","date":"2016-06-11T15:01:35.000Z","path":"posts/3637847962/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。到目前为止，“使用C#开发HTTP服务器”这个系列系列文章目前已经接近尾声了，虽然我们在服务器功能的完整性(如支持并发、缓存、异步、Htts等)上没有再继续深入下去，可是我们现在已经具备了一个基本的服务器框架啦，所以更多深层次的问题就需要大家根据自己的需要来扩展了，因为写博客更多的是一种“记录-输出-反馈”的一个过程，所以我更希望大家在看完我的博客后能对我有所反馈，因为抄博客上的代码实在是太无聊啦！好了，保持愉悦的心情我们下面来引出今天的话题：构建RESTful API。RESTful API，这个概念或许你曾经听说过，可能它和我们所熟悉的各种Web息息相关，甚至在某种意义上来讲它并不是一种新的技术，而这一切的一切归根到底都是在问一个问题，即网站真的是Web的唯一形态吗？ 什么是RESTful API&emsp;&emsp;什么是RESTful API?首先，REST即REpresentational State Transfer，通常被翻译为“表述性状态传输”或者“表述性状态转移”，它最早出自Roy Fielding的《Archltectural Styles and the Design of Network-based Software Arcltechures》这篇论文，作者曾经参与HTTP协议和Apache Web Server的设计，所以REST实际上是一个和HTTP协议联系非常紧密的一种设计思想。而从这个题目中我们可以找到三个关键词： 架构样式——(Archltectural Styles) 软件架构——(Software Arcltechures) 网络为基础——(Network-based) 所以从我个人角度来理解REST，我更倾向于将REST理解为一种以网络为基础的设计风格，因此REST从本质上来讲解决的是如何正确地使用Web标准的问题。 &emsp;&emsp;以国内为例，当Google的Chrome浏览器选择以Chormium这种形式开源以后，国内厂商纷纷表示跟进以双核为主要特点进行了新一轮的互联网入口争夺战，虽然从技术角度来讲这让Chorme浏览器更加流行，可我们更应该注意到不同的厂商纷纷建立起自己的护城河，以牺牲Web的统一性和标准性来满足其商业竞争的需要，所以我们看到了即使在HTML5定稿以后，在不同浏览器对HTML5的支持区别依然非常大。微信带动了大量可以在朋友圈内流传的“H5”媒介，可是这个东西从来就不是HTML5，而微信内置的QQ浏览器内核更是以各种不兼容让开发者为此殚精竭虑，所以你问我REST是什么的时候，我会回答它是一种风格上统一的Web API，而根据百科中的描述REST通常被这样定义： REST是一组架构约束条件和原则，而满足这些约束条件和原则的应用程序就是RESTful。 REST的目标是构建可扩展的Web Service，它是一种更简单的SOAP协议以及以WSDL为基础的WebService的替代。 REST采用的是HTTP协议并通过HTTP中的GET、POST、PUT、DELETE等动词收发数据。 REST希望通过HTTP来完成对数据的元操作，即传统的CRUD(Create、Read、Update、Delete)分别对应GET、POST、PUT、DELETE，这样就统一了数据操作的接口，实现在不同平台上提供一套相同的服务。 REST是一种面向服务的、分布式的API设计风格。 从WebService看REST&emsp;&emsp;在这里我们提到了SOAP、WSDL、RPC等概念，这是因为从某种意义上来讲，REST是这些概念的一种延伸。以我们熟悉的WebService为例，当我们需要从网络上获取天气预报信息时，我们可以采取两种思路，第一种是通过抓包分析相关天气预报网站来获取信息，第二种是通过调用互联网上提供的WebService来获得信息。虽然这两种方法在技术上具有相似性和可行性，可是我觉得对开发者来讲，除了技术层面的突破以外在道德层面的坚守更为重要，我们说”人无德不立，国无德不兴”正是如此，所以我们这里强烈推荐第二种思路。WebService能够让我们像调用一个方法一样获取信息，那么对我们来讲WebService到底是什么呢？ &emsp;&emsp;WebService首先是一种服务，它不需要客户端提供额外的软件支持，只要客户端支持HTTP协议和XML这样两个特性就可以了。而对WebService自身来讲，它本身就是一种自我描述型的设计，所以服务端和客户端可以通过它来了解响应和请求的内容及格式，因为XML是一种平台无关、语言无关的文档结构，所以WebService是一种可以跨平台的Web API。WebService能够让客户端像调用本地代码一样调用服务端代码，所以WebService是一种分布式计算的Web应用程序组件。我们对WebService下了如此多的定义，其实核心是什么呢？核心是WebService是一种基于HTTP协议和XML的Web API。 &emsp;&emsp;好了，现在我们再来说说什么是SOAP和WSDL。事实上，这些概念听起来都非常地学术，可是我保证这对我们理解REST会有所帮助。首先，SOAP即简单访问对象协议(Simple Object Access Protocol)，听起来感觉非常高大上吗？然而这是一个“唯一没有发明任何新技术的技术”。因为它是一个访问Web服务的协议，如同HTTP协议定义了访问Web的协议一样，SOAP在HTTP协议的基础上，采用XML定义了消息协议，所以SOAP本质上是使用XML进行通信的HTTP协议，这样听起来是不是非常熟悉啦，因为我们熟悉的AJAX同样是采用XML进行通信，所不同的是AJAX是运行在浏览器中的且其主要目的是实现页面的无刷新更新。需要说明的是，虽然SOAP的基础HTTP协议是基于TCP/IP协议的，可是SOAP是具有穿透防火墙的能力的，对此有兴趣的朋友可以自行了解，我们这里因为篇幅有限所以就不做详细说明啦！ &emsp;&emsp;接下来，WSDL即Web服务描述语言(Web Service Description Language)，我对它的理解是提供了一个WebService的文档，因为从定义可以看出，它是一个基于XML的用于描述Web服务以及如何访问Web服务的语言，Web服务提供者通过它可以告知使用者当前Web服务访问的规范和说明，而Web使用者通过它可以在满足平台无关性和语言无关性的情况下快速进行开发，所以综合下来看，WebService和REST都能为我们提供类似地服务需求，关于两者或者说REST能为我们带来哪些不一样的体验，我们将在本文的第二部分说明。 从WCF看REST&emsp;&emsp;我觉得对技术而言，我们每个人都应该试图去发现技术背后真正美的东西，就像我们在了解了WebService，并发现它和REST从本质上来讲都是一个东西的时候，这个时候我们应该直接去了解REST给我们带来了哪些不一样的东西。可是事实上因为开发者使用的平台和语言的多样性，让开发者再这个过程中不得不去对平台或者语言造成依赖，而当每个厂商都试图建立一套自己的标准或者框架的时候，它对开发者造成的这种依赖感就越发地强烈。虽然我目前的工作是做.NET开发，可是事实上我最喜欢的只有微软的C#语言而已。这里我们简单介绍下WCF，WCF即Windows Communication Foundation是由微软发展的一组数据通信的应用程序开发接口，它是.NET框架的一部分，从.NET Framework 3.0开始引入，其设计目标是整合不同进程的通信、不同系统间的通信、C/S架构通信等等通信目标，所以对.NET开发者而言它是一个“全家桶”般的存在，我们到底需要“小而美”还是“大而全”，这是一个问题。 &emsp;&emsp;回到我们关注本身，WCF整合了Web服务、.NET Remoting、消息队列和Enterprise Services的功能并将其整合在Visual Studio中，显然对我们而言，我们关注的核心依然在Web服务。首先，我们要明确的是WebService这个是行业标准，即WebService规范，这是一个和平台、和语言无关的标准，而微软的ASP.NET WebService是ASP.NET框架的组成部分，我不喜欢ASP.NET的一个原因就是我们常常认为网站是Web技术的核心而Web服务不是，更离谱的是我们认为开发一个Web服务器或者一个WebService一定要采用XXX框架，虽然使用Web框架、写业务代码都是技术能力的一种体现，可是不求甚解真的无法让我安心。那么WCF呢？其实WCF本质上是将ASP.NET WebService和微软的相关技术如Enterprise Services(COM+)、.NET Remoting、MSMQ消息队列等进行了整合，为什么要整合在一起呢？因为从宏观上来讲，跨进程、跨机器、跨网络都属于通信的范畴，所以我们现在回过头来看，这些东西玩来玩去有什么稀奇，归根到底还不是HTTP协议啊，我们追求新的技术并没有错，错误的是我们将希望寄托在技术本身，而不是我们自己。 让REST理解起来简单点&emsp;&emsp;我们从最初接触到REST的云里雾里，到翻来覆去地讲述WebService，其实我的目的只有一个，那就是告诉大家，Web技术发展到今天，从本质上来将变化并没有太大，可是为什么我们会看到前端领域每隔一段时间就会有新的框架产生呢？回答这个问题非常简单，所有的框架的提出都是因为某种业务的背景需要，而所有的业务无一不是因为人类增加了其复杂性，所以当你下来看待这一切的时候，你发现从WebService到REST其实变化都是非常细微的东西，与其在新技术里疲于奔命不如静下心来学习好HTML、CSS和JavaScript，虽然JavaScript是一个垃圾的语言，可是有时候它会让我们这些后端程序开发者都懵逼呢，哈哈，所以现在是时候给REST一个简单的定义： REST是一种使用URL来定位资源，使用HTTP请求描述操作的Web服务规范。 REST的约束条件和原则&emsp;&emsp;我们说REST本质上是Web服务的一种规范，一种思想，所以单独来说REST是没有意义的，这意味着，如果我们要深入了解REST，就需要了解它的约束条件和原则，下面我们就来说说这个问题。 资源(Resources)&emsp;&emsp;在REST中资源是整个架构或者说整个网络处理的核心，那么什么是资源呢？在我们传统的观念中，资源是指服务器上的一个文件，而在REST里资源则是指一个URL。URL即统一资源定位，而我们都知道通过URL可以访问互联网上的资源，所以在REST里这种对资源的指向性更加强烈，并且在这里资源的范畴会被无限放大而并非局限在文件本身，例如： 123http://api.qc.com/v1/feed 表示获取某人的最新Feedhttp://api.qc.com/v1/friends 表示获取某人的好友列表http://api.qc.com/v1/profile 表示获取某人的详细信息 由此我们注意到REST在形式上更加趋向API设计，而我们获取的资源则通过一定的形式进行统一而规范化的表达，因此REST实现了让不同的平台共享一套API这样的愿望，这是一件非常美好的事情，这个世界上的技术阵营举不胜数，而它们为了各自的利益建立一套封闭、臃肿的体系框架，很多时候当我们不需要这样的“全家桶”并且希望“跨平台”的时候，REST将会是一个不错的选择。 表现形式(Representational)&emsp;&emsp;在REST中表现形式作为我们对资源请求的一个结果的呈现，通过对HTTP协议的学习我们已经知道，服务器会给客户端返回什么形式的信息，这一点取决于服务器响应报文中相关头部字段，而对REST来讲，它通常会采用XML或者JSON来告诉请求者请求的结果，因为JSON相比XML所含的冗余信息较少，所以目前更加倾向于或者说流行使用JSON作为请求结果的表现形式。 ##状态变化(State Transfer)&emsp;&emsp;虽然我们一再强调HTTP协议是无状态，这主要体现在HTTP请求与请求、HTTP响应与响应的上下文无关性上。在REST中，我们所说状态变化更多是指HTTP中的GET、POST、DELETE等动词实现。具体来讲，虽然这一点我们在前面有所提及我们来看下面的简单示例： 12345GET http://someurl/tasks 表示获取全部的tasksPOST http://someurl/tasks 表示创建一个新的taskGET http://someurl/tasks/&#123;id&#125; 表示获取一个指定id的taskPET http://someurl/tasks/&#123;id&#125; 表示更新一个指定id的taskDELETE http://someurl/tasks/&#123;id&#125; 表示删除一个指定id的task 除此之外，我们注意到REST基于HTTP协议，所以HTTP协议中的状态码对它来讲同样适用，例如最常用的200表示成功、500表示服务器内部错误、404表示无法找到请求资源等等。 如何构建REST风格的API&emsp;&emsp;如何构建REST风格的API?这是这篇文章的最后一个问题，相信大家在阅读这篇文章的时候会感到疲惫吧，我想说写作者的疲惫不一定会比阅读者的疲惫要轻，现在到了这篇文章里最难的部分啦，这可比我们花费大量篇幅来讲什么是REST要更有意义，这是真正的说起来容易做起来难，在正式开始实践以前，我们首先提出下面的最佳实践： URLRoot采用下面这样的结构： 12http://example.com/api/v1/http://api.example.com/v1/ API版本可以放在URL或者HTTP的Header里 URL使用名词而非动词： 12http://example.com/api/v1/getProducts 这是一个糟糕的设计GET http://example.com/api/v1/products 这是一个优雅的设计 保证方法时安全的不会对资源状态有所改变。例如： 1GET http://example.com/api/v1/deleteProduct?id=1 这是一个危险的信号 资源的地址推荐使用嵌套结构 1GET http://example.com/api/v1/friends/10375923/profile 使用正确的HTTP状态码表示访问状态 返回含义明确的结果(这是我为什么推荐使用JSON的理由) &emsp;&emsp;好了，这篇文章我目前能够理解并输出给大家的只有这些啦，关于具体在Web开发中我们如何去实现RESTful API，这个我觉得并没有一个固定的方法吧，而且我现在编写的这个服务器只支持Get和Post两种类型，如果要实现一个完整的RESTful API架构，还需要很长的时间去探索，这篇文章写得我的确有些疲惫，所以有不周的地方希望大家谅解，后续更新关注我的项目HttpServer就好啦，谢谢大家！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"服务器","slug":"服务器","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"C#","slug":"C","permalink":"https://qinyuanpei.github.io/tags/C/"}]},{"title":"使用C#开发HTTP服务器系列之静态页面","date":"2016-06-11T15:01:35.000Z","path":"posts/3695777215/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。在这个系列文章的第一篇中，我们着重认识和了解了HTTP协议，并在此基础上实现了一个可交互的Web服务器，即当客户端访问该服务器的时候，服务器能够返回并输出一个简单的“Hello World”。现在这个服务器看起来非常简陋，为此我们需要在这个基础上继续开展工作。今天我们希望为这个服务器增加主页支持，即当我们访问这个服务器的时候，它可以向我们展示一个定制化的服务器主页。通常情况下网站的主页被定义为index.html，而在动态网站技术中它可以被定义为index.php。了解这些将有助于帮助我们认识Web技术的实质，为了方便我们这里的研究，我们以最简单的静态页面为例。 大意失荆州&emsp;&emsp;首先我们可以认识到的一点是，网站主页是一个网站默认展示给访问者的页面，所以对服务器而言，它需要知道两件事情，第一客户端当前请求的这个页面是不是主页，第二服务端应该返回什么内容给客户端。对这两个问题，我们在目前设计的这个Web服务器中都可以找到答案的。因为HTTP协议中默认的请求方法是GET，所以根据HttpRequest的实例我们可以非常容易的知道，当前请求的方法类型以及请求地址。我们来看一个简单的客户端请求报文： 1234567GET / HTTP/1.1Accept: text/html, application/xhtml+xml, image/jxr, */*Accept-Language: zh-Hans-CN,zh-Hans;q=0.5User-Agent: Mozilla/5.0 (Windows NT 10.0) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/46.0.2486.0 Safari/537.36 Edge/13.10586Accept-Encoding: gzip, deflateHost: localhost:4040Connection: Keep-Alive 我们在这里可以非常清晰地看到，客户端当前发出的请求是GET类型，而其请求的地址是”/“，这表示请求页面为主页，而实际上我们将Host字段和这个地址组合起来，就能得到一个完整的地址，这正是我们在HTML结构中编写超链接的时候使用相对地址的原因。好了，在明白了这样两件事情具体的运作机理以后，下面我们来继续编写相关逻辑来实现如何向访问者展示一个网站主页。 12345678910111213141516171819202122232425public override void OnGet(HttpRequest request)&#123; //判断请求类型和请求页面 if(request.Method == \"GET\" &amp;&amp; request.URL == \"/\") &#123; //构造响应报文 HttpResponse response; //判断主页文件是否存在，如存在则读取主页文件否则返回404 if(!File.Exists(ServerRoot + \"index.html\"))&#123; response = new HttpResponse(\"&lt;html&gt;&lt;body&gt;&lt;h1&gt;404 - Not Found&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\", Encoding.UTF8); response.StatusCode = \"404\"; response.Content_Type = \"text/html\"; response.Server = \"ExampleServer\"; &#125;else&#123; response = new HttpResponse(File.ReadAllBytes(ServerRoot + \"index.html\"), Encoding.UTF8); response.StatusCode = \"200\"; response.Content_Type = \"text/html\"; response.Server = \"ExampleServer\"; &#125; //发送响应 ProcessResponse(request.Handler, response); &#125;&#125; 可以注意到在这里我们首先根据请求方法和请求地址来判断当前客户端是否在请求主页页面，然后我们判断在服务器目录下是否存在index.html文件，如果该文件存在就读取文件并返回给客户端，否则我们将返回给客户端一个404的状态，熟悉Web开发的朋友应该会知道这个状态码表示的是无法找到请求资源，类似地我们还可以想到的状态码有200、501等等，通常来讲，这些状态码的定义是这样的： 1XX：指示信息-表示请求已接收，继续处理。 2XX：成功-表示请求已被成功接受、理解和处理。 3XX: 重定向-表示完成请求需要更进一步的操作。 4XX：客户端错误-表示请求错误或者无法实现。 5XX：服务端错误-表示服务器未提供正确的响应。 具体来讲，常见的状态代码描述如下： 状态码 状态描述 200 OK 客户端请求成功 400 Bad Request 客户端请求错误且不能被服务器所理解 401 Unauthorized 请求未经授权需要使用WWW-Authenticate报头域 403 Forbidden 服务器收到请求但拒绝提供服务 404 Not Found 请求资源不存在 500 Internal Server Error 服务器发生不可预期的错误 503 Server Unavailable 服务器当前不能处理客户端的请求 为了简化需求，我们这里假设服务器目录下只有一个主页文件index.html，实际上像IIS、Apache等大型的服务器软件都是支持多个主页文件的，而且同时支持静态页面和动态页面，所以这里就涉及到一个优先级的问题，无论是在Apache还是IIS中我们可以找到对主页优先级设置的选项。所谓优先级，其实就是对这些主页文件重要性的一种排序，在实际设计的过程中，会优先读取优先级较高的主页文件，如该文件不存在则退而求其次，以此类推。在读取主页文件的时候，我们需要注意的一点是编码类型，因为无论是客户端还是服务端在其各自的头部信息里都声明了它可以接受的编码类型，所以服务器端在响应请求的时候应该注意和客户端保持一致，这样可以避免“鸡同鸭讲”问题的发生，进而提高沟通效率。我们这里在说技术，可是人何尝不是这样啊，我感觉我们生活和工作中90%的时间都被用来沟通了，可是这恰恰说明了沟通的重要性啊。好了，下面我们来测试下我们编写的主页： 一个失败的尝试 龙潜在渊&emsp;&emsp;咦？这个页面显示的结果怎么和我们期望的不一样啊，看起来这是一个因为样式丢失而引发的错误啊，不仅如此我们发现页面中的图片同样丢失了。首先我们检查下静态页面是否有问题，这个怎么可能嘛？因为这是博主采用Hexo生成的静态页面，所以排除页面本身的问题后，我们不得不开始重新思考我们的设计。我们静下心来思考这样一个问题：在浏览器加载一个页面的过程中难道只有静态页面和服务器发生交互吗？这显然不是啊，因为傻子都知道一个网页最起码有HTML、CSS和JavaScript三部分组成，所以我们决定在Chrome中仔细看看浏览器在加载网页的过程中都发生了什么。按下”F12”打开开发者工具对网页进行监听： 浏览器的小秘密 &emsp;&emsp;WTF！感觉在这里懵逼了是不是？你没有想到服务器在这里会响应如此多的请求吧？所以我们自作聪明地认为只要响应静态页面的请求就好了，这完全就是在作死啊！这里我的理解是这样的，对页面来讲服务器在读取它以后会返回给客户端，所以对客户端而言这部分响应是完全可见的，而页面中关联的CSS样式和JavaScript脚本则可能是通过浏览器缓存下载到本地，然后再根据相对路径引用并应用到整个页面中来的，而为了区分这些不同类型的资源，我们需要在响应报文中的Content-Type字段中指明内容的类型，所以现在我们就清楚了，首先在请求页面的时候存在大量关联资源，这些资源必须通过响应报文反馈给客户端，其次这些资源由不同的类型具体体现在响应报文的Content-Type字段中。因此，我们在第一段代码的基础上进行修改和完善，最终编写出了下面的代码： 12345678910111213141516171819202122232425262728293031323334public override void OnGet(HttpRequest request)&#123; if(request.Method == \"GET\") &#123; ///获取客户端请求地址 ///链接形式1:\"http://localhost:4050/assets/styles/style.css\"表示访问指定文件资源， ///此时读取服务器目录下的/assets/styles/style.css文件。 ///链接形式2:\"http://localhost:4050/assets/styles/\"表示访问指定页面资源， ///此时读取服务器目录下的/assets/styles/style.index文件。 //当文件不存在时应返回404状态码 string requestURL = request.URL; requestURL = requestURL.Replace(\"/\", @\"\\\").Replace(\"\\\\..\", \"\"); //判断地址中是否存在扩展名 string extension = Path.GetExtension(requestURL); //根据有无扩展名按照两种不同链接进行处 string requestFile = string.Empty; if(extension != \"\")&#123; requestFile = ServerRoot + requestURL; &#125;else&#123; requestFile = ServerRoot + requestURL + \"index.html\"; &#125; //构造HTTP响应 HttpResponse response = ResponseWithFile(requestFile); //发送响应 ProcessResponse(request.Handler, response); &#125;&#125; 注意到我在代码中写了两种不同形式的链接的分析： 链接形式1:”http://localhost:4050/assets/styles/style.css&quot;表示访问指定文件资源，此时读取服务器目录下的/assets/styles/style.css文件。 链接形式2:”http://localhost:4050/assets/styles/&quot;表示访问指定页面资源，此时读取服务器目录下的/assets/styles/style.index文件。 &emsp;&emsp;首先我们判断这两种形式是根据扩展名来判断的，这样我们可以获得一个指向目标文件的地址requestFile。这里提供一个辅助方法ResponseWithFile，这是一个从文件中构造响应报文的方法，其返回类型是一个HttpResponse，当文件不存在时将返回给客户端404的错误代码，我们一起来看它具体如何实现： 12345678910111213141516171819202122232425262728293031/// &lt;summary&gt;/// 使用文件来提供HTTP响应/// &lt;/summary&gt;/// &lt;param name=\"fileName\"&gt;文件名&lt;/param&gt;private HttpResponse ResponseWithFile(string fileName)&#123; //准备HTTP响应报文 HttpResponse response; //获取文件扩展名以判断内容类型 string extension = Path.GetExtension(fileName); //获取当前内容类型 string contentType = GetContentType(extension); //如果文件不存在则返回404否则读取文件内容 if(!File.Exists(fileName))&#123; response = new HttpResponse(\"&lt;html&gt;&lt;body&gt;&lt;h1&gt;404 - Not Found&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\", Encoding.UTF8); response.StatusCode = \"404\"; response.Content_Type = \"text/html\"; response.Server = \"ExampleServer\"; &#125;else&#123; response = new HttpResponse(File.ReadAllBytes(fileName), Encoding.UTF8); response.StatusCode = \"200\"; response.Content_Type = contentType; response.Server = \"ExampleServer\"; &#125; /返回数据 return response;&#125; 同样的，因为在响应报文中我们需要指明资源的类型，所以这里使用一个叫做GetContentType的辅助方法，该方法定义如下，这里仅仅选择了常见的Content-Type类型来实现，有兴趣的朋友可以自行了解更多的内容并在此基础上进行扩展： 1234567891011121314151617181920212223242526272829303132333435363738394041424344/// &lt;summary&gt;/// 根据文件扩展名获取内容类型/// &lt;/summary&gt;/// &lt;param name=\"extension\"&gt;文件扩展名&lt;/param&gt;/// &lt;returns&gt;&lt;/returns&gt;protected string GetContentType(string extension)&#123; string reval = string.Empty; if(string.IsNullOrEmpty(extension)) return null; switch(extension) &#123; case \".htm\": reval = \"text/html\"; break; case \".html\": reval = \"text/html\"; break; case \".txt\": reval = \"text/plain\"; break; case \".css\": reval = \"text/css\"; break; case \".png\": reval = \"image/png\"; break; case \".gif\": reval = \"image/gif\"; break; case \".jpg\": reval = \"image/jpg\"; break; case \".jpeg\": reval = \"image/jgeg\"; break; case \".zip\": reval = \"application/zip\"; break; &#125; return reval;&#125; 风雨过后终见彩虹&emsp;&emsp;好啦，到目前为止，关于静态Web服务器的编写我们基本上告一段落啦！其实这篇文章写的不是特别顺利，因为我几乎是在不断否认自我的情况下，一边调试一边写这篇文章的。整篇文章总结下来其实就两个点，第一，Web服务器在加载一个页面的时候会发起无数个请求报文，除了页面相关的请求报文以外大部分都是和资源相关的请求，所以HTML页面的优化实际上就是从资源加载这个地方入手的。第二，不同的资源有不同的类型，具体表现在响应报文的Content-Type字段上，构造正确的Content-Type能让客户端了解到这是一个什么资源。好了，现在我们可以气定神闲的验证我们的劳动成果啦，这里我以我本地的Hexo生成的静态博客为例演示我的Web服务器，假设我的博客是存放在”D:\\Hexo\\public”这个路径下，所以我可以直接在Web服务器中设置我的服务器目录： 123ExampleServer server = new ExampleServer(\"127.0.0.1\",4050);server.SetServerRoot(\"D:\\\\Hexo\\\\public\");server.Start(); 现在打开浏览器就可以看到： Web服务器运行效果 如此激动人心的时候，让我们踏歌长行、梦想永续，下期见！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"服务器","slug":"服务器","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"C#","slug":"C","permalink":"https://qinyuanpei.github.io/tags/C/"}]},{"title":"使用C#开发HTTP服务器系列之Hello World","date":"2016-06-11T12:38:03.000Z","path":"posts/3040357134/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客。从今天起，我将开始撰写一组关于HTTP服务器开发的系列文章。我为什么会有这样的想法呢？因为人们对Web技术存在误解，认为网站开发是Web技术的全部。其实在今天这样一个时代，Web技术可谓是无处不在，无论是传统软件开发还是移动应用开发都离不开Web技术，所以在我的认识中，任何使用了HTTP协议实现数据交互都可以认为是Web技术的一种体现，而且当我们提及服务器开发的时候，我们常常提及Java或者PHP。可是这些重要吗？不，在我看来服务器开发和语言无关，和IIS、Tomcat、Apache、Ngnix等等我们熟知的服务器软件无关。Web技术可以像一个网站一样通过浏览器来访问，同样可以像一个服务一样通过程序来调用，所以在接下来的时间里，我将和大家一起见证如何使用C#开发一个基本的HTTP服务器，希望通过这些能够让大家更好的认识Web技术。 至繁至简的HTTP&emsp;&emsp;我们对HTTP协议最直观的认识应该是来自浏览器，因为在互联网时代我们都是通过浏览器这个入口来接触互联网的，而到了移动互联网时代我们开始思考新的互联网入口。在这个过程中我们有创新的模式不断涌现出来，同样有并购、捆绑、垄断等形式的恶性竞争此起彼伏，所谓“痛并快乐着”。我想说的是，HTTP是一个简单与复杂并存的东西，那么什么是HTTP呢？我们在浏览器中输入URL的时候，早已任性地连“http”和“www”都省略了吧，所以我相信HTTP对人们来说依然是一个陌生的东西。 &emsp;&emsp;HTTP是超文本传输协议(HyperText Transfer Protocol)的简称，它建立在C/S架构的应用层协议，熟悉这部分内容的朋友应该清楚，TCP/IP协议是协议层的内容，它定义了计算机间通信的基础协议，我们熟悉的HTTP、FTP、Telnet等协议都是建立在TCP/IP协议基础上的。在HTTP协议中，客户端负责发起一个Request，该Request中含有请求方法、URL、协议版本等信息，服务端在接受到该Request后会返回一个Response，该Response中含有状态码、响应内容等信息，这一模型称为请求/响应模型。HTTP协议迄今为止发展出3个版本： 0.9版本：已过时。该版本仅支持GET一种请求方法，不支持请求头。因为不支持POST方法，所以客户端无法向服务器传递太多信息。 HTTP/1.0版本：这是第一个在通讯中指定版本号的HTTP协议版本，至今依然被广泛采用，特别是在代理服务器中。 HTTP/1.1版本：目前采用的版本。持久连接被默认采用，并能很好地配合代理服务器工作。相对1.0版本，该版本在缓存处理、带宽优化及网络连接地使用、错误通知地管理、消息在网络中的发送等方面都有显著的区别。 &emsp;&emsp;HTTP协议通信的核心是HTTP报文，根据报文发送者的不同，我们将其分为请求报文和响应报文。其中，由客户端发出的HTTP报文称为请求报文，由服务端发出的报文称为响应报文。下面我们来着重了解和认识这两种不同的报文： 请求报文：请求报文通常由浏览器来发起，当我们访问一个网页或者请求一个资源的时候都会产生请求报文。请求报文通常由HTTP请求行、请求头、消息体(可选)三部分组成，服务端在接收到请求报文后根据请求报文请求返回数据给客户端，所以我们通常讲的服务端开发实际上是指在服务端接收到信息以后处理的这个阶段。下面是一个基本的请求报文示例： 1234567891011/* HTTP请求行 */GET / HTTP/1.1/* 请求头部 */Accept: text/html, application/xhtml+xml, image/jxr, */*Accept-Encoding: gzip, deflateAccept-Language: zh-Hans-CN, zh-Hans; q=0.5Connection: Keep-AliveHost: localhost:4000User-Agent: Mozilla/5.0 (Windows NT 10.0; Trident/7.0; rv:11.0) like Gecko/* 消息体 */ 响应报文：响应报文是指在服务端接收并处理了客户端的请求信息以后，服务端发送给客户端的HTTP报文，服务端开发的重要工作就是处理来自客户端的请求，所以这是我们开发一个HTTP服务器的核心工作。和请求报文类似，响应报文由HTTP状态行、响应头、消息体(可选)三部分组成。例如我们通常熟悉的200和404分别表示连接正常和无法访问资源这两种响应状态。下面是一个基本的响应报文示例： 12345678910/* HTTP状态行 */HTTP/1.1 200 OK/* 响应头部 */Content-Type: text/html;charset=utf-8Connection: keep-aliveServer: Microsoft-IIS/7.0Date: Sun, 12 Jun 2016 11:00:42 GMTX-Powered-By: Hexo/* 消息体 */ &emsp;&emsp;这里需要说明的是，实际的请求报文和响应报文会因为服务端设计的不同，和这里的报文示例略有不同，报文中头部信息参数种类比较多，我不打算在这里详细解释每个参数的含义，我们只需要对报文格式有一个基本的认识即可，想了解这些内容的朋友可以阅读这里。在请求报文中我们注意到第一行，即HTTP请求行指明当前请求的方法。所以下面我们来说说HTTP协议的基本请求方法。常见的方法有GET、POST、HEAD、DELETE、OPTIONS、TRACE、CONNECT，我们这里选取最常用的两种方式，即GET和PSOT来讲解： GET：最为常见的一种请示方式。当客户端从服务器读取文档或者通过一个链接来访问页面的时候，都是采用GET方式来请求的。GET请求的一个显著标志是其请求参数附加在URL后，例如”/index.jsp?id=100&amp;option=bind”这种形式即为GET方式请求。GET方式对用户而言，传递参数过程是透明的，因为用户可以通过浏览器地址栏直接看到参数，所以这种方式更适合用来设计API，即在不需要验证身份或者对安全性要求不高的场合，需要注意的是GET方式请求对参数长度由一定限制。 POST：POST克服了GET方式对参数长度存在限制的缺点，以键-值形式将参数封装在HTTP请求中，所以从理论上讲它对参数长度没有限制(实际上会因为浏览器和操作系统的限制而大打折扣)，而且对用户来讲参数传递过程是不可见的，所以它是一种相对安全的参数传递方式。通常用户登录都会采取这种方式，我们在编写爬虫的时候遇到需要登录的情况通常都需要使用POST方式进行模拟登录。 Socket与HTTP的紧密联系&emsp;&emsp;到目前为止，我们基本上搞清楚了HTTP是如何运作的，这恰恰符合普通人对技术的认知水平，或许在普通人看起来非常简单的东西，对技术人员来讲永远都是复杂而深奥的，所以从这个角度来讲，我觉的我们更应该向技术人员致敬，因为是技术人员让这些经过其简化以后的复杂流程以一种产品的形态走进了你我的生活，感谢有技术和技术人员的存在，让我们这个世界更加美好。好了，现在我们来思考这样一个问题，Socket和HTTP有一种怎样的关联？这是因为我们目前所有对HTTP的理解都是一种形而上学上的理解，它现在仅仅是一种协议，可是协议离真正的应用很遥远不是吗？所以我们需要考虑如何去实现这样一种协议。我们注意到HTTP是建立在TCP/IP协议上的，所以HTTP的协议应该考虑用TCP/IP协议的实现来实现，考虑到Socket是TCP/IP协议的一种实现，所以我们非常容易地想到应该用Socket来构建一个HTTP服务器，由此我们找到了Socket和HTTP的紧密联系。 &emsp;&emsp;在找到Socket和HTTP的紧密联系以后，我们现在就可以开始着手来设计一个HTTP服务器了。我们的思路是这样的，首先我们在服务端创建一个Socket来负责监听客户端连接。每次客户端发出请求后，我们根据请问报文来判断客户端的请求类型，然后根据不同的请求类型进行相应的处理，这样我们就设计了一个基本的HTTP服务器。 从头开始设计HTTP服务器&emsp;&emsp;好了，现在我们要开始从头设计一个HTTP服务器了，在此之前，我们首先来为整个项目设计下面的基本约束。我一直非常好奇为什么有的开发者会如此强烈地依赖框架。尤其是在Web开发领域，MVC和MVVM基本上是耳熟能详到烂俗的词汇。我个人更加认同这是一种思想。什么是思想呢？思想是你知道其绝妙处而绝口不提，却在潜移默化中心领神会的运行它。可事实上是什么样呢？无数开发者被框架所禁锢，因为我们缺少了犯错的机会。所以我在这里不想再提及Java、PHP、.NET在Web开发领域里那些广为人知的框架，因为我认为忘掉这些框架可以帮助我们更好的理解框架，下面我就来用我的这种方法告诉大家什么叫做MVC？ &emsp;&emsp;什么叫做MVC？我们都知道MVC由模型、视图、控制器三部分组成，可是它们的实质是什么呢？我想这个问题可能没有人想过，因为我们的时间都浪费在配置XML文档节点上。(我说的就是Java里的配置狂魔) &emsp;&emsp;首先，模型是什么呢？模型对程序员而言可以是一个实体类，亦可以是一张数据表，而这两种认知仅仅是因为我们看待问题的角度不同而已，为了让这两种认知模型统一，我们想到了ORM、想到了根据数据表生成实体类、想到了在实体类中使用各种语法糖，而这些在我看来非常无聊的东西，竟然可以让我们不厌其烦地制造出各种框架，对程序员而言我还是喜欢理解为实体类。 &emsp;&emsp;其次，视图是什么呢？视图在我看来是一个函数，它返回的是一个HTML结构的文本，而它的参数是一个模型，一个经过我们实例化以后的对象，所以控制器所做的工作无非是从数据库中获取数据，然后将其转化为实体对象，再传递给视图进行绑定而已。这样听起来，我们对MVC的理解是不是就清晰了？而现在前端领域兴起的Vue.js和React，从本质上来讲是在纠结控制器的这部分工作该有前端来完成还是该有后端来完成而已。 &emsp;&emsp;MVC中有一个路由的概念，这个概念我们可以和HTTP中请求行来对应起来，我们知道发出一个HTTP请求的时候，我们能够从请求报文中获得请求方法、请求地址、请求参数等一系列信息，服务器正是根据这些信息来处理客户端请求的。那么，路由到底是什么呢？路由就是这里的请求地址，它可以是实际的文件目录、可以是虚拟化的Web API、可以是项目中的文件目录，而一切的一切都在于我们如何定义路由，例如我们定义的路由是”http://www.zhihu.com/people/vczh“，从某种意义上来讲，它和”http://www.zhihu.com/people/?id=vczh“是一样的，因为服务器总是能够一眼看出这些语法糖的区别。 &emsp;&emsp;虽然我在竭尽全力地避免形成对框架的依赖，可是在设计一个项目的时候，我们依然需要做些宏观上的规划，我设计的一个原则就是简单、轻量，我不喜欢重度产品，我喜欢小而美的东西，就像我喜欢C#这门语言而不喜欢ASP.NET一样，因为我喜欢Nancy这个名字挺起来文艺而使用起来简单、开心的东西。我不会像某语言一样丧心病狂地使用接口和抽象类的，在我这里整体设计是非常简单的： IServer.cs：定义服务器接口，该接口定义了OnGet()、OnPost()、OnDefault()、OnListFiles()四个方法，分别用来响应GET请求、响应POST请求、响应默认请求、列取目录，我们这里的服务器类HttpServer需要实现该接口。 Request.cs：封装来自客户端的请求报文继承自BaseHeader。 Response.cs：封装来自服务端的响应报文继承自BaseHeader。 BaseHeader.cs: 封装通用头部和实体头部。 HttpServer.cs: HTTP服务器基类需实现IServer接口。 &emsp;&emsp;因为我这里希望实现的是一种全局上由我来控制，细节上由你来决定的面向开发者的设计思路，这和通常的面向大众的产品思路是完全不同的。例如委托或者事件的一个重要意义就是，它可以让程序按照设计者的思路来运行，同时满足使用着在细节上的控制权。所以，在写完这个项目以后，我们就可以无需再关注客户端和服务端如何通信这些细节，而将更多的精力放在服务器接收到了什么、如何处理、怎样返回这样的问题上来，这和框架希望我们将精力放在业务上的初衷是一样的，可是事实上关注业务对开发者来讲是趋害的，对公司来讲则是趋利的。当你发现你因为熟悉了业务而逐渐沦落为框架填充者的时候，你有足够的理由来唤起内心想要控制一切的欲望。世界很大、人生很短，这本来就是一个矛盾的存在，当我们习惯在框架中填充代码的时候，你是否会想到人生本来没有这样的一个框架？ &emsp;&emsp;好了，现在我们来开始编写这个Web服务器中通信的基础部分。首先我们需要创建一个服务端Socket来监听客户端的请求。如果你熟悉Socket开发，你将期望看到下面这样的代码： 12345678910111213141516171819202122232425/// &lt;summary&gt;/// 开启服务器/// &lt;/summary&gt;public void Start()&#123; if(isRunning) return; //创建服务端Socket serverSocket = new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); serverSocket.Bind(new IPEndPoint(IPAddress.Parse(ServerIP), ServerPort)); serverSocket.Listen(10); isRunning = true; //输出服务器状态 Console.WriteLine(\"Sever is running at http://&#123;0&#125;:&#123;1&#125;/.\", ServerIP, ServerPort); //连接客户端 while(isRunning) &#123; Socket clientSocket = serverSocket.Accept(); Thread requestThread = new Thread(() =&gt;&#123; ProcessRequest(clientSocket);&#125;); requestThread.Start(); &#125;&#125; 这里我们使用isRunning来表示服务器是否运行，显然当服务器处在运行状态时，它应该返回。我们这里使用ServerIP和ServerPort分别表示服务端IP和端口，创建服务端Socket这里就不再赘述了，因为这是非常简单而基础的东西。当服务器处在运行状态时我们接受一个客户端请求，并使用一个独立的线程来处理请求，客户端请求的处理我们这里提供了一个叫做ProcessRequest的方法，它具体都做了什么工作呢？我们继续往下看： 123456789101112131415161718/// &lt;summary&gt;/// 处理客户端请求/// &lt;/summary&gt;/// &lt;param name=\"handler\"&gt;客户端Socket&lt;/param&gt;private void ProcessRequest(Socket handler)&#123; //构造请求报文 HttpRequest request = new HttpRequest(handler); //根据请求类型进行处理 if(request.Method == \"GET\")&#123; OnGet(request); &#125;else if(request.Method == \"POST\")&#123; OnPost(request); &#125;else&#123; OnDefault(); &#125;&#125; 接下来我们可以注意到我们这里根据客户端Soket构造了一个请求报文，其实就是在请求报文的构造函数中通过解析客户端发来的消息，然后将其和我们这里定义的HttpRequest类对应起来。我们这里可以看到，根据请求方法的不同，我们这里分别采用OnGet、OnPost和OnDefault三个方法进行处理，而这些是定义在IServer接口中并在HttpServer类中声明为虚方法。严格来讲，这里应该有更多的请求方法类型，可是因为我这里写系列文章的关系，我想目前暂时就实现Get和Post两种方法，所以这里大家如果感兴趣的话可以做更深层次的研究。所以，现在我们就明白了，因为这些方法都被声明为虚方法，所以我们只需要HttpServer类的子类中重写这些方法就可以了嘛，这好像离我最初的设想越来越近了呢。关于请求报文的构造，大家可以到http://github.com/qinyuanpei/HttpServer/中来了解，实际的工作就是解析字符串而已，这些微小的工作实在不值得在这里单独来讲。 &emsp;&emsp;我们今天的正事儿是什么呢？是Hello World啊，所以我们需要想办法让这个服务器给我们返回点什么啊，接下来我们继承HttpServer类来写一个具体的类MyServer，和期望的一样，我们仅仅需要重写相关方法就可以写一个基本的Web服务器，需要注意的是子类需要继承父类的构造函数。我们一起来看代码： 123456789101112131415161718192021222324252627using System;using System.Collections.Generic;using System.Linq;using System.Text;using System.Threading.Tasks;using System.IO;namespace HttpServerLib&#123; public class MyServer : HttpServer &#123; public MyServer(string ipAddress, int port) : base(ipAddress, port) &#123; &#125; public override void OnGet(HttpRequest request) &#123; HttpResponse response = new HttpResponse(\"&lt;html&gt;&lt;body&gt;&lt;h1&gt;Hello World&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt;\", Encoding.UTF8); response.StatusCode = \"200\"; response.Server = \"A Simple HTTP Server\"; response.Content_Type = \"text/html\"; ProcessResponse(request.Handler, response); &#125; &#125;&#125; 可以注意到我们这里构造了一个HttpResponse，这是我这里定义的HTTP响应报文，我们这里响应的内容是一段简单的HTML采用UTF-8编码。在构造完HttpResponse以后我们设定了它的相关状态，熟悉Web开发的朋友应该可以想到这是抓包工具抓包时得到的服务端报文信息，最近博主最喜欢的某个妹子写真集网站开始反爬虫了，因此博主以前写的Python脚本现在执行会被告知403，这是一个禁止访问的状态码。解决方案其实非常简单地，将HTTP请求伪装成一个“浏览器”即可，思路就是在HTTP请求报文中增加相关字段，这样就可以“骗”过服务器，当然更深层次的“欺骗”就是Cookie和Session级别的伪装了，这个话题我们有时间再说。这里我们设定状态码为200，这是一个正常的请求，其次ContentType等字段可以自行阅读HTTP协议中头部字段的相关资料，最后我们通过ProcessResponse这个方法来处理响应，其内部是一个使用Socket发送消息的基本实现，详细的设计细节大家可以看项目代码。 &emsp;&emsp;现在让我们怀着无比激动的心情运行我们的服务器，此时服务器运行情况是： 服务器运行情况 这样是不是有一种恍若隔世的感觉啊，每次打开Hexo的时候看到它自带的本地服务器，感觉非常高大上啊，结果万万没想到有朝一日你就自己实现了它，这叫做“长大以后我就成了你吗”？哈哈，现在是见证奇迹的时刻： 浏览器运行情况 浏览器怀着对未来无限的憧憬，自豪地写下“Hello World”，正如很多年前诗人北岛在绝望中写下的《相信未来》一样，或许生活中眼前都是苟且，可是只要心中有诗和远方，我们就永远不会迷茫。好了，至此这个系列第一篇Hello World终于写完了，简直如释重负啊，第一篇需要理解和学习的东西实在太多了，本来打算在文章后附一份详细的HTTP头部字段说明，可是因为这些概念实在太枯燥，而使用Markdown编写表格时表格内容过多是写作者的无尽痛苦。关于这个问题，大家可以从这里找到答案。下期再见！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"HTTP","slug":"HTTP","permalink":"https://qinyuanpei.github.io/tags/HTTP/"},{"name":"服务器","slug":"服务器","permalink":"https://qinyuanpei.github.io/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"C#","slug":"C","permalink":"https://qinyuanpei.github.io/tags/C/"}]},{"title":"扫描二维码在移动设备上浏览响应式页面","date":"2016-05-01T10:58:18.000Z","path":"posts/2158696176/","text":"&emsp;&emsp;最近想尝试对一个Ghost博客主题进行移植，因为对一个后端程序员来说，进行前端方面的工作实在是个不小的挑战，而我对CSS更是有种与生俱来的恐惧感，所以我是非常喜欢Bootstrap和Materilize这种对后端程序员友好的前端框架。现在前端技术如火如荼，而前端技术作为最有可能实现跨平台技术的技术形态，相对原生技术有着更为灵活的适应性和扩展性，因此以响应式设计为代表的Web技术，能够让Web页面在不同尺寸屏幕上都有着相近的体验，因为目前软件开发基本都是在计算机设备上来完成的，这样我们在制作Web页面的时候就需要在不同的设备上进行调试，如果每次都将Web页面部署到远程服务器上，这样将浪费大量的时间而且容易将测试阶段的问题暴露给用户，因此本文将采用一种扫描二维码的方式来实现在移动设备上浏览响应式页面。 工作原理&emsp;&emsp;因为我们这里是在测试阶段在不同的移动设备上浏览响应式页面，所以这些Web页面实际上是部署在本地服务器上的，因此这个问题的实质就是如何让移动设备访问本地服务器，这个问题无论从原理上还是实现上来讲都不复杂，只要保证运行本地服务器的计算机和移动设备在同一个局域网内就可以了，考虑到移动设备的便携性，采用无线局域网的方式对移动设备更为友好。我们知道Windows系统，从Windows7版本以后就可以支持虚拟热点的创建，因此可以说是近水楼台啦！在这种情况下，理论上我们可以直接使用运行本地服务器的计算机的IP来访问本地服务器，可是因为不同的服务器软件配置不同以及不同的计算机设置不同等等外部性的因素，在实际操作的过程中依然存在各种问题，下面我们就来针对实际操作中需要注意和解决的问题，来说说具体的实现过程。 实现过程&emsp;&emsp;考虑到实际操作中的配置项目主要由计算机设置和服务器设置两部分组成，因此我们这里对这两部分各自进行详细说明。##计算机设置 热点的创建 1、创建一个名称为QRPager-WIFI的无线网络，其密码为88888888 1netsh wlan set hostednetwork ssid=QRPager-WIFI key=88888888 2、开启网络热点确保其它设备可以访问这个热点 1netsh wlan start hostednetwork 3、关闭网络热点 1netsh wlan stop hostednetwork 防火墙设置 &emsp;&emsp;防火墙设置非常简单，因为关闭防火墙就好啦，这样可以保证其它设备能够正常访问本地服务器，在测试完页面后应该立即开启防火墙，这个世界可谓是充满了诱惑，有诱惑的地方就有危险，所以当我们通过互联网获取知识的同时，更为重要的一点是学会如何去甄别信息的真伪，魏则西事件让我们每一个人都感到痛心，可我们必须认识到，即使百度在你我的口诛笔伐中宣告破产，对这个世界的影响永远都是杯水车薪，所以无论是杀毒软件还是防火墙，任何形式的东西都不能代替你保护自我的意识，就像在地震、火灾这类破坏性灾难中，学会自救互救比等待公共救援更为有效。 服务器设置 IIS设置 &emsp;&emsp;IIS设置起来非常简单，只要在网站“绑定”设置中设置本地服务器所在计算机的IP地址即可，这样做的目的是保证服务器可以使用除了127.0.0.1和localhost以外地址来访问，因为我们在手机上访问本地服务器的时候，需要指定本地服务器所在计算机的IP。 Apache设置 &emsp;&emsp;Apache设置相对Geek，因为我们都知道它需要去编辑httpd.conf这个文件来开启或者关闭特定功能。但在这里它并不会显得复杂，因为和IIS一样，我们要进行的修改是让Apache可以通过除localhost以外的地址进行访问。在该文件中找到下列片段： 1234567891011121314151617181920212223242526272829303132&lt;Directory \"D:/Program Files/WAMP/www/\"&gt; # # Possible values for the Options directive are \"None\", \"All\", # or any combination of: # Indexes Includes FollowSymLinks SymLinksifOwnerMatch ExecCGI MultiViews # # Note that \"MultiViews\" must be named *explicitly* --- \"Options All\" # doesn't give it to you. # # The Options directive is both complicated and important. Please see # http://httpd.apache.org/docs/2.2/mod/core.html#options # for more information. # Options Indexes FollowSymLinks # # AllowOverride controls what directives may be placed in .htaccess files. # It can be \"All\", \"None\", or any combination of the keywords: # Options FileInfo AuthConfig Limit # AllowOverride all # # Controls who can get stuff from this server. ## onlineoffline tag - don't remove Order Deny,Allow Allow from all #将这里由\"Deny from all\"修改为\"Allow from all\" Allow from 127.0.0.1&lt;/Directory&gt; 将第29行代码由”Deny from all”修改为”Allow from all”即可，这样就可以给其它设备访问本地服务器的权限，至此，这个问题得以成功解决。 总结&emsp;&emsp;这篇文章无论从需求还是实现上来讲都是非常简单的，我之所以想写这篇文章，更多的是希望帮助大家克服这些“非技术性”的问题，因为有时候阻碍我们的可能并非问题本身，而是因为一个微不足道的部分，就像我们无法使用Google并非是因为Google使用起来有多么的困难，而是因为一道技术含量非常低的防火墙，在开发中除了我们使用的编程语言，任何开发工具、部署工具都可能出现这种问题，所以除了技术本身以外，关注这些“非技术性”因素同样是非常重要的一件事情。在这个设计中，有一个问题，即用户连接到无线网络是一个手动去完成的行为，换言之在扫描二维码前用户必须首先连接到无线网络。这样让我感觉显得不够优雅，我一直在思考有没有一种方法可以通过扫描二维码，直接建立移动设备到本地服务器的连接，可是二维码保存的是普通的文本信息，除非我能够通过二维码去调用Android系统中的Intent，否则这个过程是没有办法实现自动化的，一个更好的想法是在PC端生成二维码图片，在手机端通过编写二维码应用来实现两者间的Socket通信，而通信的细节如IP地址、端口号等则可以通过二维码来进行加密和解密。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Web","slug":"Web","permalink":"https://qinyuanpei.github.io/tags/Web/"},{"name":"二维码","slug":"二维码","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%8C%E7%BB%B4%E7%A0%81/"},{"name":"响应式","slug":"响应式","permalink":"https://qinyuanpei.github.io/tags/%E5%93%8D%E5%BA%94%E5%BC%8F/"}]},{"title":"使用Mono打造轻量级的.NET程序运行时","date":"2016-03-25T12:47:58.000Z","path":"posts/907824546/","text":"&emsp;&emsp;在使用Mono让.NET程序跨平台运行这篇文章中，我们已经对Mono以及.NET程序的运行机制有了初步的理解。今天我想来谈谈”使用Mono打造轻量级的.NET运行时”这样一个话题。为什么我会有这样一种想法呢？因为Mono和.NET都可以执行IL代码，所以我用Mono来作为.NET程序的运行时是一个顺理成章的想法。由于.NET程序需要.NET Framework提供运行支持，所以当目标设备没有安装.NET Framework或者.NET Framework版本不对的时候，我们的程序都无法顺利运行。强迫用户安装.NET框架无疑会影响用户体验，在Windows XP尚未停止服务前，国内软件厂商为了兼容这些用户，通常会选择C++这类语言来编写原生应用，这就造成了国内.NET技术长期不被重视的现状。 考虑.NET版本的兼容&emsp;&emsp;在考虑使用Mono来作为.NET应用程序的运行时前，首先我们来考虑.NET版本的兼容问题。假设我们使用.NET Framework 3.5版本生成了一个应用程序，那么这个应用程序将在安装了.NET Framework v3.5的计算机上运行，如果目标计算机上没有安装.NET Framework v3.5，这个应用程序将无法正常运行。这个时候，我们可以有两种解决方案：第一种，强迫用户安装.NET Framework v3.5，无论是将该框架集成到安装包中，还是在安装软件的时候自动从网上下载安装，显然这种方式都会影响用户的使用体验让用户对应用程序的印象大打折扣；第二种，尝试让应用程序和.NET版本兼容。我们知道Android程序有一个最低API版本的设置，这样能够保证应用程序在不低于该API版本的设备上运行。这里我们选择这种思路，在.NET程序中，我们可以通过应用程序配置文件中的supportedRuntime节点来指定应用程序运行的.NET Framework版本。例如下面的配置文件能够保证应用程序在.NET Framework v2.0到v3.5间的版本上运行。 12345678&lt;?xml version=\"1.0\"?&gt;&lt;configuration&gt; &lt;startup&gt; &lt;supportedRuntime version=\"v2.0.50727\"/&gt; &lt;supportedRuntime version=\"v3.0\"/&gt; &lt;supportedRuntime version=\"v3.5\"/&gt; &lt;/startup&gt;&lt;/configuration&gt; 虽然说这样能够保证应用程序的兼容性，可是你这个应用程序的命运却是掌握在.NET Framework手里的，如果用户的计算机上没有安装.NET Framework我们一样还是没辙儿，那么怎么办呢？我们来搭建Mono运行时。 Mono运行时的搭建&emsp;&emsp;我们在前面说过，Mono主要由三部分组成，即C#编译器(mcs.exe)、Mono运行时(mono.exe)和基础类库。因为我们这里是为了让编写的.NET应用程序运行在Mono运行时中，所以我们这里需要的是Mono运行时(mono.exe)和基础类库。我们建立如下的目录结构： Mono运行时目录结构 下面来说说这些目录各自的结构和功能： bin目录：放置Mono运行时的目录，主要放置mono.exe、mono-2.0.dll、libgio-2.0-0.dll、libglib-2.0-0.dll、libgthread-2.0-0.dll共5个文件。 lib目录：放置Mono依赖库的目录，主要放置.NET库目录(此处以4.0为例)、Gac库目录。其中Gac库目录下的Accessibility、Mono.Posix、System、System.Drawing、System.Windows.Forms共5个子目录是我们开发WindowsForm需要使用到的依赖库。 etc目录：放置我们编写的程序及其相关文件，主程序的文件名为Main.exe。 &emsp;&emsp;好了，现在我们就具备了一个非常轻量级的.NET程序运行环境(其实整个环境的大小在40M左右)，注意以上文件都可以在安装Mono在其安装目录内找到。根据博主目前了解到的资料来看，通过Mono运行时来运行文件主要有命令行和一种被称为Mono Embedding的方案。特别地，第二种方案可以直接将运行时嵌入到程序内，我们熟悉的Unity3D引擎就是将整个脚本的运行时嵌入到了C++程序中，但是这种方式比较复杂，暂时博主还没有弄清楚它的内部机制，所以我们这里选择第一种方案。可是它要用命令行啊，迫使普通用户来使用命令行工具是件痛苦的事情，就像我们常常被Git搞得晕头转向一样。那么，我们就用程序来模拟命令行好了！什么？用程序来模拟命令行？这个用C#来写简直不能更简单了好吗？请注意我们这里是不能使用.NET Framework里的功能的，因为它就是一个引导程序嘛，如果引导程序都需要依赖.NET，那我们这个程序怎么搞啊。 &emsp;&emsp;好嘛，那就写C++原生应用吧，它是无需任何依赖的。而在C++中模拟命令行主要有WinExec、ShellExecute和CreateProcess三种方法，关于这三种方法的异同大家可以自行了解，这里我们选择最简单的WinExec。代码如下： 123456789#include &lt;Windows.h&gt;int main(int agrc,char *args[])&#123; /* 执行命令 */ WinExec(\"bin\\\\mono.exe etc\\\\Main.exe\",SW_NORMAL); return 0;&#125; 我们将编译好的程序命名为Launcher.exe，放置我们前面定义的Mono运行时目录结构的根目录下，这个文件将作为启动文件暴露给用户，当用户点击这个程序后就可以打开主文件Main.exe。好了，现在我们来验证下我们的想法： 运行在Mono运行时下的程序 作为对比，我们给出正常情况下程序的运行截图： 运行在.NET框架下的程序 这样我们现在这个程序就基本实现了脱离.NET框架运行，为什么说是基本呢？因为.NET中的基础类库是作为.NET框架中的一部分存在的，即它并非是CLR的内容。所以我们现在使用到的大部分的基础类库都是Mono重新实现的版本，如果我们使用的某一个库在Mono中没有相应的实现，那么我们就需要自己想办法来解决依赖问题了。现在这个方案每次运行的时候都会闪出命令行窗口，虽然不影响使用，但对一个追求完美的人来说就是瑕疵啦，怎么解决呢？答案就是Mono Embedding。 本文小结&emsp;&emsp;本文通过Mono实现了一个轻量级的.NET程序运行环境，从某种程度上来说，它间接地实现了.NET程序脱离.NET Framework运行。这个方案目前看起来存在的主要问题是库依赖的问题，我们现在这个环境有将近40M左右的体积，这是因为我们将常用的库都放在了lib目录中，可是在实际运行中，这些库并非完全都会用到，因此如何根据程序来生成合适的lib目录，是解决运行时环境体积的有效方法。如果靠手动来解决这个问题，这显得困难重重，因为在平时微软将这些库都给我们了，它就在我们的计算机上，所以我们从来没有关注过这个问题。现在当我们面对这个问题的时候，反射可能是种不错的想法，但这种想法的验证就要等到以后啦！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":".NET","slug":"NET","permalink":"https://qinyuanpei.github.io/tags/NET/"},{"name":"Linux","slug":"Linux","permalink":"https://qinyuanpei.github.io/tags/Linux/"},{"name":"Mono","slug":"Mono","permalink":"https://qinyuanpei.github.io/tags/Mono/"},{"name":"跨平台","slug":"跨平台","permalink":"https://qinyuanpei.github.io/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/"}]},{"title":"使用Mono让.NET程序跨平台运行","date":"2016-03-06T12:20:09.000Z","path":"posts/1836680899/","text":"&emsp;&emsp;众所周知，Unity3D引擎凭借着强大的跨平台能力而备受开发者的青睐，在跨平台应用开发渐渐成为主流的今天，具备跨平台开发能力对程序员来说就显得特别重要。传统的针对不同平台进行开发的方式常常让开发者顾此失彼，难以保证应用程序在不同的平台都有着相同的、出色的体验，这种情况下寻找到一种跨平台开发的方式将会为解决这个问题找到一种思路。从目前的开发环境来看，Web应该是最有可能成为跨平台开发的神兵利器，可是长期以来Web开发中前端和后端都有各自不同的工作流，虽然现在出现了前端和后端逐渐融合的趋势，可在博主看来想让Web开发变得像传统开发这样简单还需要一定的过渡期。 从Mono到Xamarin&emsp;&emsp;对Unity3D来说，Mono是实现它跨平台的核心技术。Mono是一个旨在使得.NET在Linux上运行的开源项目。它通过内置的C#语言编译器、CLR运行时和各种类库，可以使.NET应用程序运行在Windows、Linux、FreeBSD等不同的平台上。而在商业领域，Xamarin则实现了用C#编写Android和iOS应用的伟大创举。Windows10发布的时候，微软提出了通用应用UWP的设想，在这种设想下开发者可以直接在最新的Visual Studio中使用C#编写跨平台应用。最近微软收购了Xamarin，这一举措能够保证Xamarin这样的商业项目可以和微软的产品融合地更好。虽然在传统Web开发中Java和PHP目前占据主要优势，可是虽然云计算技术的流行，服务器成本的降低或许会让C#这样优秀的语言更加成熟。我一直坚信技术没有好坏的区别，一切技术问题的核心是人，所以接下来，我们打算追随着跨平台开发的先驱——Java，最早提出的“一次编写、到处运行”的伟大思想来探索C#程序跨平台的可能性。 Mono跨平台的原理&emsp;&emsp;在提到Mono跨平台的时候，我们首先需要引入公共语言基础(Common Language Infrastructure，CLI)这个概念，CLI是一套ECMA定义的标准，它定义了一个和语言无关的跨体系结构的运行环境，这使得开发者可以用规范定义内各种高级语言来开发软件，并且无需修正即可让软件运行在不同的计算机体系结构上。因此我们可以说跨平台的原理是因为我们定义了这样一个和语言无关的跨体系结构的运行环境规范，只要符合这个规范的应用程序都可以运行在不同的计算机体系结构上，即实现了跨平台。针对这个标准，微软实现了公共语言运行时（Common Language Runtime，CLR)，因此CLR是CLI的一个实现。我们熟悉的.NET框架就是一个在CLR基础上采用系统虚拟机的编程平台，它为我们提供了支持多种编程语言如C#、VB.NET、C++、Python等。我们编写的C#程序首先会被C#编译器编译为公共中间语言即CIL或者是MSIL(微软中间语言)，然后再由CLR转换为操作系统的原生代码（Native Code）。 &emsp;&emsp;好了，现在我们来回答最开始的问题：Mono为什么能够跨平台。我们回顾.NET程序运行机制可以发现实现.NET跨平台其实需要这三个关键：编译器、CLR和基础类库。在.NET下我们编写一个最简单的“Hello World”都需要mscorlib.dll这个动态链接库，因为.NET框架已经为我们提供了这些，因为在我们的计算机上安装着.NET框架，这是我们编写的应用程序能够在Windows下运行的原因。再回头来看Mono，首先Mono和CLR一样，都是CLI这一标准的实现，所以我们可以理解为Mono实现了和微软提供给我们的类似的东西，因为微软的.NET框架属于商业化闭源产品，所以Mono除了在实现CLR和编译器的同时实现了大量的基础库，而且在某种程度上Mono实现的版本与相同时期.NET的版本有一定的差距，这点使用Unity3D开发游戏的朋友应该深有感触吧！这就决定了我们在将应用程序移植到目标平台时能否实现在目标平台上和当前平台上是否能够具有相同的体验。因为公共中间语言即CIL能够运行在所有实现了CLI标准的环境中，而CLI标准则是和具体的平台或者说CPU无关的，因此只要Mono运行时能够保证CIL的运行，就可以实现应用程序的跨平台。我们可以通过下面这张图来总结下这部分内容： 开发第一个跨平台程序&emsp;&emsp;下面我们来尝试开发第一个跨平台程序，我们使用Visual Studio或者MonoDevelop编写一个简单的控制台应用程序，为了减少这个程序对平台特性的依赖，我们这里选择System这个命名空间来实现最为基础的Hello World，这意味着我们的应用程序没有使用任何除mscorlib.dll以外的库： 123456789101112using System;namespace MonoApplication&#123; class MainClass &#123; public static void Main(string[] args) &#123; Console.WriteLine(\"Hello World!\"); &#125; &#125;&#125; &emsp;&emsp;因为我们的计算机安装了.NET框架，所以我们编写的这个程序会被C#编译器编译为公共中间语言CIL,然后再由CLR转换为Native Code。通常情况下公共中间语言(CIL)会被存储到.il文件中，可是在这里我们在编译的时候好像并没有看到这个文件的生成啊，这是因为这里生成的可执行文件(.exe)本质上是公共中间语言(CIL)形态的可执行文件。这一点我们可以通过ildasm这个工具来验证，该工具可以帮助我们查看IL代码，通常它位于C:\\Program Files\\Microsoft SDKs\\Windows\\v7.0A\\bin这个位置。下面是通过这个工具获得的IL代码： 1234567891011.method public hidebysig static void Main(string[] args) cil managed&#123; .entrypoint // 代码大小 13 (0xd) .maxstack 8 IL_0000: nop IL_0001: ldstr \"Hello World!\" IL_0006: call void [mscorlib]System.Console::WriteLine(string) IL_000b: nop IL_000c: ret&#125; // end of method MainClass::Main &emsp;&emsp;可以看到这段代码和我们编写的程序中的Main方法完全对应，关于这段代码的含义，大家可以通过搜索引擎来了解IL代码的语法。因为我们这里想要说明的是，这里生成的可执行文件(.exe)从本质上来讲并非是一个可执行文件。因为它能否执行完全是取决于CPU的，这和我们直接用C++编写的应用程序不同，我们知道不同的编译器如Windows下的VC++和Linux下的GCC都是和硬件紧密相连的，所以我们编译的程序能够在各自的平台直接运行，即CPU是认识这些程序的。可是在.NET这里就不一样了，因为我们通过C#编译器即csc.exe编译出来的文件，其实是一个看起来像可执行文件，实际上却是一个和平台无关、和CPU无关的IL文件。 &emsp;&emsp;那么我们就会感到迷茫了啊，平时我们编译完C#程序双击就可以打开啊，哈哈，现在隆重请出.NET程序的家长公共语言运行时(CLR)。公共语言运行时实际上是程序运行的监管者，程序运行的情况完全由运行时来决定。我们双击这个文件的时候，公共语言运行时会将其加载到内存中，然后由即时编译器(JIT)来识别IL文件，然后由CPU去完成相应的操作。 &emsp;&emsp;所以我们可以这样理解.NET程序跨平台，因为IL文件是一个和平台无关、和CPU无关的、跨平台的文件结构，所以我们只需要在不同的平台上实现这样一个公共语言运行时(CLR)就可以实现在不同的平台上运行同一个程序。但这个过程中，需要有一个C#编译器负责将C#代码转换为IL代码，然后需要有一个公共语言运行时(CLR)来解析IL代码。与此同时，我们在.NET框架下使用了大量的基础类库，这些类库在Windows以外的平台是没有的，所以除了C#编译器和公共语言运行时以外，我们还需要基础类库。现在大家是不是对Mono有了更清楚的认识了呢？没错，Mono所做的事情其实就是我们在讨论的这些事情。这里博主想说说即时编译(JIT)和静态编译(AOT)，这两种编译方式我们可以按照”解释型”和”编译型”来理解,为什么Unity3D在iOS平台上做热更新的时候会出现问题呢？这是因为iOS平台考虑到安全性禁止使用JIT即时编译，所以像C#这种需要编译的语言在这里就无计可施了。 &emsp;&emsp;好了，既然我们有Mono这样的工具能够帮助我们实现跨平台开发。那么我们现在就来考虑将这个程序移植到Linux平台，这里以Linux Deepin为例，我们按照C#程序编译的过程来完成这个移植过程： 1、将C#程序编译为IL文件：在.NET下我们使用csc.exe这个程序来完成编译，在Mono下我们使用mcs.exe这个程序来完成编译，这个程序在安装完Mono以后在其安装目录内可以找到。我们在命令行下输入命令：1mcs D:\\项目管理\\CSharp\\MonoApplication\\MonoApplication\\Main.cs 2、这样将生成Main.exe这样一个IL文件，现在我们需要一个运行时来解析它，在.NET下我们使用CLR来完成这个步骤，在Mono下我们使用mono.exe这个文件来完成这个步骤。我们在命令行下输入下列命令：1mono D:\\项目管理\\CSharp\\MonoApplication\\MonoApplication\\Main.exe 在Mono中运行.NET程序 我们可以看到命令行下输出了我们期望的Hello World，这意味着我们编写的程序现在运行在Mono中了，实际上在Windows下由Mono提供的C#编译器mcs.exe编译的IL文件双击是可以直接运行的，因为我们的计算机上安装了CLR，它作为.NET的一部分内置在我们的计算机中。由此我们会发现一个问题，我们这里的跨平台实际上是编译器、运行时和基础类库这三部分的跨平台，这意味着我们在Linux下运行.NET程序是需要Mono提供支持的。因为在这里我无法在Linux离线安装Mono，所以Linux下运行.NET程序的验证需要等博主以后有时间再来更新啦！可是我们可以想象到，通过C#编译器编译得到的可执行文件在Linux下是无法正常运行的，因为通常情况下Windows程序在Linux下运行是需要虚拟机环境或者Wine这样的软件来支持的，显然让这样一个Windows程序运行在Linux环境下是因为我们在Linux下安装了Mono。 谈谈Mono跨平台以后&emsp;&emsp;好了，到现在为止我们基本理清了Mono跨平台的原理。我们知道微软的技术体系在发展过程中因为某些历史遗留问题，.NET程序在不同的Windows版本中的兼容性有时候会出现问题，虽然微软宣布Windows XP停止维护，我们编写Windows应用程序的时候可以忽略对Windows XP版本的支持，可是因为国内用户不喜欢在线更新补丁的这种普遍现状，所以假如让用户在安装程序的时候先去安装.NET框架一定会降低用户体验，其次.NET框架会增加应用程序安装包的大小，所以我们需要一种能够让我们开发的.NET应用程序在脱离微软的这套技术体系时，同时能够安全、稳定的运行，所以我们这里考虑借助Mono让.NET程序脱离.NET框架运行。 &emsp;&emsp;首先，我们来说说.NET程序为什么能够脱离.NET框架运行，我们注意到Mono提供了一个Mono运行时，所以我们可以借助这样一个运行时来运行编译器生成的IL代码。我们继续以Hello World为例，我们在使用Mono编译出IL代码以后需要使用Mono运行时来解析IL代码，所以假如我们可以编写一个程序来调用Mono运行时就可以解决这个问题。在这个问题中，其实精简应用程序安装包的大小从本质上来讲就是解决基础类库的依赖问题，因为Mono实现了.NET框架中大部分的基础类库，所以移植.NET应用程序的关键是基础类库的移植，比如WinForm在Linux下的解决方案是GTK，这些细节在考虑跨平台的时候都是非常重要的问题。 小结&emsp;&emsp;本文从Mono跨平台的原理说起，探讨了.NET应用程序跨平台的可能性和具体实现。跨平台是一个涉及到非常多内容的话题，我个人理解的跨平台是要编写跨平台的代码，这意味着我们在编写程序的时候需要考虑减少对平台特性的移植，比如说Linq是一个非常棒的特性，可是这个特性离开了Windows、离开了.NET就没有办法得到保证，所以如果要让使用了Linq的应用程序跨平台就会是一件非常麻烦的事情！在不同的平台间保持相同的体验很难，就像我们编写的Web程序在不同的浏览器间都有着不一样的表现，所以跨平台这个问题我们就抱着学习的态度来研究吧！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":".NET","slug":"NET","permalink":"https://qinyuanpei.github.io/tags/NET/"},{"name":"Linux","slug":"Linux","permalink":"https://qinyuanpei.github.io/tags/Linux/"},{"name":"Mono","slug":"Mono","permalink":"https://qinyuanpei.github.io/tags/Mono/"},{"name":"跨平台","slug":"跨平台","permalink":"https://qinyuanpei.github.io/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/"}]},{"title":"在Unity3D中基于订阅者模式实现事件机制","date":"2016-01-15T12:30:41.000Z","path":"posts/632291273/","text":"&emsp;&emsp;各位朋友，大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是http://qinyuanpei.com。今天博主想和大家分享的是在Unity3D中基于订阅者模式实现消息传递机制，我们知道Unity3D中默认提供了一种消息传递机制SendMessage，虽然SendMessage使用起来的确非常简单，可是它的这种简单是建立在付出一定的代价的基础上的。经常有朋友提及不同的模块间如何进行通信的问题，可能答案最终会落到单例模式、委托和事件机制这些关键词上，在这种情况下本文所探讨的内容可能会帮助你找到最终的答案。 从生活中得到的启示&emsp;&emsp;我们知道通过在Unity3D中通过GetComponent就可以获得某个模块的实例，进而引用这个实例完成相关任务的调用。可是显然这种方法，就像我们随身带着现金去和不同的人进行交易，每次交易的时候都需要我们考虑现金的支入和支出问题，从安全性和耦合度两个方面进行考虑，这种方法在面对复杂的系统设计的时候，非常容易造成模块间的相互依赖，即会增加不同模块间的耦合度。为了解决这个问题，大家开始考虑单例模式，因为单例模式能够保证在全局内有一个唯一的实例，所以这种方式可以有效地降低模块间的直接引用。单例模式就像是我们在银行内办理了一个唯一的账户，这样我们在交易的时候只需要通过这个账户来进行控制资金的流向就可以了。单例模式确保了各个模块间的独立性，可是单例模式更多的是一种主动行为，即我们在需要的时候主动去调用这个模块，单例模式存在的问题是无法解决被调用方的反馈问题，除非被调用方主动地去调用调用方的模块实例。说到这里我们好像看到了一种新的模式，这就是我们下面要提到的事件机制。 订阅者模式和事件机制&emsp;&emsp;首先这里要提到一种称为“订阅者模式”的设计模式，这种设计模式在《大话设计模式》这本书中称为“观察者模式”或者“发布-订阅（Publish/Subscribe）模式”，我们这里暂且叫做“订阅者模式”吧！该模式定义了一种一对多的依赖关系，让多个观察者对象同时监听某一个主题对象。这个对象在状态发生变化时会通知所有观察者对象，使它们能够自动更新自己。针对这个模式，我们可以考虑事件机制的实现，事件机制可以理解为在一个事件中心（Subject）保存有对所有事件（Observer）的引用，事件中心负责对这些事件进行分发，这样每个事件就可以通过回调函数的方式进行更新，这样就实现了一个事件机制。下面给出基本的代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109using System;using System.Collections;using System.Collections.Generic;using UnityEngine;namespace UniEventDispatcher&#123; /// &lt;summary&gt; /// 定义事件分发委托 /// &lt;/summary&gt; public delegate void OnNotification(Notification notific); /// &lt;summary&gt; ///通知中心 /// &lt;/summary&gt; public class NotificationCenter &#123; /// &lt;summary&gt; /// 通知中心单例 /// &lt;/summary&gt; private static NotificationCenter instance=null; public static NotificationCenter Get() &#123; if(instance == null)&#123; instance = new NotificationCenter(); return instance; &#125; return instance; &#125; /// &lt;summary&gt; /// 存储事件的字典 /// &lt;/summary&gt; private Dictionary&lt;string,OnNotification&gt; eventListeners = new Dictionary&lt;string, OnNotification&gt;(); /// &lt;summary&gt; /// 注册事件 /// &lt;/summary&gt; /// &lt;param name=\"eventKey\"&gt;事件Key&lt;/param&gt; /// &lt;param name=\"eventListener\"&gt;事件监听器&lt;/param&gt; public void AddEventListener(string eventKey,OnNotification eventListener) &#123; if(!eventListeners.ContainsKey(eventKey))&#123; eventListeners.Add(eventKey,eventListener); &#125; &#125; /// &lt;summary&gt; /// 移除事件 /// &lt;/summary&gt; /// &lt;param name=\"eventKey\"&gt;事件Key&lt;/param&gt; public void RemoveEventListener(string eventKey) &#123; if(!eventListeners.ContainsKey(eventKey)) return; eventListeners[eventKey] =null; eventListeners.Remove(eventKey); &#125; /// &lt;summary&gt; /// 分发事件 /// &lt;/summary&gt; /// &lt;param name=\"eventKey\"&gt;事件Key&lt;/param&gt; /// &lt;param name=\"notific\"&gt;通知&lt;/param&gt; public void DispatchEvent(string eventKey,Notification notific) &#123; if (!eventListeners.ContainsKey(eventKey)) return; eventListeners[eventKey](notific); &#125; /// &lt;summary&gt; /// 分发事件 /// &lt;/summary&gt; /// &lt;param name=\"eventKey\"&gt;事件Key&lt;/param&gt; /// &lt;param name=\"sender\"&gt;发送者&lt;/param&gt; /// &lt;param name=\"param\"&gt;通知内容&lt;/param&gt; public void DispatchEvent(string eventKey, GameObject sender, object param) &#123; if(!eventListeners.ContainsKey(eventKey)) return; eventListeners[eventKey](new Notification(sender,param)); &#125; /// &lt;summary&gt; /// 分发事件 /// &lt;/summary&gt; /// &lt;param name=\"eventKey\"&gt;事件Key&lt;/param&gt; /// &lt;param name=\"param\"&gt;通知内容&lt;/param&gt; public void DispatchEvent(string eventKey,object param) &#123; if(!eventListeners.ContainsKey(eventKey)) return; eventListeners[eventKey](new Notification(param)); &#125; /// &lt;summary&gt; /// 是否存在指定事件的监听器 /// &lt;/summary&gt; public Boolean HasEventListener(string eventKey) &#123; return eventListeners.ContainsKey(eventKey); &#125; &#125;&#125; &emsp;&emsp;注意到在这个“通知中心”中，我们首先实现了单例模式，这样我们可以通过Get方法来获取该“通知中心”的唯一实例，其次这里利用一个字典来存储对所有事件的引用，这样保证外部可以通过AddEventListener和RemoveEventListener这两个方法来进行事件的添加和移除，对于添加的事件引用我们可以通过DispatchEvent方法来分发一个事件，事件的回调函数采用委托来实现，注意到这个委托需要一个Notification类型，对该类型简单定义如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950using System;using UnityEngine;namespace UniEventDispatcher&#123; public class Notification &#123; /// &lt;summary&gt; /// 通知发送者 /// &lt;/summary&gt; public GameObject sender; /// &lt;summary&gt; /// 通知内容 /// 备注：在发送消息时需要装箱、解析消息时需要拆箱 /// 所以这是一个糟糕的设计，需要注意。 /// &lt;/summary&gt; public object param; /// &lt;summary&gt; /// 构造函数 /// &lt;/summary&gt; /// &lt;param name=\"sender\"&gt;通知发送者&lt;/param&gt; /// &lt;param name=\"param\"&gt;通知内容&lt;/param&gt; public Notification(GameObject sender, object param) &#123; this.sender = sender; this.param = param; &#125; /// &lt;summary&gt; /// 构造函数 /// &lt;/summary&gt; /// &lt;param name=\"param\"&gt;&lt;/param&gt; public Notification(object param) &#123; this.sender = null; this.param = param; &#125; /// &lt;summary&gt; /// 实现ToString方法 /// &lt;/summary&gt; /// &lt;returns&gt;&lt;/returns&gt; public override string ToString() &#123; return string.Format(\"sender=&#123;0&#125;,param=&#123;1&#125;\", this.sender, this.param); &#125; &#125;&#125; &emsp;&emsp;对Notification的定义需要提供发送者和发送内容，这样可以保证所有的通知都按照这样的格式进行定义，如果有Socket开发经验的朋友可能会联想到通讯协议的定义，这里是比较相似啦，哈哈！ 使用事件机制的一个示例&emsp;&emsp;这里以一个简单的示例来验证事件机制的可行性，我们在场景中有一个球体，默认这个球体的颜色为白色，通过调整界面中的RGB数值，可以改变球体的颜色，在这个示例中UI是事件发送者，负责UI中Slider控件的数值发生变化时向球体发送消息，传递的数据类型是Color类型；球体为事件接收者，负责注册事件及接收到消息后的处理。因为代码较为简单，所以这里写在一个脚本中： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758using UnityEngine;using UnityEngine.UI;using System.Collections;using UniEventDispatcher;public class Example : MonoBehaviour &#123; /// &lt;summary&gt; /// R数值的Slider /// &lt;/summary&gt; private Slider sliderR; /// &lt;summary&gt; /// G数值的Slider /// &lt;/summary&gt; private Slider sliderG; /// &lt;summary&gt; /// B数值的Slider /// &lt;/summary&gt; private Slider sliderB; void Start () &#123; //在接收者中注册事件及其回调方法 NotificationCenter.Get().AddEventListener(\"ChangeColor\", ChangeColor); //在发送者中分发事件，这里以UI逻辑为例 sliderR = GameObject.Find(\"Canvas/SliderR\").GetComponent&lt;Slider&gt;(); sliderG = GameObject.Find(\"Canvas/SliderG\").GetComponent&lt;Slider&gt;(); sliderB = GameObject.Find(\"Canvas/SliderB\").GetComponent&lt;Slider&gt;(); //注册UI事件 sliderR.onValueChanged.AddListener(OnValueChanged); sliderG.onValueChanged.AddListener(OnValueChanged); sliderB.onValueChanged.AddListener(OnValueChanged); &#125; public void OnValueChanged(float value) &#123; //获得RGB数值 float r = sliderR.value; float g = sliderG.value; float b = sliderB.value; //分发事件,注意和接收者协议一致 NotificationCenter.Get().DispatchEvent(\"ChangeColor\", new Color(r, g, b)); &#125; /// &lt;summary&gt; /// 改变物体材质颜色 /// &lt;/summary&gt; /// &lt;param name=\"notific\"&gt;&lt;/param&gt; public void ChangeColor(Notification notific) &#123; Debug.Log(notific.ToString()); //设置颜色 renderer.material.color = (Color)notific.param; &#125;&#125; 该示例运行效果如下： 事件机制的简单示例 小结&emsp;&emsp;虽然目前这个事件机制在实现和使用上没有什么问题，可是从扩展性和可优化性上来考虑，这个设计目前存在以下问题： 字符型的键名使用起来方便，可是对通知者和接收者由1个以上的人力来维护的时候双方需要通过沟通来确定键名，可以考虑使用GameObject或者Transform来替代现在的键名设计，可是这种设计带来的新问题是会增加不同模块间的GameObject或者Transform的相互引用。 通知者和接收者在传递参数和接受参数的时候需要分别进行装箱和拆箱，所以这并非一个优秀的设计，同时需要双方保证传递的参数类型一致。解决方法是针对不同的类型对通知中心进行派生或者考虑对通知中心提供泛型约束，这样做的目的是使Notification中的通知内容变成具体的类型，这样就可以解决目前需要进行装箱和拆箱而带来的性能问题。","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"消息","slug":"消息","permalink":"https://qinyuanpei.github.io/tags/%E6%B6%88%E6%81%AF/"},{"name":"事件","slug":"事件","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%8B%E4%BB%B6/"}]},{"title":"扩展Unity3D编辑器的脚本模板","date":"2016-01-08T13:58:44.000Z","path":"posts/3653662258/","text":"&emsp;&emsp;最近在学习Shader时感觉Shader语言参数众多、语法诡异，如果每次都从头开始写Shader一定是一件痛苦的事情。如果可以在本地定义好一组标准的Shader模板，这样当我们需要实现某些效果类似的Shader时，就可以在这个Shader模板的基础上进行修改。因为Shader文件是一个文本文件，所以我们可以非常容易地创建这样一个模板，在这个模板中我们可以进一步完善相关的参数注释，这样就不用每次写Shader的时候都需要查文档了，从这个角度出发，就进入了这篇文章的正题：扩展Unity3D编辑器的脚本模板。 按图索骥，模板在哪里？&emsp;&emsp;Unity3D默认的脚本模版位于/Editor/Data/Resources/ScriptTemplates/目录下，注意该目录相对Unity3D的安装目录而言，在这个目录中我们可以找到Unity3D中脚本模板的某些蛛丝马迹，首先，脚本模板是一个简单的文本文件，这个文本文件中预先填充了内容，我们在编辑器中创建模脚本或者Shader的时候实际上是读取这些文件然后在写入项目中的指定路径的。其次，这些模板文件中#SCRIPTNAME#或者#NAME#这样的标记，当我们在编辑器中创建文件的时候，这个标记会被替换成指定的文件名。比如Unity3D中继承自MonoBehaviour的脚本，有一个非常重要的特性是文件名必须和类名保持一致，这固然是Unity3D引擎的一个设定，可是在这里亦可以找到一个可以称得上理由的理由。我们注意到这些模板的文件名中都有一个独一无二的数字，比如C#脚本的模板中的数字是81、Shader模板中的数字是83，这些数字是什么呢，博主这里将其称为来自星星的黑科技。 来自星星的黑科技&emsp;&emsp;作为一个经常捣鼓Unity3D编辑器的人，如果说你不知道MenuItem、EditorWindow、ScriptableWizard这些黑科技，那么说明你不是一个喜欢折腾和探索的人。从Unity3D的API文档中，我们知道MenuItem的原型为： 1MenuItem(string itemName,bool isValidateFunction,int priority) 我知道我们通常使用MenuItem常常使用的是它的第一个参数，即定义一个菜单项的名称，我们可以使用”/“这样的分隔符来表示菜单的层级，MenuItem需要配合一个静态方法来使用，可以理解为当我们点击当前定义的菜单后就会去执行静态方法中的代码，因此MenuItem常常可以帮助我们做些编辑器扩展开发的工作。好了，第二个参数作为一个验证的标志，如果该标志为true，意味着我们定义的静态方法是一个验证方法在执行静态方法前会首先对方法进行验证，这个我们暂且不管，因为今天我们这个来自星星的黑科技主要和第三个参数有关，第三个参数表示一个优先级，它表示菜单项在菜单栏中的展示顺序，优先级大的菜单项会展示在优先级小的菜单项下面，由此我们就明白了了模板文件名中的类似81、83这样的数字的真实含义，注意到模板文件的排列顺序和编辑器中的菜单项顺序是一样的，我们做一个尝试，编写下面的代码： 1234567891011121314151617181920212223[MenuItem(\"Assets/Create/Lua Scripts\", false, 85)]static void CreateLuaScripts()&#123; &#125;[MenuItem(\"Assets/Create/固定功能着色器\", false, 86)]static void CreateFixedFunctionShader()&#123; &#125;[MenuItem(\"Assets/Create/表面着色器\", false, 87)]static void CreateSurfaceShader()&#123; &#125;[MenuItem(\"Assets/Create/可编程着色器\", false, 88)]static void CreateVertexAndFragmentShader()&#123; &#125; 注意到我们按照已知的优先级继续写了四个方法，现在我们在编辑器中可以发现默认的菜单栏发生了变化： 我们可以看到我们编写的这四个菜单都生效了，虽然它们暂时什么都做不了，但顺着这个方向去探索，我们是可以实现最初的梦想的。现在我们来思考如何根据模板来创建文件，这个对我们来说简直太简单了，通过StreamReader来读取模板，然后再用StreamWriter来生成文件就可以了。可是这样创建的文件的文件名是固定的，在创建文件的时候我们没法修改，而且即使修改了文件内定义的名字并不会改变啊。所以我们需要一个更好的解决方案。Unity3D提供了一个UnityEditor.ProjectWindowCallback的命名空间，在这个空间中提供了一个称为EndNameEditAction的类，我们只需要继承这个类就可以完成这个任务。这个类需要重写Action的方法，我们知道创建一个文件的完整步骤是创建文件然后使其高亮显示，因此这部分代码实现如下： 1234567891011121314151617181920212223242526272829303132333435363738394041/// &lt;summary&gt;/// 定义一个创建资源的Action类并实现其Action方法/// &lt;/summary&gt;class CreateAssetAction : EndNameEditAction&#123; public override void Action(int instanceId, string pathName, string resourceFile) &#123; //创建资源 Object obj = CreateAssetFormTemplate(pathName, resourceFile); //高亮显示该资源 ProjectWindowUtil.ShowCreatedAsset(obj); &#125; internal static Object CreateAssetFormTemplate(string pathName, string resourceFile) &#123; //获取要创建资源的绝对路径 string fullName = Path.GetFullPath(pathName); //读取本地模版文件 StreamReader reader = new StreamReader(resourceFile); string content = reader.ReadToEnd(); reader.Close(); //获取资源的文件名 string fileName = Path.GetFileNameWithoutExtension(pathName); //替换默认的文件名 content = content.Replace(\"#NAME\", fileName); //写入新文件 StreamWriter writer = new StreamWriter(fullName, false, System.Text.Encoding.UTF8); writer.Write(content); writer.Close(); //刷新本地资源 AssetDatabase.ImportAsset(pathName); AssetDatabase.Refresh(); return AssetDatabase.LoadAssetAtPath(pathName, typeof(Object)); &#125;&#125; 这部分代码相对来说比较简单，就是读取本地模板文件然后生成新文件，在生成新文件的时候会将#NAME替换成实际的文件名，这样我们就完成了文件资源的创建。现在的问题是如何在创建文件的时候获取实际的路径，这部分代码实现如下： 123456789101112131415161718192021private static string GetSelectedPath()&#123; //默认路径为Assets string selectedPath = \"Assets\"; //获取选中的资源 Object[] selection = Selection.GetFiltered(typeof(Object), SelectionMode.Assets); //遍历选中的资源以返回路径 foreach (Object obj in selection) &#123; selectedPath = AssetDatabase.GetAssetPath(obj); if (!string.IsNullOrEmpty(selectedPath) &amp;&amp; File.Exists(selectedPath)) &#123; selectedPath = Path.GetDirectoryName(selectedPath); break; &#125; &#125; return selectedPath;&#125; 现在解决了创建资源的问题，我们接下来只要调用ProjectWindowUtil的StartNameEditingIfProjectWindowExists方法即可，该方法需要传入一个继承自EndNameEditAction的类的实例、目标文件路径和模板文件的路径。例如要创建一个Lua脚本可以这样实现： 12345678[MenuItem(\"Assets/Create/Lua Scripts\", false, 85)]static void CreateLuaScripts()&#123; ProjectWindowUtil.StartNameEditingIfProjectWindowExists(0, ScriptableObject.CreateInstance&lt;CreateAssetAction&gt;(), GetSelectedPath() + \"/NewLuaScript.lua\", null, \"Assets/Editor/Template/85-Lua-NewLuaScript.lua.txt\");&#125; 小结&emsp;&emsp;现在有了这个黑科技以后，我们可以创建更多的模板来扩展编辑器的功能，比如对Shader而言，我们可以创建些基础性的Shader模板，然后每次需要写Shader的时候直接从模板库中选择一个功能类似的Shader然后在此基础上进行修改，这样比从头开始写一个新的Shader应该会轻松不少，这段时间学习Shader，感觉进程缓慢离图形学高手遥遥无期，行了，这篇博客就是这样了。","categories":[{"name":"游戏引擎","slug":"游戏引擎","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"编辑器","slug":"编辑器","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"},{"name":"模板","slug":"模板","permalink":"https://qinyuanpei.github.io/tags/%E6%A8%A1%E6%9D%BF/"}]},{"title":"《Cg Programming in Unity》读书笔记","date":"2015-12-25T12:29:20.000Z","path":"posts/1670305415/","text":"&emsp;&emsp;最近开始着手Shader语言的学习，因为Unity3D没有提供类似虚幻四引擎的材质编辑器功能，所以当在Unity3D中碰到需要提供引擎默认材质以外的效果的时候，就需要我们来编写Shader以实现各种特效，本文主要是结合《Cg Programming in Unity》这本书和浅墨博客中关于Shader的这部分内容来学习和整理，目的是帮助博主快速掌握Shader语言。 Unity3D中的Shader概述&emsp;&emsp;为Unity3D编写Sahder代码相对OpenGL和DirectX要简单。Unity3D没有刻意地区分Cg语言和HLSL语言，因为这两者是非常相似的，这意味着使用HLSL编写的代码可以直接在Cg中使用，更为深入地探索HLSL和Cg的渊源你会戏剧性地发现Cg是Microsoft和NVIDIA联手推出并试图从硬件和软件上和GLSL相抗衡的一种产物。 &emsp;&emsp;其中Cg是Nvidia提供的一种Shader编写语言，HLSL是DirectX提供的一种Shader编写语言，这意味着大部分的Cg代码同样可以被HLSL支持。Unity3D中使用的Shader编写语言是ShaderLab，其本质是对Cg进行了封装，因此在Unity3D中编写Shader本质上在给DirectX或者OpenGL写Shader，因为我猜测在引擎内部存在HLSL和GLSL的相互转换使得Unity3D能够在不同的平台都有较好的图形表现。 &emsp;&emsp;Unity3D中Shader程序的编写可以参考这里。我们知道计算机图形学的中渲染管线一般可以分为两种类型，即固定功能渲染管线和可编程渲染管线。因此从这个角度来看，Unity3D中主要有三种着色器，即固定功能着色器（Fixed Function Shader）、表面着色器（Surface Shader）和 顶点着色器&amp;片段着色器 （Vertex Shader &amp; Fragment Shader）。 Unity3D中Shader的基本结构&emsp;&emsp;首先，Unity3D中Shader的基本结构是： 12345678910111213141516Shader &#123; //------【属性】------// Properties &#123; &#125; //------【子着色器】------// SubShaders &#123; &#125; //------【回滚】------// Fallback&#125; 对这个结构我们的理解是，Shader代码首先是一些属性定义，用来指定这段代码将有哪些输入。接下来是一个或者多个的子着色器，在实际运行中，哪一个子着色器被使用是由运行的平台所决定的。子着色器是代码的主体，每一个子着色器中包含一个或者多个的Pass。在计算着色时，平台先选择最优先可以使用的着色器，然后依次运行其中的Pass，然后得到输出的结果。最后指定一个Fallback，用来处理所有SubShader都不能运行的情况称为回滚。下面来分别介绍Shader基本结构中的各个部分： Shader中的PropertiesProperties是由多条标签组成的Shader属性定义，这些属性能够在Unity3D中的编辑器中显示出来，以此来确定这段Shader代码由哪些输入。常见的标签定义有： 1name(\"display name\", Range(min, max)) = number 定义一个在编辑器中可通过滑动条修改的浮点数属性 1name(\"display name\", Color) = (number,number,number,number) 定义一个在编辑器中可通过拾色器来设置RGBA的颜色值属性 1name(\"display name\", 2D) = \"name\" &#123;options &#125; 定义一个在编辑器中可编辑的2D纹理属性，其中options可选表示即纹理自动生成纹理坐标时的模式，通常是ObjectLinear、EyeLinear、SphereMap、 CubeReflect、CubeNormal其中之一。 1name(\"display name\", Rect) = \"name\"&#123; options &#125; 定义一个在编辑器中可编辑的非二次方2D纹理属性 1name(\"display name\", Cube) = \"name\"&#123; options &#125; 定义一个在编辑器中可编辑的立方贴图纹理属性 1name(\"display name\", Float) = number 定义一个在编辑器中可通过输入框修改的浮点数值属性 1name(\"display name\", Vector) =(number,number,number,number) 定义一个在编辑器中可通过输入框修改的Vector4属性 Shader中的SubShader&emsp;&emsp;SubShader，即子着色器。子着色器是代码的主体，每一个子着色器中包含一个或者多个的Pass。在计算着色时，平台先选择最优先可以使用的着色器，然后依次运行其中的Pass，然后得到输出的结果。子着色器的基本结构是： 1234567891011Subshader&#123; //------【Tags标签】------// Tags&#123;&#125; //------【Pass通道】------// Pass &#123; &#125;&#125; Tags标签在这里子着色器使用Tags标签来告诉渲染引擎期望何时和如何渲染对象，其语法是： 1Tags &#123; \"TagName1\" = \"Value1\" \"TagName2\" = \"Value2\" &#125; 即采用一个键值对来表示标签的名称及其对应的值，通常由三种标签可以在这里使用： 1\"Queue\" = \"Transparent\" 表示决定渲染次序的队列标签，其取值定义如下： Background在所有队列渲染之前被渲染，如天空盒等。 Geometry默认渲染大部分的对象，如不透明的几何体等。 Transparent在所有队列渲染之后被渲染采用由后到前的次序，如玻璃、粒子效果等。 Overlay主要实现叠加效果的渲染，如镜头光晕等。 1Tags &#123; \"Queue\" = \"Geometry+1\" &#125; 表示自定义中间渲染队列，当默认的渲染队列不能满足要求时可选用当前渲染队列。在Unity实现中每一个队列都被一个整数的索引值所代表。Background为1000、Geometry为2000、Transparent为3000、Overlay为4000. 1Tags &#123; \"IgnoreProjector\" =\"True\" &#125; 表示忽略投影标签，其值为True表示忽略投影反之表示受投影影响。 Pass通道Pass通道块控制被渲染的对象的几何体。其结构定义如下： 123456789Pass &#123; //------【名称与标签】------// [Name and Tags] //------【渲染设置】------// [RenderSetup] //------【纹理设置】------// [TextureSetup] &#125; 名称与标签在通道中可以定义其名称和任意数目的标签，通过使用tags来告诉渲染引擎在什么时候该如何渲染他们所期望的效果，其语法和Tags标签完全相同，即采用键值对来定义标签的名称和其对应的值。常用的标签有： 1Tags &#123; \"LightMode\" = \"Always\" &#125; 表示一个光照模式标签，该标签的取值可以是： Always总是渲染。没有运用光照。 ForwardBase用于正向渲染,环境光、方向光和顶点光等 ForwardAdd用于正向渲染，用于设定附加的像素光，每个光照对应一个pass PrepassBase用于延迟光照，渲染法线/镜面光。 PrepassFinal用于延迟光照，通过结合纹理，光照和自发光渲染最终颜色 Vertex用于顶点光照渲染，当物体没有光照映射时，应用所有的顶点光照 VertexLMRGBM用于顶点光照渲染，当物体有光照映射的时候使用顶点光照渲染。在平台上光照映射是RGBM 编码 VertexLM用于顶点光照渲染，当物体有光照映射的时候使用顶点光照渲染。在平台上光照映射是double-LDR 编码（移动平台，及老式台式CPU） ShadowCaster使物体投射阴影。 ShadowCollector为正向渲染对象的路径，将对象的阴影收集到屏幕空间缓冲区中。 渲染设置渲染设置设定显示硬件的各种状态，常用的命令如下： 123456789101112131415161718192021222324Material &#123; Diffuse Color(R,G,B,A) //漫反射颜色构成，即对象的基本颜色。 Ambient Color(R,G,B,A) //环境色颜色构成，即当对象被RenderSettings中设定的环境色所照射时对象所表现的颜色。 Specular Color(R,G,B,A) //对象反射高光的颜色。 //(R,G,B,A)四个分量分别代表红绿蓝和Alpha，取值为0到1之间。 Shininess Number //加亮时的光泽度，在0和1之间。 Emission Color //自发光颜色，即当不被任何光照所照到时对象的颜色。 //(R,G,B,A)四个分量分别代表红绿蓝和Alpha，取值为0到1之间。 //【备注】对象上的完整光照颜色最终是： //FinalColor = Ambient * RenderSettings ambientsetting + //(Light Color * Diffuse + Light Color *Specular) + Emission&#125; 定义一个使用顶点光照管线的材质 1Lighting On | Off 开启或关闭顶点光照 1Cull Back | Front | Off 设置多边形剔除模式 1ZTest (Less | Greater | LEqual | GEqual |Equal | NotEqual | Always) 设置深度测试模式 1ZWrite On | Off 设置深度写模式 1Fog &#123; Fog Block &#125; 设置雾参数 1AlphaTest (Less | Greater | LEqual | GEqual| Equal | NotEqual | Always) CutoffValue 开启alpha测试 1Blend SourceBlendMode | DestBlendMode 设置alpha混合模式 1Color Color value 设置当顶点光照关闭时所使用的颜色 1ColorMask RGB | A | 0 | any combination of R, G, B, A 设置颜色写遮罩。设置为0将关闭所有颜色通道的渲染 1Offset OffsetFactor , OffsetUnits 设置深度偏移 1SeparateSpecular On | Off 开启或关闭顶点光照相关的平行高光颜色 1ColorMaterial AmbientAndDiffuse | Emission 当计算顶点光照时使用每顶点的颜色 纹理设置纹理设置的作用是在完成渲染设定后指定一定数目的纹理及其混合模式： 1SetTexture [texture property]&#123; [Combineoptions] &#125; Shader中的FallbackFallback就像switch-case结构中的default，其作用是定义当处理所有SubShader都不能运行时采取的一个补救方案，这个主要是为了解决不同的显卡对Shader支持的差异问题。 Unity3D中Shader的语法Unity3D中Shader的语法主要针对Cg代码而言，Cg代码是可编程着色器和表面着色器中的核心内容，Cg代码从CGPROGRAM开始到ENDCG结束 Unity3D中的三种着色器","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"图形","slug":"图形","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%BE%E5%BD%A2/"},{"name":"Shader","slug":"Shader","permalink":"https://qinyuanpei.github.io/tags/Shader/"},{"name":"CG","slug":"CG","permalink":"https://qinyuanpei.github.io/tags/CG/"},{"name":"Unity","slug":"Unity","permalink":"https://qinyuanpei.github.io/tags/Unity/"}]},{"title":"EasyAR尝鲜系列教程之视频播放功能的实现","date":"2015-12-09T08:40:22.000Z","path":"posts/316230277/","text":"&emsp;&emsp;各位朋友大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是http://qinyuanpei.com。到现在为止，我们对EasyAR中的ImageTarget基本上可以说是驾轻就熟了，因此我们这个系列教程可以说是接近尾声了。博主第一次接触AR这个概念是在大学时候读到一本讲解计算机图形视觉的书籍里，相对VR技术目前华而不实的市场现状，AR技术从实用性和成熟度都能得到较好的保证。可是大家都清楚这些技术背后都是建立在复杂而高深的图形学算法的基础上的，如果想学习AR技术请回归计算机图形学的本源，这就和学习游戏技术要追寻可编程渲染管线是一样的，所以这个系列完全是博主个人的兴趣使然，希望了解这个技术的可以进行更加深入的探索。这次我们来说说VideoTarget如何实现吧！ EasyAR中对视频的支持&emsp;&emsp;目前EasyAR对视频的支持主要是通过VideoPlayerBehaviour这个类，这个类继承自一个基类VideoPlayerBaseBehaviour。我们可以将其理解为一个视频播放器组件，只要我们将这个组件添加到一个GameObject上，然后简单填写下参数就可以了。可是这个组件博主在32位操作系统下并没有看到实际的效果，虽然说都到了2015年了64位操作系统相对来说更为普及了，可是我觉得支持不支持32位操作系统更多的体现的是一家公司做产品的态度。既然暂时没有办法看到这里的具体效果，我们本着学习的态度对这个组件有所了解就是了。下面是这个组件的一张截图： VideoPlayerBehaviour组件截图 从图中我们可以看到这个组件相关参数的设置，这里选取的视频资源是StreamingAssets目录下的video.mp4这个文件，视频资源的Stroge同样支持App、Assets、Absolute这三种类型，和图片资源的Stroge是一样的，关于这三种类型的资源路径的问题，我这里不想再重复说了，这个看看文档就知道了。其次会涉及到视频播放方式和视频缩放的相关参数，这些基本上没什么理解上的难度，大家对照着文档反复尝试就知道各自的用途了。博主这里不太理解EasyAR为什么不采用MovieTexture或者Unity3D中针对视频播放提供的相关插件，因为VideoTarget本质上就是把三维模型换成了可以播放的视频而已，所以大家在前面文章的基础上创建一个ImageTarget然后再其下面放置一个附加了VideoPlayerBehaviour的的子物体就可以了。官方的示例项目中提供了两种方式的VideoTarget创建方式，即手动创建和动态创建。手动创建即我们这里提到的这种方式，而动态创建则是由程序在运行时期间创建。这两种方式本质上没有什么不同，需要注意的是VideoPlayerBehaviour有一个EnableAutoPlay的选项，该选项被选中后会启用自动播放，即当识别图被识别后自动播放视频、识别图未被识别则暂停播放视频。如果这个选项没有被选中，我们需要在ITargetEventHandle接口中动手来实现。 增强ImageTarget&emsp;&emsp;这个增强ImageTarget是指在ImageTarget的基础上融入VideoPlayerBehaviour的功能，因为按照官方的示例来考虑，这两部分功能是独立的，博主希望让大家在制作识别图的时候完全忘记区别ImageTarget和VideoTarget，这样我们可以更为专注地制作识别图，因为视频组件就只是设置参数这一件事情，完全可以一次性搞定，所以我们首先来定义一个VideoTargetBaseBehaviour类，一起来看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161using UnityEngine;using System.Collections;using EasyAR;public class VideoTargetBaseBehaviour : ImageTargetBehaviour,ITargetEventHandler&#123; /// &lt;summary&gt; /// 视频播放模块 /// &lt;/summary&gt; private VideoPlayerBehaviour videoPlayer; /// &lt;summary&gt; /// 视频文件路径 /// &lt;/summary&gt; public string VideoPath; /// &lt;summary&gt; /// 是否自动播放视频 /// &lt;/summary&gt; public bool VideoEnableAutoPlay = true; /// &lt;summary&gt; /// 是否允许视频循环 /// &lt;/summary&gt; public bool VideoEnableLoop = true; /// &lt;summary&gt; /// 视频类型 /// &lt;/summary&gt; public VideoPlayer.VideoType VideoType = VideoPlayer.VideoType.TransparentSideBySide; /// &lt;summary&gt; /// 视频资源类型 /// &lt;/summary&gt; public StorageType VideoStorage = StorageType.Assets; /// &lt;summary&gt; /// 视频是否加载 /// &lt;/summary&gt; private bool isVideoLoaded; protected override void Start() &#123; //在Start方法中加载视频、隐藏模型 base.Start(); LoadVideo(); HideObjects(transform); &#125; /// &lt;summary&gt; /// 加载视频 /// &lt;/summary&gt; private void LoadVideo() &#123; //创建子物体VideoObject并为其添加视频组件 GameObject VideoObject = new GameObject(\"VideoObject\"); videoPlayer = VideoObject.AddComponent&lt;VideoPlayerBehaviour&gt;(); VideoObject.transform.SetParent(transform); VideoObject.transform.localPosition = Vector3.zero; VideoObject.transform.localRotation = Quaternion.identity; VideoObject.transform.localScale = Vector3.one; //设置视频组件相关参数 videoPlayer.Storage = VideoStorage; videoPlayer.Path = VideoPath; videoPlayer.EnableAutoPlay = VideoEnableAutoPlay; videoPlayer.EnableLoop = VideoEnableLoop; videoPlayer.Type = VideoType; videoPlayer.VideoReadyEvent+=videoPlayer_VideoReadyEvent; videoPlayer.VideoReachEndEvent+=videoPlayer_VideoReachEndEvent; videoPlayer.VideoErrorEvent+=videoPlayer_VideoErrorEvent; videoPlayer.Open(); videoPlayer.Play(); &#125; #region 视频组件相关事件定义 public virtual void videoPlayer_VideoErrorEvent(object sender, System.EventArgs e) &#123; &#125; public virtual void videoPlayer_VideoReachEndEvent(object sender, System.EventArgs e) &#123; &#125; public virtual void videoPlayer_VideoReadyEvent(object sender, System.EventArgs e) &#123; &#125; #endregion /// &lt;summary&gt; /// 隐藏模型的方法 /// &lt;/summary&gt; /// &lt;param name=\"trans\"&gt;要隐藏的Transform&lt;/param&gt; void HideObjects(Transform trans) &#123; for (int i = 0; i &lt; trans.childCount; ++i) HideObjects(trans.GetChild(i)); if (transform != trans) gameObject.SetActive(false); &#125; /// &lt;summary&gt; /// 显示模型的方法 /// &lt;/summary&gt; /// &lt;param name=\"trans\"&gt;要显示的Transform&lt;/param&gt; public void ShowObjects(Transform trans) &#123; for (int i = 0; i &lt; trans.childCount; ++i) ShowObjects(trans.GetChild(i)); if (transform != trans) gameObject.SetActive(true); &#125; /// &lt;summary&gt; /// 实现ITargetEventHandler接口中的OnTargetFound方法 /// &lt;/summary&gt; /// &lt;param name=\"target\"&gt;识别目标&lt;/param&gt; void ITargetEventHandler.OnTargetFound(Target target) &#123; if (videoPlayer) videoPlayer.Play(); ShowObjects(transform); &#125; /// &lt;summary&gt; /// 实现ITargetEventHandler接口中的OnTargetLost方法 /// &lt;/summary&gt; /// &lt;param name=\"target\"&gt;识别目标&lt;/param&gt; void ITargetEventHandler.OnTargetLost(Target target) &#123; if (videoPlayer) videoPlayer.Pause(); HideObjects(transform); &#125; /// &lt;summary&gt; /// 实现ITargetEventHandler接口中的OnTargetLoad方法 /// &lt;/summary&gt; /// &lt;param name=\"target\"&gt;识别目标&lt;/param&gt; void ITargetEventHandler.OnTargetLoad(Target target, bool status) &#123; &#125; /// &lt;summary&gt; /// 实现ITargetEventHandler接口中的OnTargetUnload方法 /// &lt;/summary&gt; /// &lt;param name=\"target\"&gt;识别目标&lt;/param&gt; void ITargetEventHandler.OnTargetUnload(Target target, bool status) &#123; &#125;&#125; 在这段代码中博主采用了动态创建视频组件的方法，这样我们在制作VideoTarget的时候只需要按照以下步骤即可： 在Assets/EasyAR/Prefabs目录下找到EasyAR这个预制体，添加EasyARConfig组件，然后填写KEY。具体请参考系列教程第三篇EasyAR尝鲜系列教程之ImageTarget千呼万唤始出来。 在Assets/EasyAR/Prefabs目录中找到ImageTarget这个预制体，然后使用VideoTargetBaseBehaviour组件替换默认的ImageTargetBehaviour组件。下面是博主这里的参数配置截图 我制作的VideoTarget 这里博主继续选择idback这张图片，这种方法是博主喜欢的方法，大家可以按照个人喜欢的方式来实现，总而言之万变不离其宗，只需要掌握它的原理就好了。在文章中已经提到过这个组件在32位操作系统下无法正常工作，所以这篇文章就不给大家展示相关的截图了，本文暂时先写到这里等有时间测试成功了再来更新这篇文章。如果像博主这样对Unity3D比较熟悉的朋友，可以考虑使用MovieTexture或者其它的方式来替代官方目前的这个方案，好了，这篇文章就是这样了，希望大家喜欢!","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"增强现实","slug":"增强现实","permalink":"https://qinyuanpei.github.io/tags/%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E/"},{"name":"教程","slug":"教程","permalink":"https://qinyuanpei.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"EasyAR","slug":"EasyAR","permalink":"https://qinyuanpei.github.io/tags/EasyAR/"}]},{"title":"EasyAR尝鲜系列教程之ImageTarget千呼万唤始出来","date":"2015-12-09T08:39:54.000Z","path":"posts/3736599391/","text":"&emsp;&emsp;各位朋友大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是http://qinyuanpei.com。最近EasyAR终于迎来了一次重大的版本更新：v1.10，真可谓是“千呼万唤始出来”啊，所以在官方文档和示例项目基本完善的情况下，博主决定将EasyAR尝鲜系列教程继续下去。本次教程主要以官方新发布的Unity示例项目为基础来进行讲解，关注Androis/iOS原生应用开发的朋友请自行针对官方示例项目进行研究。好了，今天主要的内容是通过EasyAR SDK来自行构建一个ImageTarget的实例，采用Unity3D 4.6.4版本进行开发。 EasyAR SDK的结构&emsp;&emsp;将EasyAR SDK导入Unity3D后会在项目的Assets根目录下生成EasyAR和Plugins两个文件夹。其中EasyAR文件夹中提供了开发AR应用相关的标准接口、材质、Shader和Prefab，Plugins文件夹中提供了针对各个平台的插件。好了，下面我们来介绍EasyAR SDK中提供的标准接口： ARBuilder: 该类提供了EasyAR初始化的相关方法，我们在编写EasyAR配置类的时候会用到这个类，这是一个可以直接使用的类。 ImageTargetBehaviour: 该类是一个抽象类，我们需要对其进行override，可以将这个类理解为ImageTarget生命周期相关的一个类，在实际使用中需要配合ITargetEventHandle这个接口来使用。 VideoPlayerBaseBehaviour: 该类是一个组件，我们可以使用这个组件来播放视频。其原理和ImageTarget类似，所不同的地方是ImageTarget在识别成功后会显示一个模型，而这里则是使用一个隐藏的物体来播放视频，VideoPlayerBaseBehaviour负责控制视频的播放、暂停等工作。 ITargetEventHandle: 这是一个接口，通过该接口可以捕捉到识别过程中的OnTargetFound、OnTargetLost、OnTargetLoad和OnTargetUnload四个事件，对于一个基本的AR应用来说，我们通常需要关注的是OnTargetFound、OnTargetLost这两个方法。 构建第一个ImageTarget项目&emsp;&emsp;好了，在了解了EasyAR中常用的标准接口以后，我们下面来着手构建第一个ImageTarget项目，和我们第一次接触EasyAR不同，这次我们会编写些简单地代码，打开场景填入应用程序密钥(Key)然后运行它，这种方式在这里会显得略LOW。##EasyAR的初始化&emsp;&emsp;首先我们在Assets/EasyAR/Prefabs目录下找到EasyAR这个预制体，然后将其拖放到场景中，这样我们就创建了基本的EasyAR应用场景，接下来我们要做的事情就是在这个场景中填入各种各样的识别物。为了让EasyAR正常工作，我们首先要编写一个初始化EasyAR的脚本： 123456789101112131415161718192021222324using UnityEngine;using System.Collections;using EasyAR;public class EasyARConfig : MonoBehaviour &#123; /// &lt;summary&gt; /// 应用程序密钥 /// &lt;/summary&gt; [TextArea(1,10)] public string Key; public void Awake() &#123; //检查KEY是否存在 if(string.IsNullOrEmpty(Key)) Debug.Log(\"请先输入应用程序密钥\"); //初始化EasyAR ARBuilder.Instance.InitializeEasyAR(Key); ARBuilder.Instance.EasyBuild(); &#125; &#125; 我确信这个类简单到彻底，它需要开发者在编辑器中填入KEY然后再Awake方法中完成对EasyAR的初始化，就是这样简单，我们这里将这个脚本附加到EasyAR这个物体上去，这样我们就完成了引擎的初始化工作，下面我们就可以专注于AR内容的产生了。 制作一个ImageTarget&emsp;&emsp;接下来我们在Assets/EasyAR/Prefabs目录中找到ImageTarget这个预制体，将其拖放到场景中，确保它在摄像机的视野范围内。我们注意到默认情况下它附加了一个ImageTargetBehaviour脚本，我们在前面已经说过，这个类是一个抽象类，抽象类通常是不做任何事情的，因此我们需要继承这个类来编写一个具体类，我们将这个具体类命名为CustomImageTargetBehaviour。下面给出它的代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374using UnityEngine;using System.Collections;using EasyAR;public class CustomImageTargetBehaviour :ImageTargetBehaviour,ITargetEventHandler&#123; protected override void Start() &#123; //在Start方法中隐藏模型 base.Start(); HideObjects(transform); &#125; /// &lt;summary&gt; /// 隐藏模型的方法 /// &lt;/summary&gt; /// &lt;param name=\"trans\"&gt;要隐藏的Transform&lt;/param&gt; void HideObjects(Transform trans) &#123; for (int i = 0; i &lt; trans.childCount; ++i) HideObjects(trans.GetChild(i)); if (transform != trans) gameObject.SetActive(false); &#125; /// &lt;summary&gt; /// 显示模型的方法 /// &lt;/summary&gt; /// &lt;param name=\"trans\"&gt;要显示的Transform&lt;/param&gt; void ShowObjects(Transform trans) &#123; for (int i = 0; i &lt; trans.childCount; ++i) ShowObjects(trans.GetChild(i)); if (transform != trans) gameObject.SetActive(true); &#125; /// &lt;summary&gt; /// 实现ITargetEventHandler接口中的OnTargetFound方法 /// &lt;/summary&gt; /// &lt;param name=\"target\"&gt;识别目标&lt;/param&gt; void ITargetEventHandler.OnTargetFound(Target target) &#123; ShowObjects(transform); &#125; /// &lt;summary&gt; /// 实现ITargetEventHandler接口中的OnTargetLost方法 /// &lt;/summary&gt; /// &lt;param name=\"target\"&gt;识别目标&lt;/param&gt; void ITargetEventHandler.OnTargetLost(Target target) &#123; HideObjects(transform); &#125; /// &lt;summary&gt; /// 实现ITargetEventHandler接口中的OnTargetLoad方法 /// &lt;/summary&gt; /// &lt;param name=\"target\"&gt;识别目标&lt;/param&gt; void ITargetEventHandler.OnTargetLoad(Target target, bool status) &#123; &#125; /// &lt;summary&gt; /// 实现ITargetEventHandler接口中的OnTargetUnload方法 /// &lt;/summary&gt; /// &lt;param name=\"target\"&gt;识别目标&lt;/param&gt; void ITargetEventHandler.OnTargetUnload(Target target, bool status) &#123; &#125;&#125; 可以注意到在这个类中我们主要做了两件事情：第一，定义了隐藏和显示识别模型的方法HideObjects和ShowObjects，其作用是在没有识别到Target的时候隐藏物体，在识别到Target的时候显示物体；第二，实现了ITargetEventHandler接口并在OnTargetFound和OnTargetLost两个方法中实现我们第一步希望达到的目的。至此，我们完成了一个基本的AR识别组件，我们下面所有的AR识别物体都是通过这个组件来工作的，所以我们从场景中的ImageTarget物体上移除默认的ImageTargetBehaviour脚本然后为其添加我们定义的CustomImageTargetBehaviour脚本。 &emsp;&emsp;编写完脚本以后我们就可以着手制作识别图和Marker了，EasyAR最让人喜欢的一点就是你可以按照自己的意愿来制作识别图和Marker。虽然Vuforia在识别效果上比EasyAR更好点，可是对程序员来说选择一个透明的产品方案比面对着黑箱子进行调试要明智得多。EasyAR中的识别图相对来说比较简单，因为我们只需要选择一张图片然后为其创建一个材质，再将这个材质附加到ImageTarget物体上就可以了。此外还会涉及到某些参数的设置，我们下面会提到。好了，我们继续选择官方示例中的idback这张图片来作为我们的识别图，因为身份证每个人都有可以随时用来进行测试，而一般的图片则需要打印出来制成硬质卡片来使用。我们在Assets目录中创建一个StreamingAssets目录，将官方示例中targets.json和idbcak.jpg两个文件拷贝过来。创建材质就不再说了，这是Unity3D中非常非常基础的内容。我们将创建好的材质附加到ImageTarget物体上以后，可能在场景中并不会看到对应的识别图，这是因为我们没有为其配置参数。具体的参数配置如下图： ImageTarget参数配置 具体这些参数的定义请大家自己去看文档，因为我这里说得再明白如果大家不看等于我没有说。好了，下面我们来创建Marker，这个就比较简单了，我们直接找一个模型缩放到合适的大小然后拖拽到ImageTarget这个物体下面就可以了。如图是博主参照官方示例制作的两个识别图及其Marker： 两个ImageTarget及其对应Maker 走向成功的关键步骤1、在EasyAR物体的EasyARConfig组件中填入从官网申请的KEY。2、在BuildSetting中填写KEY对应的AppID。3、安装SDK中附带的VC++2015运行库。4、如要编译Android版本，请确保安装Java环境和Android SDK更多的问题请自行到官方文档中对照寻找解决办法。 截图展示","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"增强现实","slug":"增强现实","permalink":"https://qinyuanpei.github.io/tags/%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E/"},{"name":"AR","slug":"AR","permalink":"https://qinyuanpei.github.io/tags/AR/"},{"name":"教程","slug":"教程","permalink":"https://qinyuanpei.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"EasyAR","slug":"EasyAR","permalink":"https://qinyuanpei.github.io/tags/EasyAR/"}]},{"title":"C#中的扩展方法学习总结","date":"2015-12-05T12:01:02.000Z","path":"posts/305484621/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客。最近偶然接触到了C#中的扩展方法，觉得这个语法特性是一个不错的特性，因此决定在这里系统地对C#中的扩展方法相关内容进行下总结和整理，因为博主觉得学习这件事情本身就是一个积累的过程，所以博主有时候会对现在的线上培训和视频教程这种“在线教育”感到反感。试想《射雕英雄传》中江南七怪远赴大漠传授郭靖武艺苦历十八载，何以难及全真教丹阳子马钰传授内功两年的积累？这里固然有郭靖愚笨木讷的天性和江南七怪武功低微的因素，可是在博主看来更重要的是强调了一个积累。想郭靖一生受益自全真教的玄门内功终成一代“为国为民”的侠之大者，则我辈需更加努力方可在这世间行走奔波。 什么是扩展方法？&emsp;&emsp;扩展方法从字面上理解是指扩展的方法，而对应到面向对象编程这个格局中则是指为一个类提供的扩展方法。按照我们通常的理解，我们首先需要获得某个类的源代码，然后在这个类代码中增加成员方法，这样就可以达到为一个类提供扩展方法的目的。可是不幸地是，这种方法在没有源代码的情况下就无法奏效了，而且我们人为地去改变源代码有可能会破坏整个代码的稳定性。那么有没有一种方法能在不改变源代码的前提下为某个类提供扩展方法呢？这就是我们今天要说的扩展方法，所以我们可以将扩展方法理解为在不改变源代码的前提下向外部提供扩展方法的一种方式。C#中的扩展方法实现起来是相对来说比较简单的，例如我们做在Unity3D游戏开发的时候，可能会用到DOTween这个插件。这个插件是iTween的作者重新编写一个动画插件，效率上比iTween有较大的提升。更为重要的一点是，它采用扩展方法这种实现方式，使得我们在调用这些API接口的时候难以感觉到我们是在使用一个插件，更像是在使用Unity3D的原生函数，所以当我们使用DOTween + uGUI 这样的组合的时候，内心会感到无比的舒畅，一切都像是水到渠成一般。 扩展方法有哪些特点？&emsp;&emsp;扩展方法在实现上和普通的面向对象编程是一样的，换句话说，我们只需要定义一个类，然后在里面添加并实现相应的方法即可。但是这里需要注意的地方有三点，第一，实现扩展方法的类必须是静态类且类的名称和实现扩展方法的类无关；第二、实现扩展方法的类方法必须是静态方法；第三、实现扩展方法的类方法的第一个参数必须是使用this关键字指明要实现扩展方法的类。例如，我们知道将一个合法字符串类型转换为整型，可以使用int.parse()方法，假如我们希望为string类型扩展一个ToInt方法应该怎么办呢？我们一起来看下面的这段代码： 12345678910111213141516/// &lt;summary&gt;/// 1、定义一个静态类/// 2、静态类的名称和要实现扩展方法的具体类无关/// &lt;/summary&gt;public static class SomeClass&#123; /// &lt;summary&gt; /// 3、实现一个具体的静态方法 /// &lt;/summary&gt; /// &lt;param name=\"str\"&gt;4、第一个参数必须使用this关键字指定要使用扩展方法的类型&lt;/param&gt; /// &lt;returns&gt;&lt;/returns&gt; public static int ToInt(this string str) &#123; return int.Parse(str); &#125;&#125; 需要注意的是C#支持扩展方法是从.NET3.5版本开始，所以在编写扩展方法的时候请确保你的.NET版本是否满足这一要求。提到版本问题，有很多朋友尤其是从Unity5.0以后开始学习Unity3D的朋友，常常会在我的博客中留言提到我的代码无法在新环境下运行等等类似地问题，我觉得这个世界上更新速度最快的当属IT技术了，大家使用新版本没有问题，可是有时候因为技术发展中的历史遗留问题例如Python2.7和Python3、Unity4.X和Unity5.X，这个时候可能出现版本不兼容的问题，这个时候如果网络上的资源没有及时更新，建议大家还是及时查看官方的最新文档，因为在博主看来网络上的书籍或者相关文章都是用来参考的，古话说：尽信书不如无书，只有客观、冷静地判断知识的正确与否，我们方能学到真正有用的知识。 &emsp;&emsp;好了，现在我们编写完这个扩展方法以后，就可以像下面这样使用扩展方法了： 12string str = \"1234\";int val = str.ToInt(); 这个示例向大家展示了如何编写一个无参数的扩展方法，那么当我们需要在扩展方法中传入参数的时候该怎么做呢？我们只需要在第一个参数后继续加入参数的声明就好了。例如我们在Unity3D中常常需要给一个3D物体设置坐标，通常我们可以通过下面的代码来实现： 1transform.position = new Vector3(1,1,1); 这个代码到目前为止是比较简洁的，可是我们知道在Unity3D中除了position属性以外还有localPosition属性，如果我们的代码中再涉及坐标计算的话，我相信这个代码一定会变得非常的长。更有甚者，有时候我们只想改变三维坐标中的一个维度，可是我们必须给transform.position一个三维坐标，毫无意外地此时的代码会变得更长。为了解决这个问题，我们可以扩展出三个方法SetPositionX、SetPositionY、SetPositionZ来分别为x、y、z三个坐标分量进行赋值，我们继续在SomeClass这个类中添加方法： 1234567891011121314151617181920212223242526272829/// &lt;summary&gt;/// 设置Tranform的X坐标/// &lt;/summary&gt;/// &lt;param name=\"tran\"&gt;当前Transform&lt;/param&gt;/// &lt;param name=\"x\"&gt;X坐标&lt;/param&gt;public static void SetPositionX(this Transform tran, float x)&#123; tran.position = new Vector3(x, tran.position.y, tran.position.z);&#125;/// &lt;summary&gt;/// 设置Tranform的Y坐标/// &lt;/summary&gt;/// &lt;param name=\"tran\"&gt;当前Transform&lt;/param&gt;/// &lt;param name=\"x\"&gt;Y坐标&lt;/param&gt;public static void SetPositionY(this Transform tran, float y)&#123; tran.position = new Vector3(tran.position.x, y, tran.position.z);&#125;/// &lt;summary&gt;/// 设置Tranform的Z坐标/// &lt;/summary&gt;/// &lt;param name=\"tran\"&gt;当前Transform&lt;/param&gt;/// &lt;param name=\"x\"&gt;Z坐标&lt;/param&gt;public static void SetPositionZ(this Transform tran, float z)&#123; tran.position = new Vector3(tran.position.x, tran.position.y, z);&#125; 同样的，我们现在可以直接为一个三维物体的坐标进行赋值： 123transform.SetPositionX(1.0f);transform.SetPositionY(1.0f);transform.SetPositionZ(1.0f); 使用扩展方法的利弊&emsp;&emsp;扩展方法使用起来得心应手，所以我们这里来讨论下使用扩展方法的利弊。好处当然是自由而任性地使用扩展方法对类进行扩展，而且扩展方法在Visual Studio中的智能提示会以蓝色向下箭头进行标识。扩展方法的坏处则是要看设计扩展方法的人能否较好的驾驭这个特性啦，其实所有的技术都是一样的，我常常在游戏群里听到人鄙视Unity3D引擎，以UnReal Engine4为游戏引擎世界里的泰山北斗，我承认UE4的画面效果好，可是能真正用好这个引擎的人有多少呢？扩展方法在使用的时候应该遵守就近原则，即是在最小的范围内使用扩展方法，对具体类而非抽象类实现扩展方法。我们使用扩展方法无非是因为它在逻辑层需要这样的功能，所以我们没有必要去改变抽象层的逻辑，因为这样会“污染”整个代码。举一个简单的例子，我们知道.NET中的基类是object，如果我们对这个类进行扩展，毫无疑问它会影响所有继承自object的类，这样就会造成“污染”，显然是不可取的。 小结 在C#中实现扩展方法的类必须是静态类且类的名称和实现扩展方法的类无关 实现扩展方法的类方法必须是静态方法 实现扩展方法的类方法的第一个参数必须是使用this关键字指明要实现扩展方法的类 实现扩展方法应遵守就近原则，在最小的范围内使用扩展方法以避免造成“污染”","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"CSharp","slug":"CSharp","permalink":"https://qinyuanpei.github.io/tags/CSharp/"},{"name":"扩展方法","slug":"扩展方法","permalink":"https://qinyuanpei.github.io/tags/%E6%89%A9%E5%B1%95%E6%96%B9%E6%B3%95/"},{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"技巧","slug":"技巧","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E5%B7%A7/"}]},{"title":"青黄未接的2015","date":"2015-12-01T19:24:18.000Z","path":"posts/1394521917/","text":"&emsp;&emsp;匆匆时光总是把我们这些过客留在感慨和叹息中，而它却如风之旅人一般渐行远去。转眼这大半年的时间里，每天我都在努力让时间发挥它的意义，可是有时候这种努力却像枷锁一样让我有些莫名的压抑。从毕业那天起，我就决定这辈子不会再靠我的本科专业生活，因为它从来没有和我的内心发生过强烈的共鸣，所以当我毕业以后就意味着我再没有回头的路可以走。曾经因为怯懦而将自己封闭在这座小城市，其结果就是我在我人生中的第一家公司的项目在拖延和等待中慢慢地死亡。 &emsp;&emsp;从刚进公司时的踌躇满志到此时此刻心灰意冷，大概就像冬日里的懒洋洋的太阳，一个季节的凋落需要的可能只是一片枯萎的叶子而已。我每天都坚持早起，因为我不想被这种安逸到近似麻木的生活拔去梦想的翅膀，虽然我在乎的事情没有人懂、更没有人在乎，可我就是不愿做一只温水中的青蛙，因为当危险临近的时候更加不会有人来救我。每天穿梭在来来往往的人群中、听着年轻的男男女女们讨论被生活剥夺去的纷纷扰扰，我曾经为了让自己和别人不同而努力过，此时此刻却要为了和别人一样而满腹忧愁。我不甘心让我的生活变成电视连续剧，一切都在编剧和观众的期望之中。我想要一个独特的故事，虽然狗血可它却是我在这世界上来过的真实写照。 &emsp;&emsp;古语说：父母在，不远游，游必有方。我固然不愿意离开年迈的父母，我固然不愿意离开生养我的土地，可是对我来说这一切都没有可以选择的余地，每次看到回家看到父母不停地辛劳，我意识到他们渐渐地老了，他们的身体不再像以前那般硬朗，他们的头发一天比一天白，我不愿意他们再为我辛劳下去，留在这座小城市里除了可以经常看到他们以外，对我而言并不会有更好的理由。虽然在这座小城市里我可以勉强混得下去，可对我付出过的精力和时间来说，它更像是一种灵魂上的亵渎。我还要照顾她、和她在一起生活，看看此时此刻的我有什么资格这样说呢？我身边的同龄人有的人已经买好了房子、有的人已经在准备结婚成家，可我什么都没有啊，我没有资格让每天的日子都这样平淡而安稳地过下去，大概这就是我一直在纠结的原因吧！ &emsp;&emsp;将近七个月的时间，可对我来说真正为第一家公司工作的时间只有三个月。我自问每天都在认真的做事情，可是因为领导层和整个公司的问题现在这个项目变成这个样子，我真的感到失望而寒心。时光一过不再有，这过去的大半年时间就让它过去吧，在接下来的2016年里，我希望我可以更加勇敢、更加努力，我要更好地把握我的人生，我要变得更加成熟，我要做最初的、最好的自己！2016，加油！","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://qinyuanpei.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"},{"name":"成长","slug":"成长","permalink":"https://qinyuanpei.github.io/tags/%E6%88%90%E9%95%BF/"}]},{"title":"Unity3D游戏开发之C++插件接入","date":"2015-11-21T14:47:26.000Z","path":"posts/2527231326/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。虽然Unity3D引擎依靠强大的跨平台能力睥睨高手林立的游戏引擎世界，我们在使用Unity3D游戏引擎的时候基本上不会去接触底层的东西，可是有时候面对某些奇葩的要求的时候，我们就不得不考虑使用C++这样的语言来为其编写相关的插件。你如果问我是什么样的奇葩要求，比如接入蓝牙手柄来控制游戏、接入类似街机的设备来控制游戏、接入同一个游戏到两个不同的设备上并响应不同的控制……诸如此类的种种问题，可能目前在Unity3D引擎中找不到解决方案，这个时候写C++插件就变成了一种刚性需求，这就是我们今天要来一起探讨的问题。 &emsp;&emsp;Unity3D主要使用C#进行开发，所以为Unity3D编写插件本质上就是让C#调用C++代码。目前主要有C++ CLR和C++ Native两种实现方法，其中C++ CLR可以理解为运行在.Net CLR即公共语言运行库上的C++代码，这种代码是托管的C++代码，目前并没有被C++标准承认，因为它更像是C++和C#两种语言的混合代码，这种代码的优势是可以像普通的.NET库一样被C#调用，考虑到Unity3D建立在和.Net类似的Mono上，因此这种方式应该是我们的最佳实践方案；C++ Native则是指传统的C++ 动态链接库，通过DllImport在C#中进行包装后在C#中进行调用，相对地这种方式调用的是非托管的C++代码，这种方式相信接触过Windows开发的朋友应该不会感到陌生啦，它是一种更为普遍的方法，例如我们要接入苹果官方SDK的时候，需要对Object C的代码进行封装后交给C#去调用，而这里使用的方法就是DllImport了。 &emsp;&emsp;好了，下面我们来看看两种方式各自是如何实现的吧！这里博主使用的开发环境是Windows 8.1 32bit 和 Visual Studio 2012，Unity3D的版本为4.6版本。 C++ CLR创建一个C++ CLR类库项目&emsp;&emsp;首先我们按照下图中的步骤创建一个C++ CLR项目： 截图是件讨厌的事情，虽然懒惰的人们都喜欢 请注意.Net版本问题，重要的事情说三遍，不认真看这里的人出现问题就不要到我这里来评论了，我最讨厌连文章都没有看明白就来和你纠缠不清的人，谢谢。创建好项目后请打开项目属性窗口设置【公共语言运行时支持】节点的值为【安全 MSIL 公共语言运行时支持(/clr:safe)】好了，下面我们找到CLR4Unity.h文件，添加ExampleClass声明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/// &lt;summary&gt;/// 一个简单的托管C++示例类/// &lt;/summary&gt;public ref class ExampleClass&#123; public: /// &lt;summary&gt; /// 产生一个介于min和max之间的整型随机数 /// &lt;returns&gt;整型随机数&lt;/returns&gt; /// &lt;param name=\"min\"&gt;最小值&lt;/param&gt; /// &lt;param name=\"max\"&gt;最大值&lt;/param&gt; /// &lt;/summary&gt; static int Random(int min,int max) &#123; //注意在托管的C++中使用gcnew来代替new //我承认C++写CLR代码略显奇葩像是C++和C#语法的混合 return (gcnew System::Random)-&gt;Next(min,max); &#125; /// &lt;summary&gt; /// 计算一个整数的平方 /// &lt;returns&gt;整型数值&lt;/returns&gt; /// &lt;param name=\"a\"&gt;需要平方的数值&lt;/param&gt; /// &lt;/summary&gt; static int Square(int a) &#123; return a * a; &#125; /// &lt;summary&gt; /// 返回两个数中的最大值 /// &lt;returns&gt;整型数值&lt;/returns&gt; /// &lt;param name=\"a\"&gt;参数1&lt;/param&gt; /// &lt;param name=\"b\"&gt;参数2&lt;/param&gt; /// &lt;/summary&gt; static int Max(int a,int b) &#123; if(a&lt;=b)&#123; return b; &#125;else&#123; return a; &#125; &#125;&#125;; 显然我们这里定义了三个简单的方法，注意到第一个方法Random依赖于System.Rnadom类，而在托管的C++中是使用gcnew来代替new这个关键字的，所以请尽情感受C#和C++的混搭语法风格吧！这样我们就可以编译得到CLR4Unity.dll这个类库，将这个文件复制到Unity3D项目中的Plugins目录下下，然后将其加入项目引用列表。如果你以为引用就是： 1using CLR4Unity; 呵呵，我严重怀疑你对.Net的熟悉程度。你没有添加对CLR4Unity.dll的引用，你到底在using什么啊？ 先添加引用然后using 如果你对.NET熟悉到足以无视这里的一切，请闭上眼接着往下看，哈哈！ 在C#中添加引用及方法调用&emsp;&emsp;接下来我们在Unity3D中创建一个脚本PluginTest.cs，然后在OnGUI方法增加下列代码。可是你要以为这些代码就应该写在OnGUI方法中，抱歉请你先去了解MonoBehaviour这个类。什么？添加了这些代码报错？没有using的请自行面壁： 1234567//调用C++ CLR中的方法if(GUILayout.Button(\"调用C++ CLR中的方法\", GUILayout.Height (30))) &#123; Debug.Log(\"调用C++ CLR中的方法Random(0,10):\" + ExampleClass.Random(0,10)); Debug.Log(\"调用C++ CLR中的方法Max(5,10):\" + ExampleClass.Max(5,10)); Debug.Log(\"调用C++ CLR中的方法Square(5):\" + ExampleClass.Square(5));&#125; C++ Native创建一个C++动态链接库项目&emsp;&emsp;首先我们按照下图中的步骤来创建一个C++ Win32项目： 不要问我从哪里来 我的故乡在远方 好了，接下来我们找到Native4Unity.cpp写入下列代码： 123456789101112131415161718192021222324252627282930313233343536373839404142// Native4Unity.cpp : 定义 DLL 应用程序的导出函数。//#include \"stdafx.h\"//为了使用rand()函数引入C++标准库#include \"stdlib.h\"/// &lt;summary&gt;/// 产生一个介于min和max之间的整型随机数/// &lt;returns&gt;整型随机数&lt;/returns&gt;/// &lt;param name=\"min\"&gt;最小值&lt;/param&gt;/// &lt;param name=\"max\"&gt;最大值&lt;/param&gt;/// &lt;/summary&gt;extern \"C\" __declspec(dllexport) int Random(int min,int max)&#123; return rand() % (max - min + 1) + min;&#125;/// &lt;summary&gt;/// 返回两个数中的最大值/// &lt;returns&gt;整型数值&lt;/returns&gt;/// &lt;param name=\"a\"&gt;参数1&lt;/param&gt;/// &lt;param name=\"b\"&gt;参数2&lt;/param&gt;/// &lt;/summary&gt;extern \"C\" __declspec(dllexport) int Max(int a ,int b)&#123; if(a&lt;=b)&#123; return b; &#125;else&#123; return a; &#125;&#125;/// &lt;summary&gt;/// 计算一个整数的平方/// &lt;returns&gt;整型数值&lt;/returns&gt;/// &lt;param name=\"a\"&gt;需要平方的数值&lt;/param&gt;/// &lt;/summary&gt;extern \"C\" __declspec(dllexport) int Square(int a)&#123; return a * a;&#125; 和C++ CLR类似，我们使用标准的C++语言来实现同样的功能。注意到rand()这个函数是C++标准库里的内容，所以我们在文件开头增加了对stdlib.h这个头文件的引用。这里需要注意的一点是：所有希望使用DllImport引入C#的C++方法都应该在方法声明中增加__declspec(dllexport)关键字，除非它在.def文件中对这些方法进行显示声明。关于.def文件的相关定义大家可以到MSDN上检索，这些都是属于C++编译器的内容，这里不再详细说了。 在C#中使用DllImport封装方法&emsp;&emsp;将编译好的Native4Unity.dll复制到Plugins目录中后，下面我们要做的事情就是在C#里对这些方法进行封装或者说是声明： 12345678[DllImport(\"Native4Unity\")]private extern static int Random(int min, int max);[DllImport(\"Native4Unity\")]private extern static int Max(int a, int b);[DllImport(\"Native4Unity\")]private extern static int Square(int a); 然后就是简单地调用啦： 1234567//调用C++ Native中的方法if(GUILayout.Button(\"调用C++ Native中的方法\", GUILayout.Height (30))) &#123; Debug.Log(\"调用C++ Native中的方法Random(0,10):\" + Random(0, 10)); Debug.Log(\"调用C++ Native的方法Max(5,10):\" + Max(5, 10)); Debug.Log(\"调用C++ Native中的方法Square(5):\" + Square(5));&#125; 最终程序的运行效果如图： 这个结果来之不易请大家珍惜","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"C++","slug":"C","permalink":"https://qinyuanpei.github.io/tags/C/"},{"name":"插件","slug":"插件","permalink":"https://qinyuanpei.github.io/tags/%E6%8F%92%E4%BB%B6/"}]},{"title":"在Hexo中为文章自动添加版权信息声明模块","date":"2015-11-15T13:12:22.000Z","path":"posts/2950334112/","text":"&emsp;&emsp;各位朋友，大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是http://qinyuanpei.com。今天想和大家说说博客文章版权这件事情。每当提到版权的时候，我知道大家内心深处都是对此不以为然的，因为国内版权意识薄弱，所以版权在我们的眼中就变成了这样一件可有可无的东西，可是事实真的是这样的吗？首先我们必须承认一件事情，即你从互联网上获得的知识都是有价值的，即使这些知识的创造者并未因此而获得利益。相对其它的行业，因为程序员这个职业本身需要其通过不断地学习新知识来适应新变化，因此程序员这个群体更喜欢在互联网上分享知识和经验，而这些知识的受众面窄、技术门槛高则决定了程序员们无法像普通的博客作者一样有更多的机会来获得收入。大部分的程序员都是从分享知识、记录学习和技术交流这样的角度来撰写博客的。那么这样就会造成一个问题，在国内版权意识薄弱和技术博客变现困难的双重夹缝中，博客作者该如何寻求新的突破呢？ 为什么要说博客文章版权这件事儿&emsp;&emsp;首先，我们为什么要说博客文章版权这件事情呢？因为博客是文字创造的产物，是知识共享的一种形式。当我们无视版权的时候，这意味着知识是没有价值的，创造是无关痛痒的，脑力劳动和创意活动的价值在现实中被无情地扼杀。当你引用一个人的观点却不加以注明的时候，当你盗用一个人的创意却不给予报酬的时候，试问谁还会愿意为这个社会贡献创意和想法呢？引用许锡良的观点，尊重版权更深层次的含义在于对人权的尊重： 从人权的角度看，人与动物的区别在于知识与思想，因此，人类最根本的财富也应该是知识与思想上的财富，一切社会财富都来源于知识与思想，这是从自然界获得生活资料，以及改造社会的根本。没有知识与思想的人类将与动物世界没有什么区别。尊重人权，首先就要学会尊重人的劳动成果，特别是创造性劳动成果，只有人，才能创造出来的知识产权与发明专利。尊重人权，首先就要学会尊重一个人的思想与创意。只有人，才能创造出来的知识产权与发明专利。因为每个人都是一个独立的个体，每个人头脑里的想法都是独一无二的，无人能替代的。在没有说出来，或者写出来之前，也无人能盗取的，这种思想就是个人独有，就是只属于个人的专利。 &emsp;&emsp;我常常遇到在博客评论中和我直接要源代码的人，我不明白从什么时候起对知识的分享变成了某些人懒惰的借口。我选择将我知道的某个分享出来，当然我同样有权利可以选择沉默。你不能因为习惯了做伸手党就认为我应该理所当然地把源代码给你，这是对我的不尊重。我写博客的目的在于和别人交流技术、互相学习，如果你根本没有看懂我博客写了什么，只是希望可以找到可以“抄”来就能用的代码。抱歉!这违背了我的初衷我更没有道理要将源代码分享给你,况且如果我的代码都清清楚楚（命名规范、注释清晰）地写在博客里，如果这样的代码你都不能看懂，就算把完整的工程分享给你又有什么用呢？我本来不情愿论坛来转载我的文章，因为论坛盖楼的这种互动模式实在难以产生较为良好的互动效果，可是人家来诚心诚意地询问你的态度，如此拒绝难免有点却之不恭吧！当然最让人讨厌的是网络爬虫和网站编辑，这种让人讨厌是因为它”简单粗暴”，完全不考虑博客作者的感受，文章的原始链接被删除、文章的作者署名被删除。或许大家都觉得一个署名、一个原始链接都是无足轻重的东西，可是在我看来这恰恰是体现责任的地方。作者的责任在于对文章的真实性和客观性负责，转发者的责任在于帮助读者找到作者当他们之间需要某种交流的时候，这就是我为什么强调署名和原始链接的理由！ 谈谈如何保护博客文章版权&emsp;&emsp;在保护博客文章版权这个问题上，我们可以采取的方式固然很多，但是这件事情的根本原因在于人们普遍不重视知识产权的保护，所以我们这里提到的这些方式都是外家功夫，真正要根除这等沉疴痼疾需要人们不断提升自我、勤修内功。 第一种方式，我们称为通过技术方式提醒，比如通过编写JavaScript脚本，实现当对方复制你的博客内容的时候，程序可以自动在这段复制的内容中增加署名和连接。当然我们可以通过修改文章的模板来在文章中加入版权信息，这个我们留到最后会说，因为实际上这个是我们今天要重点研究的内容，博主是个程序员，我们当然要用技术的方式来实现了，前面的这些大家看完心里有个数就是了，哈哈！ 第二种方式，我们称为增加文章内链的方式，就是在文章中尽可能地使用指向这个博客的连接，这样可以保证在文章转载后为博客带来一定的反向访客。 第三种方式，在图片上增加水印，这样读者在看到图片的时候就可以很容易地找到原始出处，可是如果你不能保证拥有所引用的图片得版权，建议不要轻易地使用这种方式。 第四种方式，逐渐形成个性化的写作风格，这样当读者读到这些文字的时候，可以通过文章的风格知道文章的作者和出处。 第五种方式，努力提高自己博客的文章质量，让更多的读者从中受益，形成有独立风格的博客品牌。一个博客有了高质量的内容和品牌，那么在搜索引擎中的权重就会很高，网民通过搜索引擎进行查找的时候，博客原文都会排在第一位。 博主之所以要使用http://qinyuanpei.com这个独立博客的原因正是基于这个原因。博主目前采用的知识共享许可是署名(BY)-非商业性使用(NC)-相同方式共享(SA)，请各位在转载文章的时候注意保留作者署名和文章出处，谢谢！ 保护博客文章版权，独立博客在行动&emsp;&emsp;我的博客是采用Hexo这个博客系统来搭建的，说到底程序员是天生爱折腾的命吧，都有对掌控事物的欲望，不喜欢受到条件制约。CSDN的博客虽然还不错，可是“限制因素 + 服务器奔溃”这样的强效组合实在让我很难有继续坚持下去的动力，所以果断就自己搭了博客买了域名，老老实实地开始管理起独立博客。好了，废话少说，放码过来，我们下面来看看怎么在Hexo中的文章中增加一个展示版权信息的模块，这里以Jacman主题为例，我们首先定位到该主题文件夹下的\\layout_partial\\post\\article.ejs文件： 123456789101112131415161718192021222324&lt;div id=\"main\" class=\"&lt;%= item.layout %&gt;\" itemscope itemprop=\"blogPost\"&gt; &lt;% if (page.layout=='photo' &amp;&amp; item.photos &amp;&amp; item.photos.length)&#123; %&gt; &lt;%- partial('gallery') %&gt; &lt;% &#125; %&gt; &lt;article itemprop=\"articleBody\"&gt; &lt;%- partial('header') %&gt; &lt;div class=\"article-content\"&gt; &lt;% if( table&amp;&amp;(item.toc !== false) &amp;&amp; theme.toc.article)&#123; %&gt; &lt;div id=\"toc\" class=\"toc-article\"&gt; &lt;strong class=\"toc-title\"&gt;&lt;%= __('contents') %&gt;&lt;/strong&gt; &lt;% if(item.list_number == false) &#123;%&gt; &lt;%- toc(item.content,&#123;list_number:false&#125;) %&gt; &lt;% &#125;else&#123; %&gt; &lt;%- toc(item.content) %&gt; &lt;% &#125; %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;%- item.content %&gt; &lt;/div&gt; &lt;%- partial('footer') %&gt; &lt;/article&gt; &lt;%- partial('pagination') %&gt; &lt;%- partial('comment') %&gt;&lt;/div&gt; 我们可以注意到文章的内容是在&lt;%- item.content %&gt;这个标签里，因此我们如果要在文章中增加内容，只需要在&lt;%- item.content %&gt;的后面引入一个ejs模板文件即可，所以我们接下在article.ejs的同级目录下创建一个declare.ejs文件： 1&lt;pre&gt;&lt;code&gt;&lt;b&gt; 版权声明&lt;/b&gt;:本文由&lt;b&gt;&lt;a href=\"&lt;%= config.root %&gt;about\" target=\"_blank\" title=\"&lt;%= config.author %&gt;\"&gt;&lt;%= config.author %&gt;&lt;/a&gt;&lt;/b&gt;创作和发表,采用&lt;b&gt;署名(BY)&lt;/b&gt;-&lt;b&gt;非商业性使用(NC)&lt;/b&gt;-&lt;b&gt;相同方式共享(SA)&lt;/b&gt;国际许可协议进行许可,转载请注明作者及出处,本文作者为&lt;b&gt;&lt;a href=\"&lt;%= config.root %&gt;about\" target=\"_blank\" title=\"&lt;%= config.author %&gt;\"&gt;&lt;%= config.author %&gt;&lt;/a&gt;&lt;/b&gt;,本文标题为&lt;b&gt;&lt;a href=\"&lt;%- config.root %&gt;&lt;%- item.path %&gt;\" target=\"_blank\" title=\"&lt;%= item.title %&gt;\"&gt;&lt;%= item.title %&gt;&lt;/a&gt;&lt;/b&gt;,本文链接为&lt;b&gt;&lt;a href=\"&lt;%- config.root %&gt;&lt;%- item.path %&gt;\" target=\"_blank\" title=\"&lt;%= item.title %&gt;\"&gt;&lt;%- config.url %&gt;/&lt;%- item.path %&gt;&lt;/a&gt;&lt;/b&gt;.&lt;/code&gt;&lt;/pre&gt; 大家可以看到这里就是一段HTML代码，因为我们要引入的这个模板和article.ejs在同一个页面中，所以我们可以直接在这里调用item这个变量，而item这个变量里是封装了当前文章的标题和链接的，因此我们可以顺利成章的构造这样一段HTML代码，因为博主不会写CSS样式，所以使用了一个默认的代码样式来完成这个工作，如果大家懂CSS，请自行发挥你的创意将它做得更好。好了，下面我们要做的工作就是将这个模版引用到article.ejs文件中，类似地我们可以使用&lt;%- partial(‘footer’) %&gt;这样的结构来引入这个模板，这里给出完整的article.ejs文件内容： 123456789101112131415161718192021222324252627282930313233&lt;div id=\"main\" class=\"&lt;%= item.layout %&gt;\" itemscope itemprop=\"blogPost\"&gt; &lt;% if (page.layout=='photo' &amp;&amp; item.photos &amp;&amp; item.photos.length)&#123; %&gt; &lt;%- partial('gallery') %&gt; &lt;% &#125; %&gt; &lt;article itemprop=\"articleBody\"&gt; &lt;%- partial('header') %&gt; &lt;div class=\"article-content\"&gt; &lt;% if(theme.show_declare) &#123; %&gt; &lt;%- partial('declare') %&gt; &lt;% &#125; %&gt; &lt;% if( table&amp;&amp;(item.toc !== false) &amp;&amp; theme.toc.article)&#123; %&gt; &lt;div id=\"toc\" class=\"toc-article\"&gt; &lt;strong class=\"toc-title\"&gt;&lt;%= __('contents') %&gt;&lt;/strong&gt; &lt;% if(item.list_number == false) &#123;%&gt; &lt;%- toc(item.content,&#123;list_number:false&#125;) %&gt; &lt;% &#125;else&#123; %&gt; &lt;%- toc(item.content) %&gt; &lt;% &#125; %&gt; &lt;/div&gt; &lt;% &#125; %&gt; &lt;%- item.content %&gt; &lt;% if(theme.show_declare) &#123; %&gt; &lt;%- partial('declare') %&gt; &lt;% &#125; %&gt; &lt;/div&gt; &lt;%- partial('footer') %&gt; &lt;/article&gt; &lt;%- partial('pagination') %&gt; &lt;%- partial('comment') %&gt;&lt;/div&gt; 这里博主在文章的开头和结尾处插入了这个模板，同时在主题文件夹中设置了一个是否显示版权声明的开关变量，这样我们就可以在主题中设置是否开启版权声明模块了。好啦，相信你在看到这边文章的时候你已经看到了它的版权声明了，这就是我们今天的内容啦，谢谢大家！","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"Hexo","slug":"Hexo","permalink":"https://qinyuanpei.github.io/tags/Hexo/"},{"name":"版权","slug":"版权","permalink":"https://qinyuanpei.github.io/tags/%E7%89%88%E6%9D%83/"},{"name":"知识共享","slug":"知识共享","permalink":"https://qinyuanpei.github.io/tags/%E7%9F%A5%E8%AF%86%E5%85%B1%E4%BA%AB/"}]},{"title":"解析OBJ模型并将其加载到Unity3D场景中","date":"2015-11-15T13:07:57.000Z","path":"posts/1124152964/","text":"&emsp;&emsp;各位朋友，大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是http://qinyuanpei.com。今天想和大家交流的是解析obj模型并将其加载到Unity3D场景中，虽然我们知道Unity3D是可以直接导入OBJ模型的，可是有时候我们并不能保证我们目标客户知道如何使用Unity3D的这套制作流程，可能对方最终提供给我们的就是一个模型文件而已，所以这个在这里做这个尝试想想还是蛮有趣的呢，既然如此，我们就选择在所有3D模型格式中最为简单的OBJ模型来一起探讨这个问题吧！ 关于OBJ模型&emsp;&emsp;OBJ格式是一种3D模型文件格式，是由Alias|Wavefront公司为3D建模和动画软件 “Advanced Visualizer”开发的一种标准，适合用于3D软件模型之间的互相转换。和FBX、Max这种内部私有格式不同，OBJ模型文件是一种文本文件，我们可以直接使用记事本等软件打开进行编辑和查看，因此我们这里选择OBJ模型主要是基于它开放和标准这两个特点。需要说明的是，OBJ文件是一种3D模型文件，它主要支持多边形模型（三个点以上的面）。OBJ模型支持法线和贴图坐标，可是因为它本身并不记录动画、材质特性、贴图路径、动力学及粒子等信息，所以我们在游戏开发中基本看不到这种模型格式的，所以我们这里做下简单研究就好。 OBJ模型解读&emsp;&emsp;因为OBJ模型文件是一个文本文件，所以我们可以使用记事本等软件打开它来对它的文件结构进行下了解。首先OBJ文件没有头文件，如果你曾经尝试解析过mp3文件的ID3v1/ID3v2标签就应该知道它是根据mp3文件的开头或者末尾的若干字节来判断这些标签信息的，而在OBJ文件中是没有类似这样的头文件的。OBJ文件是由一行行由关键字、空格和文本字符组成的文本文件，通过关键字我们就可以知道这一行的文本表示的是什么数据。例如： 1# Blender v2.76 (sub 0) OBJ File: '' #关键字表示一个注释行，通过这个注释信息我们可以知道这个OBJ模型是由Blender2.76版本导出的。再比如： 1mtllib liumengli.mtl mtllib关键字则表示当前模型对应的材质库(.mtl)文件名称，每个OBJ模型文件都会有这样一个对应和它同名的.mtl文件，在这个文件中记录了材质相关的信息，稍后我们说到材质的时候会详细说说这个文件的格式，因为它和OBJ文件一样是一个文件文件。再比如： 1usemtl Material__33 usemtl关键字则表示从当前行到下一个usemtl关键字所在行间的全部网格结构都使用其对应的材质，通过这个材质名称我们可以在.obj文件对应的.mtl文件中找到它的材质定义，这个我们在讲到材质部分的时候会详细说。 &emsp;&emsp;好了，目前我们要做的工作室解析.obj文件然后创建网格进而可以使其显示在Unity3D场景中，在这里我们要重点关注的关键字有： v即Vertex，表示一个顶点的局部坐标系中的坐标，通常有三个分量，因为这里讨论的是三角面。例如： 1v 1.5202 14.9252 -1.1004 vn即Vertex Normal，表示法线，注意到这些向量都是单位向量，所以我们可以认为三维软件在导出模型的时候已经做好了相关的标准化工作。 1vn 0.8361 -0.0976 0.5399 vt即Vertex Texture，表示纹理坐标，就是我们熟悉的UV坐标啦，显然UV是个2D坐标，有两个分量。 1vt -0.5623 0.4822 1.0000 f即face，这是一个真正描述面的关键字，通常它后面有三个索引结构，每个索引结构由顶点索引、法线索引和纹理坐标索引三部分构成。例如： 1f 256/303/637 257/304/638 258/305/639 以上这些关键字对我们解析.obj文件来说已经完全足够了，如果大家想对这些细节有更为深入的了解，可以参考这里这里。 OBJ模型的读取&emsp;&emsp;OBJ模型的读取涉及到网格部分的读取和材质部分的读取两个部分，其中网格部分的读取难点在于当模型存在多个材质的时候，需要将模型分为若干个子物体，然后分别为这些子物体添加材质。可是不幸的是到目前为止，博主并没有找到一种行之有效的方法来对这些网格进行分类，所以这里我们假定模型是一个整体且共享同一种材质和一张贴图。如果大家找到了更好的解决方案，请记得告诉我，再次谢谢大家！ 网格部分&emsp;&emsp;在网格读取这部分，因为我们已经假设所有的面构成一个物体，因此我们可以先将OBJ文件内的文本按照换行符来进行分割，然后再按照关键字去判断每一行的数据类型并进行相应的处理就可以了。读取OBJ模型的基本流程是： 读取顶点、法线、UV以及三角面 将三角面合并为四边面 根据索引重新计算顶点、法线、UV数组 读取顶点、法线、UV以及三角面&emsp;&emsp;首先我们来看第一步的代码实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/// &lt;summary&gt;/// 从一个文本化后的.obj文件中加载模型/// &lt;/summary&gt;public ObjMesh LoadFromObj(string objText)&#123; if(objText.Length &lt;= 0) return null; //v这一行前面是两个空格后面是一个空格 objText=objText.Replace(\" \", \" \"); //将文本化后的obj文件内容按行分割 string[] allLines = objText.Split('\\n'); foreach(string line in allLines) &#123; //将每一行按空格分割 string[] chars = line.Split(' '); //根据第一个字符来判断数据的类型 switch(chars[0]) &#123; case \"v\": //处理顶点 this.vertexArrayList.Add(new Vector3( ConvertToFloat(chars[1]), ConvertToFloat(chars[2]), ConvertToFloat(chars[3])) ); break; case \"vn\": //处理法线 this.normalArrayList.Add(new Vector3( ConvertToFloat(chars[1]), ConvertToFloat(chars[2]), ConvertToFloat(chars[3])) ); break; case \"vt\": //处理UV this.uvArrayList.Add(new Vector3( ConvertToFloat(chars[1]), ConvertToFloat(chars[2])) ); break; case \"f\": //处理面 GetTriangleList(chars); break; &#125; &#125; 在这段代码中，我们首先将文本化的.obj文件按照换行符分割成字符串数组allLines，然后再对每一行按照空格分隔成字符串数组chars，这样我们就可以通过该数组的第一个元素chars[0]来判断当前行中的数据类型。这样我们将每一行的文本读取完后，所有的数据都被存储到了其相对应的列表中。其中，vertexArrayList存储顶点信息、normalArrayList存储法线信息、uvArrayList存储UV坐标。至此，我们完成第一部分中的顶点、法线和UV的读取。 &emsp;&emsp;这里可以注意到我们在开始对文本化的.obj文件的内容有1次替换操作，这是因为在3dsMax中导出的.obj文件关键字v这一行中v后面的第一处空格位置是有2个空格，而我们在处理的时候是按照空格来分割每一行的内容的，这样chars[1]就会变成一个空字符串，显然这不符合我们的初衷，所以这里就需要对字符串进行这样一个操作，希望大家在解析的过程中注意，好吧，我承认我想吐槽3dsMax了，我不明白同一家公司的3dsMax和Maya为什么不能互相转换，我不明白3dsMax导出.obj文件的时候要做这样奇葩的设定，我更不明白为什么有开源、免费、轻巧的Blender都不去用非要每次都去安装容量动辄上G的盗版软件和不知道会不会变成下一个GhostXXXX的注册机，我更加不能容忍的是封闭的FBX格式和用起来就如同自虐的FBX SDK。 &emsp;&emsp;好了，吐槽结束，我们接下来来看看三角面是如何读取的。三角面的读取定义在GetTriangleList()方法中，因此三角面的读取实际上首先需要将每一行文本按照空格进行分割，然后再将每一个元素按照/分割，这样就可以依次得到顶点索引、法线索引和UV索引。在某些情况下法线索引可能不存在，所以在处理的过程中需要对其进行处理。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647/// &lt;summary&gt;/// 获取面列表./// &lt;/summary&gt;/// &lt;param name=\"chars\"&gt;Chars.&lt;/param&gt;private void GetTriangleList(string[] chars)&#123; List&lt;Vector3&gt; indexVectorList = new List&lt;Vector3&gt;(); List&lt;Vector3&gt; triangleList = new List&lt;Vector3&gt;(); for(int i = 1; i &lt; chars.Length;++i ) &#123; //将每一行按照空格分割后从第一个元素开始 //按照/继续分割可依次获得顶点索引、法线索引和UV索引 string[] indexs = chars[i].Split('/'); Vector3 indexVector = new Vector3(0, 0); //顶点索引 indexVector.x = ConvertToInt(indexs[0]); //法线索引 if(indexs.Length &gt; 1)&#123; if(indexs[1] != \"\") indexVector.y = ConvertToInt(indexs[1]); &#125; //UV索引 if(indexs.Length &gt; 2)&#123; if(indexs[2] != \"\") indexVector.z = ConvertToInt(indexs[2]); &#125; //将索引向量加入列表中 indexVectorList.Add(indexVector); &#125; //这里需要研究研究 for(int j = 1; j &lt; indexVectorList.Count - 1; ++j) &#123; //按照0,1,2这样的方式来组成面 triangleList.Add(indexVectorList[0]); triangleList.Add(indexVectorList[j]); triangleList.Add(indexVectorList[j + 1]); &#125; //添加到索引列表 foreach(Vector3 item in triangleList) &#123; faceVertexNormalUV.Add(item); &#125;&#125; 在这里，我们首先使用一个索引向量列表indexVectorList存储每一行的索引向量。这里的索引向量是指由顶点索引、法线索引和UV索引分别构成Vector3的三个分量，这样做的好处是我们可以节省重新去定义数据机构的时间。好了，我们把所有的索引向量读取完后，按照0、1、2这样的方式组成三角面，这里可能是.obj文件本身定义的一种方式，我们暂且按照这样的方式来处理。最后，全部的三角面会被读取到faceVertexNormalUV列表中，它表示的是每个三角面的顶点、法线和UV的索引向量，是一个List类型的变量。 将三角面合并为四边面&emsp;&emsp;现在我们读取到的是三角面，接下来我们需要将它们合并成四边面，合并的原理是判断它们是否在同一个面上。如果两个点的顶点索引相同则表明它们是同一个点，如果两个点的法线索引相同则表明它们在同一个面上。好了，我们来看定义的一个方法Combine(): 123456789101112131415161718192021222324252627282930313233343536373839/// &lt;summary&gt;/// 合并三角面/// &lt;/summary&gt;private void Combine()&#123; //使用一个字典来存储要合并的索引信息 Dictionary&lt;int, ArrayList&gt; toCambineList = new Dictionary&lt;int,ArrayList&gt;(); for(int i = 0; i &lt; faceVertexNormalUV.Count; i++) &#123; if(faceVertexNormalUV[i] != Vector3.zero) &#123; //相同索引的列表 ArrayList SameIndexList = new ArrayList(); SameIndexList.Add(i); for(int j = 0; j &lt; faceVertexNormalUV.Count; j++) &#123; if(faceVertexNormalUV[j]!=Vector3.zero) &#123; if(i != j) &#123; //如果顶点索引和法线索引相同，说明它们在一个面上 Vector3 iTemp = (Vector3)faceVertexNormalUV[i]; Vector3 jTemp = (Vector3)faceVertexNormalUV[j]; if(iTemp.x == jTemp.x &amp;&amp; iTemp.y == jTemp.y) &#123; //将索引相同索引列表然后将其重置为零向量 //PS:这是个危险的地方，如果某个索引信息为Vector3.Zero //就会被忽略过去，可是貌似到目前为止没有发现为Vector3.Zero的情况 SameIndexList.Add(j); faceVertexNormalUV[j]=Vector3.zero; &#125; &#125; &#125; &#125; //用一个索引来作为字典的键名，这样它可以代替对应列表内所有索引 toCambineList.Add(i, SameIndexList); &#125; &#125; &#125; 在这里我们使用了一个字典来存储合并后的四边面，这个字典的键名为这一组三角面共同的索引，因为大家都是用同一个索引，因此它可以代替那些被合并的三角面的索引，这样合并以后的四边面列表中元素的个数就是实际的网格中的面数个数，因为如果采用三角面的话，这个面数会比现在的面数还要多，这意味着这样会带来更多的性能上的消耗。这里可能不大好理解，大家可以将博主这里的表达方式换成自己能够理解的方式。佛曰不可说，遇到这种博主自己都说不明白的地方，博主就只能请大家多多担待了。好了，接下来要做的是重新计算顶点、法线和UV数组。可能大家会比较疑惑，这部分内容我们在第一步不是就已经读取出来了嘛，怎么这里又要重新计算了呢？哈哈，且听我慢慢道来！ 根据索引重新计算顶点、法线、UV数组&emsp;&emsp;虽然我们在第一步就读取到了这些坐标数据，可是当我们合并三角面以后，就会出现大量的无用的点，为什么无用呢，因为它被合并到四边面里了，这样我们原来读取的这些坐标数据就变得不适用了。那怎么办呢？在第三步中我们合并四边面的时候已经用一个字典保存了合并后的索引信息，这就相当于我们已经知道哪些是合并前的索引，哪些是合并后的索引，这个时候我们只要根据索引重新为数组赋值即可： 123456789101112131415161718192021222324252627282930313233343536373839//初始化各个数组this.VertexArray = new Vector3[toCambineList.Count];this.UVArray = new Vector2[toCambineList.Count];this.NormalArray = new Vector3[toCambineList.Count];this.TriangleArray = new int[faceVertexNormalUV.Count];//定义遍历字典的计数器int count = 0;//遍历词典foreach(KeyValuePair&lt;int,ArrayList&gt; IndexTtem in toCambineList)&#123; //根据索引给面数组赋值 foreach(int item in IndexTtem.Value) &#123; TriangleArray[item] = count; &#125; //当前的顶点、UV、法线索引信息 Vector3 VectorTemp = (Vector3)faceVertexNormalUV[IndexTtem.Key]; //给顶点数组赋值 VertexArray[count] = (Vector3)vertexArrayList[(int)VectorTemp.x - 1]; //给UV数组赋值 if(uvArrayList.Count &gt; 0) &#123; Vector3 tVec =(Vector3)uvArrayList[(int)VectorTemp.y - 1]; UVArray[count] = new Vector2(tVec.x, tVec.y); &#125; //给法线数组赋值 if(normalArrayList.Count &gt; 0) &#123; NormalArray[count] = (Vector3)normalArrayList[(int)VectorTemp.z - 1]; &#125; count++; &#125; 这样我们就读取到了合并后的坐标信息，通过顶点、法线、UV、面等信息我们现在就可以生成网格了。这部分我们暂且不着急，因为这基本上属于最后整合到Unity3D中步骤了。好了，为了方便大家理解，我已经完整的项目上传到Github，大家可以通过这里了解完整的项目。 材质部分&emsp;&emsp;材质这块儿的解析主要集中在.mtl文件中，和.obj文件类似，它同样是一个文本文件、同样采用关键字、空格、文本字符这样的结构来表示数据，因此我们可以借鉴.obj文件的读取。例如： 1newmtl Material newmtl关键字表示从当前行到下一个newmtl关键字所在行间都表示该关键字所对应的材质，这里的Material即表示材质的名称，它和.obj文件中的usemtl关键字相对应，因此我们给模型添加材质的过程本质上是从.obj文件中读取网格，然后找到其对应的材质名称，然后在.mtl文件中找到对应的材质定义，并根据定义来生成材质。目前已知的关键字有： 1Ka 0.5880 0.5880 0.5880 Ka关键字表示环境反射的RGB数值。 1Kd 0.640000 0.640000 0.640000 Kd关键字表示漫反射的RGB数值。 1Ks 0.500000 0.500000 0.500000 Ks关键字表示镜面反射的RGB数值。 1map_Ka E:\\学习资料\\Unity3D技术\\Unity3D素材\\柳梦璃\\Texture\\1df2eaa0.dds map_Ka关键字表示环境反射的纹理贴图，注意到这里使用的是绝对路径，显然我们在读取模型的时候不会将贴图放在这样一个固定的路径，因此我们这里初步的想法读取贴图的文件名而非贴图的完整路径，考虑到我们在Unity3D中一般使用PNG格式的贴图，因此这里需要对路径进行处理。 1map_Kd E:\\学习资料\\Unity3D技术\\Unity3D素材\\柳梦璃\\Texture\\1df2eaa0.dds map_Kd关键字表示漫反射的纹理贴图，和环境反射的纹理贴图是类似地，这里就不再说了。此外还有其它的关键字，初步可以推断出的结论是它和3dsMax中材质编辑器里的定义特别地相似，感兴趣的朋友可以进一步去研究。可是现在就有一个新的问题了，怎样将这些参数和Unity3D里的材质关联起来呢？我们知道Unity3D里的材质是是由着色器和贴图两部分组成的，博主对Shader并不是很熟悉，因此这里确实有些说不清楚了。博主感觉对OBJ文件来说，其实使用Diffuse就完全足够了，所以这里对材质部分的研究我们点到为止，不打算做代码上的实现。如果不考虑这些参数的话，我们要做的就是通过WWW或者Resource将贴图加载进来，然后赋值给我们通过代码创建的Shader即可。而对于.obj文件来说，无论是通过Resource、WWW或者是IO流，只要我们拿到了这个文件中的内容就可以使用本文中的方式加载进来，因为我们假定的是读取只有一种材质的模型。有朋友可能要问，那如果有多种材质怎么办呢？答案是在.mtl问价中获取到所有贴图的名称，然后再到程序指定的路径去读取贴图，分别为其创建不同的材质，可是这些材质要怎么附加到它对应的物体上呢？这个目前博主没有找到解决的方法，所以此事暂且作罢吧！ 在Unity3D中加载obj模型&emsp;&emsp;下面我们以一个简单的例子来展示今天研究的成果，我们将从.obj文件中读取出一个简单的模型并将其加载到场景中。好了，我们一起来看代码： 123456789101112131415161718192021222324if(!File.Exists(\"D:\\\\cube.obj\")) Debug.Log(\"请确认obj模型文件是否存在!\");StreamReader reader = new StreamReader(\"D:\\\\cube.obj\",Encoding.Default);string content = reader.ReadToEnd();reader.Close();ObjMesh objInstace = new ObjMesh();objInstace = objInstace.LoadFromObj(content); Mesh mesh = new Mesh();mesh.vertices = objInstace.VertexArray;mesh.triangles = objInstace.TriangleArray;if(objInstace.UVArray.Length &gt; 0) mesh.uv = objInstace.UVArray;if(objInstace.NormalArray.Length&gt;0) mesh.normals = objInstace.NormalArray;mesh.RecalculateBounds(); GameObject go = new GameObject();MeshFilter meshFilter = go.AddComponent&lt;MeshFilter&gt;();meshFilter.mesh = mesh; MeshRenderer meshRenderer = go.AddComponent&lt;MeshRenderer&gt;(); 这里没有处理材质，所以读取出来就是这个样子的，哈哈！ 最终效果，这是一个悲伤的故事 材质大家可以尝试用代码去创建一个材质，然后在给一张贴图，这个玩玩就好，哈哈！好了，今天的内容就是这样子了，希望大家喜欢，为了写这篇文章我都怀疑我是不是有拖延症啊！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"OBJ","slug":"OBJ","permalink":"https://qinyuanpei.github.io/tags/OBJ/"},{"name":"格式","slug":"格式","permalink":"https://qinyuanpei.github.io/tags/%E6%A0%BC%E5%BC%8F/"}]},{"title":"Unity3D游戏开发之分页效果在uGUI中的实现","date":"2015-11-10T20:46:35.000Z","path":"posts/166983157/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。今天想和大家分享的是uGUI中分页效果的实现，我们知道相对NGUI来说uGUI在功能覆盖上来讲，它并没有像NGUI那样提供较为丰富和炫酷的组件，可是因为uGUI有着较好的扩展性，因此我们可以通过编写脚本来扩展它的功能。虽然在移动开发时代以开发速度论成败，可是这并不是我们“不求甚解”的正当理由。每次看到NGUI各种”丰富”的组件在脑海中打转的时候，每次看到编译项目时弹出各种Warming的时候，我内心是如此地期望有这样一个简单高效的UI系统啊，直到有一天我遇上了uGUI。 &emsp;&emsp;好了，博主这里并没有想要表达厚此薄彼的观点啦，博主真正想要表达的是我们在开发中应该摒弃“唯语言论”、“唯平台论”的狭隘观点，努力去掌握和语言无关、平台无关的“通用型技能”。这样，当我们面对全新的任务的时候我们可以更快地适应新的环境。言归正传，我们这里来接着说uGUI中的分页，分页通常是指将内容分散到不同的页面上来显示的一种手段，这种手段我们在传统的Web开发中可以经常看到。到了移动互联网以后分页被我们更为熟知的“下拉更新”所替代，这种方式我们就更为熟悉啦。好了，我们回到分页，为什么要要分页呢？这里有两个关键点：第一，内容在一页内无法展示完全；第二，对内容的数量无法进行估计。 &emsp;&emsp;例如，我们在uGUI中可以使用ScrollRect组件 + GridLayout组件 + Mask组件实现一个滚动列表，具体的案例可以参考这里。这里我们可以注意到一件事情就是这个滚动列表，它可以滚动的范围是由Mask组件来决定的，因此这个滚动列表是无法无限滚动的，虽然我们知道在游戏设计中不会出现这种无限滚动的列表，可是我们这里是为了探讨这个问题，所以我们假设这个情况是允许发生的。那么面对这个问题，我们有什么好的解决方案呢？博主尝试过一种思路，即借鉴Android中的ListView控件，这个控件的特点是可以对列表中的项目进行回收。相信说到这里，大家都明白我想做什么了吧，大概的思路就是制作一个高度大于屏幕高度的列表，然后让所有的列表项在这个列表中循环显示。可是新的问题就来了，第一，频繁地生成和销毁物体是Unity3D大忌。虽然我们可以缓存池来解决这个问题，可是因为博主并没有具体这样实践过，所以这里目前是存疑的。第二，GridLayout这个组件内的元素排序是根据子元素添加的顺序来决定的，因此每次列表更新以后都需要将所有的子元素更新一遍。曾经因为这样需求和策划发生过争执，最终妥协的一个结果就是采用分页来解决这个问题。分页首先解决了无限滚动的需求，因为它是一种“以不变应万变”的策略，不论列表内元素有多少它都可以显示出来。其次，在分页的过程是将数据模板化的过程，它改变是界面的外观和行为，UI结构是相对稳定的，这样可以避免频繁地生成和销毁物体。 &emsp;&emsp;下面我们以一个简单的案例来探讨分页效果在uGUI中的实现，首先我们使用GridLayoutGroup来制作一个简单的网格布局，请用心感受下图中萌萌哒十二生肖： 请不要伤害一个程序员的艺术细胞，虽然我知道它比较难看 这里我们不再对这个布局的制作方法进行详细的说明，因为我们今天的重点不在这里。我们注意到这里有12个元素，当我们每次对页面进行切换的时候，实际上这12个元素是基本不会发生变化的，真正变化的是这些元素的外观（如这里的精灵图片和名称）以及其对应的UI事件，在这个案例中我们利用匿名函数实现了一个简单的Click事件的监听。好了，前面我们说到分页的一个目的是可以解决列表内元素数目不确定的问题，因此我们这里利用一个12生肖的数组来随机生成元素数目不同的列表，代码实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940/// &lt;summary&gt; /// 初始化元素 /// &lt;/summary&gt; private void InitItems() &#123; //准备一个存储着12生肖信息的数组 GridItem[] items = new GridItem[] &#123; new GridItem(\"鼠\",\"Mouse\"), new GridItem(\"牛\",\"Ox\"), new GridItem(\"虎\",\"Tiger\"), new GridItem(\"兔\",\"Rabbit\"), new GridItem(\"龙\",\"Dragon\"), new GridItem(\"蛇\",\"Snake\"), new GridItem(\"马\",\"Horse\"), new GridItem(\"羊\",\"Goat\"), new GridItem(\"猴\",\"Monkey\"), new GridItem(\"鸡\",\"Rooster\"), new GridItem(\"狗\",\"Dog\"), new GridItem(\"猪\",\"Pig\") &#125;; //利用12生肖数组来随机生成列表 m_ItemsList = new List&lt;GridItem&gt;(); for(int i = 0; i &lt; Random.Range(1,1000); i++) &#123; m_ItemsList.Add(items[Random.Range(0,items.Length)]); &#125; //计算元素总个数 m_ItemsCount = m_ItemsList.Count; //计算总页数 m_PageCount = (m_ItemsCount % 12) == 0 ? m_ItemsCount / 12 : (m_ItemsCount / 12) + 1; BindPage(m_PageIndex); //更新界面页数 m_PanelText.text = string.Format(\"&#123;0&#125;/&#123;1&#125;\", m_PageIndex.ToString(), m_PageCount.ToString()); &#125; 在这段代码中，m_ItemList表示我们要展示的元素列表，m_ItemsCount表示元素列表中元素的个数，m_PageCount表示这些元素可以分成的总页数，m_PageIndex表示页数的索引默认从1开始。其中GridItem是一个简单的类，它有ItemName和ItemSprite两个属性，这里不再具体说明了。好了，现在我们来思考如何将这些元素和UI对应起来，因为列表中元素的数目不确定，因此我们可以分成两种情况来讨论： 页面总数为1，即m_PageCount=1，此时列表内的元素个数的范围是1~12，因此我们可以利用循环判断哪些元素是要展示的？哪些元素是不需要的？因为如果此时列表内的元素为10，则意味着前面10个元素是要展示给用户，而剩下的2个元素是不需要的。在这里我们简单地使用SetActive来让这些元素隐藏起来。 页面总数大于1，即m_PageCount&gt;1，此时前面的m_PageCount-1个页面都是显示完全的，它相当于元素总个数中被12整除的部分。而第m_PageCount个页面此时的情况和页数总数为1的情况类似，我们可以采取和页面总数为1类似的方法来处理。 &emsp;&emsp;好了，下面我们来看这部分代码的具体实现： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/// &lt;summary&gt;/// 绑定指定索引处的页面元素/// &lt;/summary&gt;/// &lt;param name=\"index\"&gt;页面索引&lt;/param&gt;private void BindPage(int index)&#123; //列表处理 if(m_ItemsList == null || m_ItemsCount &lt;= 0) return; //索引处理 if(index &lt; 0 || index &gt; m_ItemsCount) return; //按照元素个数可以分为1页和1页以上两种情况 if(m_PageCount == 1) &#123; int canDisplay = 0; for(int i = 12; i &gt; 0; i--) &#123; if(canDisplay &lt; 12)&#123; BindGridItem(transform.GetChild(canDisplay), m_ItemsList[12 - i]); transform.GetChild(canDisplay).gameObject.SetActive(true); &#125;else&#123; //对超过canDispaly的物体实施隐藏 transform.GetChild(canDisplay).gameObject.SetActive(false); &#125; canDisplay += 1; &#125; &#125;else if(m_PageCount &gt; 1)&#123; //1页以上需要特别处理的是最后1页 //和1页时的情况类似判断最后一页剩下的元素数目 //第1页时显然剩下的为12所以不用处理 if(index == m_PageCount)&#123; int canDisplay = 0; for(int i = 12; i &gt; 0; i--) &#123; //最后一页剩下的元素数目为 m_ItemsCount - 12 * (index-1) if(canDisplay &lt; m_ItemsCount - 12 * (index-1))&#123; BindGridItem(transform.GetChild(canDisplay), m_ItemsList[12 * index-i]); transform.GetChild(canDisplay).gameObject.SetActive(true); &#125;else&#123; //对超过canDispaly的物体实施隐藏 transform.GetChild(canDisplay).gameObject.SetActive(false); &#125; canDisplay += 1; &#125; &#125; else&#123; for(int i = 12; i &gt; 0; i--) &#123; BindGridItem(transform.GetChild(12 - i), m_ItemsList[12 * index - i]); transform.GetChild(12 - i).gameObject.SetActive(true); &#125; &#125; &#125;&#125; 好了，在这里完成BindPage方法的定义以后，我们就可以指定程序显示对应页面的元素，此时上一页和下一页的工作基本上就是改变索引的一个过程了。这部分我们不再说了，大家可以去看最终给出的完整代码，我们这里来看看实际的效果吧！ 简单的分页效果展示 其实这里核心的内容是分页的处理，在处理里只有1页时的元素个数和超过1页的最后1页时我们可以采取两个循环处理的方法，即先从0循环到m_ItemsCount - 12 * (index-1))设置要显示的元素，然后再从m_ItemsCount - 12 * (index-1))循环到12设置要隐藏的元素，可是这样的方式我不太喜欢，所以在文章中就没有采取这样的方式。这篇文章是根据一个项目当时的经历写的，因为时间过得比较久，所以如果文章中不当之处希望大家指出并批评。现在这个方案感觉还可以在特效上进行改进，因为现在感觉切换的时候画面比较突兀，这一点请大家注意。好了，下面给出完整的代码和场景布局截图。再次强调：请在看懂文章的基础上“抄”代码，每次看到别人问我把XXX脚本挂到场景中不起作用这类的问题，我就觉得整个世界充满了深深地罪恶感。别人愿意分享技术文章，更多的是希望可以和别人交流学习相互促进，如果你只是希望拿到一个随便抄来就能用地代码，抱歉！这违背了我的初衷所以我很难做到！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249/* * 一个基于uGUI的分页功能的实现 * 作者：秦元培 * 时间：2015年11月11日 * 博客：http://qinyuanpei.com */using UnityEngine;using System.Collections;using System.Collections.Generic;using UnityEngine.UI;public class PaginationPanel : MonoBehaviour&#123; /// &lt;summary&gt; /// 当前页面索引 /// &lt;/summary&gt; private int m_PageIndex = 1; /// &lt;summary&gt; /// 总页数 /// &lt;/summary&gt; private int m_PageCount = 0; /// &lt;summary&gt; /// 元素总个数 /// &lt;/summary&gt; private int m_ItemsCount = 0; /// &lt;summary&gt; /// 元素列表 /// &lt;/summary&gt; private List&lt;GridItem&gt; m_ItemsList; /// &lt;summary&gt; /// 上一页 /// &lt;/summary&gt; private Button m_BtnPrevious; /// &lt;summary&gt; /// 下一页 /// &lt;/summary&gt; private Button m_BtnNext; /// &lt;summary&gt; /// 显示当前页数的标签 /// &lt;/summary&gt; private Text m_PanelText; void Start() &#123; InitGUI(); InitItems(); &#125; /// &lt;summary&gt; /// 初始化GUI /// &lt;/summary&gt; private void InitGUI() &#123; m_BtnNext = GameObject.Find(\"Canvas/Panel/BtnNext\").GetComponent&lt;Button&gt;(); m_BtnPrevious = GameObject.Find(\"Canvas/Panel/BtnPrevious\").GetComponent&lt;Button&gt;(); m_PanelText = GameObject.Find(\"Canvas/Panel/Text\").GetComponent&lt;Text&gt;(); //为上一页和下一页添加事件 m_BtnNext.onClick.AddListener(() =&gt; &#123; Next(); &#125;); m_BtnPrevious.onClick.AddListener(() =&gt; &#123; Previous(); &#125;); &#125; /// &lt;summary&gt; /// 初始化元素 /// &lt;/summary&gt; private void InitItems() &#123; //准备一个存储着12生肖信息的数组 GridItem[] items = new GridItem[] &#123; new GridItem(\"鼠\",\"Mouse\"), new GridItem(\"牛\",\"Ox\"), new GridItem(\"虎\",\"Tiger\"), new GridItem(\"兔\",\"Rabbit\"), new GridItem(\"龙\",\"Dragon\"), new GridItem(\"蛇\",\"Snake\"), new GridItem(\"马\",\"Horse\"), new GridItem(\"羊\",\"Goat\"), new GridItem(\"猴\",\"Monkey\"), new GridItem(\"鸡\",\"Rooster\"), new GridItem(\"狗\",\"Dog\"), new GridItem(\"猪\",\"Pig\") &#125;; //利用12生肖数组来随机生成列表 m_ItemsList = new List&lt;GridItem&gt;(); for(int i = 0; i &lt; Random.Range(1,1000); i++) &#123; m_ItemsList.Add(items[Random.Range(0,items.Length)]); &#125; //计算元素总个数 m_ItemsCount = m_ItemsList.Count; //计算总页数 m_PageCount = (m_ItemsCount % 12) == 0 ? m_ItemsCount / 12 : (m_ItemsCount / 12) + 1; BindPage(m_PageIndex); //更新界面页数 m_PanelText.text = string.Format(\"&#123;0&#125;/&#123;1&#125;\", m_PageIndex.ToString(), m_PageCount.ToString()); &#125; /// &lt;summary&gt; /// 下一页 /// &lt;/summary&gt; public void Next() &#123; if(m_PageCount &lt;= 0) return; //最后一页禁止向后翻页 if(m_PageIndex &gt;= m_PageCount) return; m_PageIndex += 1; if (m_PageIndex &gt;= m_PageCount) m_PageIndex = m_PageCount; BindPage(m_PageIndex); //更新界面页数 m_PanelText.text = string.Format(\"&#123;0&#125;/&#123;1&#125;\", m_PageIndex.ToString(), m_PageCount.ToString()); &#125; /// &lt;summary&gt; /// 上一页 /// &lt;/summary&gt; public void Previous() &#123; if(m_PageCount &lt;= 0) return; //第一页时禁止向前翻页 if(m_PageIndex &lt;= 1) return; m_PageIndex -= 1; if(m_PageIndex &lt; 1) m_PageIndex = 1; BindPage(m_PageIndex); //更新界面页数 m_PanelText.text = string.Format(\"&#123;0&#125;/&#123;1&#125;\", m_PageIndex.ToString(), m_PageCount.ToString()); &#125; /// &lt;summary&gt; /// 绑定指定索引处的页面元素 /// &lt;/summary&gt; /// &lt;param name=\"index\"&gt;页面索引&lt;/param&gt; private void BindPage(int index) &#123; //列表处理 if(m_ItemsList == null || m_ItemsCount &lt;= 0) return; //索引处理 if(index &lt; 0 || index &gt; m_ItemsCount) return; //按照元素个数可以分为1页和1页以上两种情况 if(m_PageCount == 1) &#123; int canDisplay = 0; for(int i = 12; i &gt; 0; i--) &#123; if(canDisplay &lt; 12)&#123; BindGridItem(transform.GetChild(canDisplay), m_ItemsList[12 - i]); transform.GetChild(canDisplay).gameObject.SetActive(true); &#125;else&#123; //对超过canDispaly的物体实施隐藏 transform.GetChild(canDisplay).gameObject.SetActive(false); &#125; canDisplay += 1; &#125; &#125;else if(m_PageCount &gt; 1)&#123; //1页以上需要特别处理的是最后1页 //和1页时的情况类似判断最后一页剩下的元素数目 //第1页时显然剩下的为12所以不用处理 if(index == m_PageCount)&#123; int canDisplay = 0; for(int i = 12; i &gt; 0; i--) &#123; //最后一页剩下的元素数目为 m_ItemsCount - 12 * (index-1) if(canDisplay &lt; m_ItemsCount - 12 * (index-1))&#123; BindGridItem(transform.GetChild(canDisplay), m_ItemsList[12 * index-i]); transform.GetChild(canDisplay). gameObject.SetActive(true); &#125;else&#123; //对超过canDispaly的物体实施隐藏 transform.GetChild(canDisplay). gameObject.SetActive(false); &#125; canDisplay += 1; &#125; &#125; else&#123; for(int i = 12; i &gt; 0; i--) &#123; BindGridItem(transform.GetChild(12 - i), m_ItemsList[12 * index - i]); transform.GetChild(12 - i).gameObject.SetActive(true); &#125; &#125; &#125; &#125; /// &lt;summary&gt; /// 加载一个Sprite /// &lt;/summary&gt; /// &lt;param name=\"assetName\"&gt;资源名称&lt;/param&gt; private Sprite LoadSprite(string assetName) &#123; Texture texture = (Texture)Resources.Load(assetName); Sprite sprite = Sprite.Create((Texture2D)texture, new Rect(0, 0, texture.width, texture.height), new Vector2(0.5f, 0.5f)); return sprite; &#125; /// &lt;summary&gt; /// 将一个GridItem实例绑定到指定的Transform上 /// &lt;/summary&gt; /// &lt;param name=\"trans\"&gt;&lt;/param&gt; /// &lt;param name=\"gridItem\"&gt;&lt;/param&gt; private void BindGridItem(Transform trans,GridItem gridItem) &#123; trans.GetComponent&lt;Image&gt;().sprite = LoadSprite(gridItem.ItemSprite); trans.Find(\"Item/Name\").GetComponent&lt;Text&gt;().text = gridItem.ItemName; trans.GetComponent&lt;Button&gt;().onClick.AddListener(()=&gt; &#123; Debug.Log(\"当前点击的元素名称为:\" + gridItem.ItemName); &#125;); &#125;&#125; 好了，今天的内容就是这样啦，欢迎大家继续关注我的博客，谢谢大家！ 2016年1月10日更新：&emsp;&emsp;经过博客中一位朋友指出，这篇文章中实现BindPage这个方法时可以在代码上再精简些，主要是考虑这个代码中有部分功能是重合的，因此这里对这个方法进行重写，分页从本质上来讲是编写这样一个函数：输入数据集合data、每页显示的元素个数pageSize以及当前页数page，然后返回一个新的数据集合。为了考虑扩展性我们这里编写一个分页的泛型方法，代码实现如下： 12345678910111213141516171819202122232425262728293031323334List&lt;T&gt; Pagination(List&lt;T&gt; data,int size,int page)&#123; //要返回的结果 List&lt;T&gt; output = new List&lt;T&gt;(); //计算最大页数 int PageCount = (data.Count % size) == 0 ? (data.Count / size) : (data.Count / size) + 1; //判断输入页数的合法性 if(page &lt; 1 || page &gt; PageCount) return null; //计算第page页第一个元素的索引 int startIndex = (page - 1) * size; //除了尾页所有的页面中元素个数都是size个 if(page &lt; PageCount) &#123; for (int i = 0; i &lt; size; i++) &#123; output.Add(data[startIndex + i]); &#125; &#125; else &#123; for (int i = startIndex; i &lt; data.Count; i++) &#123; output.Add(data[i]); &#125; &#125; return output;&#125; 这里我们只需要考虑传入的页数是不是尾页即可，因为在所有的页面中除了尾页以外都有size个元素，所以我们只需要计算出第page页的第一个元素的索引，然后以此递增即可，而尾页显然是从startIndex到data.Count-1个。现在回过头来看，写个分页函数确实是简单至极，这篇博客显然是小题大做了。","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"uGUI","slug":"uGUI","permalink":"https://qinyuanpei.github.io/tags/uGUI/"}]},{"title":"EasyAR尝鲜系列教程之自定义Marker的实现","date":"2015-11-03T10:23:14.000Z","path":"posts/1156673678/","text":"&emsp;&emsp;各位朋友大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是http://qinyuanpei.com。通过本系列第一篇文章，我们初步了解了EasyAR这个增强现实引擎，这次我们来尝试自己定义一个Marker，这样我们就可以用自己喜欢的图片来作为Marker。因为目前EasyAR文档并不完善，所以下面的这些内容可能更多的是我个人的尝试和探索。如果大家对此感兴趣的话继续往下看否则就不要往下看了，因为我担心在官方正式文档出来以后大家可能会骂我啊。好了，对这个话题感兴趣的朋友就请继续往下看吧！ EasyAR的基本流程&emsp;&emsp;首先我们来看看官方给出的一张EasyAR的基本流程示意图： EasyAR基本流程示意图 在这张流程图，当中作为开发者的我们此刻需要关注的Target这一条线和Frame这条线。前者对应的是如何将普通的图片如.jpg、.png配合JSON文件转化为系统可以识别的Target，后者对应的是我们在识别到Target后要去处理哪些逻辑。在官方文档中我们可以找到这样一段话： 创建相机设备、图像追踪器和增强对象（Create CameraDevice and ImageTracker and Augmenter objects）. 打开相机设备（Open CameraDevice）. 给相机设备附加图像追踪器（Attach ImageTracker to CameraDevice）. 开始执行相机设备和图形追踪器的相关逻辑（Start CameraDevice and ImageTracker）. 获得从图像追踪器增强后的帧画面（New frame using Augmenter from ImageTracker）. 绘制视频和其它的内容（Draw video background and other stuffs）. 这段话基本上就是EasyAR流程示意图的全面解读了，所以我们学习EasyAR可以从这个基本流程来入手，了解这个流程能帮助我们更快地理解API接口，虽然现在官方的API文档依然处在Debug状态下，想到这里简直各种不开心啊！ 创建自定义Marker&emsp;&emsp;在了解了EasyAR的基本流程后，我们就来说说如何在EasyAR中创建自定义Marker吧！相信使用过Vuforia的人都知道要创建一个自定义的Marker需要到开发者后台去创建然后下载资源包，这种方式虽然高效、直接，可是因为没有人为地干预过程，所以我们对AR引擎内部究竟做了怎样的处理基本上是一无所知的，换句话说我们大部分的工作都是在做黑箱测试。到了EasyAR这里，一切就变得特别简单，这一点要给EasyAR点个赞。首先在EasyAR中配置Marker是通过StreamingAssets目录下的dataset.json这个文件来实现的： 123456789101112131415&#123; \"images\" : [ &#123; \"image\" : \"mousepad.jpg\", \"name\" : \"mousepad\" &#125;, &#123; \"image\" : \"idback.jpg\", \"name\" : \"idback\", \"size\" : [8.56, 5.4], \"uid\" : \"todo=uid-string\" &#125; ]&#125; 从这个文件中我们可以发现每一张图片都具有某些不同的属性，从目前博主掌握的资料来看，每张图片最重要的两个属性是image和name。其中image是指图片的相对路径，该路径相对于StreamingAssets目录，因为我们做Unity3D游戏开发的时候都知道这个目录下的资源在编译的时候不会被压缩，当导出APK安装包的时候它会被完整的保留到根目录下的assets目录中。同样地，name是指图片的名称即ID，EasyAR正是通过这个ID来和图片资源关联起来的。比如在默认的SDK项目中身份证背面这张图片是和idback这个ID对应的，如图所示，在这里Easy提供了四种存储方案即Assets、App、Absolute、Json。和官方的人交流的时候说可以支持路径和Json字符串两种形式，但是对更加具体的这四种存储方案上的区别和优缺点目前并没有一个确切的说法，所以在这里我们就继续沿用Assets这种存储方案吧！我们可以注意到idback这张图片和mousepad这张图片相比增加了两个属性，即uid和size。size目前基本可以了解为Unity3D中的缩放，因为这个值表示的是在物理空间里的范围大小，单位是米，而我们知道Unity3D里默认的单位就是米，所以这个数值可以暂时理解为Unity3D里的缩放，它对应到下图里的Size，我已经用红色字体标示出来。对于uid这个属性嘛，既然配置文件里都有todo标识出来了，那么我们就姑且认为这是一个暂时没有启用的属性值吧！ 好了，下面我们来具体看看如何创建一个自定义Markder。 首先我们在StreamingAssets目录中添加一张图片ziying.jpg，然后在dataset.json文件中增加该图片的信息。此时ziying.jpg的位置是在StreamingAssets根目录下。如果我们希望把它放在一个自定义的文件夹中，如StreamingAssets/ziying目录下，则需要将ziying的image属性值改为ziying/ziying.jpg，以此类推。 12345678910111213141516171819&#123; \"images\" : [ &#123; \"image\" : \"mousepad.jpg\", \"name\" : \"mousepad\" &#125;, &#123; \"image\" : \"ziying.jpg\", \"name\" : \"ziying\" &#125;, &#123; \"image\" : \"idback.jpg\", \"name\" : \"idback\", \"size\" : [8.56, 5.4], \"uid\" : \"todo=uid-string\" &#125; ]&#125; 在Materials目录下新建一个材质，然后找到ziying.jpg将其作为该材质的纹理贴图。 在场景中找到ImageTargetDataSet-idback节点，修改其附加的SimpleImageTargetBehaviour脚本下的Name属性，将其修改为ziying，同时将第二步创建的材质赋给ImageTargetDataSet-idback节点。此时场景效果如图所示，这意味着我们使用手机摄像头来扫描这张图片就可以看到场景中的这个模型啦！ 自定义Markder效果 好了，现在编译这个项目并部署到手机上可以得到我们期望的结果，哈哈，慕容紫英站在桌面上和我一起玩对一个仙剑迷来说是不是特别有趣呢？ 站在手机上的慕容紫英 总结&emsp;&emsp;到目前为止，EasyAR官方还没有给出一个完整的API文档，所以我们目前能做的研究依然十分有限，在本文中涉及到的部分没有解决的问题，博主会在官方给出文档后第一时间给予解决，希望大家继续关注我的博客！我们现在使用的都是SDK中现成的脚本，如果我们希望自己来设计脚本来满足自己的要求实现某些定制的功能或者是想用原生代码来减少Unity3D这类游戏引擎带来的性能上的损耗以及实现播放视频的功能等等。这些内容博主在稍后会陆续写出来，好了，今天的内容就是这个样子啦！希望大家喜欢。","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"增强现实","slug":"增强现实","permalink":"https://qinyuanpei.github.io/tags/%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E/"},{"name":"AR","slug":"AR","permalink":"https://qinyuanpei.github.io/tags/AR/"},{"name":"教程","slug":"教程","permalink":"https://qinyuanpei.github.io/tags/%E6%95%99%E7%A8%8B/"}]},{"title":"EasyAR尝鲜系列教程之Hello EasyAR","date":"2015-10-30T09:44:18.000Z","path":"posts/3120185261/","text":"&emsp;&emsp;各位朋友，大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。从今天起博主将为大家带来EasyAR尝鲜系列教程，本教程适用的对象是增强现实应用开发者和Unity3D游戏开发者，在阅读本教程前请确保具备增强现实应用开发及Unity3D游戏开发的相关基础知识。在本节及后续内容中，博主将以国产增强现实引擎EasyAR为主要开发平台来带领大家一起走进增强现实应用开发的世界，希望大家能够喜欢！ 什么是增强现实？&emsp;&emsp;为了让更多的人了解增强现实，所以在开始本文教程前，我们首先来了解下什么是增强现实。增强现实(Augmented Reality，简称 AR)，它是一种将真实世界信息和虚拟世界信息进行融合和集成的新技术，这种技术的目标是在屏幕上把虚拟世界和现实世界进行叠加并在此基础上进行互动。增强现实是真实世界和虚拟世界的信息集成，具有实时交互性，是在三维尺度空间中增添定位虚拟物体。增强现实技术可广泛应用到军事、医疗、建筑、教育、工程、影视、娱乐等领域。增强现实是新型的人机交互和三维仿真工具，目前已发挥出了重要的作用，具有巨大的应用潜力。 增强现实概念图 增强现实应用现状&emsp;&emsp;目前，增强现实在国内尚处在起步阶段。2012年4月Google发布的Google Class是全球唯一一款真正意义上实现增强现实技术的硬件设备。随着移动设备的普及和相关技术的成熟，增强现实开始逐渐地走进人们的生活。如国内首款聚合了目前移动互联最新增强现实技术的智能手机应用《城市镜头》以及中视典数字科技研发的VRP系统等。AR技术在人工智能、CAD、图形仿真、虚拟通讯、遥感、娱乐、模拟训练等许多领域带来了革命性的变化。目前增强现实相关技术主要有开源社区的ARToolkit、面向商业化解决方案的Metaio和Vuforia等。 国产增强现实引擎EasyAR&emsp;&emsp;EasyAR(Easy Augmented Reality)是视辰信息科技（上海）有限公司的增强现实解决方案系列的子品牌，其含义是希望让增强现实变得简单易实施。EasyAR提供了诸如手机APP互动营销、户外大屏幕互动活动、网络营销互动等形式在内的增强现实互动营销技术和解决方案。著作权归作者所有。EasyAR无需授权、无水印、无识别次数的限制，开放后可免费下载，无需任何费用，是一款完全免费的AR引擎。EasyAR具有强大的跨平台特性可支持Windows、 Mac OS、 Android和iOS等主流平台。从目前的情况来看，EasyAR的SDK是目前市场上同类产品中最为简单易用的，唯一的不足是产品刚发布不久尚未能提供完整的技术文档。 Hello EasyAR&emsp;&emsp;好了，下面我们以EasyAR提供的Unity3D版本SDK为例来学习EasySDK的使用。在开始前请确保你的计算机上正确安装了以下开发工具或者硬件： Unity3D(必选)：主要的开发环境 JDK相关工具(必选)：编译Android应用所需环境 Android SDK(必选)：编译Android应用所需环境 摄像头(可选)：如使用手机进行调试则不需要 在完成以上准备工作后： 打开EasyAR官网并登录官网，我们将在登陆后创建应用以获得开发所需的密钥以及SDK。如果尚未注册可以在注册后完成这一步骤。 创建应用 点击创建应用，并在这里填入应用的名称和包的名称，此处以“EasyAR测试”和“com.easyar.first”为例，在创建完应用后可以在应用列表中找到当前创建的应用，点击显示可以查看当前应用对应的密钥。 点击“下载EasyAR SDK v1.0.1”完成SDK的下载。 下载SDK 解压下载的SDK压缩包，找到vc_redist目录安装对应平台的VC++运行库。请注意，即使在你的计算机上安装了VC++运行库，这里依然需要安装。Win8及Win8.1请先使用磁盘清理工具清理系统垃圾，否则可能会出现无法安装的问题。建议使用64位操作系统且安装x86和x64的VC++运行库。 找到SDK压缩包内的package/unity目录下的EasyAR.unitypackage文件并将其导入到Unity3D中。 在Unity3D中找到Scenes目录下的easyar场景并打开该场景，然后找到EasyAR节点名称，在右侧属性窗口中填入应用对应的密钥。 填入应用程序密钥 打开BuildSetting-&gt;PlayerSetting在右侧属性窗口中填入应用对应的包名。 填入应用程序包名 SDK默认提供了三张识别图片，我们选择每个人都有的身份证照片作为识别目标，在场景中找到ImageTargetDataSet-idback这个物体，找到它的子节点Cube。这意味着如果我们识别到了身份证照片，那么就会在身份证照片上显示一个Cube。如果大家手头上有自己喜欢的模型，可以将Cube隐藏，然后将模型添加进来，并为其添加VideoPlayerBehaviour.cs脚本。如手头上没有模型，这一步可以忽略。如图是我现在的场景效果： 加入自定义模型后的效果 &emsp;&emsp;好了，现在编译程序，将其导出为APK安装包，这样我们就可以在手机上测试EasyAR的效果啦。假如一切顺利的话，在手机上将会看到这样的画面。下面放点运行情况截图供大家参考： 截图1 截图2 问题汇总&emsp;&emsp;作为一款国产的增强现实引擎，目前EasyAR的表现我还是比较满意的，虽然在识别的准确度上无法和国外的同类产品相比，但是它的简单易用确实是做得不错。作为一个程序员尝鲜更像是吃螃蟹，目前发现的问题及解决方案有： 编辑器提示DllNotFoundException错误，请安装SDK中对应的VC++运行库。 视频导入失败，Unity3D导入视频需要依赖苹果公司的QuickTime播放器，所以请安装最新版的QuickTime后重试。 在64位计算机上编译的Android应用可以正常运行，在32位计算机上编译的Android应用无法正常运行。具体表现如图 32位计算机下的问题 &emsp;&emsp;好了，作为整个系列的第一篇文章，我们至此对EasyAR有了一个较为直观的印象。在接下来的内容中，我们将对SDK中的内容进行更加深入的了解，因此希望大家继续关注我的博客，谢谢大家！","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"增强现实","slug":"增强现实","permalink":"https://qinyuanpei.github.io/tags/%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E/"},{"name":"AR","slug":"AR","permalink":"https://qinyuanpei.github.io/tags/AR/"},{"name":"教程","slug":"教程","permalink":"https://qinyuanpei.github.io/tags/%E6%95%99%E7%A8%8B/"}]},{"title":"教你一步步实现一个虚拟摇杆","date":"2015-10-30T09:44:18.000Z","path":"posts/331752533/","text":"&emsp;&emsp;各位朋友，大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。最近因为项目需要决定尝试自己来实现一个虚拟摇杆，所以在今天的文章中我们的目标是使用uGUI来制作一个可以在移动平台稳定运行的虚拟摇杆(请不要问我为什么不使用NGUI来实现，你说我做个虚拟摇杆有必要在项目里导入那么多的资源嘛23333)。关于使用第三方插件来实现虚拟摇杆，请大家参照我以前写的文章Unity3D游戏开发之使用EasyTouch虚拟摇杆控制人物移动，在这里就不再赘述了。 &emsp;&emsp;虚拟摇杆这种输入方式相信大家在手机游戏平台上已经相当的熟悉了，首先我们来简单了解下虚拟摇杆的设计原理。虚拟摇杆有一张固定的2D贴图(背景层)和一张可拖动的2D贴图(控制层)构成，默认情况下控制层在背景层的中心，我们称这个位置为初始位置，当移动控制层后移动层的位置会发生变化，此时控制层的当前位置和初始位置两点间可以计算出一个2D向量，通过这个向量我们就可以判断虚拟摇杆的移动方向。在经典的八方向摇杆导航中摇杆中可移动方向被分成了上、左上、右上、下、左下、右下、左、右共8个方向。我们知道根据三角函数可以非常容易地计算出这个2D向量的角度并由此判定摇杆是在向着这8个方向中的哪一个方向移动。在今天的文章中，我们不需要考虑这8个方向，因为我们可以向任何一个方向进行移动。 &emsp;&emsp;好了，首先在场景中创建两个Image组件和一个空的游戏体，然后将这两个Image组件拖拽到这个空的游戏体下使它们称为其子节点。这里需要注意的是这两个Image的层级关系。现在我们来编写脚本，这个脚本将被添加到控制层物体上： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161/* * uGUI虚拟摇杆 * 作者：秦元培 * 博客：http://qinyuanpei.com * 时间：2015年10月24日 */using UnityEngine;using System.Collections;using UnityEngine.UI;using UnityEngine.EventSystems;public class JoyStick : MonoBehaviour,IPointerDownHandler, IPointerUpHandler, IDragHandler&#123; /// &lt;summary&gt; /// 摇杆最大半径 /// 以像素为单位 /// &lt;/summary&gt; public float JoyStickRadius = 50; /// &lt;summary&gt; /// 摇杆重置所诉 /// &lt;/summary&gt; public float JoyStickResetSpeed = 5.0f; /// &lt;summary&gt; /// 当前物体的Transform组件 /// &lt;/summary&gt; private RectTransform selfTransform; /// &lt;summary&gt; /// 是否触摸了虚拟摇杆 /// &lt;/summary&gt; private bool isTouched = false; /// &lt;summary&gt; /// 虚拟摇杆的默认位置 /// &lt;/summary&gt; private Vector2 originPosition; /// &lt;summary&gt; /// 虚拟摇杆的移动方向 /// &lt;/summary&gt; private Vector2 touchedAxis; public Vector2 TouchedAxis &#123; get &#123; if(touchedAxis.magnitude &lt; JoyStickRadius) return touchedAxis.normalized / JoyStickRadius; return touchedAxis.normalized; &#125; &#125; /// &lt;summary&gt; /// 定义触摸开始事件委托 /// &lt;/summary&gt; public delegate void JoyStickTouchBegin(Vector2 vec); /// &lt;summary&gt; /// 定义触摸过程事件委托 /// &lt;/summary&gt; /// &lt;param name=\"vec\"&gt;虚拟摇杆的移动方向&lt;/param&gt; public delegate void JoyStickTouchMove(Vector2 vec); /// &lt;summary&gt; /// 定义触摸结束事件委托 /// &lt;/summary&gt; public delegate void JoyStickTouchEnd(); /// &lt;summary&gt; /// 注册触摸开始事件 /// &lt;/summary&gt; public event JoyStickTouchBegin OnJoyStickTouchBegin; /// &lt;summary&gt; /// 注册触摸过程事件 /// &lt;/summary&gt; public event JoyStickTouchMove OnJoyStickTouchMove; /// &lt;summary&gt; /// 注册触摸结束事件 /// &lt;/summary&gt; public event JoyStickTouchEnd OnJoyStickTouchEnd; void Start () &#123; //初始化虚拟摇杆的默认方向 selfTransform = this.GetComponent&lt;RectTransform&gt;(); originPosition = selfTransform.anchoredPosition; &#125; public void OnPointerDown(PointerEventData eventData) &#123; isTouched = true; touchedAxis = GetJoyStickAxis(eventData); if(this.OnJoyStickTouchBegin != null) this.OnJoyStickTouchBegin(TouchedAxis); &#125; public void OnPointerUp(PointerEventData eventData) &#123; isTouched = false; selfTransform.anchoredPosition = originPosition; touchedAxis = Vector2.zero; if(this.OnJoyStickTouchEnd != null) this.OnJoyStickTouchEnd(); &#125; public void OnDrag(PointerEventData eventData) &#123; touchedAxis = GetJoyStickAxis(eventData); if(this.OnJoyStickTouchMove != null) this.OnJoyStickTouchMove(TouchedAxis); &#125; void Update() &#123; //当虚拟摇杆移动到最大半径时摇杆无法拖动 //为了确保被控制物体可以继续移动 //在这里手动触发OnJoyStickTouchMove事件 if(isTouched &amp;&amp; touchedAxis.magnitude&gt;=JoyStickRadius) &#123; if(this.OnJoyStickTouchMove != null) this.OnJoyStickTouchMove(TouchedAxis); &#125; //松开虚拟摇杆后让虚拟摇杆回到默认位置 if(selfTransform.anchoredPosition.magnitude &gt; originPosition.magnitude) selfTransform.anchoredPosition -= TouchedAxis * Time.deltaTime * JoyStickResetSpeed; &#125; /// &lt;summary&gt; /// 返回虚拟摇杆的偏移量 /// &lt;/summary&gt; /// &lt;returns&gt;The joy stick axis.&lt;/returns&gt; /// &lt;param name=\"eventData\"&gt;Event data.&lt;/param&gt; private Vector2 GetJoyStickAxis(PointerEventData eventData) &#123; //获取手指位置的世界坐标 Vector3 worldPosition; if (RectTransformUtility.ScreenPointToWorldPointInRectangle (selfTransform, eventData.position, eventData.pressEventCamera, out worldPosition)) selfTransform.position = worldPosition; //获取摇杆的偏移量 Vector2 touchAxis = selfTransform.anchoredPosition-originPosition; //摇杆偏移量限制 if(touchAxis.magnitude &gt;= JoyStickRadius) &#123; touchAxis = touchAxis.normalized * JoyStickRadius; selfTransform.anchoredPosition = touchAxis; &#125; return touchAxis; &#125;&#125; &emsp;&emsp;在这段脚本中，我们实现了OnPointerDown、OnPointerUp和OnDrag三个uGUI事件接口，然后注册了相关的事件委托，这里借鉴了EasyTouch的设计，可以使得虚拟摇杆的逻辑和角色控制逻辑相互分离。这里的核心方法是GetJoyStickAxis()方法，通过这个方法我们可以获得一个Vector2类型的值，它表示的是未标准化过的虚拟摇杆的偏移量。这里的RectTransformUtility.ScreenPointToWorldPointInRectangle()方法表示将一个屏幕坐标转化为对应RectTransform的世界坐标，RectTransform的anchoredPosition属性表示的是当前元素在场景中的屏幕坐标。我们知道屏幕坐标是以像素为单位的，因此这里使用屏幕坐标可以计算出虚拟摇杆在水平方向和垂直方向上移动了多少个像素，我们以此来作为虚拟摇杆的偏移量衡量指标。TouchedAxis是经过标准化以后的偏移量，我们将把这个值传递到事件委托中以提供给外部来调用。好了，要说的就这些了，没有说到的大家可以看看代码里的注释或者是在博客中给我留言，就是这样啦。 &emsp;&emsp;接下来，我们在场景中添加一个角色模型来测试我们编写的虚拟摇杆，因为在JoyStick中我们已经定义了事件委托，所以在这里就是简单的调用啦。好了，我们一起来看看代码吧！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657/* * Joystick3D.cs * 3D模式下的虚拟摇杆测试 * 作者：秦元培 * 博客：http://qinyuanpei.com * 时间：2015年10月30日 */using UnityEngine;using System.Collections;public class JoyStick3D : MonoBehaviour &#123; private JoyStick js; void Start () &#123; js = GameObject.FindObjectOfType&lt;JoyStick&gt; (); js.OnJoyStickTouchBegin += OnJoyStickBegin; js.OnJoyStickTouchMove += OnJoyStickMove; js.OnJoyStickTouchEnd += OnJoyStickEnd; &#125; void OnJoyStickBegin(Vector2 vec) &#123; Debug.Log(\"开始触摸虚拟摇杆\"); &#125; void OnJoyStickMove (Vector2 vec) &#123; Debug.Log(\"正在移动虚拟摇杆\"); //设置角色朝向 Quaternion q = Quaternion.LookRotation (new Vector3 (vec.x, 0, vec.y)); transform.rotation = q; //移动角色并播放奔跑动画 transform.Translate(Vector3.forward * 75f * Time.deltaTime); animation.CrossFade(\"Run\"); &#125; void OnJoyStickEnd () &#123; Debug.Log(\"触摸移动摇杆结束\"); //播放默认待机动画 animation.CrossFade(\"idle\"); &#125; void OnGUI() &#123; GUI.Label(new Rect(30,30,200,30),\"3D模式下的虚拟摇杆测试\"); &#125;&#125; &emsp;&emsp;最终程序的运行效果如下图所示，我们编写的这个虚拟摇杆可以在手机上完美的运行，欢饮大家来一起测试和吐槽！ 2D模式演示 3D模式演示 &emsp;&emsp;好了，今天的内容就是这样啦！欢迎大家继续关注我的博客，希望大家喜欢！","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"uGUI","slug":"uGUI","permalink":"https://qinyuanpei.github.io/tags/uGUI/"},{"name":"虚拟摇杆","slug":"虚拟摇杆","permalink":"https://qinyuanpei.github.io/tags/%E8%99%9A%E6%8B%9F%E6%91%87%E6%9D%86/"}]},{"title":"Unity3D游戏开发之Unity3D场景编辑器扩展开发","date":"2015-10-13T12:59:01.000Z","path":"posts/3019914405/","text":"&emsp;&emsp;今天博主想和大家分享的是Unity3D场景编辑器的扩展开发，相关的话题我们在Unity3D游戏开发之编辑器扩展程序开发实例这篇文章中我们已经有所涉及，今天博主想特别针对场景编辑器的扩展开发来进行下深入研究。对于一个场景编辑器来说，它主要的作用是3D场景视图中实时显示、输入反馈和相关信息的更新。在Unity3D中提供了Editor、EditorWindow、GUILayout、EditorGUILayout、GUIUtility、EditorGUIUtility、Handles、Event等来完成这些工作。其中基于EditorWindow的这种扩展方式我们已经研究过了，这种扩展方式拥有自己的独立窗口使用OnGUI方法进行界面的绘制。今天我们想说的是基于Editor的这种扩展方式，这种扩展方式只能针对脚本，从脚本内容在Inspector里的显示布局到变量在Scene视图的可视化编辑，它都可以完全胜任。这里特别想说的是Handles和Event这两个类，这两个类分别提供了3D显示和输入反馈的功能，我们下面就来学习如何使用这些类来扩展Unity3D的场景编辑器。 创建一个扩展的Transform组件&emsp;&emsp;Transform是Unity3D中一个基本的组件，下面我们来创建一个扩展的Transform组件，该组件可以对游戏体的坐标、旋转、缩放进行重置。首先，我们创建一个ExtendTransform的类，该类继承自Editor类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899using UnityEngine;using System.Collections;using UnityEditor;[CustomEditor(typeof(Transform),true)]public class ExtendTransform : Editor &#123; /// &lt;summary&gt; /// Position属性 /// &lt;/summary&gt; private SerializedProperty mPos; /// &lt;summary&gt; /// Scale属性 /// &lt;/summary&gt; private SerializedProperty mScale; void OnEnable() &#123; mPos = serializedObject.FindProperty(\"m_LocalPosition\"); mScale = serializedObject.FindProperty(\"m_LocalScale\") ; &#125; /// &lt;summary&gt; /// Inspector相关GUI函数 /// &lt;/summary&gt; public override void OnInspectorGUI() &#123; EditorGUIUtility.labelWidth = 15; //获取最新的可序列化对象 serializedObject.Update(); //绘制物体的坐标、旋转和缩放 DrawPosition(); DrawRotate(); DrawScale(); //更新可序列化对象的属性 serializedObject.ApplyModifiedProperties(); &#125; /// &lt;summary&gt; /// 绘制位置 /// &lt;/summary&gt; private void DrawPosition() &#123; GUILayout.BeginHorizontal(); &#123; bool Reset = GUILayout.Button(\"P\", GUILayout.Width(20f)); EditorGUILayout.LabelField(\"Position\"); EditorGUILayout.PropertyField(mPos.FindPropertyRelative(\"x\")); EditorGUILayout.PropertyField(mPos.FindPropertyRelative(\"y\")); EditorGUILayout.PropertyField(mPos.FindPropertyRelative(\"z\")); if(Reset) mPos.vector3Value = Vector3.zero; &#125; GUILayout.EndHorizontal(); &#125; /// &lt;summary&gt; /// 绘制旋转 /// &lt;/summary&gt; private void DrawRotate() &#123; Vector3 eulerAngles = ((Transform)target).eulerAngles; GUILayout.BeginHorizontal(); &#123; bool Reset = GUILayout.Button(\"R\", GUILayout.Width(20f)); EditorGUILayout.LabelField(\"Rotation\", GUILayout.Width(70f)); EditorGUILayout.LabelField(\"X\", GUILayout.Width(13f)); float angleX=EditorGUILayout.FloatField(eulerAngles.x, GUILayout.Width(56f)); EditorGUILayout.LabelField(\"Y\", GUILayout.Width(13f)); float angleY = EditorGUILayout.FloatField(eulerAngles.y, GUILayout.Width(56f)); EditorGUILayout.LabelField(\"Z\", GUILayout.Width(13f)); float angleZ = EditorGUILayout.FloatField(eulerAngles.z, GUILayout.Width(56f)); ((Transform)target).eulerAngles = new Vector3(angleX, angleY, angleZ); if(Reset) &#123; eulerAngles = Vector3.zero; ((Transform)target).eulerAngles = Vector3.zero; &#125; &#125; GUILayout.EndHorizontal(); &#125; /// &lt;summary&gt; /// 绘制缩放 /// &lt;/summary&gt; private void DrawScale() &#123; GUILayout.BeginHorizontal(); &#123; bool Reset = GUILayout.Button(\"S\", GUILayout.Width(20f)); EditorGUILayout.LabelField(\"Scale\"); EditorGUILayout.PropertyField(mScale.FindPropertyRelative(\"x\")); EditorGUILayout.PropertyField(mScale.FindPropertyRelative(\"y\")); EditorGUILayout.PropertyField(mScale.FindPropertyRelative(\"z\")); if (Reset) mScale.vector3Value = Vector3.one; &#125; GUILayout.EndHorizontal(); &#125;&#125; &emsp;&emsp;首先我们注意到ExtendTransform继承自Editor，这是我们开发这类编辑器扩展的第一个前提。其次我们注意到在该类的声明位置有这样一个标记: 1[CustomEditor(typeof(Transform),true)] 该标记表明我们这个编辑器扩展是针对Transform组件进行扩展的，即当物体存在Tranform组件时会在编辑器中响应这个编辑器扩展程序。我们在这个编辑器扩展程序中都做了哪些事情呢？第一，我们实现了OnEnable()方法，该方法相当于一个初始化的方法；第二，我们重写了OnOnInspectorGUI()方法，该方法将覆盖默认的Inspector窗口外观。 扩展后的Transform 好了，现在我们点击场景中默认的相机MainCamera可以发现默认的Transform会变成具有重置功能的扩展型Transform。下面我们来介绍这段程序中较为重要的核心内容： Unity3D中的可序列化对象&emsp;&emsp;通常我们所说的序列化是指将一个对象的实例转化为字符串的过程，而在Unity3D中可序列化对象更像是一种智能对象，它可以将脚本中的属性显示在Inspector窗口中，当场景发生变化时这些属性值将自动被更新。例如我们可以定义这样一个简单的脚本： 1234567891011121314151617181920212223/// &lt;summary&gt;/// 定义一个可序列化类/// &lt;/summary&gt;[System.Serializable]public class ExampleClass &#123; [SerializeField] public int ID; [SerializeField] public string Name; [SerializeField] public Vector3[] Points; private bool editable = false;&#125;/// &lt;summary&gt;/// 定义一个简单的脚本/// &lt;/summary&gt;public class ExampleScript : MonoBehaviour &#123; public ExampleClass Example;&#125; 此时如果我们给场景中的某个物体附加上该脚本，则我们在Inspector窗口可以看到Example类的实例Example将被序列化到编辑器面板中，同时我们可以注意到私有的editable字段并没有被序列化出来，这是因为在Unity3D中，公有的字段默认支持序列化，私有的字段除非显式的增加[SerializeField]标记，否则都不会被序列化，这一点希望大家注意。好了，那么我们为什么要讲这部分内容呢，这是因为它和我们下面要讲的Editor基类中的属性和方法有着十分密切的关联。 Unity3D中的可序列化对象 Editor基类中的属性和方法&emsp;&emsp;Editor基类中有两个重要的属性，即target和serializedObject。target表示当前受检查的物体我们可以通过它获得当前物体；而serializedObject表示当前物体的全部可序列化信息，我们可以通过它获得指定的序列化字段及其数值。Editor基类中重要的方法有： OnInspectorGUI():该方法可对Inspector窗口面板进行扩展或者重写，比如我们可以通过DrawDefaultInspector()方法来绘制默认Inspector窗口面板然后在此基础上使用GUILayout或者EditorGUILayout等辅助类进行自定义的绘制。在这个示例中我们对整个面板进行了重写，值得注意的是为了让Inspector窗口面板正常工作，如果要重绘该窗口请确保对该方法进行覆盖。 OnSceneGUI():该方法可对场景视图进行绘制，在实际的使用中可以配合Handles类和Event类来进行网格编辑、地形绘制或高级Gizmos等方面的工作。在本文的第二个示例中，我们将利用这一特性来编写一个用于NPC寻路的路径节点编辑工具。 对第一个示例的总结&emsp;&emsp;在第一个示例中，可以注意到我们使用了FindProperty()方法来获取一个可序列化物体的属性(字段)，然后我们在EditorGUILayout.PropertyField()方法来绘制了各种属性框，这种方式可以实现属性的自动更新。注意到DrawRotate()方法与DrawPositin()及DrawScale()方法在实现方式上略有不同，这是因为Transform组件的Rotation属性是一个Quaternion即四元数的结构，四元数是利用x、y、z、w四个数值来表示物体的三维旋转，这不仅和我们平时习惯的欧拉角相违背而且更为关键的是貌似目前我还没有发现可以直接绘制四元数的API接口，如果有的话希望大家可以告诉我，所以这里我们用了变通的一种方法，即通过Transform的eulerAngles来实现，但是这种方式绘制的属性框大小和EditorGUILayout.PropertyField()方法绘制的属性框大小并不一致，同时我们需要自己去完成属性值的更新。好了，暂时先总结到这里更多的细节大家可以通过代码来了解。 创建一个NPC寻路节点编辑工具&emsp;&emsp;创建这样一个工具的想法来自我实际的工作体验，当我Unity3D中使用的Tween动画库从iTween变成Dotween后，我在使用Dotween的过程中一直没有找到类似于iTweenPath的路径节点编辑工具。作为一个有节操的程序员，去寻找破解版的Dotween Pro这样的事情我是能不干就不干啦，因为我觉得自己有能力做这样一个类似的小工具，所以在一边准备这篇文章的时候，一边开始设计这样一个路径节点编辑工具。相信经过第一个示例的铺垫和相关知识的储备，大家都了解了这些内容，所以这里直接给出代码啦，因为实在是没有多少内容，嘿嘿： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152using UnityEngine;using System.Collections;using UnityEditor;[CustomEditor(typeof(PatrolNPC))]public class PatrolPathEditor : Editor &#123; /// &lt;summary&gt; /// 寻路节点 /// &lt;/summary&gt; private Vector3[] paths; /// &lt;summary&gt; /// 显示寻路信息的GUI /// &lt;/summary&gt; private GUIStyle style=new GUIStyle(); /// &lt;summary&gt; /// 初始化 /// &lt;/summary&gt; void OnEnable() &#123; //获取当前NPC的寻路路径 paths = ((PatrolNPC)target).Paths; //初始化GUIStyle style.fontStyle = FontStyle.Normal; style.fontSize = 15; &#125; void OnSceneGUI() &#123; //获取当前NPC的寻路路径 paths = ((PatrolNPC)serializedObject.targetObject).Paths; //设置节点的颜色为红色 Handles.color = Color.red; if(paths.Length &lt;= 0 || paths.Length&lt;2) return; //在场景中绘制每一个寻路节点 //可以在场景中编辑节点并将更新至对应的NPC for (int i = 0; i &lt; paths.Length; i++) &#123; paths[i] = Handles.PositionHandle(paths[i], Quaternion.identity); Handles.SphereCap(i, paths[i], Quaternion.identity, 0.25f); Handles.Label(paths[i], \"PathPoint\" + i, style); if (i &lt; paths.Length &amp;&amp; i + 1 &lt; paths.Length) &#123; Handles.DrawLine(paths[i], paths[i + 1]); &#125; &#125; &#125; &#125; &emsp;&emsp;这里的PatrolNPC是一个可寻路NPC类，基本和这篇文章的内容无关，大家只要知道那个Paths字段是一个Vector3[]就好啦，这样当我们在场景中编辑这些路径节点的时候，对应NPC的路径节点信息就会同步发生更新，这样我们就可以随心所欲地规划NPC的移动路径啦，哈哈。好了，今天的内容就是这样啦，写完熬到这个点真心不容易啊，大家晚安，这是这个小工具在场景编辑器中的效果，嘻嘻，感觉还是蛮不错的吧，反正我是很喜欢就对啦！ 路径节点编辑工具演示","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"扩展","slug":"扩展","permalink":"https://qinyuanpei.github.io/tags/%E6%89%A9%E5%B1%95/"},{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"编辑器","slug":"编辑器","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"}]},{"title":"在Unity3D中加载外部图片的两种方法","date":"2015-10-08T15:03:01.000Z","path":"posts/821259985/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客。最近在做项目的过程中遇到这样的一个需求：玩家可以在游戏过程中进行实时存档，在存档过程中会保存当前游戏进度，同时会截取当前游戏画面并加载到游戏存档界面中。当下一次进入游戏的时候，将读取本地存档图片并加载到游戏界面中。这在单机游戏中是特别常见的一种功能，这里主要有两个关键点。首先是截取游戏画面，这个问题大家可以在《Unity3D游戏开发之截屏保存精彩瞬间》这篇文章中找到答案。其次是从本地加载图片，因为这里要保证可读可写，因此传统的Resources.Load()方式和AssetBundle方式均无法实现这样的功能。那么怎样从外部加载图片到游戏中，这就是我们今天要讨论的内容啦。好了，这里介绍两种方法来实现这一目的。 喜闻乐见的WWW方式&emsp;&emsp;喜闻乐见的WWW方式之所以喜闻乐见，这是因为这是我们最为熟悉的一种，我们都知道通过WWW可以从网络上加载文本、图片、音频等形式的内容，那么通过WWW能否加载本地外部（相对于应用程序）资源呢？答案是肯定的，这是因为WWW可以支持http和file两种协议。我们通常接触到的WWW默认都是指http协议，现在我们来说说file协议，该协议可以用来访问本地资源（绝对路径）。例如我们希望加载文件D:\\TestFile\\pic001.png这个文件，则此时对应的C#脚本为： 123456789//请求WWWWWW www = new WWW(\"file://D:\\\\TestFile\\\\pic001.png);yield return www; if(www != null &amp;&amp; string.IsNullOrEmpty(www.error))&#123; //获取Texture Texture texture=www.texture; //更多操作... &#125; 注意到这里出现了yield return结构，这表示这里使用到了协程，因此我们需要付出的代价就是需要在项目中使用StartCoroutine等协程相关的方法来调用这些协程。虽然在Unity3D中使用协程是件简单的事情，可是如果我们随随便便地使用协程而不注意去维护这些协程，那么这些让我们引以为傲的简单代码可能就会变成我们痛苦不堪的无尽深渊。 亘古不变的传统IO方式&emsp;&emsp;好了，下面我们隆重推出亘古不变的传统IO方式，这种方式相信大家都没有接触过，所以这里将这种方法和大家分享。既然是传统的IO方式，那么无非就是各种IO流的处理啦。好，我们一起来看下面这段代码： 1234567891011121314151617//创建文件读取流FileStream fileStream = new FileStream(screen, FileMode.Open, FileAccess.Read);fileStream.Seek(0, SeekOrigin.Begin);//创建文件长度缓冲区byte[] bytes = new byte[fileStream.Length]; //读取文件fileStream.Read(bytes, 0, (int)fileStream.Length);//释放文件读取流fileStream.Close();fileStream.Dispose();fileStream = null;//创建Textureint width=800;int height=640;Texture2D texture = new Texture2D(width, height);texture.LoadImage(bytes); 可以看到在使用这种方式读取图片文件的时候主要是将图片文件转化为byte[]数组，再利用Texture2D的LoadImage方法转化为Unity3D中的Texture2D。这种方法需要在创建过程中传入图片的大小，在这里我们创建了一张800X640的图片。经过博主的研究发现，这种方式加载外部图片相对于使用WWW加载外部图片效率更高，所以如果大家遇到类似的需求，博主个人推荐大家使用这种方式进行加载。 &emsp;&emsp;到目前为止我们解决了如何从外部加载图片到Unity3D中，现在我们回到最开始的问题，我们从外部读取到这些图片以后需要将它们加载到游戏界面中。比如当我们使用UGUI的时候，UGUI中的Image控件需要一个Sprite来作为它的填充内容，那么此时我们就需要将Texture转化为Sprite.号了，下面我们给出一个简单的例子： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788using UnityEngine;using System.Collections;using UnityEngine.UI;using System.IO;public class TestLoading : MonoBehaviour &#123; /// &lt;summary&gt; /// Image控件 /// &lt;/summary&gt; private Image image; void Start () &#123; image = this.transform.Find(\"Image\").GetComponent&lt;Image&gt;(); //为不同的按钮绑定不同的事件 this.transform.Find(\"LoadByWWW\").GetComponent&lt;Button&gt;().onClick.AddListener ( delegate()&#123;LoadByWWW();&#125; ); this.transform.Find(\"LoadByIO\").GetComponent&lt;Button&gt;().onClick.AddListener ( delegate()&#123;LoadByIO();&#125; ); &#125; /// &lt;summary&gt; /// 以IO方式进行加载 /// &lt;/summary&gt; private void LoadByIO() &#123; double startTime = (double)Time.time; //创建文件读取流 FileStream fileStream = new FileStream(\"D:\\\\test.jpg\", FileMode.Open, FileAccess.Read); fileStream.Seek(0, SeekOrigin.Begin); //创建文件长度缓冲区 byte[] bytes = new byte[fileStream.Length]; //读取文件 fileStream.Read(bytes, 0, (int)fileStream.Length); //释放文件读取流 fileStream.Close(); fileStream.Dispose(); fileStream = null; //创建Texture int width = 300; int height = 372; Texture2D texture = new Texture2D(width, height); texture.LoadImage(bytes); //创建Sprite Sprite sprite = Sprite.Create(texture, new Rect(0, 0, texture.width, texture.height), new Vector2(0.5f, 0.5f)); image.sprite = sprite; startTime=(double)Time.time-startTime; Debug.Log(\"IO加载用时:\" + startTime); &#125; /// &lt;summary&gt; /// 以WWW方式进行加载 /// &lt;/summary&gt; private void LoadByWWW() &#123; StartCoroutine(Load()); &#125; IEnumerator Load() &#123; double startTime = (double)Time.time; //请求WWW WWW www = new WWW(\"file://D:\\\\test.jpg\"); yield return www; if(www != null &amp;&amp; string.IsNullOrEmpty(www.error)) &#123; //获取Texture Texture2D texture=www.texture; //创建Sprite Sprite sprite = Sprite.Create(texture, new Rect(0, 0, texture.width, texture.height), new Vector2(0.5f, 0.5f)); image.sprite = sprite; startTime = (double)Time.time - startTime; Debug.Log(\"WWW加载用时:\" + startTime); &#125; &#125;&#125; &emsp;&emsp;现在我们运行程序可以发现两种方式均可以让图片加载进来，为了对比两种方式在执行效率上的高低，我们在脚本中加入了相关代码，通过对比可以发现使用IO方式加载一张227k的图片需要的时间为0s，而使用WWW方式加载需要0.0185s，因此传统的IO方式具有更高的效率，建议大家在遇到这类问题时尽可能地使用这种方式。好了，今天的内容就是这样啦，欢迎大家在我的博客中留言、欢迎大家关注和支持我的博客，谢谢大家！ 2016年6月12日更新：&emsp;&emsp;针对有朋友指出WWW加载和传统IO加载方式在效率上的差异，我们这里重新做一个效率测试。","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"uGUI","slug":"uGUI","permalink":"https://qinyuanpei.github.io/tags/uGUI/"}]},{"title":"做最初的自己","date":"2015-09-30T10:19:26.000Z","path":"posts/786195243/","text":"&emsp;&emsp;在中秋节这样一个万家团圆的日子，我却再度因为工作的问题和家人发生争执。发生争执的原因简单到习以为常，家人喜欢稳定、安逸的生活，而我却喜欢有挑战、梦想的生活。我不知道梦想对一个二十三岁的人是不是一种奢侈品，我只知道当我住在狭小、拥挤的出租房里的时候，我想努力去拥有一个温暖的家，我不想靠着一张嘴去哗众取宠，我不想刻意地迎合和奉承这个世界，我只想靠我平凡而微薄的努力让我的生活一天天地温暖起来。从小我被告诉要做一个正直、善良的人，可是随着我慢慢地长大，在我的耳边总会听到“要去适应这个社会”这样的话，然而最讽刺的是这样的话常常出自同一人的口中。 &emsp;&emsp;虽然我知道当今中国的社会是一个人情社会、关系社会，可我就是不愿意把时间浪费在交际应酬这样的事情上，因为我知道人的这一生的时间是非常宝贵的，从小我就看到身边熟悉的人因为各种各样的原因突然离开这个世界，我们每一个人都会面临死亡，所以当我懒得理会这些无聊的事情的时候，我更希望在我喜欢或者关注的事情上投入精力。每次当家人说我应该应该怎么样的时候，我常常假设自己如果按照这样的规划来度过这一生，那么当我衰老直至死亡的那一刻我心里又会想些什么？我讨厌政治和宗教，因为这是由人类自己为人类制造的精神枷锁，在它们涉足的领域常常伴随各种无可争辩的假象或者谎言，这恰恰是我这样一个正直的本性中极度厌恶的部分。长辈们或多或少地喜欢给我这样的年轻人冠以“愤青”这样的荣誉称号，可我做错了什么呢？我无非就是像《皇帝的新装》里的那个小孩，突然说出了一个大家都习以为常的秘密而已，我们从小到大的成长过程其实就是小孩从见到了就要说出来，变成现在见到了习以为常、看在眼里说在心里。人们常常把这种转变当作成熟，可是事实上人们只是变得更加麻木而已。此时此刻我假装麻木想要摆脱这些掩耳盗铃的秘密，长辈们却再度摆出“社会就是这样，你必须要去适应”这样的架势，大概是嫌弃我假装麻木难以入戏需要变得更加虚伪。 &emsp;&emsp;我天生就是一个不会表演的人，从小时候排练舞蹈学习动作到此时此刻需要我去逢场作戏的各种场合，我不会说除了让人高兴还是高兴的话，我不会让喜怒哀乐像变脸、像翻书一样快。长辈们一直希望我变成一个圆滑世故、胸有城府的人，可我听惯了许嵩的《城府》、《别咬我》、《秋千坠》对这些东西天生排斥，所以在长辈们的世界观里，我就变成了一个冥顽不灵、图样图森破的年轻人。长辈们固然是从自己的经验出发，想让作为年轻人的我走上一条平坦舒适的道路，可是这个世界早已在不知不觉中发生着天翻地覆的变化，长辈们的经验获取可以让你顺利通关人生这场游戏，然而缺少了自我探索的旅程未免显得平凡而无趣。我有幸在小学三年级的时候接触计算机，在初中的时候接触互联网，在高中的时候接触编程，然而在这短短的若干年间互联网行业风起云涌、起起伏伏却并非我们的父辈可以理解和掌握。我走进大学的时候社交网站(SNS)开始兴起，以Facebook、Twitter、人人网、新浪微博、腾讯微博等等为代表的社会化平台迅速地占领了整个互联网行业的制高点。或许和70后、80后相比，我们这一代人在这个变化剧烈的时代显得有点生不逢时，可是机遇和挑战总是并存的，当我们无法和前辈们一起成为时代的弄潮儿的时候，我们只有努力去追赶这个时代忙碌的脚步。短短大学四年，我感受到了互联网每天天翻地覆的变化，从SNS到云计算、移动互联网、大数据、物联网再到互联网金融、O2O，这个行业慢慢地渗透到我们的生活中来。曾经我的长辈认为如果依靠政治力量毁灭了百度，则我们完全可以借由政治力量重新创造出来一个百度，可是同样是由政治力量领导的人民网、同样是由政治力量推到台前的邓亚萍，人民网最终依然在这场搜索引擎大战中以失败告终。我们无法访问国外网站并非是我们拥有世界山最先进的互联网技术，而是我们依靠政治力量用流氓一样的手段在全球一体化的今天实施信息领域的闭关锁国。我一直认为互联网行业是政治干预较为稀疏的一个行业，所以在这个行业当中我不会遭遇那些让我厌恶的政治因素，虽然有人聚集的地方就会有政治产生，但是作为互联网基础要素之一的技术是一个相对纯粹的领域，它依靠最为简单的0和1构成了今天丰富多彩的世界，它讲道理、守规矩让我觉得这个领域简单而纯粹。长辈们不理解我为什么会对计算机有这样独特的情结，因为在普通人眼中它就是一个可以娱乐和办公的机器，然而在我眼中它像是我的一位朋友默默地支持着我去解决各种问题。从我高中的时候起我就认定这个行业将会成为我一辈子的一种寄托，我相信技术可以让我们这个世界变得更加美好，这是我永恒的信仰，所以我不会把政治和宗教当成我一生的信仰。 &emsp;&emsp;大学四年里它每天和我如影随形，让我去思考、去创造、去解决，我喜欢这样的一个过程。长辈们认为大学学习什么样的专业并不重要，因为当你从事实际的工作以后注定要去从头学习新的东西不是吗？可是这样的思路通常适用于那些对未来没有目标、随遇而安的人，显然我并不是这样的人，我一直都清楚地知道自己想要做什么，从始至终这个目标由大到小，但是从未有所改变。我的长辈们对互联网、对计算机技术基本都没有过深入的了解，他们从来不愿意去尝试这些新的东西，却习惯于去指责我做出了这样一个他们并不期望的选择。我是一名程序员，可是我从来没有觉得我的工作低人一等，我每天的付出和老师给学生授课、销售员给顾客售货、银行柜员给消费者办理业务、公务员为人民服务……并没有什么不同，我靠自己掌握的技能去解决工作中的问题，我靠自己掌握的知识去帮助更多的人，我并没有觉得我选择了一条错误的道路，难道在安逸中渐渐迷失了自我会让你从此与众不同？曾经和老师一起做艾依河的毕业设计，当时觉得对整个艾依河了如指掌，然而每天上下班从宝湖经过的时候却突然发现自己的渺小，我是一个普通人，我想做的事情就是努力让自己变得强大去拥有一个温暖的家，能够让因衰老而疲惫的心有个归宿，不至于在满是迷雾的现实中丢失本心，我就想一直这样简单地生活下去，做正直、正确的事情，做一个温暖、善良的人，做最初的自己。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"生活","slug":"生活","permalink":"https://qinyuanpei.github.io/tags/%E7%94%9F%E6%B4%BB/"},{"name":"梦想","slug":"梦想","permalink":"https://qinyuanpei.github.io/tags/%E6%A2%A6%E6%83%B3/"},{"name":"人生","slug":"人生","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%BA%E7%94%9F/"}]},{"title":"Unity3D游戏场景优化系列之批处理","date":"2015-09-07T10:59:13.000Z","path":"posts/927393529/","text":"&emsp;&emsp;各位朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。最近开始研究Unity3D游戏场景优化，每次提及游戏优化这个话题的时候，我的脑海中都会浮现出《仙剑奇侠传六》这个让四路泰坦都光荣陨落的神奇游戏，作为一个使用Unity3D引擎进行游戏开发的仙剑玩家，我曾经天真的以为，这款使用Unity3D引擎打造的仙剑二十周年献礼之作，会让我对《仙剑奇侠传》这个系列游戏的未来充满更多期待，然而当游戏真正呈现在我眼前的时候，我感受到了在历代仙剑游戏中从未有过的尴尬和失望，我尴尬的是Unity3D这样一个比较强大的游戏引擎硬生生地被北软玩成了这个鬼样子，我失望的是这部游戏除了剧情和跳跳乐以外并没有什么让人看到希望的东西。 仙剑奇侠传六 不到20帧的优化 &emsp;&emsp;我知道我这样说会有一堆仙剑玩家指责我说，仙剑本来就是玩剧情的嘛，所以只要剧情好其它的都可以原谅啦。然而我们每一个人都清楚《仙剑奇侠传》是一个RPG游戏，它不是每隔三年出一次新番的GAL动漫、不是每隔三年更新一次的言情小说、更不是每隔三年播放一次的偶像电影。两年前的今天我可以耐着性子玩通关《仙剑奇侠传五》，但是这一次我真的玩不下去了。当一个游戏因为优化问题而获得《仙剑奇侠传六：泰坦陨落》称号的时候，作为一个玩家我真的不想再为这个游戏洗白什么，虽然我曾经深爱过这个游戏。所以言归正传，作为一个程序员，我们还是来做点程序员该做的事情，那么我们今天说什么呢，我们来说说Unity3D里的批处理！ 一、什么是批处理？&emsp;&emsp;我们知道Unity3D在屏幕上绘制一个图形本质上调用OpneGL或者DirectX这样的API，因此在这个过程中会产生一定程度上的性能消耗。DrawCall是OpenGL中描述绘制次数的一个量，例如一个基本的OpenGL绘制流程是设置颜色-&gt;绘图方式-&gt;顶点坐标-&gt;绘制-&gt;结束，在绘制的过程中每帧都会重复这个过程，这就是一次DrawCall，所以当游戏中的绘制过程变得复杂的时候，就会带来DrawCall的急剧增加，进而带来游戏的性能问题，反映到游戏表现上就变成了优化问题。那么在Unity3D中采取了什么样的措施来降低DrawCall呢？这就是我们今天要说的批处理，换句话说Unity3D使用了批处理来达到降低DrawCall的目的，批处理希望通过对物体网格的重组来获得更高的绘制效率，试想以下如果将多个物体合并为一个物体，那么在绘制的时候只需要绘制一次就够了，因此从这个角度上来讲这样做肯定是可以降低DrawCall的，更深刻的一种理解是这里体现了一种资源循环调用的思想，接触过Android开发的朋友们一定知道ListView控件可以对其元素进行“缓存”从而提高效率，因为我们可以发现其实ListView是对列表项进行某种程度上的“复用”从而提高了效率，在Unity3D这里同样遵循了这个原理。在Unity3D中进行批处理的一个前提是相同材质的物体可以被合并，如果这些物体使用不同的材质，那么当我们把这些材质对应的纹理打成“图集”以后可以对其进行合并，并且在合并的时候应该是用Renderer.sharedMaterial 而非 Renderer.material以保证材质是可以共享的。关于DrawCall的相关细节大家从这里来了解,博主并未对图形学领域有过深入的研究，因此就不在这里班门弄斧了啊，哈哈！ 二、Unity3D中批处理的两种方式&emsp;&emsp;在Unity3D中有静态批处理和动态批处理两种方式，下面我们就来分别说说这两种不同的批处理方式！ 静态批处理&emsp;&emsp;静态批处理其实大家都是知道的。为什么这样说呢？因为我们在使用Unity3D的过程中无形中培养了这样一个习惯，那就是将场景中相对来说“静态”的物体都勾选Static选项，这在Unity3D中称为Static GameObjects，并且因为这一特性和Lightmapping、Navigation、Off-meshLinks、ReflectionProbe、Occluder and Occludee等内容均有着密切的联系，因此说静态批处理大家都是知道的其实一点都为过，和场景优化相关的内容博主会在后续的博客中涉及，希望大家能及时关注我的博客更新。静态批处理允许游戏引擎尽可能多的去降低绘制任意大小的物体所产生的DrawCall，它会占用更多的内存资源和更少的CPU资源，因为它需要额外的内存资源来存储合并后的几何结构，如果在静态批处理之前，如果有几个对象共享相同的几何结构，那么将为每个对象创建一个几何图形，无论是在编辑器还是在运行时。这看起来是个艰难的选择，你需要在内存性能和渲染性能间做出最为正确的选择。在内部，静态批处理是通过将静态对象转换为世界空间，并为它们构建一个大的顶点+索引缓冲区。然后，在同一批中，一系列的“便宜”画调用，一系列的“便宜”，几乎没有任何状态变化之间的。所以在技术上它并不保存“三维的调用”，但它可以节省它们之间的状态变化（这是昂贵的部分）。使用静态批处理非常简单啦，只要勾选物体的Static选项即可！ 动态批处理&emsp;&emsp;相对静态批处理而言，动态批处理的要求更为严格一些，它要求批处理的动态对象具有一定的顶点，所以动态批处理只适用于包含小于900个顶点属性的网格。如果你的着色器使用顶点位置，法线和单光，然后你可以批处理300个顶点的动态对象；而如果你的着色器使用顶点位置，法线，uv0，UV1和切线，那么只能处理180个顶点的动态对象。接下来最为重要的一点，如果动态对象使用的是不同的材质，那么即使进行了动态批处理从效率上来讲并不会有太大的提升。如果动态对象采用的是多维子材质，那么批处理是无效的。如果动态对象接收实时光影，同样批处理是无效的。下面展示的是一个将多个物体合并为一个物体的脚本示例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748[MenuItem(&quot;ModelTools&#x2F;将多个物体合并为一个物体&quot;)] static void CombineMeshs2() &#123; &#x2F;&#x2F;在编辑器下选中的所有物体 object[] objs&#x3D;Selection.gameObjects; if(objs.Length&lt;&#x3D;0) return; &#x2F;&#x2F;网格信息数组 MeshFilter[] meshFilters &#x3D;new MeshFilter[objs.Length]; &#x2F;&#x2F;渲染器数组 MeshRenderer[] meshRenderers &#x3D; new MeshRenderer[objs.Length]; &#x2F;&#x2F;合并实例数组 CombineInstance[] combines &#x3D; new CombineInstance[objs.Length]; &#x2F;&#x2F;材质数组 Material[] mats &#x3D; new Material[objs.Length]; for (int i &#x3D; 0; i &lt; objs.Length; i++) &#123; &#x2F;&#x2F;获取网格信息 meshFilters[i]&#x3D;((GameObject)objs[i]).GetComponent&lt;MeshFilter&gt;(); &#x2F;&#x2F;获取渲染器 meshRenderers[i]&#x3D;((GameObject)objs[i]).GetComponent&lt;MeshRenderer&gt;(); &#x2F;&#x2F;获取材质 mats[i] &#x3D; meshRenderers[i].sharedMaterial; &#x2F;&#x2F;合并实例 combines[i].mesh &#x3D; meshFilters[i].sharedMesh; combines[i].transform &#x3D; meshFilters[i].transform.localToWorldMatrix; &#125; &#x2F;&#x2F;创建新物体 GameObject go &#x3D; new GameObject(); go.name &#x3D; &quot;CombinedMesh_&quot; + ((GameObject)objs[0]).name; &#x2F;&#x2F;设置网格信息 MeshFilter filter &#x3D; go.transform.GetComponent&lt;MeshFilter&gt;(); if (filter &#x3D;&#x3D; null) filter &#x3D; go.AddComponent&lt;MeshFilter&gt;(); filter.sharedMesh &#x3D; new Mesh(); filter.sharedMesh.CombineMeshes(combines,false); &#x2F;&#x2F;设置渲染器 MeshRenderer render &#x3D; go.transform.GetComponent&lt;MeshRenderer&gt;(); if (render &#x3D;&#x3D; null) render &#x3D; go.AddComponent&lt;MeshRenderer&gt;(); &#x2F;&#x2F;设置材质 render.sharedMaterials &#x3D; mats; &#125; &emsp;&emsp;这段脚本的核心是CombineMeshes()方法，该方法有三个参数，第一个参数是合并实例的数组，第二个参数是是否对子物体的网格进行合并，第三个参数是是否共享材质，如果希望物体共享材质则第三个参数为true，否则为false。在我测试的过程中发现，如果选择了对子物体的网格进行合并，那么每个子物体都不能再使用单独的材质，默认会以第一个材质作为合并后物体的材质，下面演示的是合并前的多个物体和合并后的一个物体的对比： 合并前 合并后 三、批处理效率分析&emsp;&emsp;那么批处理对游戏效率提升究竟有怎样的作用呢？我们来看下面几组测试对比： &emsp;&emsp;1、三个不同的物体使用同一种材质，不做静态批处理，不做动态批处理：DrawCall为4、面数为584、顶点数为641 &emsp;&emsp;2、三个不同的物体使用同一种材质，只做静态批处理，不做动态批处理：DrawCall为2、面数为584、顶点数为641 &emsp;&emsp;3、三个不同的物体使用不同的材质，不做静态批处理，不做动态批处理：DrawCall为4、面数为584、顶点数为641 &emsp;&emsp;4、三个不同的物体使用不同的材质，只做静态批处理，不做动态批处理：DrawCall为4、面数为584、顶点数为641 &emsp;&emsp;5、三个不同的物体使用不同的材质，不做静态批处理，只做动态批处理：DrawCall为4、面数为584、顶点数为641 &emsp;&emsp;6、三个不同的物体使用不同的材质，做静态批处理，做动态批处理：DrawCall为4、面数为584、顶点数为641 &emsp;&emsp;7、三个不同的物体使用同一种材质，不做静态批处理，只做动态批处理：：DrawCall为4、面数为584、顶点数为641 &emsp;&emsp;大家可以注意到各组测试结果中，只有第二组的DrawCall降低，这说明只有当不同的物体使用同一种材质时通过批处理可以从一定程度上降低DrawCall，即我们在文章开始提到的尽可能地保证材质共享。昨天下午兴冲冲地将游戏场景里的某些物体进行了动态批处理，但是实际测试的过程中发现DrawCall非常地不稳定，但是在场景中的某些地方DrawCall却可以降得非常低，如果静态批处理和动态批处理都不能对场景产生较好的优化，那么Unity3D游戏场景的优化究竟要从哪里抓起呢？我觉得这是我们每一个人都该用心去探索的地方，毕竟游戏做出来首先要保证能让玩家流畅的玩下去吧，一味的强调引擎、强调画面，却时常忽略引擎使用者的主观能动性，希望把一切问题都交给引擎去解决，这样的思路是错误而落后的，仙剑六的问题完全是用不用心的问题，我常常看到有人在公开场合说仙剑以后要换虚幻三，其实按照北软现在这样的状态，给他们一个虚幻四也不过是然并卵。我在知乎上看到了号称15岁就开发次时代游戏的高中生妹子，做出个能称为DEMO的游戏就觉得自己可以搞引擎了，更有甚者随便用DirectX或者OpenGL封装若干函数就敢说自己会做游戏引擎了，呵呵，你确定你的游戏能在别人的电脑或者手机上运行起来吗？优化的重要性可见一斑。 四、小结&emsp;&emsp;好了，通过今天这篇文章，我们可以整理出以下观点：&emsp;&emsp;1、如果不同的物体间共享材质，则可以直接通过静态批处理降低DrawCall&emsp;&emsp;2、动态批处理并不能降低DrawCall、面数和顶点数（我不会告诉你我昨天傻呵呵地合并了好多场景中的模型，结果面数和顶点数并没有降下来，23333）&emsp;&emsp;3、不管是静态批处理还是动态批处理都会影响Culiing，这同样是涉及到场景优化的一个概念，好吧，为了让场景的DrawCall降下来我最近可能要研究好多涉及的优化的内容……&emsp;&emsp;那么今天的内容就是这样子了，希望对大家学习Unity3D有所帮助，欢迎大家和我交流这些问题来相互促进，毕竟这才是我写博客最初的目的嘛，哈哈！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"优化","slug":"优化","permalink":"https://qinyuanpei.github.io/tags/%E4%BC%98%E5%8C%96/"}]},{"title":"Unity3D游戏开发游戏读/存档在Unity3D中的实现","date":"2015-08-20T08:57:10.000Z","path":"posts/887585917/","text":"&emsp;&emsp;大家好，我是秦元培，欢迎大家关注我的博客。近期博客的更新频率基本直降到冰点，因为这段时间实在是忙得没有时间来写博客了。今天想和大家分享的内容是RPG游戏中游戏存档的实现，因为最近在做一个RPG游戏的项目，所以遇到这个问题就随时记录下来，在对知识进行总结的同时可以将这种思路或者想法分享给大家，这是一件快乐而幸运的事情。我讨厌写按部就班的技术教程，因为我觉得学习是一种自我的探索行为，如果一切都告诉你了，探索的过程便会变得没有意义了。 &emsp;&emsp;游戏存档是一种在单机游戏中特别常见的机制，这种机制是你在玩网络游戏的时候无法体验到的，你知道每次玩完一款单机游戏都会把游戏存档保存起来是一种怎样的感觉吗？它就像是一个征战沙场的将军将陪伴自己一生金戈铁马的宝剑静静地收入剑匣，然而每一次打开它的时候都会不由自主的热泪盈眶。人的本性其实就是游戏，我们每一天发生的故事何尝不是一个游戏？有时候让我们怀念的可能并不是游戏本身，而只是搁浅在时光里的那时的我们。好了，游戏存档是我们在游戏世界里雪泥鸿爪，它代表了我们曾经来到过这个世界。以RPG游戏为例，一个一般化的游戏存档应该囊括以下内容： 角色信息：指一切表征虚拟角色成长路线的信息，如生命值、魔法值、经验值等等。 道具信息：指一切表征虚拟道具数量或者作用的信息，如药品、道具、装备等等。 场景信息：指一切和游戏场景相关的信息，如场景名称、角色在当前场景中的位置坐标等等。 事件信息：指一切和游戏事件相关的信息，如主线任务、支线任务、触发性事件等等。 &emsp;&emsp;从以上信息划分的层次来看，我们可以发现在游戏存档中要储存的信息相对是比较复杂的，那么我们这里不得不说说Unity3D中的数据持久化方案PlayerPrefs。该方案采用的是一种键值型的数据存储方案，支持int、string、float三种基本数据类型，通过键名来获取相对应的数值，当值不存在时将返回一个默认值。这种数据存储方案本质上是将数据写入到一个Xml文件。这种方案如果用来存储简单的信息是没有问题的，可是如果用它来存储游戏存档这样负责的数据结构就显得力不从心了。一个更为重要的问题是在数据持久化的过程中我们希望得到是一个结构化的【游戏存档】实例，显然此时松散的PlayerPrefs是不能满足我们的要求的。因此我们想到了将游戏数据序列化的思路，常见的数据序列化思路主要有Xml和JSON两种形式，在使用Xml的数据序列化方案的时候通常有两种思路，即手动建立数据实体和数据字符间的对应关系和基于XmlSerializer的数据序列化。其中基于XmlSerializer的数据序列化是利用了[Serializable]这样的语法特性来帮助.NET完成数据实体和数据字符间的对应关系，两种思路本质上一样的。可是我们知道Xml的优点是可读性强，缺点是冗余信息多，因此在权衡了两种方案的利弊后，我决定采用JSON来作为数据序列化的方案，而且JSON在数据实体和数据字符间的对应关系上有着天然的优势，JSON所做的事情不就是将数据实体转化为字符串和从一个字符串中解析出数据实体吗？所以整个方案基本一气呵成。好了，下面我们来看具体的代码实现过程吧！ ##一、JSON的序列化和反序列化&emsp;&emsp;这里我使用的是Newtonsoft.Json这个类库，相信大家都是知道的了！因此，序列化和反序列化特别简单。 1234567891011121314151617181920212223242526272829/// &lt;summary&gt; /// 将一个对象序列化为字符串 /// &lt;/summary&gt; /// &lt;returns&gt;The object.&lt;/returns&gt; /// &lt;param name=\"pObject\"&gt;对象&lt;/param&gt; /// &lt;param name=\"pType\"&gt;对象类型&lt;/param&gt; private static string SerializeObject(object pObject) &#123; //序列化后的字符串 string serializedString = string.Empty; //使用Json.Net进行序列化 serializedString = JsonConvert.SerializeObject(pObject); return serializedString; &#125; /// &lt;summary&gt; /// 将一个字符串反序列化为对象 /// &lt;/summary&gt; /// &lt;returns&gt;The object.&lt;/returns&gt; /// &lt;param name=\"pString\"&gt;字符串&lt;/param&gt; /// &lt;param name=\"pType\"&gt;对象类型&lt;/param&gt; private static object DeserializeObject(string pString,Type pType) &#123; //反序列化后的对象 object deserializedObject = null; //使用Json.Net进行反序列化 deserializedObject=JsonConvert.DeserializeObject(pString,pType); return deserializedObject; &#125; ##二、Rijandel加密/解密算法&emsp;&emsp;因为我们这里要做的是一个游戏存档的方案设计，因为考虑到存档数据的安全性，我们可以考虑采用相关的加密/解密算法来实现对序列化后的明文数据进行加密，这样可以从一定程度上保证游戏存档数据的安全性。因为博主并没有深入地研究过加密/解密方面的内容，所以这里仅仅提供一个从MSDN上获取的Rijandel算法，大家感兴趣的话可以自行去研究。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; Rijndael加密算法 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pString&quot;&gt;待加密的明文&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pKey&quot;&gt;密钥,长度可以为:64位(byte[8]),128位(byte[16]),192位(byte[24]),256位(byte[32])&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;iv&quot;&gt;iv向量,长度为128（byte[16])&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;&lt;&#x2F;returns&gt; private static string RijndaelEncrypt(string pString, string pKey) &#123; &#x2F;&#x2F;密钥 byte[] keyArray &#x3D; UTF8Encoding.UTF8.GetBytes(pKey); &#x2F;&#x2F;待加密明文数组 byte[] toEncryptArray &#x3D; UTF8Encoding.UTF8.GetBytes(pString); &#x2F;&#x2F;Rijndael解密算法 RijndaelManaged rDel &#x3D; new RijndaelManaged(); rDel.Key &#x3D; keyArray; rDel.Mode &#x3D; CipherMode.ECB; rDel.Padding &#x3D; PaddingMode.PKCS7; ICryptoTransform cTransform &#x3D; rDel.CreateEncryptor(); &#x2F;&#x2F;返回加密后的密文 byte[] resultArray &#x3D; cTransform.TransformFinalBlock(toEncryptArray, 0, toEncryptArray.Length); return Convert.ToBase64String(resultArray, 0, resultArray.Length); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; ijndael解密算法 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pString&quot;&gt;待解密的密文&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pKey&quot;&gt;密钥,长度可以为:64位(byte[8]),128位(byte[16]),192位(byte[24]),256位(byte[32])&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;iv&quot;&gt;iv向量,长度为128（byte[16])&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;&lt;&#x2F;returns&gt; private static String RijndaelDecrypt(string pString, string pKey) &#123; &#x2F;&#x2F;解密密钥 byte[] keyArray &#x3D; UTF8Encoding.UTF8.GetBytes(pKey); &#x2F;&#x2F;待解密密文数组 byte[] toEncryptArray &#x3D; Convert.FromBase64String(pString); &#x2F;&#x2F;Rijndael解密算法 RijndaelManaged rDel &#x3D; new RijndaelManaged(); rDel.Key &#x3D; keyArray; rDel.Mode &#x3D; CipherMode.ECB; rDel.Padding &#x3D; PaddingMode.PKCS7; ICryptoTransform cTransform &#x3D; rDel.CreateDecryptor(); &#x2F;&#x2F;返回解密后的明文 byte[] resultArray &#x3D; cTransform.TransformFinalBlock(toEncryptArray, 0, toEncryptArray.Length); return UTF8Encoding.UTF8.GetString(resultArray); &#125; ##三、完整代码&emsp;&emsp;好了，下面给出完整代码，我们这里提供了两个公开的方法GetData()和SetData()以及IO相关的辅助方法，我们在实际使用的时候只需要关注这些方法就可以了！ 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159&#x2F;** * Unity3D数据持久化辅助类 * 作者:秦元培 * 时间:2015年8月14日 **&#x2F;using UnityEngine;using System.Collections;using System;using System.IO;using System.Text;using System.Security.Cryptography;using Newtonsoft.Json;public static class IOHelper&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 判断文件是否存在 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public static bool IsFileExists(string fileName) &#123; return File.Exists(fileName); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 判断文件夹是否存在 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public static bool IsDirectoryExists(string fileName) &#123; return Directory.Exists(fileName); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 创建一个文本文件 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;fileName&quot;&gt;文件路径&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;content&quot;&gt;文件内容&lt;&#x2F;param&gt; public static void CreateFile(string fileName,string content) &#123; StreamWriter streamWriter &#x3D; File.CreateText(fileName); streamWriter.Write(content); streamWriter.Close(); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 创建一个文件夹 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public static void CreateDirectory(string fileName) &#123; &#x2F;&#x2F;文件夹存在则返回 if(IsDirectoryExists (fileName)) return; Directory.CreateDirectory(fileName); &#125; public static void SetData(string fileName,object pObject) &#123; &#x2F;&#x2F;将对象序列化为字符串 string toSave &#x3D; SerializeObject(pObject); &#x2F;&#x2F;对字符串进行加密,32位加密密钥 toSave &#x3D; RijndaelEncrypt(toSave, &quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;); StreamWriter streamWriter &#x3D; File.CreateText(fileName); streamWriter.Write(toSave); streamWriter.Close(); &#125; public static object GetData(string fileName,Type pType) &#123; StreamReader streamReader &#x3D; File.OpenText(fileName); string data &#x3D; streamReader.ReadToEnd(); &#x2F;&#x2F;对数据进行解密，32位解密密钥 data &#x3D; RijndaelDecrypt(data, &quot;xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx&quot;); streamReader.Close(); return DeserializeObject(data,pType); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; Rijndael加密算法 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pString&quot;&gt;待加密的明文&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pKey&quot;&gt;密钥,长度可以为:64位(byte[8]),128位(byte[16]),192位(byte[24]),256位(byte[32])&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;iv&quot;&gt;iv向量,长度为128（byte[16])&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;&lt;&#x2F;returns&gt; private static string RijndaelEncrypt(string pString, string pKey) &#123; &#x2F;&#x2F;密钥 byte[] keyArray &#x3D; UTF8Encoding.UTF8.GetBytes(pKey); &#x2F;&#x2F;待加密明文数组 byte[] toEncryptArray &#x3D; UTF8Encoding.UTF8.GetBytes(pString); &#x2F;&#x2F;Rijndael解密算法 RijndaelManaged rDel &#x3D; new RijndaelManaged(); rDel.Key &#x3D; keyArray; rDel.Mode &#x3D; CipherMode.ECB; rDel.Padding &#x3D; PaddingMode.PKCS7; ICryptoTransform cTransform &#x3D; rDel.CreateEncryptor(); &#x2F;&#x2F;返回加密后的密文 byte[] resultArray &#x3D; cTransform.TransformFinalBlock(toEncryptArray, 0, toEncryptArray.Length); return Convert.ToBase64String(resultArray, 0, resultArray.Length); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; ijndael解密算法 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pString&quot;&gt;待解密的密文&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pKey&quot;&gt;密钥,长度可以为:64位(byte[8]),128位(byte[16]),192位(byte[24]),256位(byte[32])&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;iv&quot;&gt;iv向量,长度为128（byte[16])&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;&lt;&#x2F;returns&gt; private static String RijndaelDecrypt(string pString, string pKey) &#123; &#x2F;&#x2F;解密密钥 byte[] keyArray &#x3D; UTF8Encoding.UTF8.GetBytes(pKey); &#x2F;&#x2F;待解密密文数组 byte[] toEncryptArray &#x3D; Convert.FromBase64String(pString); &#x2F;&#x2F;Rijndael解密算法 RijndaelManaged rDel &#x3D; new RijndaelManaged(); rDel.Key &#x3D; keyArray; rDel.Mode &#x3D; CipherMode.ECB; rDel.Padding &#x3D; PaddingMode.PKCS7; ICryptoTransform cTransform &#x3D; rDel.CreateDecryptor(); &#x2F;&#x2F;返回解密后的明文 byte[] resultArray &#x3D; cTransform.TransformFinalBlock(toEncryptArray, 0, toEncryptArray.Length); return UTF8Encoding.UTF8.GetString(resultArray); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 将一个对象序列化为字符串 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;The object.&lt;&#x2F;returns&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pObject&quot;&gt;对象&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pType&quot;&gt;对象类型&lt;&#x2F;param&gt; private static string SerializeObject(object pObject) &#123; &#x2F;&#x2F;序列化后的字符串 string serializedString &#x3D; string.Empty; &#x2F;&#x2F;使用Json.Net进行序列化 serializedString &#x3D; JsonConvert.SerializeObject(pObject); return serializedString; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 将一个字符串反序列化为对象 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;returns&gt;The object.&lt;&#x2F;returns&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pString&quot;&gt;字符串&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;pType&quot;&gt;对象类型&lt;&#x2F;param&gt; private static object DeserializeObject(string pString,Type pType) &#123; &#x2F;&#x2F;反序列化后的对象 object deserializedObject &#x3D; null; &#x2F;&#x2F;使用Json.Net进行反序列化 deserializedObject&#x3D;JsonConvert.DeserializeObject(pString,pType); return deserializedObject; &#125;&#125; &emsp;&emsp;这里我们的密钥是直接写在代码中的，这样做其实是有风险的，因为一旦我们的项目被反编译，我们这里的密钥就变得很不安全了。这里有两种方法，一种是把密钥暴露给外部方法，即在读取数据和写入数据的时候使用同一个密钥即可，而密钥可以采取由机器MAC值生成的方法，这样每台机器上的密钥都是不同的可以防止数据被破解；其次可以采用DLL混淆的方法让反编译者无法看到代码中的内容，这样就无法获得正确的密钥从而无法获得存档里的内容了。##四、最终效果好了，最后我们来写一个简单的测试脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445using UnityEngine;using System.Collections;using System.Collections.Generic;public class TestSave : MonoBehaviour &#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 定义一个测试类 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public class TestClass &#123; public string Name &#x3D; &quot;张三&quot;; public float Age &#x3D; 23.0f; public int Sex &#x3D; 1; public List&lt;int&gt; Ints &#x3D; new List&lt;int&gt; () &#123; 1, 2, 3 &#125;; &#125; void Start () &#123; &#x2F;&#x2F;定义存档路径 string dirpath &#x3D; Application.persistentDataPath + &quot;&#x2F;Save&quot;; &#x2F;&#x2F;创建存档文件夹 IOHelper.CreateDirectory (dirpath); &#x2F;&#x2F;定义存档文件路径 string filename &#x3D; dirpath + &quot;&#x2F;GameData.sav&quot;; TestClass t &#x3D; new TestClass (); &#x2F;&#x2F;保存数据 IOHelper.SetData (filename,t); &#x2F;&#x2F;读取数据 TestClass t1 &#x3D; (TestClass)IOHelper.GetData(filename,typeof(TestClass)); Debug.Log(t1.Name); Debug.Log(t1.Age); Debug.Log(t1.Ints); &#125; &#125; &emsp;&emsp;脚本执行结果： p1 &emsp;&emsp;加密后游戏存档： p2 &emsp;&emsp;好了，这就是今天的内容了，希望大家能够喜欢，有什么问题可以给我留言，谢谢！&emsp;&emsp;感谢风宇冲Unity3D教程宝典之两步实现超实用的XML存档一文提供相关思路！ 喜欢我的博客请记住我的名字：秦元培，我的博客地址是：http://qinyuanpei.com转载请注明出处，本文作者：秦元培， 本文出处：http://blog.csdn.net/qinyuanpei/article/details/39717795","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"JSON","slug":"JSON","permalink":"https://qinyuanpei.github.io/tags/JSON/"},{"name":"加密","slug":"加密","permalink":"https://qinyuanpei.github.io/tags/%E5%8A%A0%E5%AF%86/"}]},{"title":"SDL游戏开发系列第二话：基本图形的绘制","date":"2015-07-27T08:48:59.000Z","path":"posts/3789971938/","text":"&emsp;&emsp;各位朋友，大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是：http://qinyuanpei.com。话题紧接上回，在上回我们讲到了SDL的下载、安装和配置并对SDL游戏有了初步的了解。我们知道游戏开发中最为基础的内容是图形的绘制，因此在我们学习SDL游戏开发的过程中我们同样要从最简单的图形绘制开始学习。在2D游戏开发中，精灵（Sprite）是一个基础而核心的内容，具体来讲精灵首先是一张2D图片，精灵的绘制从本质上是图片的绘制，所以这是一个基础的内容。因为精灵在2D游戏中承担着GameObject的重要角色，所以一个图形引擎对精灵的支持好坏会决定游戏设计的最终效果。今天这篇文章主要是通过使用SDL中的SDL_LoadBMP()、SDL_CreateTextureFromSurface()和SDL_RenderCopy()这三个方法来实现在SDL中基本图形的绘制，从整体上尚属较为简单的内容。可是从学习SDL游戏开发的角度来看，一切都值得我们深入地去研究。好了，这就开始吧！ 使用SDL_loadBMP加载位图&emsp;&emsp;从SDL_LoadBMP()这个方法的名称，我们就可以看出这是一个读取BMP位图的方法。BMP是Windows操作系统中最早的图形格式，这种图形格式的容量较大，经常出现在Win32 API中。好了，言归正传，我们下面来看看整个绘制过程： 1、首先我们使用SDL_LoadBMP()方法来加载一张BMP位图： 12//读取一张BMP位图SDL_Surface* m_pSurface=SDL_LoadBMP(\"background.bmp\"); 2、接下来我们使用SDL_CreateTextureFromSurface()方法将SDL_Surface类型转化为SDL_Texture类型 1234//获取SDL纹理SDL_Texture* m_pTexture=SDL_CreateTextureFromSurface(g_pRenderer,m_pSurface);//释放m_pBackgroundSurfaceSDL_FreeSurface(m_pSurface); 注意到在这里m_pSurface扮演了一个临时演员的角色。当我们获得了SDL纹理后，它的演员生涯便就此结束了，因此我们需要使用SDL_FreeSurface()方法来释放它的内存。 3、接下来是关键性的一个步骤，我们首先来关注SDL_RenderCopy()的方法定义: 1SDL_RenderCopy(SDL_Renderer * renderer,SDL_Texture * texture,const SDL_Rect * srcrect,const SDL_Rect * dstrect); 如你所见，该方法的第一个参数和第二个参数我们已经相当熟悉了，即SDL渲染器和SDL纹理。这里想说的是第三个参数srcrect和第四个参数dstrect，这两个参数都是SDL_Rect类型，表示一个矩形范围，它有四个参数，即矩形左上角横坐标、矩形左上角纵坐标、矩形宽度、矩形高度。那么该如何理解这两个参数呢？ SDL绘图中的精灵裁剪&emsp;&emsp;这里我是这样理解的：第一个参数srcrect表示一个裁剪范围，即我们希望绘制图形的一个范围。例如我们现在有一张大小为640*480的图片，当我们使用(0,0,640,480)这样一个矩形对图片进行裁剪时，我们将获得整张图片；当我们使用(320,240,320,240)这个矩形对图片进行裁剪的时，我们将获得整张图片右下角1/4的部分。依次类推。相反地，dstrect则更加类似于一个画布（Canvas）的概念，即我们可以在一个多大的矩形范围内去绘制这样一张图片。 &emsp;&emsp;在这里，我们可以联想到2D图形绘制中的SpriteSheet，即“雪碧图”这个概念。在游戏开发中我们常常会使用TexturePacker这样的工具来将零散的小图打包成一张大图，因为这样可以提高游戏运行的效率，该工具最终导出的文件由.plist文件和合成的大图两部分组成，其中的.plist文件中记录了每张小图的位置信息，因此将这个概念引申到这里来，你就会理解这里提到的精灵裁剪，即srcrect这个矩形的作用是选择“大图”中的“小图”，而dstrect这个矩形的作用是决定将选出的“小图”绘制在一个多大的范围内。 &emsp;&emsp;一个经典的例子是我们现在一个有一张1124x676的图片，我们希望将其绘制到一个800x640的窗口作为背景图片，那么我们的代码可以这样写： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/* 添加对SDL的引用 */#include&lt;SDL.h&gt;/* 声明SDL窗口 */SDL_Window *g_pWindow;/* 声明SDL渲染器 */SDL_Renderer *g_pRenderer;/* 声明程序入口函数main */int main(int agrc,char *args[])&#123; //初始化SDL int SDLInit=SDL_Init(SDL_INIT_EVERYTHING); if(SDLInit&gt;=0) &#123; //创建一个SDL窗口 g_pWindow=SDL_CreateWindow(\"SDL Game Development-02\", SDL_WINDOWPOS_CENTERED,SDL_WINDOWPOS_CENTERED, 800,640, SDL_WINDOW_SHOWN); if(g_pWindow!=0)&#123; //创建SDL渲染器 g_pRenderer=SDL_CreateRenderer(g_pWindow,-1,0); &#125; &#125; //设置背景色 SDL_SetRenderDrawColor(g_pRenderer,255,255,255,255); //渲染器清空 SDL_RenderClear(g_pRenderer); //读取一张BMP位图 SDL_Surface* m_pSurface=SDL_LoadBMP(\"background.bmp\"); //获取SDL纹理 SDL_Texture* m_pTexture=SDL_CreateTextureFromSurface(g_pRenderer,m_pSurface); //释放m_pBackgroundSurface SDL_FreeSurface(m_pSurface); //构造SDL矩形 SDL_Rect* m_pSrcRect=new SDL_Rect(); m_pSrcRect-&gt;x=0; m_pSrcRect-&gt;y=0; m_pSrcRect-&gt;w=1124; m_pSrcRect-&gt;h=676; SDL_Rect* m_pTargetRect=new SDL_Rect(); m_pTargetRect-&gt;x=0; m_pTargetRect-&gt;y=0; m_pTargetRect-&gt;w=800; m_pTargetRect-&gt;h=640; //绘制SDL纹理 SDL_RenderCopy(g_pRenderer,m_pTexture,m_pSrcRect,m_pTargetRect); //显示绘制结果 SDL_RenderPresent(g_pRenderer); //注意这里增加秒的延迟是为了看到渲染的结果 //在实际的开发中不应该出现这样的代码因为在运行期间会导致窗口的卡顿 //正确的做法是使用循环来处理这样一个渲染的过程 SDL_Delay(5000); //退出 SDL_Quit(); return 0;&#125; &emsp;&emsp;好了，现在运行这段代码，在运行这段代码前请确保完成了SDL的配置、在Debug目录中存放有一张名为background.bmp的位图文件以及SDL2.dll。如果你准确无误地完成以上注意事项，那么你将毫无意外地看到这样一个画面： SDL游戏开发 工程示例&emsp;&emsp;现在让我们为这个示例增加点有趣的东西，我们知道在游戏设计中一般背景图片的大小是和游戏设计的窗口大小保持一致的，因为这样能够避免图片拉伸的问题。假定我们目前使用的精灵图片素材都是单个精灵的素材，那么我们可以设计这样一个方法来更加自由地绘制图片： 123456789101112131415161718192021222324/* 实现绘制BMP位图的方法 */void DrawBMP(SDL_Renderer* renderer,const char* fileName,int positionX,int positionY,int textureWidth,int textureHeight)&#123; //读取一张BMP位图 SDL_Surface* m_pSurface=SDL_LoadBMP(fileName); //获取SDL纹理 SDL_Texture* m_pTexture=SDL_CreateTextureFromSurface(renderer,m_pSurface); //释放m_pBackgroundSurface SDL_FreeSurface(m_pSurface); //构造SDL矩形 SDL_Rect* m_pSrcRect=new SDL_Rect(); m_pSrcRect-&gt;x=0; m_pSrcRect-&gt;y=0; m_pSrcRect-&gt;w=textureWidth; m_pSrcRect-&gt;h=textureHeight; SDL_Rect* m_pTargetRect=new SDL_Rect(); m_pTargetRect-&gt;x=positionX; m_pTargetRect-&gt;y=positionY; m_pTargetRect-&gt;w=textureWidth; m_pTargetRect-&gt;h=textureHeight; //绘制SDL纹理 SDL_RenderCopy(renderer,m_pTexture,m_pSrcRect,m_pTargetRect); &emsp;&emsp;在认为背景图片大小和窗口大小一致的前提下，我们修改下代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/* 添加对SDL的引用 */#include&lt;SDL.h&gt;/* 声明SDL窗口 */SDL_Window *g_pWindow;/* 声明SDL渲染器 */SDL_Renderer *g_pRenderer;/* 声明相关方法 */void DrawBMP(SDL_Renderer* renderer,const char* fileName,int positionX,int positionY,int textureWidth,int textureHeight);/* 声明程序入口函数main */int main(int agrc,char *args[])&#123; //初始化SDL int SDLInit=SDL_Init(SDL_INIT_EVERYTHING); if(SDLInit&gt;=0) &#123; //创建一个SDL窗口 g_pWindow=SDL_CreateWindow(\"SDL Game Development-02\", SDL_WINDOWPOS_CENTERED,SDL_WINDOWPOS_CENTERED, 1124,676, SDL_WINDOW_SHOWN); if(g_pWindow!=0)&#123; //创建SDL渲染器 g_pRenderer=SDL_CreateRenderer(g_pWindow,-1,0); &#125; &#125; //设置背景色 SDL_SetRenderDrawColor(g_pRenderer,255,255,255,255); //渲染器清空 SDL_RenderClear(g_pRenderer); //在绘制背景图片时因为我们已通过画图软件获得了该图片的大小为1124*676 //并且保证图片的大小和窗口大小一致因此我们可以直接构造一个(0,0,1024,676)的矩形来绘制 DrawBMP(g_pRenderer,\"background.bmp\",0,0,1124,676); //接下来我们在窗口中心绘制一个大小为161*400的美少女 DrawBMP(g_pRenderer,\"girl.bmp\",1124/2-161/2,676/2-400/2,161,400); //显示绘制结果 SDL_RenderPresent(g_pRenderer); SDL_Delay(10000); //退出 SDL_Quit(); return 0;&#125;/* 实现绘制BMP位图的方法 */void DrawBMP(SDL_Renderer* renderer,const char* fileName,int positionX,int positionY,int textureWidth,int textureHeight)&#123; //读取一张BMP位图 SDL_Surface* m_pSurface=SDL_LoadBMP(fileName); //获取SDL纹理 SDL_Texture* m_pTexture=SDL_CreateTextureFromSurface(renderer,m_pSurface); //释放m_pBackgroundSurface SDL_FreeSurface(m_pSurface); //构造SDL矩形 SDL_Rect* m_pSrcRect=new SDL_Rect(); m_pSrcRect-&gt;x=0; m_pSrcRect-&gt;y=0; m_pSrcRect-&gt;w=textureWidth; m_pSrcRect-&gt;h=textureHeight; SDL_Rect* m_pTargetRect=new SDL_Rect(); m_pTargetRect-&gt;x=positionX; m_pTargetRect-&gt;y=positionY; m_pTargetRect-&gt;w=textureWidth; m_pTargetRect-&gt;h=textureHeight; //绘制SDL纹理 SDL_RenderCopy(renderer,m_pTexture,m_pSrcRect,m_pTargetRect);&#125; SDL游戏开发 &emsp;&emsp;现在我们再来运行程序，可以发现在背景图片上绘制了一个美少女，并且这个美少女处于窗口的中心。好了，通过今天的这部分内容我们可以实现在屏幕任意位置绘制图片，这里要注意一个前提，即图片表示的是单个精灵，在绘制过程中不存在裁切和缩放的问题。作为一个有节操的程序员，我们怎么能为了目前的这点成果而止步不前呢？注意到窗口标题上出现了未响应的字样，这是因为我们这里使用了SDL_Delay()这个方法的缘故，该方法会造成程序在运行过程中的卡顿。那么怎么解决这个问题呢？这里就需要涉及到SDL中的事件机制，可能这里大家会有点迷茫，可是我们暂时只需要用到SDL_PollEvent这个方法，这个方法可以帮助我们判断是否触发了某个事件，比如我们需要判断用户是否点击了窗口右上角的关闭按钮： 123456SDL_Event m_event;if(SDL_PollEvent(&amp;m_event))&#123; if(m_event.type==SDL_QUIT) SDL_Quit();&#125; &emsp;&emsp;考虑到游戏渲染是一个循环的过程，因此我们只需要在工程示例中增加事件处理的相关代码，就可以解决因为使用SDL_Delay方法而带来的卡顿问题。好了，今天的内容暂时就研究到这里，我们注意到这里的图片都是静态的缺乏某种交互感，而且窗口中心绘制的美少女的有白色背景的，如果我们希望这里透明该怎么做呢？欲知后事如何，且听下回分解，敬请期待SDL游戏开发系列第三话：说说SDL中的扩展库。","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://qinyuanpei.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"SDL","slug":"SDL","permalink":"https://qinyuanpei.github.io/tags/SDL/"},{"name":"图形","slug":"图形","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%BE%E5%BD%A2/"},{"name":"游戏引擎","slug":"游戏引擎","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E/"}]},{"title":"SDL游戏开发系列第一话：Hello SDL","date":"2015-07-25T15:19:01.000Z","path":"posts/183718218/","text":"&emsp;&emsp;各位读者朋友大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。从今天起博主将带领大家一起走进SDL游戏开发的世界，如果说此前的Unity3D游戏开发系列文章让大家感受到的是游戏引擎工具化开发的方便与快捷，那么这一次就让我们以SDL库为基础，通过了解游戏开发中的底层图形渲染、输入事件响应等内容来全面认识游戏引擎，博主为SDL游戏开发系列文章建立了专栏，大家可以通过这里获取所有的系列文章，希望大家能够喜欢！好了，作为SDL游戏开发系列的第一篇文章，按照技术性文章写作的国际惯例这将是一篇介绍SDL入门内容的文章，因此这篇文章叫做：Hello SDL。 什么是SDL&emsp;&emsp;SDL（Simple DirectMedia Layer）是一套开放源代码的跨平台多媒体开发库，使用C语言写成。SDL提供了数种控制图像、声音、输出入的函数，让开发者只要用相同或是相似的代码就可以开发出跨多个平台如Linux、Windows、Mac OS X等的应用软件。目前SDL可用于游戏、模拟器、媒体播放器等多媒体应用领域的开发，SDL最为著名的案例是曾赢得Linux组游戏开发大奖的游戏《文明：权利的召唤》。或许大家对这个游戏会感到陌生吧，可是如果我提到一个Linux下经典单机游戏《仙剑奇侠传》的开源实现SDLPal相信大家就没有不知道的了吧？这款经典的单机游戏所以能够移植到Linux平台下就是因为使用SDL。好了，在对SDL有了大概的认识后，我们来看看SDL有哪些值得我们去研究的优良特性吧！ SDL提供了从图像、视频、音频、事件、线程、计时器的API，功能特别强大。 SDL具有良好的跨平台性能，支持Windows、Linux及Android和IOS，是开发跨平台多媒体应用的神兵利器。 SDL内置了OpenGL相关函数，使SDL开发3D应用成为可能，因此SDL是一个同时支持2D和3D开发的强力工具。 通过使用SDL_image、SDL_ttf、SDL_mixer、SDL_net等外部扩展库，可以轻松实现JPG、PNG、TIFF图像的加载使用，TrueType字体的使用，MP3文件的使用、网络相关的使用等。 SDL支持C++、C#、Java、 Lisp、Lua、Objective C、Pascal、Perl、 PHP、Python、Ruby等近20种编程语言。 SDL是GNU LGPL 2开源协议下发布的开源软件，该协议允许用户将SDL以动态链接库的形式免费地用于商业游戏软件的开发。 SDL的下载、安装和配置&emsp;&emsp;SDL开发相关的资源都可以从http://www.libsdl.org/来获取。目前SDL存在1.2和2.0两个版本，从效率上来说SDL2.0支持硬件加速效率较SDL1.2有了较好的提升，从稳定性上来讲SDL2.0尚处于发展阶段，因此可能其中的Bug较SDL1.2可能会多些。博主这里选择的SDL2.0，下面是相关的下载链接： SDL源代码——下载 SDL二进制库——Win_x86、Win_x64、Mac SDL开发包——VC++、GCC、Mac &emsp;&emsp;博主选择的开发环境是Visual Studio2012，因此下载VC++的SDL开发包。我们将下载得到的SDL开发包解压到本地，可以发现SDL开发包中已经为我们准备好了相关的include文件夹和lib文件夹。其中include文件夹下存放的是SDL的各种头文件，lib文件夹下存放的是编译好的动态链接库（.dll）和依赖库（.lib），如果读者朋友有能力或是希望自行编译SDL源代码的，请先去编译源代码。这里我们为了节省时间，就直接使用编译好的文件了,请大家不要鄙视我啊，哈哈。好了，下面我们来以一个VC++项目为例来讲解SDL的配置： 1、使用Visual Studio创建一个空的VC++项目 2、右键单击项目【属性】打开项目属性页找到【配置属性】-&gt;【VC++目录】然后将包含目录和库目录分别定位到SDL开发包中的include目录和lib目（x86和x64视系统情况而定） 3、在【配置属性】-&gt;【链接器】-&gt;【输入】-&gt;【附加依赖项】中增加SDL2.lib和SDL2main.lib 4、将【配置属性】-&gt;【链接器】-&gt;【系统】-&gt;【子系统】设置为窗口 (/SUBSYSTEM:WINDOWS) 5、将SDL2.dll复制到项目的Debug目录中 SDL游戏开发的基本流程&emsp;&emsp;SDL游戏开发的一般流程是： 1、使用SDL_Init()方法对SDL进行初始化。其中该初始化方法的参数类型为int类型，可以从SDL_INIT_HAPTIC、SDL_INIT_AUDIO、SDL_INIT_VIDEO、SDL_INIT_TIMER、SDL_INIT_JOYSTICK、SDL_INIT_EVERYTHING、SDL_INIT_NOPARACHUTE七个类型中选择，分别表示力反馈子系统、音频子系统、视频子系统、计时器子系统、摇杆子系统、全部和忽略致命信号。 2、在SDL初始化成功后使用SDL_CreateWindow()方法创建一个SDL窗口（SDL_Window）。在这里我们可以设置窗口的名称、对齐方式、窗口宽度和窗口高度。 3、在SDL窗口创建成功后使用SDL_CreateRenderer()方法创建一个SDL渲染器（SDL_Renderer）。其中SDL渲染器有SDL_RENDERER_SOFTWARE、SDL_RENDERER_ACCELERATED、SDL_RENDERER_PRESENTVSYNC、SDL_RENDERER_TARGETTEXTURE四种类型分别表示软件渲染、硬件加速、屏幕同步刷新渲染和支持渲染纹理。 4、使用SDL_RenderClear()方法清空SDL渲染器、使用SDL_RenderPresent()方法将渲染的结果显示出来 工程示例&emsp;&emsp;下面以一个简单的示例来向大家演示SDL游戏开发的一般流程： 12345678910111213141516171819202122232425262728293031323334/* 添加对SDL的引用*/#include&lt;SDL.h&gt;/* 声明SDL_Window */SDL_Window *g_pWindow;/* 声明SDL_Renderer */SDL_Renderer *g_pRenderer;/* 定义入口函数main */int main(int argc,char *args[])&#123; /* SDL三部曲——1:初始化SDL */ int sdlInit=SDL_Init(SDL_INIT_EVERYTHING); if(sdlInit&gt;=0)&#123; /* 当SDL初始化完成后创建一个标题为\"SDL Game Development——01\" */ /* 窗口对齐方式为居中对齐，窗口大小为640*480的窗口 */ g_pWindow=SDL_CreateWindow(\"SDL Game Development——01\", SDL_WINDOWPOS_CENTERED,SDL_WINDOWPOS_CENTERED, 640,480,SDL_WINDOW_SHOWN); /* SDL三部曲——2:初始化SDL渲染 */ if(g_pWindow!=0)&#123; g_pRenderer=SDL_CreateRenderer(g_pWindow,-1,0); &#125; &#125; /* SDL三部曲——3:绘制窗口 */ SDL_SetRenderDrawColor(g_pRenderer,0,0,0,255); SDL_RenderClear(g_pRenderer); SDL_RenderPresent(g_pRenderer); SDL_Quit(); return 0;&#125; &emsp;&emsp;在以上代码中我们基本遵循了SDL游戏开发的一般流程，即首先对SDL进行初始化，当SDL初始化完成后，我们创建一个标题为”SDL学习示例1”,窗口对齐方式为居中对齐，窗口大小为640*480的窗口，然后创建了模式为软件渲染的SDL渲染器，并设置渲染器的背景色为黑色。作为第一个项目，它简单到纯粹，当我们运行项目，会发现一个黑色的窗口一闪而过，这是因为我们这里在渲染了一次后就使用SDL_Quit()方法退出了，第一篇文章并不会有太复杂的内容，因为它的意义在于让我们对SDL游戏开发有个基本的认识和了解。关于SDL绘制图片、文字以及处理渲染循环等问题我们放到后面的文章中去讲，这篇文章的内容就是这样啦，谢谢大家！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"教程","slug":"教程","permalink":"https://qinyuanpei.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"SDL","slug":"SDL","permalink":"https://qinyuanpei.github.io/tags/SDL/"},{"name":"图形","slug":"图形","permalink":"https://qinyuanpei.github.io/tags/%E5%9B%BE%E5%BD%A2/"},{"name":"引擎","slug":"引擎","permalink":"https://qinyuanpei.github.io/tags/%E5%BC%95%E6%93%8E/"}]},{"title":"《仙剑奇侠传六》游戏感言","date":"2015-07-24T09:21:20.000Z","path":"posts/1118169753/","text":"&emsp;&emsp;目前游戏主线剧情进行到50%左右，在游戏尚未通关前，我对于这一部游戏的感觉始终是一种说不清道不明的情感，作为仙剑系列中唯一一部，从项目立项到宣传曝光再到游戏上市整个过程中持续关注的游戏，它可以说是承载了无数玩家的期待和祝福。和大部分玩家一样，在游戏曝光的第一时刻我们曾经热火朝天地讨论过各种各样可能的设定、曾经为这部游戏的系统玩家想过各种各样的尝试，然而当我面对这款游戏的时候，我的内心平静得像一潭死水。我今天23岁，刚刚从大学毕业的我本应该还没有被这个社会完全改变，可我不知道是我变了还是仙剑变了，这一次打开仙剑的时候，我总有一种恍若隔世的恍惚感。 引子&emsp;&emsp;曾经，仙剑一的游戏开始界面是简单到不能再简单的竹简、酒葫芦、剑，这些元素组合起来就仗剑江湖的行侠仗义、白云苍狗的醉梦人生和徐徐道来的温暖故事；曾经，仙剑三的《御剑江湖》伴随着云山雾绕的蜀山像一幅遗留在历史深处的卷轴缓缓地打开让人不由得心头一阵惊艳；曾经，仙三外传开头蜀山掌门大战狼妖，无数道剑气凝成的剑柱从天而降可以让你感受到那种仙家道法的玄妙和奇幻；曾经，仙剑四的《回梦游仙》在耳畔响起的时候卷云台像朵清新脱俗的莲花静静地盛开却在最后一刻明白这朵莲花是一切悲剧的开始；曾经，仙剑五前传的明州码头在夕阳和晚霞的交相辉映中，瑾轩和瑕妹依偎在一起看着落霞与孤鹜齐飞是永远的温馨画面…… &emsp;&emsp;可是仙剑六让我看到了什么呢？我看到了一片经过高斯模糊的绿油油的草地，没错！它真的是一片绿油油的草地，以至于当我打开这个游戏的时候我不得不在心里问自己：这真的是一个古风的仙侠/武侠游戏吗？在仙剑奇侠传六的宣传阶段，我在我的QQ群里、我的博客中不断向大家输送着这样一个概念：仙剑六是仙剑奇侠传系列二十年的突破之作，它一定不会让大家失望的，甚至我不遗余力地和游戏圈子里使用Unity3D引擎开发游戏的朋友们说，看，仙剑六是使用Unity3D引擎开发的，它的画面是历代游戏中最好的，这一次它终于要尝试即时战斗了。然而当我打开这个游戏的时候，我知道自己会被打脸，尤其是当我面对接受了我的这些观点的朋友的时候。 &emsp;&emsp;对于此次仙剑六游戏优化的问题，我不想做详细的说明，我更不想为北软洗白，当我们觉得仙剑奇侠传六之泰坦陨落变成一个笑话的时候，我觉得我们可以说说Unity3D这个游戏引擎了。我承认，Unity3D是个手机游戏引擎；我承认，Unity3D在画面表现上无法和UE、CE这些顶级的游戏引擎相提并论；我承认，现在国内各种各样的Unity3D教程满天飞；我承认，Unity3D入门快、成本低、跨平台性能强…….可是这些都不是你们不用心做仙剑六的理由好吗？在我看来，技术从来都没有优劣之分，真正让技术体现出差异的是使用工具的人。Unity3D本质上并非是一个差劲的游戏引擎，所以以引擎来论仙剑六的成败是不恰当而且不应该的，因为使用Unity3D开发的游戏目前已经相当的多了，比如《蒸汽之城》、《太空冒险》、《新仙剑OL》等等以及无数的手机游戏。可是能将这个引擎用到如此地步的恐怕只有仙剑六吧！目前Unity3D的授权方式是收入超过3万美元即18万人民币左右需要按照一定的比例向Unity3D官方支付费用，我不知道这次的优化问题是否会对仙剑六的销量产生影响，可是我觉得恐怕官方都会认为这款游戏存在影响Unity3D引擎声誉的问题吧！ 画面&emsp;&emsp;首先我们来说说游戏画面，我不知道有多少玩家可以在这款游戏中保证特效全开，总之在我的电脑上看起来整个画面有一种糊糊的感觉，远景看起来比较唯美壮丽，然而当我将镜头拉近的时候我觉得我还是不要计较仙剑奇侠传这个游戏的画面了吧！可是我真的不理解，作为仙剑奇侠传系列的好兄弟轩辕剑系列在使用Unity3D制作了两款游戏这样的背景下，北软为什么就不肯向DOMO小组学习哪怕借鉴相关的经验呢？虽然《轩辕剑六》恶名在外、《穹之扉》销量不佳，可是最起码人家的游戏的画面做得相对仙剑六要好很多好不好，况且人家在处理人物和场景时刻意加强了人物面部的特征，通过渲染景深和整体的光照使得画面透露出一种唯美的风格。可是仙剑六呢？仙剑六中做得最好看的永远都是人物的脸，我不知道北软是不是在有意告诉大家：这是一个看脸、靠脸的时代，所以当我们面对这个游戏的时候我们就发现整个游戏除了脸比较漂亮以外基本没有什么优点，可是事实上不同的人物在不同的场合、年龄他的面部应该都是不一样的啊，北软你把所有人的脸都做的这么漂亮，是想告诉玩家都不用去努力工作、只要拼脸就可以了吗？我不知道使用国外的3A级别的游戏引擎如UE、CE等来表现这种中国古典美的场景是否合适，因为这种类型的引擎更适合写实的渲染，而无疑中国的古风游戏需要的是一种意蕴上的美感的渲染。然而《古剑奇谭》和《轩辕剑》在表现这种场景时处理的相对来说是比较好的，这次的所有场景中我比较喜欢的是与青山，因为这个场景的色彩运用可以让玩家很明显的区分开场景中的不同的区域，反观忘尘寰、归墟、天晴之海、饮马河等场景因为使用的色彩较为接近，因为在玩家探索迷宫的时候常常搞晕，再辅以本次游戏中那个神奇的相机视角，探索迷宫的乐趣真是大大的增强啊！我不理解为什么北软连全局光照这种只需要简单设置下参数的东西都不愿意用，却要花大力气在角色的头顶上放置点光源，你告诉我，放置点光源就是为了让角色的头顶亮一下、脸白一点吗？更不要说启魂邪教总坛里那些支持实时反射的水晶石了？难道你宁可要这种华而不实的效果，都要让玩家的计算机耗费资源去支持它吗？景安正武盟门前的那条河的果冻绿材质就不能让美术想办法替换下吗？难道怕玩家不知道你是使用的Unity3D里的标准材质？ 下面是游戏中主角及配角的面部截图，颜值爆表啊！ 果然还是看脸的 下面是《古剑奇谭二》、《穹之扉》、《仙剑六》三部游戏在特效全开的情况下的画面表现，相信高下立判了吧！ 古剑奇谭2最高画质](https://ww1.sinaimg.cn/large/4c36074fly1fziyubagmjj20im0ppn3x.jpg)![穹之扉最高画质 仙剑六最高画质 建模&emsp;&emsp;好了，下面说说建模的问题，我使用disunity对仙剑六的部分.unity3d文件进行了解包，然后发现每个模型文件的包大概在10M左右，像太空步、循环动画、穿模这种问题我就不说了，反正每次说了你们又不打算改。我就来说说这个游戏里的模型吧？对三个模型进行了解包，然后发现这三个模型的单位都是不一样的，就是说在scale为1、1、1的时候三个模型的大小是不一样的；其次模型的角度需要手动改为-90,180,0，我觉得建模的时候难道不应该制定相关的规范吗？我觉得从Max、Maya里导出到FBX到Unity3D的时候难道不应该规范单位、角度和中心点位置吗？我从来不认为游戏引擎就是美术把模型做好了给程序用就行了，我觉得美术在建模的时候更应该去关注模型在这个引擎下的渲染效果，如怎么调整材质、怎么打灯光等等的问题，这些问题不应该推给程序而且不能推给程序。从模型贴图来看，美术想到了诸如法线贴图等等的次世代特性，可是到了实际使用的时候，我看到的结果的是整个游戏里基本清一色的使用了Diffuse着色器，那请问这样做这些贴图有什么意义？既然你根本用不到为什么还要放到游戏里？而且我在模型文件中经常看到诸如Object01或者A_toufa、B_yifu这样的命名，我是一个程序员，对命名比较敏感，我觉得出现汉语拼音式的命名，说明建模的人是特别不专业的。然后我想说的是这次整体美术风格的问题，难道大家不觉得天晴之海的建筑风格偏欧式了吗？这是一个中国的古风游戏啊！难道大家不觉得盈辉堡的道路和房子都是一样的颜色吗？我在地图里转了半天才找到路啊！此次的配角如赢旭危和朔漩的建模普遍要比主角团好看多了，难道你们要开始学《古剑奇谭二》在游戏中潜伏隐藏主角团吗？我不知道一个2015年的游戏出现NPC配音时嘴巴不动是出于什么考虑？NPC不重要吗？NPC戏份没有主角团多可以忍、长得没有主角团帅可以忍，可是你剥夺人家说话的权利是什么鬼？还有骆驼移动的时候没有移动动画直接悬空移动又是想干什么？一个骆驼值得你使用刚体这样的移动方式去移动吗？关于游戏读条慢的情况，我自己测试了下、同时找了相关的资料去查阅，Unity3D场景的异步加载的确有坑存在，可是我相信只要运用合适的方法是可以规避这个问题的，因为目前仅仅解了部分AssetBundle包的内容，所以对程序内部的一些东西还有待确定，等确定后会继续更新到这里。 朔璇模型 赢旭危模型 剧情&emsp;&emsp;剧情、配音、配乐这里放到一起说，因为这是仙剑六引以为豪的地方，此次的剧情主线有两条，即双越身世之谜和洛家双生子早逝之谜，将这两条线交织在一起的是横道众和柷敔间的矛盾冲突，这样的设定明显是继承了仙五前的多线程叙事方式，这样的叙事方式应该是值得肯定的。但是我不能理解整个游戏到底是以谁为叙事中心的，正如仙剑五是以主角姜云凡为叙事中心的，他所看到的一切推进着整个剧情的深入，再入仙剑五前传是以主角夏侯瑾轩为叙事中心的，围绕着为姜承洗刷冤屈、为瑕妹治病两条主线将所有相关的人或事联系了起来。可是仙剑六我真没看出来是以谁为中心的，整个主角团是仙剑史上最冷漠、最分裂的团队，将大家联系到一起的唯一理由就是存在感爆表的神农九泉，然而这并没有什么卵用，大家都是站在自己的立场上做着自己关心的事情。 &emsp;&emsp;比如越今朝是霸道总裁“只有我一个人可以叫你祈”。一路上不是摸头就是捏脸，可惜手压根没有放到脸上去；再比如越祈是天真傻“我听今朝的”。一路上吃面吃得我都饿了，可是那碗鸡蛋面就是一张贴图啊，吃半天空气最后居然吃完了，我要向仙剑六的四位程序员致敬；再比如闲卿是典型的双标狗，一面要讨好老婆洛昭言和世侄小绣儿，一面还要做出一副闲适淡泊的样子，我都忍不住要为你的演技点赞；再比如耳光绣明绣，我觉得要么是美术和策划有仇，故意将这样一个凶狠的角色画成甜美可人的女神范儿，要么就是编剧经常看琼瑶剧比较热衷于打人耳光，一个武侠游戏有什么不满直接亮兵器不就好了，要是当年月如被逍遥在扬州城外欺负了直接打李逍遥一个耳光，我觉得这个角色恐怕要失去不少忠实粉丝吧;再比如说技术宅居士方这货总是一副“你们都是对的，怪我咯”的态度，我至今都想不明白他有什么不对的地方，既然大家都不拿你当朋友，你凭什么要为这样一群人牺牲豆包啊。我一直喜欢仙剑营造的那种朋友间比较温暖的情感，比如仙剑四里小紫英一句“承君此诺必守一生”就会让人觉得温暖，即使以后大家分开了彼此的心中还可以相互牵挂。可是仙剑六呢，那晚大家做一起赏月喝酒本来应该是彼此相互了解和认识的机会，结果大家都忙着去约会了，留下居十方一个人在哪里喝闷酒，甚至他喝醉了酒吐露心事主角团中竟然无一人听见，我严重怀疑编剧每次和同学聚会的时候都是那个抢着麦克风嘶吼却从来不会有人去安慰他的那个人，编剧啊，己所不欲勿施于人啊。我一直认为一个RPG游戏的核心在于代入感，就是说你要让玩家觉得他就是游戏中的主角。比如我们玩仙剑一的时候就感觉自己是李逍遥，仙五前谢叔单挑姜世离的时候我们就感觉自己是谢叔，这就是代入感。 &emsp;&emsp;可是仙剑六呢，居然巧妙的避开了这一点，搞得从头到尾都像在看电影，不，应该是叫做在看幻灯片。我不知道仙六是不是借鉴了《古剑奇谭二》的叙事方式，整个叙述视角更像是以上帝俯视人间的视角在讲整个故事，如果说《古剑奇谭二》成就了流月城，那么仙剑六便成就了衡道众，而且编剧觉得为了和《古剑奇谭二》拉开差距，刻意让站在对立面的衡道众认识到自己的错误并对主角一行人提供了补偿。我承认，这让仙剑六在立意上有了深度，可是我接下来要说的就是你们的不对了。我们玩仙剑一的时候比武招亲、蜀山剑法、林家绝学、苗疆蛊术、五灵仙术我们从来不会觉得存在违和感，因为这些东西都是东方文化中已有或者说可以找到起源追朔的东西，可是仙剑六的编剧你告诉我整个仙剑六除了鲲鹏能够在庄子的《逍遥游》中找到记载以外，其他的这些是中国传统文化存在的吗？是，时空穿越早就有了，可是回魂仙梦和血濡回魂都无法改变已经发生的事情；是，在天上飞早就有了，可是蜀山仙剑派御剑飞行早在武侠小说、志怪小说中有记载，所以蜀山的御剑术不会存在丝毫的违和感，可是你搞个二十一世纪都未必有的飞行器是什么鬼，古时候尝试上天的人最多是在一个椅子上捆满火药，希望通过反冲力飞到天上去，结果为科学事业献身了，编剧你告诉我这是什么鬼。我真傻，我单单知道黑科技会在仙剑剧里出现，却不知道有一天会在仙剑游戏里出现，你告诉我御界枢的人都是外星人吗？我们使用智能手机、平板电脑不过四五年的样子，编剧你告诉我衡道众里的人是怎么做到的，他们是从未来穿越过去的嘛？好了，下面请允许我替历代仙剑中因为剧情需要而牺牲的各位男主角、女主角、男配角、女配角、小怪以及Boss说句公道话，为什么六代的人可以通过交换实现“不死”的愿望，而六代以前的就只能领便当？我知道编剧一定会说，因为这次我们采用了全新的以神农为中心的世界观，可是编剧好像忘了神农和女娲差不多是同时在宇宙中产生的吧？我觉得五代的Boss魔翳比较冤枉，冒着做坏人的危险、拼着命为魔界找来了水源，结果你说九泉之一的热海同样可以产生水源，我原本只要伤害洛埋名一人就可以取得水源，结果就因为你这奇怪的设定，五代造就了仙剑史上最大的牺牲，编剧啊编剧原来你是真正的幕后黑手，神马黑包子各种连携技全都弱爆了好吗？你把仙剑六的故事设定到仙五前的五六十年里难道不担心这个世界的变化跟不上你的节奏吗？编剧你一句话就让蜀山派这样的神权天授、依靠盘古之心存在于世间的正派组织荡然无存啊，你告诉我御剑术都在江湖上失传了，这是摆明了以后不会再出现蜀山或者御剑术的节奏吗？我乐意看到仙剑六在世界观上的变化，可是这个新的世界观应该是原来以女娲为中心的世界观的一种补充而非推翻啊，你提出了神农九泉的概念，我觉得这个设定可以让仙剑的题材变得新颖些，然并卵这一次就把九泉的故事差不多都讲完了，是想等下一部游戏立项的时候再次推翻这次的设定，编剧啊，你到底是来挖坑的还是扩展仙剑的游戏世界观的啊！ 仙剑六黑科技 游戏性&emsp;&emsp;下面我们来重点说说游戏性。你问我为什么要说游戏性啊？一个游戏、一个商业游戏不提游戏性你觉得提什么呢？首先我想强调一个观点，认为仙剑六只要剧情好就行了的朋友请向姚仙建议将仙剑做成一个动漫或者电影，这样大家连自动战斗都不用点了对吧！仙剑六的突破挺多的，可惜注重了量而不注重质，这样平均下来仙剑六的突破其实很少很少。首先，我们来说说开放地图的问题，因为地图开放了玩家可以自由探索的地方就多了，可是你要真的想做好开放地图，就应该认真的去设计空气墙而不是等玩家掉坑里出来的时候打开游戏菜单重新回到原点。因为你们在设置空气墙的时候不用心，在过饮马河和去落日部的路上，比如祈妹的隔空移物和今朝的凌空飞剑，我不会告诉你我是直接从两边的石头上跳过去的。抓猫是挺好玩的，可是你告诉我玩家站在树顶纹丝不动、走绳子如履平地是什么鬼，在没有对Unity3D内部集成的Physic物理引擎进行完全充分的了解的情况下，贸然使用这样的技术你确定你能驾驭得好吗？浮金堂我跳了一个下午没有跳过去，然后跳出各种Bug，我终于明白这次为什么有人能玩到70个小时以上啦，恭喜北软你们终于知道了怎样延长一个游戏的时间。这次的开机关让居十方都觉得郁闷，因为每次需要开机关的时候都会提示“开机关这种事情还是让十方去做吧!”，当我终于庆幸有用得着十方的时候，这下轮到我郁闷了，难道小游戏就不能给点提示吗？我总得知道自己要做什么吧！划船我再转了不知多久以后才明白过来怎么控制船的移动方向和角度，这种小问题难道每次都要让大家说吗？这次的迷宫设计有了层次感和立体感，比如启魂邪教总坛的迷宫和机关设计得都不错，天晴之海得迷宫设计得比较好，然而我最喜欢的是与青山这个场景！ 我就放个图，不说话！ 浮金堂跳跃Bug &emsp;&emsp;好了，说完这些小游戏，我们来说说这次仙剑六的战斗系统。我想知道，究竟是什么样的一种考量让你们选择去模仿FF13的战斗模式，难道是为了刻意和《古剑奇谭二》有所不同？然并卵，这次的战斗系统糟糕透了。首先，我是希望仙剑的战斗系统慢慢地向着即时制的方向发展的，因为这是现在的大势所趋吧，尤其是《古剑奇谭》、《雨血》和《御天降魔传》这类游戏正在引领着大家的兴趣往即时方向转变，在这样的背景下仙剑积极地向即时制转变从某种程度上来讲是一种不得不采取的防御性措施。可是我有教过你用一个伪即时制的战斗系统来欺骗大家的感情吗？以前大家对排站好在每个回合里我们可以依次控制多名角色，然后依次释放技能，通过不同角色间策略的调整来将游戏进行下去；现在大家迈着太空步，在每个回合里我们可以控制一名角色，每次可以发动多次行动，其他角色由AI控制，然后场景中各种粒子特效乱飞。当我看到粒子特效贴图的矩形边框时，我的内心是奔溃的。你告诉我这样的战斗系统和回合制有什么区别？当初主企划说为了让大家更好的观赏战斗画面特意将UI做到了右下角，可是你告诉我在一个即时制的游戏里用眼角的余光扫视右下角然后用滚动条从一堆物品中选择需要的物品该有多蛋疼，等你选好了，队友或者玩家可能已经死了。所以我们的数值策划为明绣配置逆天的治疗数值，这样一来大家就不用吃药了。呵呵，是你们该吃药了吧，你告诉我一个游戏玩到现在我都没记住几个技能的名称，以后问起来大家提到万剑诀、天剑、酒神、真元护体、天罡战气、五灵归宗、乾坤一掷、气疗术、气指剑、万物归烬、仙风云体、千方残光剑等等经典招式的时候，我希望你们不要说我们厚此薄彼就好。我相信有好多妹子已经习惯开着自动战斗直接看剧情的习惯了吧，如果这样仙剑还不如买小说或者拍动漫呢，正好这次所有的过场动画都是2D动画的形式，可是你告诉我2D动画是一种风格、3D建模是一种风格、小剧情表情是一种风格，一个游戏里三种风格，你是打算同时照顾动漫和游戏两个不同群体的玩家吗？然并卵，你这样做了不见得人家会领情，人家会说你抄袭、撞梗，你说你又是何苦呢？我给仙剑六战斗系统提点意见吧，希望可以支持玩家自定义快捷键，比如玩家可以挑选自己喜欢的技能和常用的物品，每次使用都会消耗行动点数，行动点数目消耗完了就触发技能动画，这样至少可以让点鼠标变得高端些，就像英雄联盟说白了就是Q、W、E三个键各种按，可是你同样可以装X地说这里面涉及到走位和意识。对了，灵脉系统界面能不能点击了以后不要放大，你觉得那样真的好看吗？再说三种培养方式我非得一条路走到黑？ 战斗系统截图1 战斗系统截图2 &emsp;&emsp;好了，熬夜到凌晨三点写完这篇文章，我对仙剑绝对是真爱，我知道一定会有许多人来吐槽我写的这篇吐槽，可我想说的是：你要真的爱它就别总是惯着它，真正的爱从来都不是溺爱！在官方放出第三版补丁后，整个游戏的优化得到了较好的提升，从感官上像个游戏了，如果有朋友还在徘徊不定，不妨在这个时候尝试下吧！以上观点，一家之言，不足为据！","categories":[{"name":"单机游戏","slug":"单机游戏","permalink":"https://qinyuanpei.github.io/categories/%E5%8D%95%E6%9C%BA%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"仙剑奇侠传","slug":"仙剑奇侠传","permalink":"https://qinyuanpei.github.io/tags/%E4%BB%99%E5%89%91%E5%A5%87%E4%BE%A0%E4%BC%A0/"},{"name":"RPG","slug":"RPG","permalink":"https://qinyuanpei.github.io/tags/RPG/"}]},{"title":"Unity3D游戏开发之SQLite让数据库开发更简单","date":"2015-07-09T09:47:06.000Z","path":"posts/582264328/","text":"&emsp;&emsp;各位朋友大家好，欢迎大家关注我的博客，我是秦元培，我是博客地址是http://blog.csdn.net/qinyuanpei。在经历了一段时间的忙碌后，博主终于有时间来研究新的东西啦，今天博客向和大家一起交流的内容是在Unity3D游戏开发中使用SQLite进行数据库开发，坦白来讲，在我的技术体系中Web和数据库是相对薄弱的两个部分，因此正好这段时间项目需要和服务器、数据库进行交互，因此在接下来的文章中博主可能会更加倾向于讲解这方面的内容，希望大家能够喜欢啊！ 一、什么是SQLite？&emsp;&emsp;SQLite是一款轻型的数据库，是遵守ACID的关系型数据库管理系统，它包含在一个相对小的C库中，以嵌入式作为它的设计目标，它占用资源非常的低，因此适合在嵌入式设备如Android、Ruby on Rails等中使用。它能够支持Windows/Linux/Unix等等主流的操作系统，同时能够跟和C、C++、Ruby、Python、C#、PHP、Java等编程语言相结合。SQLite是一个以文件形式存在的关系型数据库，尽管无法实现分布式和横向扩展，可是作为一个轻量级的嵌入式数据库，它不需要系统提供服务支持，通过SDK直接操作文件避免了对数据库维护的相关事务，从这个角度来讲它是一个出色的数据库。 二、为什么要选择SQLite&emsp;&emsp;好了，在了解了SQLite后，我们来了解下SQLite有哪些让我们心动的特性，或者说我们为什么要选择SQLite，因为在这个世界上我们有太多的数据库可以选择，诸如Oracle、MySQL、SQLServer、DB2、NoSQL、MongoDB等等： ACID事务 零配置 – 无需安装和管理配置 储存在单一磁盘文件中的一个完整的数据库 数据库文件可以在不同字节顺序的机器间自由的共享 支持数据库大小至2TB 足够小, 大致13万行C代码, 4.43M 比一些流行的数据库在大部分普通数据库操作要快—SQLite读写效率如此之高，会使用其他数据库的理由是？ 简单, 轻松的API 包含TCL绑定, 同时通过Wrapper支持其他语言的绑定 良好注释的源代码, 并且有着90%以上的测试覆盖率 独立: 没有额外依赖 源码完全的开源, 你可以用于任何用途, 包括出售它 支持多种开发语言，C, C++, PHP, Perl, Java, C#,Python, Ruby等 三、Unity3D中的SQLite&emsp;&emsp;在Unity3D中使用SQLite，我们首先要明白这样一件事情，即我们这里的使用的SQLite并非是通常意义上的SQLite.NET,而是经过移植后的Mono.Data.Sqlite。因为Unity3D基于Mono，因此使用移植后的Mono.Data.Sqlite能够减少我们的项目在不同平台上出现各种各样的问题。在Unity3D中使用的SQLite以Mono.Data.Sqlite.dll即动态链接库的形式给出，因此我们需要将这个文件放置在项目目录下的Plugins文件夹中，此外我们需要System.Data.dll或者Mono.Data.dll这两个文件添加到Plugins目录中，因为我们需要的部分数据相关的API或者类都定义在这两个文件当中，这些文件可以从这里直接下载。 PS：博主注意到在网上有使用Mono.Data.SQLiteClient.dll这个库实现在Unity3D操作SQLite数据库的相关文章，博主大概看了下，感觉和使用Mono.Data.Sqlite.dll这个库大同小异，大家喜欢哪个就用哪个吧！哈哈！博主在开源社区找到一个版本库，据说可以同时支持.NET和Mono，如果大家感兴趣欢迎大家去测试啊，哈哈! &emsp;&emsp;在正式开始写代码前，我们首先来回顾下通常情况下数据库读写的基本流程吧！ 定义数据库连接字符串(ConnectionString)完成数据库连接的构造，建立或者打开一个数据库。 定义相关的SQL命令(Command)通过这些命令实现对数据库的增加、删除、更新、读取四种基本功能。 在完成各种数据库操作后及时关闭数据库连接，解除对数据库的连接和引用。 &emsp;&emsp;SQLite作为一款优秀的数据库，在为其编写数据库相关代码时同样遵循这样的流程，考虑到对数据库的增加、删除、更新、读取四种操作具有类似性和统一性，因此在动手写Unity3D脚本前，首先让我们来编写一个SQLite的辅助类SQLiteHelper.cs。该类代码定义如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222using UnityEngine;using System.Collections;using Mono.Data.Sqlite;using System;public class SQLiteHelper&#123; /// &lt;summary&gt; /// 数据库连接定义 /// &lt;/summary&gt; private SqliteConnection dbConnection; /// &lt;summary&gt; /// SQL命令定义 /// &lt;/summary&gt; private SqliteCommand dbCommand; /// &lt;summary&gt; /// 数据读取定义 /// &lt;/summary&gt; private SqliteDataReader dataReader; /// &lt;summary&gt; /// 构造函数 /// &lt;/summary&gt; /// &lt;param name=\"connectionString\"&gt;数据库连接字符串&lt;/param&gt; public SQLiteHelper(string connectionString) &#123; try&#123; //构造数据库连接 dbConnection=new SqliteConnection(connectionString); //打开数据库 dbConnection.Open(); &#125;catch(Exception e) &#123; Debug.Log(e.Message); &#125; &#125; /// &lt;summary&gt; /// 执行SQL命令 /// &lt;/summary&gt; /// &lt;returns&gt;The query.&lt;/returns&gt; /// &lt;param name=\"queryString\"&gt;SQL命令字符串&lt;/param&gt; public SqliteDataReader ExecuteQuery(string queryString) &#123; dbCommand = dbConnection.CreateCommand(); dbCommand.CommandText = queryString; dataReader = dbCommand.ExecuteReader(); return dataReader; &#125; /// &lt;summary&gt; /// 关闭数据库连接 /// &lt;/summary&gt; public void CloseConnection() &#123; //销毁Command if(dbCommand != null)&#123; dbCommand.Cancel(); &#125; dbCommand = null; //销毁Reader if(dataReader != null)&#123; dataReader.Close(); &#125; dataReader = null; //销毁Connection if(dbConnection != null)&#123; dbConnection.Close(); &#125; dbConnection = null; &#125; /// &lt;summary&gt; /// 读取整张数据表 /// &lt;/summary&gt; /// &lt;returns&gt;The full table.&lt;/returns&gt; /// &lt;param name=\"tableName\"&gt;数据表名称&lt;/param&gt; public SqliteDataReader ReadFullTable(string tableName) &#123; string queryString = \"SELECT * FROM \" + tableName; return ExecuteQuery (queryString); &#125; /// &lt;summary&gt; /// 向指定数据表中插入数据 /// &lt;/summary&gt; /// &lt;returns&gt;The values.&lt;/returns&gt; /// &lt;param name=\"tableName\"&gt;数据表名称&lt;/param&gt; /// &lt;param name=\"values\"&gt;插入的数值&lt;/param&gt; public SqliteDataReader InsertValues(string tableName,string[] values) &#123; //获取数据表中字段数目 int fieldCount=ReadFullTable(tableName).FieldCount; //当插入的数据长度不等于字段数目时引发异常 if(values.Length!=fieldCount)&#123; throw new SqliteException(\"values.Length!=fieldCount\"); &#125; string queryString = \"INSERT INTO \" + tableName + \" VALUES (\" + values[0]; for(int i=1; i&lt;values.Length; i++) &#123; queryString+=\", \" + values[i]; &#125; queryString += \" )\"; return ExecuteQuery(queryString); &#125; /// &lt;summary&gt; /// 更新指定数据表内的数据 /// &lt;/summary&gt; /// &lt;returns&gt;The values.&lt;/returns&gt; /// &lt;param name=\"tableName\"&gt;数据表名称&lt;/param&gt; /// &lt;param name=\"colNames\"&gt;字段名&lt;/param&gt; /// &lt;param name=\"colValues\"&gt;字段名对应的数据&lt;/param&gt; /// &lt;param name=\"key\"&gt;关键字&lt;/param&gt; /// &lt;param name=\"value\"&gt;关键字对应的值&lt;/param&gt; public SqliteDataReader UpdateValues(string tableName,string[] colNames,string[] colValues,string key,string operation,string value) &#123; //当字段名称和字段数值不对应时引发异常 if(colNames.Length!=colValues.Length) &#123; throw new SqliteException(\"colNames.Length!=colValues.Length\"); &#125; string queryString = \"UPDATE \" + tableName + \" SET \" + colNames[0] + \"=\" + colValues[0]; for(int i=1; i&lt;colValues.Length; i++) &#123; queryString+=\", \" + colNames[i] + \"=\" + colValues[i]; &#125; queryString += \" WHERE \" + key + operation + value; return ExecuteQuery(queryString); &#125; /// &lt;summary&gt; /// 删除指定数据表内的数据 /// &lt;/summary&gt; /// &lt;returns&gt;The values.&lt;/returns&gt; /// &lt;param name=\"tableName\"&gt;数据表名称&lt;/param&gt; /// &lt;param name=\"colNames\"&gt;字段名&lt;/param&gt; /// &lt;param name=\"colValues\"&gt;字段名对应的数据&lt;/param&gt; public SqliteDataReader DeleteValuesOR(string tableName,string[] colNames,string[] operations,string[] colValues) &#123; //当字段名称和字段数值不对应时引发异常 if(colNames.Length!=colValues.Length || operations.Length!=colNames.Length || operations.Length!=colValues.Length) &#123; throw new SqliteException(\"colNames.Length!=colValues.Length || operations.Length!=colNames.Length || operations.Length!=colValues.Length\"); &#125; string queryString = \"DELETE FROM \" + tableName + \" WHERE \" + colNames[0] + operations[0] + colValues[0]; for(int i=1; i&lt;colValues.Length; i++) &#123; queryString+=\"OR \" + colNames[i] + operations[0] + colValues[i]; &#125; return ExecuteQuery(queryString); &#125; /// &lt;summary&gt; /// 删除指定数据表内的数据 /// &lt;/summary&gt; /// &lt;returns&gt;The values.&lt;/returns&gt; /// &lt;param name=\"tableName\"&gt;数据表名称&lt;/param&gt; /// &lt;param name=\"colNames\"&gt;字段名&lt;/param&gt; /// &lt;param name=\"colValues\"&gt;字段名对应的数据&lt;/param&gt; public SqliteDataReader DeleteValuesAND(string tableName,string[] colNames,string[] operations,string[] colValues) &#123; //当字段名称和字段数值不对应时引发异常 if(colNames.Length!=colValues.Length || operations.Length!=colNames.Length || operations.Length!=colValues.Length) &#123; throw new SqliteException(\"colNames.Length!=colValues.Length || operations.Length!=colNames.Length || operations.Length!=colValues.Length\"); &#125; string queryString = \"DELETE FROM \" + tableName + \" WHERE \" + colNames[0] + operations[0] + colValues[0]; for(int i=1; i&lt;colValues.Length; i++) &#123; queryString+=\" AND \" + colNames[i] + operations[i] + colValues[i]; &#125; return ExecuteQuery(queryString); &#125; /// &lt;summary&gt; /// 创建数据表 /// &lt;/summary&gt; + /// &lt;returns&gt;The table.&lt;/returns&gt; /// &lt;param name=\"tableName\"&gt;数据表名&lt;/param&gt; /// &lt;param name=\"colNames\"&gt;字段名&lt;/param&gt; /// &lt;param name=\"colTypes\"&gt;字段名类型&lt;/param&gt; public SqliteDataReader CreateTable(string tableName,string[] colNames,string[] colTypes) &#123; string queryString = \"CREATE TABLE \" + tableName + \"( \" + colNames [0] + \" \" + colTypes [0]; for (int i=1; i&lt;colNames.Length; i++) &#123; queryString+=\", \" + colNames[i] + \" \" + colTypes[i]; &#125; queryString+= \" ) \"; return ExecuteQuery(queryString); &#125; /// &lt;summary&gt; /// Reads the table. /// &lt;/summary&gt; /// &lt;returns&gt;The table.&lt;/returns&gt; /// &lt;param name=\"tableName\"&gt;Table name.&lt;/param&gt; /// &lt;param name=\"items\"&gt;Items.&lt;/param&gt; /// &lt;param name=\"colNames\"&gt;Col names.&lt;/param&gt; /// &lt;param name=\"operations\"&gt;Operations.&lt;/param&gt; /// &lt;param name=\"colValues\"&gt;Col values.&lt;/param&gt; public SqliteDataReader ReadTable(string tableName,string[] items,string[] colNames,string[] operations, string[] colValues) &#123; string queryString = \"SELECT \" + items [0]; for (int i=1; i&lt;items.Length; i++) &#123; queryString+=\", \" + items[i]; &#125; queryString += \" FROM \" + tableName + \" WHERE \" + colNames[0] + \" \" + operations[0] + \" \" + colValues[0]; for (int i=0; i&lt;colNames.Length; i++) &#123; queryString+=\" AND \" + colNames[i] + \" \" + operations[i] + \" \" + colValues[0] + \" \"; &#125; return ExecuteQuery(queryString); &#125;&#125; &emsp;&emsp;SQLiteHelper类主要实现了数据库、数据表的创建以及数据表中记录的增加、删除、更新、读取四种基本功能。该类最初由国外的Unity3D开发者发布在Unity3D官方论坛,后来经宣雨松使用C#进行重写，我在此基础上进行了完善，再此对两位大神的无私付出表示感谢。这里要说明的有三点： 一、在Unity3D编辑器下生成数据库文件(.db)默认位于和Assets目录同级的位置，即项目的工程文件夹中。我们可以通过修改路径在改变数据库文件的存储位置，具体来讲：Windows平台：data source=Application.dataPath/数据库名称.dbIOS平台：data source=Application.persistentDataPath/数据库名称.dbAndroid平台：URL=file:Application.persistentDataPath/数据库名称.db(我想说Android平台就是个奇葩，搞什么特殊化嘛) 二、确保Unity3D编辑器中的.NET版本和MonoDevelop中的.NET版本都为2.0版本，在Unity3D中打包导出的程序可能不会保留数据库文件，因此需要手动将数据库文件拷贝到相应的位置，当然更加合理的方案是将数据库文件存放到StreamingAssets文件夹下，然后在第一次加载游戏的时候将数据库文件复制到对应平台上的存放位置。 三、在使用InsertValues方法时请参考SQLite中字段类型与C#中数据类型的对应关系，博主目前测试了int类型和string类型都没有什么问题，更多类型的数据请大家自行测试然后告诉博主测试的结果，如果大家有兴趣扩展这个辅助类的话可以自行去扩展哦，嘿嘿！ &emsp;&emsp;好了，千呼万唤始出来的时候到了，下面我们以一个实例来完成今天的项目讲解，因为我们已经定义好了SQLite的辅助类，因此我们可以快速地编写出下面的脚本代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566using UnityEngine;using System.Collections;using System.IO;using Mono.Data.Sqlite;public class SQLiteDemo : MonoBehaviour &#123; /// &lt;summary&gt; /// SQLite数据库辅助类 /// &lt;/summary&gt; private SQLiteHelper sql; void Start () &#123; //创建名为sqlite4unity的数据库 sql = new SQLiteHelper(\"data source=sqlite4unity.db\"); //创建名为table1的数据表 sql.CreateTable(\"table1\",new string[]&#123;\"ID\",\"Name\",\"Age\",\"Email\"&#125;,new string[]&#123;\"INTEGER\",\"TEXT\",\"INTEGER\",\"TEXT\"&#125;); //插入两条数据 sql.InsertValues(\"table1\",new string[]&#123;\"'1'\",\"'张三'\",\"'22'\",\"'Zhang3@163.com'\"&#125;); sql.InsertValues(\"table1\",new string[]&#123;\"'2'\",\"'李四'\",\"'25'\",\"'Li4@163.com'\"&#125;); //更新数据，将Name=\"张三\"的记录中的Name改为\"Zhang3\" sql.UpdateValues(\"table1\", new string[]&#123;\"Name\"&#125;, new string[]&#123;\"'Zhang3'\"&#125;, \"Name\", \"=\", \"'张三'\"); //插入3条数据 sql.InsertValues(\"table1\",new string[]&#123;\"3\",\"'王五'\",\"25\",\"'Wang5@163.com'\"&#125;); sql.InsertValues(\"table1\",new string[]&#123;\"4\",\"'王五'\",\"26\",\"'Wang5@163.com'\"&#125;); sql.InsertValues(\"table1\",new string[]&#123;\"5\",\"'王五'\",\"27\",\"'Wang5@163.com'\"&#125;); //删除Name=\"王五\"且Age=26的记录,DeleteValuesOR方法类似 sql.DeleteValuesAND(\"table1\", new string[]&#123;\"Name\",\"Age\"&#125;, new string[]&#123;\"=\",\"=\"&#125;, new string[]&#123;\"'王五'\",\"'26'\"&#125;); //读取整张表 SqliteDataReader reader = sql.ReadFullTable (\"table1\"); while(reader.Read()) &#123; //读取ID Debug.Log(reader.GetInt32(reader.GetOrdinal(\"ID\"))); //读取Name Debug.Log(reader.GetString(reader.GetOrdinal(\"Name\"))); //读取Age Debug.Log(reader.GetInt32(reader.GetOrdinal(\"Age\"))); //读取Email Debug.Log(reader.GetString(reader.GetOrdinal(\"Email\"))); &#125; //读取数据表中Age&gt;=25的所有记录的ID和Name reader = sql.ReadTable (\"table1\", new string[]&#123;\"ID\",\"Name\"&#125;, new string[]&#123;\"Age\"&#125;, new string[]&#123;\"&gt;=\"&#125;, new string[]&#123;\"'25'\"&#125;); while(reader.Read()) &#123; //读取ID Debug.Log(reader.GetInt32(reader.GetOrdinal(\"ID\"))); //读取Name Debug.Log(reader.GetString(reader.GetOrdinal(\"Name\"))); &#125; //自定义SQL,删除数据表中所有Name=\"王五\"的记录 sql.ExecuteQuery(\"DELETE FROM table1 WHERE NAME='王五'\"); //关闭数据库连接 sql.CloseConnection(); &#125;&#125; &emsp;&emsp;在上面的代码中我们是在Start方法中创建了数据库和数据表，然而在实际使用中我们需要判断数据库和数据表是否存在，因此如果你使用这段脚本提示错误信息，请确保数据库和数据表是否已经存在。好了，下面的截图展示了程序运行的结果： 数据库效果演示 Unity3D效果展示 &emsp;&emsp;作为一个强大的数据库怎么能没有图形化的数据库管理工具呢？所以这里博主向大家推荐一个免安装的小工具SqliteStudio，使用这个工具可以帮助我们方便地管理Sqlite数据库里的数据，这样是不是比较方便呢？哈哈！这个工具可以从这里下载哦！ SQLiteStudio界面演示 &emsp;&emsp;好了，今天的内容就是这样了，为了写这篇文章花了三个晚上准备，希望大家喜欢啊！如果大家觉得这篇文章有用，请继续关注我的博客，我是秦元培，我的博客地址是http://blog.csdn.net/qinyuanpei。 &emsp;&emsp;2015年11月3日更新内容如下：不同平台上的数据库存储路径 12345678910111213141516//各平台下数据库存储的绝对路径(通用)//PC：sql = new SQLiteHelper(\"data source=\" + Application.dataPath + \"/sqlite4unity.db\");//Mac：sql = new SQLiteHelper(\"data source=\" + Application.dataPath + \"/sqlite4unity.db\");//Android：sql = new SQLiteHelper(\"URI=file:\" + Application.persistentDataPath + \"/sqlite4unity.db\");//iOS：sql = new SQLiteHelper(\"data source=\" + Application.persistentDataPath + \"/sqlite4unity.db\");//PC平台下的相对路径//sql = new SQLiteHelper(\"data source=\"sqlite4unity.db\");//编辑器：Assets/sqlite4unity.db//编译后：和AppName.exe同级的目录下，这里比较奇葩//当然可以用更随意的方式sql = new SQLiteHelper(\"data source=\"D://SQLite//sqlite4unity.db\");//确保路径存在即可否则会发生错误//如果是事先创建了一份数据库//可以将这个数据库放置在StreamingAssets目录下然后再拷贝到//Application.persistentDataPath + \"/sqlite4unity.db\"路径即可","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"数据库","slug":"数据库","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"SQLite","slug":"SQLite","permalink":"https://qinyuanpei.github.io/tags/SQLite/"}]},{"title":"Unity3D游戏开发之从Unity3D项目版本控制说起","date":"2015-07-02T09:35:42.000Z","path":"posts/1320325685/","text":"&emsp;&emsp;各位朋友，大家好，欢迎大家关注我的博客，我是秦元培，我的独立博客地址是http://qinyuanpei.com、CSDN博客地址是http://blog.csdn.net/qinyuanpei。今天我想和大家聊聊Unity3D游戏项目的版本控制。 为什么要进行版本控制？&emsp;&emsp;当我一个人写代码的时候，在我的脑海中是不存在版本控制这个概念的，因为我对整个项目的代码如数家珍。可是当我和一群人在一起写代码的时候，我可能并不会清楚团队中有谁修改了哪一行代码，即使是一个变量的名称或者是一个函数的名称，在我毫不知情的情况下，可能这样的修改会使得程序无法运行，这个时候我需要版本控制；尽管Unity3D是一个适合小团队开发的游戏引擎，可是即使再小的团队同样会有不同的分工，当大家需要将各自的工作合并到一个完整的项目中的时候，这个时候我需要版本控制；当我需要了解团队成员实际的编程能力的时候，最好的方法是让他们参与到一个项目的开发中，这样我可以从他提交代码的情况了解他的工作能力，这个时候我需要版本控制；当我希望时时刻刻对项目进行备份，并在某一个关键的时刻将项目恢复到一个正确的状态的时候，复制、黏贴不会让这个工作变得简单，这个时候我需要版本控制。 怎样在Unity3D中进行版本控制？&emsp;&emsp;在Unity3D中进行版本控制主要针对Assets和ProjectSetting这两个文件夹，因为除此以外的文件和文件夹都是Unity3D在运行过程中产生的临时文件，这些文件会在使用Unity3D打开项目后重新生成，因此无需对这些文件或文件夹进行版本控制。好了，在了解了Unity3D版本控制中需要关注的主要内容后，接下来我们要关注的是怎样让版本控制的软件对我们提交的内容进行差异化识别，我们知道版本控制的一个核心任务就是将服务器上的文件和本地的文件进行比对，找出哪些文件是最新生成的、哪些文件是被修改过的等等。因此为了方便版本控制软件对文件进行比对，常常需要项目变动的这些因素转化为文本形式，如果熟悉Github的朋友应该知道，Github中判断两个文件的差异就是根据文本(代码)来比较的，因此在Unity3D中使用版本控制同样需要遵循这个原则，好在Unity3D在管理Unity3D项目时已经考虑到了这一点，通常在对Unity3D项目进行版本控制的时候，我们需要做这样的事情： 通过Edit-&gt;Project Settings-&gt;Editor菜单打开编辑器设置选项，将Version Control选项下的Mode设为Visual Meta Files，这样Unity3D将为项目中的每个文件或者每个文件夹生成对应的.Meta文件。该文件是一个文本文件，记录了对应文件的相关信息，版本控制软件可以以此来对文件版本进行对比和合并操作。 Unity3D中的资源默认是以二进制的形式进行组织的，这种组织方式对版本控制来说是不合适的，因此需要通过通过Edit-&gt;Project Settings-&gt;Editor菜单打开编辑器设置选项，将Asset Serialization下的Mode设为Force Text。 通过Edit-&gt;Prefences-&gt;External Tools找到Revision Control Diff/Merge选项，在安装了版本控制软件后可以在这里找到相关的选项，以博主为例，博主使用的是TortoiseSVN，这里的选项是TortoiseMegre。目前Unity3D支持的版本控制软件有SourceGear DiffMerge、TKDiff、P4Megre、TortoiseMegre、WinMegre、PlasticSCM Megre。 &emsp;&emsp;好了，在完成以上准备工作后，我们就可以开始进行Unity3D项目的版本控制了，目前在Unity3D中我们主要有以下三种方式来对Unity3D项目进行版本控制： 使用Asset Server进行版本控制&emsp;&emsp;Unity3D的Asset Server是一个Unity3D内部集成的版本控制软件，它和我们熟知的SVN类似，适合在小团队内进行版本控制，这是一个收费软件，尽管在某些方面它甚至比SVN还要方便，不过在实际的项目中使用这个的还是比较少的，所以如果大家对这个感兴趣，可以从这里了解它的具体情况，这里我们不打算介绍这个软件的使用。 Unity3D游戏制作（四）——Asset Server搭建 【教程】Asset Server（联合开发） 使用Github进行版本控制&emsp;&emsp;使用Github进行版本控制时可以在Git仓库中添加一个.gitignore文件来对项目中需要同步的文件进行过滤，在文章开始我们已经知道Unity3D项目的版本控制主要针对Assets和ProjectSetting这两个文件，因此.gitignore的内容可以这样填写: 12345678Library/Temp/*.sln*.csproj*.sln*.userprefs*.unityproj*.DS_Store &emsp;&emsp;这样每次提交文件的时候Github将忽略这些文件的更改。关于Github的使用及其相关命令可以查看这里： 总结自己的Git常用命令 Git远程操作详解 &emsp;&emsp;Github中每个仓库的容量限制为1G，适合小项目的版本控制，对于大型项目的版本控制应该考虑使用SVN。 使用SVN进行版本控制&emsp;&emsp;使用SVN进行版本控制时可以通过右键菜单将某些文件和文件夹添加到忽略的文件列表中，这样SVN在每次提交文件的时候将忽略这些文件的更改。这块儿其实和Github的.gitignore是相同的。SVN常用的软件组合是 TortoiseSVN(客户端)+VisualSVN Server(服务端)，具体内容请参考这2篇文章：SVN使用教程总结和客户端TortoiseSVN的安装及使用方法 小结&emsp;&emsp;不管使用什么版本控制软件，建立相关的代码提交规范和流程控制规范都是必要的，因此在团队中应该有一个人负责对团队成员提交的代码进行审核和规范化，这样可以减少因为因为代码提交而产生的各种问题。好了，今天这篇文章先写到这里了，希望大家喜欢！","categories":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/categories/Unity3D/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"版本控制","slug":"版本控制","permalink":"https://qinyuanpei.github.io/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/"},{"name":"SVN","slug":"SVN","permalink":"https://qinyuanpei.github.io/tags/SVN/"},{"name":"Github","slug":"Github","permalink":"https://qinyuanpei.github.io/tags/Github/"}]},{"title":"Unity3D游戏开发之路：一月工作总结","date":"2015-06-24T07:42:48.000Z","path":"posts/1059499448/","text":"&emsp;&emsp;不知不觉已经在公司上班一个月了，在这一个月里每一天发生的事情是我平凡而普通的生活。作为一名有节操的程序员，当我大学的同学开始称我为程序员的时候，我知道我即将在这条路上踏下一个属于开始的足迹。和我大学的同学相比，可能我会显得幸运而孤独吧！我不用像他们一样到各种工厂里采样、监测，可是与此同时我会因为离大家越来越远而感到孤独。每天下班做公交车回到住处，简单地料理着我一个人的生活，不紧不慢却永远是一个人在摸黑赶路，这是我自己选择的路，我从来不曾后悔，即使在这段时间和美术各种闹别扭，我相信这些都会是暂时的，以后总会变得越来越好。 &emsp;&emsp;第一份工作没有想象中的高大上，这是一个融合了3D漫游、Web和电子商务的综合项目，可我想说我在努力地做好这件事情。当互联网+的概念被人们所熟知以后，传统行业和互联网的结合让人们对未来的生活充满了遐想，因为在这个过程中不断涌现出想要迫切进入互联网+时代的传统行业。可是当传统行业试图进入互联网行业的时候，我不知道传统行业经营者心中到底对互联网行业了解多少。我的第一份工作在家人的口中被演绎出了三个不同的版本，我想这就是传统行业对互联网行业认识的一种缩影吧，那就是传统行业并不了解互联网行业，当他们想要做互联网+的时候可能更多的是脑海中一闪而过的热情吧！ &emsp;&emsp;我的一位朋友告诉我，当你处在传统行业和互联网行业的十字路口的时候，你首先要虚心地了解和掌握传统行业的运作模式，然后再尝试将其和互联网结合起来。可是更为实际的情况是当这些传统行业的经营者有了进入互联网行业的想法以后，可能并不会从互联网的行业来看待这个想法，甚至片面的认为这个项目已然成竹在胸我们需要的仅仅是两三个懂技术的人就好了。这种想法其实是特别可怕的，以公司为例，从我进公司以来，公司从未对即将要做的项目进行过技术上的评估和立项讨论，公司的大部分美术甚至都不知道有这样一个项目存在、更不知道做好的模型要运用到一个怎样的技术上去以及最终会以什么样的方式呈现给用户。我所看到的情况就是公司里没日没夜的做模型。我想这就是领导脑袋一热的结果吧，大概知道要做一个什么样的东西，可是对具体怎么实施这个项目、实施这个项目需要哪些资源却没有详细的思考。我进公司这么长时间，基本没有看到过成文的策划或者是方案，更多的时候是大家在一块儿做，然后做的过程中发现有什么问题再返回去改，领导的态度从来没有准，觉得什么东西可以借鉴过来就要求程序和美术去实现，计划朝令夕改内心深处就不知道自己想做什么。我在公司从法律上来讲应该是一名普通员工，可是在很多时候我不得不担当项目管理者的角色。或许在这样的情况下，我可能会收获比普通员工更为丰富的除技术以外的经验，可是从长远发展的角度来看，只会让我内心更加厌倦目前的生活，希望早一天离开这家公司！ 1、项目该谁说了算？&emsp;&emsp;在一个没有策划的团队里，美术和程序就像水火不容的两股势力此消彼长。虽然说作为一名有节操的程序员，我的内心是拒绝让策划来领导程序的。因为在游戏网游化的今天，在国内基本是找不到多少对历史、人文、宗教等领域都有研究的策划的。在过去开发一款游戏，可能在游戏的世界观的构建上都需要花费很长的时间去研究相关的资料，可是在策划办公软件化的今天，策划关注的重点早已不再是游戏的世界观这些深层次的内容了，大家的关注点在什么地方呢？可能都在关注游戏的盈利和各种游戏系统数值的设计上吧，这一点我不想做太多的说明，因为大家都明白是怎么回事啦！好了，那么现在的问题是我们处在一个没有策划的团队里，如果程序按照美术的思路去做，可能程序会在修改了若干次项目以后对美术的要求失去信心，因为相对于程序解决问题而言，作为美术的普通人提出需求的难度显然更低。可是如果按程序的思路去做，可能美术不大会接受程序的审美，因为从我自己的角度来讲，程序更喜欢纯粹而简洁的东西、更看重能否解决问题，好不好看通常都是在考虑了这些问题后再去考虑的。 &emsp;&emsp;我进公司以后，基本经历了这样两种做事方式的洗礼，刚开始技术这边和我说了大概思路，然后我做出了第一个原型(1.0版本),结果这个思路和公司的思路完全是两个东西，因此1.0版本就在这样被扼杀在襁褓中。接下来，美术提出了先做UI,然后我们在等待她们做UI的过程中重新审视了这个项目，那段时间天天往隔壁办公室跑，搞得那个办公室里的妹子每次看到我进去都要抬起头看一下。每天跑来跑去做什么呢？答案是沟通，和领导沟通、和美术沟通，目的是在相互沟通的基础上加深对项目需求的理解。等到美术的UI做出来以后，我们就准备做UI了，结果做到一半的时候，领导说UI设计不合格，被打回去重新做，然后我们花了一周时间开会讨论，我从一开始没有资格参与公司会议变成了每次会议都要参加，我不知道这对我是好事还是坏事，说好事吧是因为我终于有发言权了，说坏事吧是因为经常和美术争得面红耳赤，总之每次开完会我都忍不住要吐槽下。 &emsp;&emsp;那么好了，各位看官，说到这里我无非是想告诉大家一个简单到不能再简单的道理：凡事预则立，不预则废。这就是说我们在做一件事情前一定要做好规划，游戏开发是一个特别考验团队合作的工作，如果在这个过程中我们没有在项目立项前做好充足的准备，就会很容易出现上面的问题。当我了解到仙剑项目立项就需要三个月的时候，我深深地感受到了这些传统行业经营者们的脑门一拍的决定是多么的不靠谱啊。在知乎上曾经看到过说”项目万事俱备，再差个程序员就好了”的类似言论，其实说这句话的往往就是这些自命不凡的传统行业经营者们，当你觉得一个项目仅仅需要若干个程序员就够了的时候，恰恰说明你还不够懂互联网行业！ 2、猪一样的队友&emsp;&emsp;我身边许多玩LOL的人都在吐槽打匹配的时候遇到的都是猪一样的队友，这种情况在项目开发中则更为常见。我不知道美术出身的领导怎么会认为程序员越多项目进度就越能赶上。做项目不是大家一块儿做模型，每个人分给几个然后用着破解版的3DsMax就搞定了。程序在我看来更应该在保证人员配备合理的基础上保证质量。 &emsp;&emsp;首先第一条，人员配备合理就是说程序员的数量要合理，其次大家的层次差别应该不会太大。因为人多了的话，对项目代码的影响可能更大，尤其是当大家编程的风格和技术水平存在差异的时候，体现在项目中就是各种未知的Bug。为什么要求大家的层次差别不大呢，因为层次差别太大，首先团队内沟通就是问题，以我为例，我手下的两个人都是培训班培训出来的，基本上就是老师给一套视频然后照着视频做出一款游戏就结束了，我一直反感用视频的方式来学习游戏开发，因为你是在学习一个游戏引擎而不是在学习一个工具软件，虽然Unity3D提供了可视化编辑器，可是在我眼里它始终都是一个游戏引擎，而非一个类似Office或者是3D软件的东西。那么我想说的是什么呢？我想说的是不要把编程当作一种固定的套路，经常有人直接抄我博客里的代码直接运行项目，然后出了各种问题再来问我怎么回事？碰到这种情况我首先问的第一句话是你能不能明白这个代码是干什么的？如果对方不理解，我一般会先让它搞懂这些代码的意义。 &emsp;&emsp;我们公司里的美术都不愿意碰Unity3D，因为他们觉得这个游戏引擎会增加他们学习软件的各种成本，可是事实是这个游戏引擎比我见过的Max、Maya、Blender等软件都简单啊，而且Unity3D免费版的就可以开发简单地游戏，比之美术口中各种不择手段的盗版、破解软件不知道要干净了多少？归根到底一句话，美术不愿意尝试新的东西，美术总认为Max里的模型导出到Unity3D后材质啊、灯光啊会丢，美术总认为Max渲染的效果要比Unity3D好许多，可是既然你选择了这个引擎来做项目，我觉得美术是有责任来了解这个引擎的，你让程序员帮你拼UI我可以接受，可是你让程序员帮你打灯光、修改材质、摆场景，这是程序员该做的事情嘛?我说虚幻四这样的引擎都是由策划来编辑关卡的，为什么你们美术就不能尝试了解下这个引擎呢？得到的答案是我们要做模型，显然当美术的眼睛只盯着手头的那几样工具软件的时候，你和他们间的差距已经拉开，如果有能力、有时间的话，不妨尝试下将编程以外的能力整合到自身的体系中，未来是属于全能型人才的！ 3、怎样让项目流程化&emsp;&emsp;我觉得像游戏这样负责的软件工程，在立项之初就应该明确美术、策划、程序各自的责任。我的想法是美术来制作素材、程序来编写相关逻辑和外部工具、策划使用外部工具来编辑关卡。 &emsp;&emsp;在我来公司前，曾看过一位前辈写过的关于这个项目的一个Demo，当初这个Demo里只有两个场景，我最初是对这位前辈颇为敬重的，因为感觉这个Demo的表现还不错，甚至觉得如果能够得到这个前辈指点一二，实乃三生有幸啊。可是当我和这位前辈聊过以后以及看过他写的代码，我对他的敬重慢慢地变成了鄙夷。这是为什么呢？因为他向领导提议使用硬代码来编写项目，通过研究他写的项目，我发现他的项目确实使用硬代码写成的，你能想象在一个脚本中并列7个if仅仅是因为它们的tag不同嘛，你能想象在一个脚本中的命名都是汉语拼音的变量定义嘛。 &emsp;&emsp;抛开他写的项目不说，从规模和负责程度上目前这个项都比他的Demo有难度，首先我们大概需要制作35个场景涉及到上千种模型和贴图而非Demo中的两个场景，其次我们最终的发布平台是Web平台而非Demo中的PC平台。写硬代码意味着放弃复用和扩展性，顾及目前而不考虑以后。可是我们这个项目肯定是需要扩整规模的，难道每次添加一个新的场景都需要把代码重新写一遍，因此这个方案在和他交流的时候我当着他的面就给Pass了，然后他说我们先做个Demo看看，因为在前面我们已经积累了部分代码，所以在这部分代码的基础上我们迅速地完成了一个较为灵活的框架。整个框架是将模型单独打包后和贴图一起存放在服务器上，因为模型和贴图对不同的户型来说都是通用的，因为使用配置文件设计了一个类似数据库的结构，这样当我们在程序中需要某些模型和贴图的时候只需要下载就可以了，因为模型和贴图都被存放在服务器上，本地仅仅存放相关的户型模型和配置文件，因此项目的体积被大大地压缩，从而可以解决Web平台浏览器的压力，因为所有的场景都是使用配置文件来定义，因此当需要更新项目的时候，只需要更新服务器上的模型和贴图以及配置文件即可，提高了项目更新得速度。总体来讲，我对我设计的这个架构表示满意，因为它让硬代码的优越感荡然无存。同时为了减少人工编写配置文件、打包等过程的工作量，通过为Unity3D编写插件的方式实现了整个过程的半自动化。为什么是半自动化啊？因为人在做事情的时候没有统一、规范的习惯或者说难以统一和规范。我一直强调统一和规范，可是美术总认为程序的要求过于苛刻，可是事实上懂得编程的人都明白计算机程序不过是对某个过程的一种模拟，而且这个过程是有限状态的，因此当美术说需要XXX功能的时候，程序员的内心其实是拒绝的，因为为了这点需求，他可能需要写十几行重复的代码，为了满足用户的懒惰和弱智，领导让我们将户型内的物体尽量全部实现动态化，要给用户最大的自由，结果却是剥夺了程序员的自由写了若干个if或者是重复调用相同的方法，这简直是恶魔啊！ &emsp;&emsp;好了，写了这么多，大家可能觉得这不符合我作为一个有节操的程序员的风格，说好的每周一篇技术博客呢？其实技术运用的好坏，完全取决于运用技术的人，所以我们不能仅仅关注技术的高低，更要关注怎样让整个团队高效率、高沟通率的执行下去，因为千里之堤，毁于蚁穴啊，虽然团队间沟通这些东西看似都是些政治或者是形式的东西，可是实际上会占到整个项目开发中相当大的一部分，所以希望大家在看了今天的博客后能够有所启发吧，好了，睡觉，哈哈！今天居然写到了这个时候！","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"工作","slug":"工作","permalink":"https://qinyuanpei.github.io/tags/%E5%B7%A5%E4%BD%9C/"},{"name":"生活","slug":"生活","permalink":"https://qinyuanpei.github.io/tags/%E7%94%9F%E6%B4%BB/"}]},{"title":"Unity3D游戏开发之使用AssetBundle和Xml实现场景的动态加载","date":"2015-06-15T07:24:17.000Z","path":"posts/1467630055/","text":"&emsp;&emsp;各位朋友，大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://qinyuanpei.com。 今天我想和大家聊聊在Unity3D中关于场景的动态加载的问题。众所周知在Unity3D游戏开发过程中，因为受到游戏容量、平台性能和热更新等诸多因素的限制，我们可能无法将所有的游戏场景打包到项目中然后相对”静态”地加载，那么这个时候就需要我们使用动态加载的方式来将游戏场景加载到场景中。博主在研究了Unity3D动态加载的相关资料后发现，目前Unity3D中实现动态加载场景的方式主要有以下两种方式： 使用BuildStreamedSceneAssetBundle()方法将场景打包为AssetBundle：这种方法将生成一个流式的.unity3d文件，从而实现按需下载和加载，因此这种方式特别适合Web环境下游戏场景的加载，因为在Web环境下我们可以希望的是玩家可以在玩游戏的同时加载游戏。可是因为这种打包方式仅仅是保证了场景中的GameObject与本地资源的引用关系而非是将本地资源打包，因此从减少游戏容量的角度来说并不是十分实用，而且当我们使用WWW下载完AssetBundle后，需要使用Application.Load()方法来加载场景，我们知道在Unity3D中加载一个关卡(场景)是需要在BuildSetting中注册关卡的，因此在使用这种方式动态加载的时候请注意到这一点。 将场景内的所有物体打包为AssetBundle配合相关配置文件动态生成场景：这种方法的思路是使用一个配置文件来记录下当前场景中所有物体的位置、旋转和缩放信息，然后再根据配置文件使用Instantiate方法逐个生成即可。这种思路是考虑到需要在一个场景中动态替换GameObject或者是动态生成GameObject的情形，使用这种方法首先要满足一个条件，即：场景内所有的物体都是预制件(Prefab)。这是由Unity3D的机制决定的，因为Prefab是一个模板，当你需要动态生成一个物体的时候就需要为其提供一个模板(Prefab)。 &emsp;&emsp;如果你对这两种方式没有什么疑问的话，那么我觉得我们可以正式开始今天的内容了。既然今天的题目已然告诉大家是使用AssetBundle和Xml文件实现场景的动态加载，我相信大家已经明白我要使用那种方式了。好了，下面我们正式开始吧！ ##准备工作&emsp;&emsp;在实现场景的动态加载前，我们首先要在本地准备好一个游戏场景，然后做两件事情： 将场景内的所有GameObject打包为AssetBundle 将场景内所有的GameObject的信息导出为Xml文件做这两件事情的时候，相当于我们是在准备食材和菜谱，有了食材和菜谱我们就可以烹制出美味佳肴了。可是在做着两件事情前，我们还有一件更为重要的事情要做，那就是我们需要将场景中使用到的GameObject制作成预制体(Prefab)。因为在博主的印象中，Unity3D打包的最小粒度应该是Prefab，所以为了保险起见，我还是建议大家将场景中使用到的GameObject制作成预制体(Prefab)。那么问题来了，当我们将这些Prefab打包成AssetBundle后是否还需要本地的Prefab文件？这里博主一直迷惑，因为理论上当我们将这些Prefab打包成AssetBundle后，我们实例化一个物体的时候实际上是在使用AssetBundle的Load方法来获取该物体的一个模板，这个模板应该是存储在AssetBundle中的啊！因为我的笔记本使用的是免费版的Unity3D无法对此进行测试，所以如果想知道这个问题结果的朋友可以等我下周到公司以后测试了再做讨论(我不会告诉你公司无耻地使用了破解版)，当然如果有知道这个问题的答案的朋友欢迎给我留言啊，哈哈！这里就是想告诉大家要准备好场景中物体的预设体(Prefab),重要的事情说三遍!!! ##将场景内物体打包为AssetBundle&emsp;&emsp;Unity3D打包的相关内容这里就不展开说了，因为在官方API文档中都能找到详细的说明，虽然说Unity5.0中AssetBundle打包的方式发生了变化，不过考虑到大家都还在使用4.X的版本，所以等以后我用上了Unity5.0再说吧，哈哈！好了，下面直接给出代码： 12345678910111213[MenuItem(&quot;Export&#x2F;ExportTotal----对物体整体打包&quot;)]static void ExportAll()&#123; &#x2F;&#x2F;获取保存路径 string savePath&#x3D;EditorUtility.SaveFilePanel(&quot;输出为AssetBundle&quot;,&quot;&quot;,&quot;New Resource&quot;,&quot;unity3d&quot;); if(string.IsNullOrEmpty(savePath)) return; &#x2F;&#x2F;获取选择的物体 Object[] objs&#x3D;Selection.GetFiltered(typeof(Object),SelectionMode.DeepAssets); if(objs.Length&lt;0) return; &#x2F;&#x2F;打包 BuildPipeline.BuildAssetBundle(null,objs,savePath,BuildAssetBundleOptions.CollectDependencies|BuildAssetBundleOptions.CompleteAssets); AssetDatabase.Refresh();&#125; ##将场景内物体信息导出为Xml文件&emsp;&emsp;导出场景内物体信息需要遍历场景中的每个游戏物体，因为我们在制作场景的时候通常会用一个空的GameObject作为父物体来组织场景中的各种物体，因此我们在导出Xml文件的时候仅仅考虑导出这些父物体，因为如果考虑子物体的话，可能会涉及到递归，整个问题将变得特别复杂。为了简化问题，我们这里仅仅考虑场景中的父物体。好了，开始写代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152[MenuItem(&quot;Export&#x2F;ExportScene----将当前场景导出为Xml&quot;)]static void ExportGameObjects()&#123; &#x2F;&#x2F;获取当前场景完整路径 string scenePath&#x3D;EditorApplication.currentScene; &#x2F;&#x2F;获取当前场景名称 string sceneName&#x3D;scenePath.Substring(scenePath.LastIndexOf(&quot;&#x2F;&quot;)+1,scenePath.Length-scenePath.LastIndexOf(&quot;&#x2F;&quot;)-1); sceneName&#x3D;sceneName.Substring(0,sceneName.LastIndexOf(&quot;.&quot;)); &#x2F;&#x2F;获取保存路径 string savePath&#x3D;EditorUtility.SaveFilePanel(&quot;输出场景内物体&quot;,&quot;&quot;,sceneName,&quot;xml&quot;); &#x2F;&#x2F;创建Xml文件 XmlDocument xmlDoc&#x3D;new XmlDocument(); &#x2F;&#x2F;创建根节点 XmlElement scene&#x3D;xmlDoc.CreateElement(&quot;Scene&quot;); scene.SetAttribute(&quot;Name&quot;,sceneName); scene.SetAttribute(&quot;Asset&quot;,scenePath); xmlDoc.AppendChild(scene); &#x2F;&#x2F;遍历场景中的所有物体 foreach(GameObject go in Object.FindObjectsOfType(typeof(GameObject))) &#123; &#x2F;&#x2F;仅导出场景中的父物体 if(go.transform.parent&#x3D;&#x3D;null) &#123; &#x2F;&#x2F;创建每个物体 XmlElement gameObject&#x3D;xmlDoc.CreateElement(&quot;GameObject&quot;); gameObject.SetAttribute(&quot;Name&quot;,go.name); gameObject.SetAttribute(&quot;Asset&quot;,&quot;Prefabs&#x2F;&quot;+ go.name + &quot;.prefab&quot;); &#x2F;&#x2F;创建Transform XmlElement transform&#x3D;xmlDoc.CreateElement(&quot;Transform&quot;); transform.SetAttribute(&quot;x&quot;,go.transform.position.x.ToString()); transform.SetAttribute(&quot;y&quot;,go.transform.position.y.ToString()); transform.SetAttribute(&quot;z&quot;,go.transform.position.z.ToString()); gameObject.AppendChild(transform); &#x2F;&#x2F;创建Rotation XmlElement rotation&#x3D;xmlDoc.CreateElement(&quot;Rotation&quot;); rotation.SetAttribute(&quot;x&quot;,go.transform.eulerAngles.x.ToString()); rotation.SetAttribute(&quot;y&quot;,go.transform.eulerAngles.y.ToString()); rotation.SetAttribute(&quot;z&quot;,go.transform.eulerAngles.z.ToString()); gameObject.AppendChild(rotation); &#x2F;&#x2F;创建Scale XmlElement scale&#x3D;xmlDoc.CreateElement(&quot;Scale&quot;); scale.SetAttribute(&quot;x&quot;,go.transform.localScale.x.ToString()); scale.SetAttribute(&quot;y&quot;,go.transform.localScale.y.ToString()); scale.SetAttribute(&quot;z&quot;,go.transform.localScale.z.ToString()); gameObject.AppendChild(scale); &#x2F;&#x2F;添加物体到根节点 scene.AppendChild(gameObject); &#125; &#125; xmlDoc.Save(savePath);&#125; &emsp;&emsp;好了，在这段代码中我们以Scene作为根节点，然后以每个GameObject作为Scene的子节点，重点在Xml文件中记录了每个GameObject的名称、Prefab、坐标、旋转和缩放等信息。下面是一个导出场景的Xml文件的部分内容： 123456789101112131415161718192021&lt;Scene Name=\"DoneStealth\" Asset=\"Assets/Done/DoneScenes/DoneStealth.unity\"&gt; &lt;GameObject Name=\"char_robotGuard_002\" Asset=\"Prefabs/char_robotGuard_002.prefab\"&gt; &lt;Transform x=\"-18.99746\" y=\"0\" z=\"37.2443\" /&gt; &lt;Rotation x=\"0\" y=\"0\" z=\"0\" /&gt; &lt;Scale x=\"1\" y=\"1\" z=\"1\" /&gt; &lt;/GameObject&gt; &lt;GameObject Name=\"fx_laserFence_lasers_003\" Asset=\"Prefabs/fx_laserFence_lasers_003.prefab\"&gt; &lt;Transform x=\"-17.90294\" y=\"1.213998\" z=\"24.07678\" /&gt; &lt;Rotation x=\"0\" y=\"90.00001\" z=\"0\" /&gt; &lt;Scale x=\"1\" y=\"1\" z=\"3.735847\" /&gt; &lt;/GameObject&gt; &lt;GameObject Name=\"door_generic_slide_001\" Asset=\"Prefabs/door_generic_slide_001.prefab\"&gt; &lt;Transform x=\"-15.91264\" y=\"-0.001293659\" z=\"7.006886\" /&gt; &lt;Rotation x=\"0\" y=\"90.00001\" z=\"0\" /&gt; &lt;Scale x=\"1\" y=\"1\" z=\"1\" /&gt; &lt;/GameObject&gt; &lt;GameObject Name=\"door_generic_slide_003\" Asset=\"Prefabs/door_generic_slide_003.prefab\"&gt; &lt;Transform x=\"-7.910765\" y=\"-0.001293659\" z=\"37.01304\" /&gt; &lt;Rotation x=\"0\" y=\"90.00001\" z=\"0\" /&gt; &lt;Scale x=\"1\" y=\"1\" z=\"1\" /&gt; &lt;/GameObject&gt; &emsp;&emsp;在这里我们假设所有的Prefab是放置在Resources/Prefabs目录中的，那么此时我们便有了两种动态加载场景的方式 通过每个GameObject的Asset属性，配合Resources.Load()方法实现动态加载 通过每个GameObject的Name属性，配合AssetBundle的Load()方法实现动态加载这两种方法大同小异，区别仅仅在于是否需要从服务器下载相关资源。因此本文的主题是使用AssetBundle和Xml实现场景的动态加载，因此，接下来我们主要以第二种方式为主，第一种方式请大家自行实现吧！ ##动态加载物体到场景中&emsp;&emsp;首先我们来定义一个根据配置文件动态加载AssetBundle中场景的方法LoadDynamicScene 123456789101112131415161718192021222324252627282930313233343536373839404142&#x2F;&#x2F;&#x2F; &lt;summary&gt;&#x2F;&#x2F;&#x2F; 根据配置文件动态加载AssetBundle中的场景&#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt;&#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;bundle&quot;&gt;从服务器上下载的AssetBundle文件&lt;&#x2F;param&gt;&#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;xmlFile&quot;&gt;AssetBundle文件对应的场景配置文件&lt;&#x2F;param&gt;public static void LoadDynamicScene(AssetBundle bundle,string xmlFile)&#123; &#x2F;&#x2F;加载本地配置文件 XmlDocument xmlDoc&#x3D;new XmlDocument(); xmlDoc.LoadXml(((TextAsset)Resources.Load(xmlFile)).text); &#x2F;&#x2F;读取根节点 XmlElement root&#x3D;xmlDoc.DocumentElement; if(root.Name&#x3D;&#x3D;&quot;Scene&quot;) &#123; XmlNodeList nodes&#x3D;root.SelectNodes(&quot;&#x2F;Scene&#x2F;GameObject&quot;); &#x2F;&#x2F;定义物体位置、旋转和缩放 Vector3 position&#x3D;Vector3.zero; Vector3 rotation&#x3D;Vector3.zero; Vector3 scale&#x3D;Vector3.zero; &#x2F;&#x2F;遍历每一个物体 foreach(XmlElement xe1 in nodes) &#123; &#x2F;&#x2F;遍历每一个物体的属性节点 foreach(XmlElement xe2 in xe1.ChildNodes) &#123; &#x2F;&#x2F;根据节点名称为相应的变量赋值 if(xe2.Name&#x3D;&#x3D;&quot;Transform&quot;) &#123; position&#x3D;new Vector3(float.Parse(xe2.GetAttribute(&quot;x&quot;)),float.Parse(xe2.GetAttribute(&quot;y&quot;)),float.Parse(xe2.GetAttribute(&quot;z&quot;))); &#125;else if(xe2.Name&#x3D;&#x3D;&quot;Rotation&quot;) &#123; rotation&#x3D;new Vector3(float.Parse(xe2.GetAttribute(&quot;x&quot;)),float.Parse(xe2.GetAttribute(&quot;y&quot;)),float.Parse(xe2.GetAttribute(&quot;z&quot;))); &#125;else&#123; scale&#x3D;new Vector3(float.Parse(xe2.GetAttribute(&quot;x&quot;)),float.Parse(xe2.GetAttribute(&quot;y&quot;)),float.Parse(xe2.GetAttribute(&quot;z&quot;))); &#125; &#125; &#x2F;&#x2F;生成物体 GameObject go&#x3D;(GameObject)GameObject.Instantiate(bundle.Load(xe1.GetAttribute(&quot;Name&quot;)),position,Quaternion.Euler(rotation)); go.transform.localScale&#x3D;scale; &#125; &#125;&#125; &emsp;&emsp;因为该方法中的AssetBundle是需要从服务器下载下来的，因此我们需要使用协程来下载AssetBundle： 1234567891011121314IEnumerator Download()&#123; WWW _www &#x3D; new WWW (&quot;http:&#x2F;&#x2F;localhost&#x2F;DoneStealth.unity3d&quot;); yield return _www; &#x2F;&#x2F;检查是否发生错误 if (string.IsNullOrEmpty (_www.error)) &#123; &#x2F;&#x2F;检查AssetBundle是否为空 if(_www.assetBundle!&#x3D;null) &#123; LoadDynamicScene(_www.assetBundle,&quot;DoneStealth.xml&quot;); &#125; &#125;&#125; &emsp;&emsp;好了，现在运行程序，可以发现场景将被动态地加载到当前场景中:)，哈哈 ##小结 使用这种方式来加载场景主要是为了提高游戏的性能，如果存在大量重复性的场景的时候，可以使用这种方式来减小游戏的体积，可是这种方式本质上是一种用时间换效率的方式，因为在使用这种方法前，我们首先要做好游戏场景，然后再导出相关的配置文件和AssetBundle，从根本上来讲，工作量其实没有减少。 当场景导出的Xml文件中的内容较多时，建议使用内存池来管理物体的生成和销毁，因为频繁的生成和销毁是会带来较大的内存消耗的。说到这里的时候，我不得不吐槽下公司最近的项目，在将近300个场景中只有30个场景是最终发布游戏时需要打包的场景，然后剩余场景将被用来动态地加载到场景中，因为领导希望可以实现动态改变场景的目的，更为郁闷的是整个场景要高度DIY,模型要能够随用户拖拽移动、旋转，模型和材质要能够让用户自由替换。从整体上来讲，频繁地销毁和生成物体会耗费大量资源，因此如果遇到这种情况建议还是使用内存池进行管理吧！ &emsp;&emsp;好了，今天的内容就是这样子了，如果大家对此有什么疑问，欢迎给我留言，谢谢大家！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"动态加载","slug":"动态加载","permalink":"https://qinyuanpei.github.io/tags/%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD/"},{"name":"AssetBundle","slug":"AssetBundle","permalink":"https://qinyuanpei.github.io/tags/AssetBundle/"}]},{"title":"Unity3D游戏开发之快速打造流行的关卡系统","date":"2015-06-11T08:11:01.000Z","path":"posts/1424645834/","text":"&emsp;&emsp;各位朋友，大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是blog.csdn.net/qinyuanpei。今天想和大家分享的是目前在移动平台上较为流行的关卡系统，关卡系统通常是单机手机游戏如《愤怒的小鸟》、《保卫萝卜》中对游戏内容的组织形式，玩家可通过已解锁的关卡(默认第一关是已解锁的)获取分数进而解锁新的关卡，或者是通过付费购买解锁新的关卡。那么好了，在今天的文章中博主将带领大家快速实现一个可扩展的关卡系统，这个实例的灵感来自博主最近的工作经历，希望对大家学习Unity3D游戏起到一定帮助性的作用。 原理&emsp;&emsp;在本地配置一个Xml文件，在这个文件中定义当前游戏中关卡的相关信息，通过解析该文件并和UI绑定最终实现一个完整的关卡系统。 1、定义关卡&emsp;&emsp;首先我们来定义一个关卡的基本结构： 1234567891011121314151617public class Level&#123; /// &lt;summary&gt; /// 关卡ID /// &lt;/summary&gt; public string ID; /// &lt;summary&gt; /// 关卡名称 /// &lt;/summary&gt; public string Name; /// &lt;summary&gt; /// 关卡是否解锁 /// &lt;/summary&gt; public bool UnLock = false;&#125; &emsp;&emsp;在这里，我们假定关卡的名称和该关卡在Unity3D中场景名称一致。其中最为重要的一个属性是UnLock，该值是一个布尔型变量，表明该关卡是否解锁，因为在游戏中，只有解锁的场景是可以访问的。 2、定义关卡配置文件&emsp;&emsp;从关卡的基本结构Level可以定义出如下的配置文件，这里使用Xml作为配置文件的存储形式： 12345678910111213&lt;?xml version=\"1.0\" encoding=\"utf-8\"?&gt;&lt;levels&gt; &lt;level id=\"0\" name=\"level0\" unlock=\"1\" /&gt; &lt;level id=\"1\" name=\"level1\" unlock=\"0\" /&gt; &lt;level id=\"2\" name=\"level2\" unlock=\"0\" /&gt; &lt;level id=\"3\" name=\"level3\" unlock=\"0\" /&gt; &lt;level id=\"4\" name=\"level4\" unlock=\"0\" /&gt; &lt;level id=\"5\" name=\"level5\" unlock=\"0\" /&gt; &lt;level id=\"6\" name=\"level6\" unlock=\"0\" /&gt; &lt;level id=\"7\" name=\"level7\" unlock=\"0\" /&gt; &lt;level id=\"8\" name=\"level8\" unlock=\"0\" /&gt; &lt;level id=\"9\" name=\"level9\" unlock=\"0\" /&gt;&lt;/levels&gt; &emsp;&emsp;和关卡结构定义类似，这里使用0和1来表示关卡的解锁情况，0表示未解锁，1表示解锁，可以注意到默认情况下第一个关卡是解锁的，这符合我们在玩《愤怒的小鸟》这类游戏时的直观感受。那么好了，在完成了关卡的结构定义和配置文件定义后，接下来我们开始思考如何来实现一个关卡系统，因为此处并不涉及到Unity3D场景中的具体逻辑，因此我们在关卡系统中主要的工作就是维护好主界面场景和各个游戏场景的跳转关系，我们可以注意到这里要完成两件事情，即第一要将配置文件中的关卡以一定形式加载到主界面中，并告诉玩家哪些关卡是已解锁的、哪些关卡是未解锁的，当玩家点击不同的关卡时可以得到不同的响应，已解锁的关卡可以访问并进入游戏环节，未解锁的关卡则需要获得更多的分数或者是通过付费来解锁关卡；第二是要对关卡进行编辑，当玩家获得了分数或者是支付一定的费用后可以解锁关卡进入游戏环节。这两点综合起来就是我们需要对关卡的配置文件进行读写，因为我们注意到一个关卡是否解锁仅仅取决于unlock属性，那么好了，明白了这一点后我们来动手编写一个维护关卡的类。 3、编写一个维护关卡的类&emsp;&emsp;这里直接给出代码，因为从严格的意义上来说，这段代码并非我们此刻关注的重点，可能这让大家感到难以适应，因为文章明明就是在教我们实现一个关卡系统，可是此刻博主却说这部分不重要了，请大家稍安勿躁，因为这里有比代码更为深刻的东西。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778using UnityEngine;using System.Collections;using System.Collections.Generic;using System.Xml;public static class LevelSystem &#123; /// &lt;summary&gt; /// 加载Xml文件 /// &lt;/summary&gt; /// &lt;returns&gt;The levels.&lt;/returns&gt; public static List&lt;Level&gt; LoadLevels() &#123; //创建Xml对象 XmlDocument xmlDoc = new XmlDocument(); //如果本地存在配置文件则读取配置文件 //否则在本地创建配置文件的副本 //为了跨平台及可读可写，需要使用Application.persistentDataPath string filePath = Application.persistentDataPath + \"/levels.xml\"; if (!IOUntility.isFileExists (filePath)) &#123; xmlDoc.LoadXml (((TextAsset)Resources.Load (\"levels\")).text); IOUntility.CreateFile (filePath, xmlDoc.InnerXml); &#125; else &#123; xmlDoc.Load(filePath); &#125; XmlElement root = xmlDoc.DocumentElement; XmlNodeList levelsNode = root.SelectNodes(\"/levels/level\"); //初始化关卡列表 List&lt;Level&gt; levels = new List&lt;Level&gt;(); foreach (XmlElement xe in levelsNode) &#123; Level l=new Level(); l.ID=xe.GetAttribute(\"id\"); l.Name=xe.GetAttribute(\"name\"); //使用unlock属性来标识当前关卡是否解锁 if(xe.GetAttribute(\"unlock\")==\"1\")&#123; l.UnLock=true; &#125;else&#123; l.UnLock=false; &#125; levels.Add(l); &#125; return levels; &#125; /// &lt;summary&gt; /// 设置某一关卡的状态 /// &lt;/summary&gt; /// &lt;param name=\"name\"&gt;关卡名称&lt;/param&gt; /// &lt;param name=\"locked\"&gt;是否解锁&lt;/param&gt; public static void SetLevels(string name,bool unlock) &#123; //创建Xml对象 XmlDocument xmlDoc = new XmlDocument(); string filePath=Application.persistentDataPath + \"/levels.xml\"; xmlDoc.Load(filePath); XmlElement root = xmlDoc.DocumentElement; XmlNodeList levelsNode = root.SelectNodes(\"/levels/level\"); foreach (XmlElement xe in levelsNode) &#123; //根据名称找到对应的关卡 if(xe.GetAttribute(\"name\")==name) &#123; //根据unlock重新为关卡赋值 if(unlock)&#123; xe.SetAttribute(\"unlock\",\"1\"); &#125;else&#123; xe.SetAttribute(\"unlock\",\"0\"); &#125; &#125; &#125; //保存文件 xmlDoc.Save (filePath); &#125;&#125; &emsp;&emsp;这里我们首先将关卡配置文件levels.xml放置在Resources目录下，这是因为我们可以使用Resources.Load()这种方式来加载本地资源，这种方式对于Unity3D来说有着得天独厚的优势： 它使用相对于Resources目录的相对路径，所以在使用的时候不用考虑是相对路径还是绝对路径的问题 它使用名称来查找一个本地资源，所以在使用的时候不用考虑扩展名和文件格式的问题 它可以是Unity3D支持的任意类型，从贴图到预制体再到文本文件等等，可以和Unity3D的API完美地结合 &emsp;&emsp;说了这么多它的优点，我们自然要痛心疾首地说说它的缺点，它的缺点是什么呢？那就是不支持写入操作，这当然不能责怪Unity3D，因为当Unity3D导出游戏的时候会将Rsources目录下的内容压缩后再导出，我们当然不能要求在一个压缩后的文件里支持写入操作啦，所以我们是时候来总结下Unity3D中资源读写的常见方案了，那么Unity3D中常见的资源读写方案由哪些呢？ 1、Resources.Load:只读，当我们的资源不需要更新且对本地存储无容量要求的时候可以采用这种方式2、AssetBundle：只读，当我们的资源需要更新且对本地存储有容量要求的时候可以采用这种方式3、WWW:只读，WWW支持http协议和file协议，因此可以WWW来加载一个网络资源或者本地资源4、PlayerPrefs：可读可写，Unity3D提供的一种的简单的键-值型存储结构，可以用来读写float、int和string三种简单的数据类型，是一种较为松散的数据存储方案5、序列化和反序列化：可读可写，可以使用Protobuf、序列化为Xml、二进制或者JSON等形式实现资源读写。6、数据库：可读可写，可以使用MySQL或者SQLite等数据库对数据进行存储实现资源读写。 &emsp;&emsp;好了，在了解了Unity3D中资源读写的常见方案后，我们接下来来讨论下Unity3D中的路径问题：1、Application.dataPath：这个路径是我们经常使用的一个路径，可是我们真的了解这个路径吗？我看这里要打个大大的问号，为什么这么说呢？因为这个路径在不同的平台下是不一样的，从官方API文档中可以了解到这个值依赖于运行的平台： Unity 编辑器：&lt;工程文件夹的路径&gt;/Assets Mac：&lt;到播放器应用的路径&gt;/Contents IOS: &lt;到播放器应用的路径&gt;/&lt;AppName.app&gt;/Data Win：&lt;.exe文件目录&gt;\\Data Web：&lt;.unity3d文件的绝对路径&gt;&emsp;&emsp;这个路径是在PC上支持读写的，可是因为到了不同的平台上文件的路径发生变动，因此我们在程序中设置的路径可能就变成了一个错误的路径。在网上大家找到类似的内容，这一点是网上说的最多、坑最多的一块儿，希望大家在以后遇到这个问题的时候能够留心点，尽量能不用这个路径就不用这个路径吧！什么?不用这个路径，那该用什么路径呢？呵呵，不要着急啊，下面隆重向大家推荐Application.persistentDataPath这个路径。2、Application.persistentDataPath：这个路径是Unity3D中的一个数据持久化路径，呵呵，千万不要问我什么叫做数据持久化路径，我不会告诉你我今天这篇文章的关键就是数据持久化啊！总之呢，我们把握住一点，这个路径是可以在移动平台上使用的一个可以读写的路径，当然在路径这块儿可能同样会碰到和Application.dataPath类似的问题，因为博主写这篇文章的时候并没有对移动平台进行测试，这一点希望大家能够注意啊，这并不是我偷懒，实在是公司最近的事情比较多，没有时间做进一步的测试，不过除了路径的问题以外，我可以向大家保证，这个路径是可以读写的，所以如果我们在开发Unity3D游戏过程中需要在本地存储某些文件的话，这个路径是个不错的选择。 &emsp;&emsp;好了，现在我们回到维护关卡的这个类中，大家可以注意到我在加载配置文件的时候做了这样一个处理：如果本地(指游戏外部)存在配置文件则直接读取配置文件，否则使用Resources.Load()方法加载Resources目录下的配置文件，并在本地创建一个配置文件的副本。这样做的目的是为了方便对配置文件进行修改，因为Resources目录下的配置文件在导出游戏后是没有路径的，我们没有办法用常规的访问文件的方式来读取这个文件，这个时候我们就用到Application.persistentDataPath这个路径，因为我们在本地创建了副本，所以只要读取副本文件就可以对其进行读取和修改了。那么，接下来，我们来写一个Main文件作为项目的入口文件吧！ 4、编写入口文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556using UnityEngine;using System.Collections;using System.Collections.Generic;using UnityEngine.UI;using System.Xml.Serialization;public class Main : MonoBehaviour &#123; //关卡列表 private List&lt;Level&gt; m_levels; void Start () &#123; //获取关卡 m_levels = LevelSystem.LoadLevels (); //动态生成关卡 foreach (Level l in m_levels) &#123; GameObject prefab=(GameObject)Instantiate((Resources.Load(\"Level\") as GameObject)); //数据绑定 DataBind(prefab,l); //设置父物体 prefab.transform.SetParent(GameObject.Find(\"UIRoot/Background/LevelPanel\").transform); prefab.transform.localPosition=new Vector3(0,0,0); prefab.transform.localScale=new Vector3(1,1,1); //将关卡信息传给关卡 prefab.GetComponent&lt;LevelEvent&gt;().level=l; prefab.name=\"Level\"; &#125; //人为解锁第二个关卡 //在实际游戏中玩家需要满足一定条件方可解锁关卡 //此处仅作为演示 LevelSystem.SetLevels (\"level1\", true); &#125; /// &lt;summary&gt; /// 数据绑定 /// &lt;/summary&gt; void DataBind(GameObject go,Level level) &#123; //为关卡绑定关卡名称 go.transform.Find(\"LevelName\").GetComponent&lt;Text&gt;().text=level.Name; //为关卡绑定关卡图片 Texture2D tex2D; if(level.UnLock)&#123; tex2D=Resources.Load(\"nolocked\") as Texture2D; &#125;else&#123; tex2D=Resources.Load(\"locked\") as Texture2D; &#125; Sprite sprite=Sprite.Create(tex2D,new Rect(0,0,tex2D.width,tex2D.height),new Vector2(0.5F,0.5F)); go.transform.GetComponent&lt;Image&gt;().sprite=sprite; &#125;&#125; &emsp;&emsp;在这段脚本中，我们首先加载了关卡信息，然后将关卡信息和界面元素实现绑定，从而实现一个简单的关卡选择界面，并人为地解锁了第二个关卡。好吧，如果这是一个正式游戏的配置关卡配置文件，相信大家都知道怎么免费玩解锁的关卡了吧，哈哈！当然，我不推荐大家这样做，因为作为一个程序员，当你全身心地投入到一个项目中的时候，你就会明白完成一款软件或者游戏需要投入多少精力，所以大家尽量还是不要想破解或者盗版这些这些事情，毕竟作为开发者可能他的出发点是想做出来一个让大家都喜欢的产品，可是更现实的问题是开发者一样要生活，所以请善待他们吧。好了，言归正传，这里的UI都是基于UGUI实现的，不要问我为什么不用NGUI，因为我就是喜欢UGUI！我们知道我们需要为每个关卡的UI元素绑定一个响应的事件，因此我们需要为其编写一个LevelEvent的脚本： 1234567891011121314151617181920212223using UnityEngine;using System.Collections;using UnityEngine.UI;using UnityEngine.EventSystems;public class LevelEvent : MonoBehaviour&#123; //当前关卡 public Level level; public void OnClick() &#123; if(level.UnLock)&#123; //假设关卡的名称即为对应场景的名称 //Application.LoadLevel(level.Name); Debug.Log (\"当前选择的关卡是:\"+level.Name); &#125;else&#123; Debug.Log (\"抱歉!当前关卡尚未解锁!\"); &#125; &#125;&#125; &emsp;&emsp;记得在本文开始的时候，博主提到了一个假设，就是关卡的名称和其对应的游戏名称一致的假设，相信到此处大家都知道为什么了吧！为了让每个关卡的UI元素知道自己对应于哪个关卡，我们设置了一个level变量，这个变量的值在加载关卡的时候已经完成了初始化，所以此时我们可以在这里知道每个关卡的具体信息，从而完成事件的响应。好了，今天的内容就是这样了，我们来看看最终的效果吧！ DEMO1 DEMO2 &emsp;&emsp;可以注意到在第二次打开游戏后，第二个关卡已经解锁了，说明我们在最开始设计的两个目标都达到了，那么内容就是这样子啦，如果大家有什么好的想法或者建议，欢迎在文章后面给我留言，谢谢大家！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"关卡系统","slug":"关卡系统","permalink":"https://qinyuanpei.github.io/tags/%E5%85%B3%E5%8D%A1%E7%B3%BB%E7%BB%9F/"}]},{"title":"Unity3D游戏开发之路：一周工作总结","date":"2015-06-11T08:02:45.000Z","path":"posts/719322223/","text":"&emsp;&emsp;大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是http://blog.csdn.net/qinyuanpei。到公司上班已经一周了，趁着今天周末休息的时间，想将最近在工作和生活中的感受和想法写下来，因为生命就是一个不断积累、厚积薄发，最终实现自我超越的一个过程。作为第一份工作，尽管没有想象中那样理想，可我还是在很努力的工作。工作后接手的第一个项目是一个房地产的漫游展示项目，因为这家公司之前是做影视后期的，所以在决定做这个项目后，公司领导层对这个项目具体要做到什么样的效果并没有一个明确的认识，所以在项目开展前期无论是在对项目所使用的技术的熟悉程度上还是项目整体的策划上，都没有一个具体的的可操作的方案。因为公司领导是美术出身，所以从我进了公司以后，整个公司上下一直沉浸在一种加班加点赶制模型的压抑氛围当中。 &emsp;&emsp;我进公司的第一天，公司负责技术的人向我演示了一个视频，告诉我项目做出来大概就是这样一个样子，然后就让我开始写所谓的”框架”，因为他对Unity3D的技术并不熟悉，所以基本上从我上班开始，所有和Unity3D相关的工作都由我一个人来完成，让我这样一个新入职的人来担当”主程”，我感到受宠若惊而压力山大，不过因为他和我年龄相差不大，一直都比较尊重我的想法，所以Unity3D这块整个项目就比较放心地交给了我来做，这样的结果就是我大概花了一周时间就写好了整体的框架[偷笑：)]。可是在设计整个项目的过程中，因为美术都忙着建模，所以UI设计这块儿基本上都是空白，作为一个刚进公司不久没有什么话语权的新人，在这种情况下我只能自己先大致做出来一个DEMO，然后再听取领导的意见反复进行修改，可是如果这样，到了项目后期如果因为项目需求发生变动，可能UI设计就需要重新制作，我个人是比较讨厌做UI，因为UI有时候会因为参数设置不合理等等的原因造成无法调试的错误，这样你折腾了大半天找了可能出现的各种错误，最终却发现是因为一个参数设置不合理，这该有多蛋疼啊！我比较喜欢Cocos Studio这种制作UI的方式，就是让美术直接在UI编辑器里做好UI然后导出为程序可以解析的数据类型，这样程序只需要负责将这些数据解析出来为它们绑定相关的UI事件就好了。然而现实是残酷的，在这个项目中，因为楼盘、户型、家装等等因素的不可控性，所以在设计UI的时候全部都是以动态加载的形式来处理的，因为你并不能确定这些UI里显示的元素到底有多少个，这样我在设计这个框架的时候是这样考虑的，就是把所有需要人力来调整、控制的部分(如模型摆放、场景设计等等)都手动完成，所以和UI相关的部分(如UI元素的动态加载、模型的加载、本地配置文件等等)都通过动态加载来实现，因为在整个项目中第三部分的家装会涉及到大量的模型，所以这部分考虑的是将模型文件打包成AssetBundle文件从服务器加载。 &emsp;&emsp;我不知道公司领导当初是怎么样确定使用Unity3D来做这个项目，因为考虑到虚拟展示的需要，这个项目最终展示给用户的是一个网页，这样就更需要考虑资源组织的问题，就这样在工作的第一周时间内我想到了以前在学校做游戏的时候都没”舍得”使用的技术方案，基本的思路是本地的游戏文件最终仅仅保留一个主场景文件(MainMenu.cs)，主场景负责维护从楼盘到户型再到家装的所有逻辑，各个场景中的动态的部分则是通过Resource.Load()和AssetBundle来实现，将这些场景放到服务器上，主场景将决定具体加载哪一个场景。因为整个项目主要分成楼盘、户型、家装这三个部分，这些场景除了模型以外逻辑都是一样的，因此将这部分的逻辑都写成公用的脚本，在制作这些场景时只需要将脚本拖拽到某些物体上就可以了。因为需要从服务器上获取符合筛选要求的楼盘信息，因此还需要编写服务器端的相关逻辑，目前项目组中还没有服务器端的程序，这部分我表示无能为力啊，哈哈。如果希望将最终的网页做得漂亮些，可能还需要前端工程师的加入吧，目前这块同样是空白！好吧，做项目的时候即使是程序员都会有分身乏术的时候，成为全栈工程师是我的梦想，可是目前做不到啊！我不知道在游戏开发中程序和美术的关系怎么样，反正在我目前的项目组里我这个程序的存在感实在是太弱了啊，可能是项目组程序的比例太低，可能是我和大家还不熟悉吧，不过昨天居然有个美术跑过来问我能不能教他Unity3D，因为他觉得建模做得再好做出来的模型终究是死的，哈哈，瞬间感觉有种相见恨晚的感觉啊。好了，这些闲话先聊到这里吧，今天想和大家分享的是我在开发过程中遇到的某些坑，因为我是一个程序员，归根到底我和大家要聊的还是程序嘛！ 一、下载AssetBundle时遇到”跨域”的问题&emsp;&emsp;这个问题主要是因为服务器上缺少一个叫做crossdomain.xml的文件，这是由Adobe提出的以保证Flash能够跨域访问文件的一种策略，当发生这个错误时具体的表现就是你可以通过浏览器从服务器上下载AssetBundle文件，可是当你试图在Unity里使用WWW访问该文件时就会报错，具体的错误信息我已经不记得了，不过错误信息中特别明确的指出了是因为缺少crossdomain.xml这个文件，所以解决的方案就是在服务器根目录里增加这样一个文件，文件的内容如下： 12345&lt;?xml version=\"1.0\" encoding=\"UTF-8\"?&gt;&lt;cross-domain-policy&gt; &lt;site-control permitted-cross-domain-policies=\"master-only\" /&gt; &lt;allow-access-from domain=\"*\" to-ports=\"*\"/&gt;&lt;/cross-domain-policy&gt; &emsp;&emsp;具体使用的时候需要将*号部分分别替换成允许跨域访问的地址和端口，因为我是用WAMP这个软件搭建的本地服务器，所以这里都采用的是默认值，具体怎么去设置这里的内容还需要大家自己去探索，不过这里就是像告诉大家使用Unity3D做网页游戏或者是从服务器上下载文件是一定要考虑这个问题的啊！ 二、动态生成的UI Prefab被拉伸的问题&emsp;&emsp;这个问题出现在动态生成UI元素的过程中，就是生成物体以后物体的大小和位置会发生变化，这个问题在宣雨松的博客中曾经读到过，不过当时他并没有说清楚产生这个问题的原因，所以当同样的问题发生在我身上的时候我果断选择和他一样，哈哈，解决方法是把物体的localScale设为(1,1,1)、localPosition设为(0,0,0)，当然按照我的传统如果大家知道是为什么的话还是告诉我吧！ 三、AssetBundle的mainAsset问题&emsp;&emsp;这个问题产生在最初确定AssetBundle打包是将单个物体打包还是将多个物体一起打包的时候，后来发现mainAsset取决于bool BuildAssetBundle (Object mainAsset,Object[] assets,string pathName, BuildAssetBundleOptionsoptionsBuildAssetBundleOptions.CollectDependencies | BuildAssetBundleOptions.CompleteAssets,BuildTarget targetPlatform= BuildTarget.WebPlayer)这个方法中的第一个参数，就是说指定了一个参数则可以通过mainAsset来获取AssetBundle中的主物体，否则只能通过Load方法传入一个名称来获取指定物体。这里想说一件诡异的事情，比如说我们选中两个物体然后将其打包，但是通过LoadAll方法获取到的物体的数目却不是两个，因为打包的时候GamObject和Transform是分开打包的，父物体下的子物体同样是被分开打包的，因此这个方法使用起来并不是那么地尽如人意，这点希望大家注意！ ##四、场景打包为AssetBundle的问题&emsp;&emsp;我们知道在Unity中可以通过BuildStreamedSceneAssetBundle方法将场景打包为AssetBundle文件，然后按照如下方法加载到游戏中。场景打包的方法如下所示： 1234static function MyBuild()&#123; var levels : String[] = [\"Assets/Level1.unity\"]; BuildPipeline.BuildStreamedSceneAssetBundle( levels, \"Streamed-Level1.unity3d\", BuildTarget.WebPlayer); &#125; &emsp;&emsp;接下来我们就可以通过WWW方法将其加载到游戏中 12345678910111213141516171819function Start () &#123; // Download compressed scene. If version 5 of the file named \"Streamed-Level1.unity3d\" was previously downloaded and cached. // Then Unity will completely skip the download and load the decompressed scene directly from disk. var download = WWW.LoadFromCacheOrDownload (\"http://myWebSite.com/Streamed-Level1.unity3d\", 5); yield download; // Handle error if (download.error != null) &#123; Debug.LogError(download.error); return; &#125; // In order to make the scene available from LoadLevel, we have to load the asset bundle. // The AssetBundle class also lets you force unload all assets and file storage once it is no longer needed. var bundle = download.assetBundle; // Load the level we have just downloaded Application.LoadLevel (\"Level1\"); &emsp;&emsp;注意到最后一行我们是使用LoadLevel方法来加载一个场景的，该方法需要一个参数，它是我们在Unity3D中注册过的关卡，即在编译游戏的时候需要将其加入到关卡列表中。那么现在问题来了，这个Level11到底是本地的场景还是下载的场景啊，既然我们选择了从服务器上加载一个场景，那么本地应该是不会有这个场景了，那么游戏关卡列表中就不会有这个关卡，因此如果调用最后一样代码应该会提示找不到这个关卡。我在这里纠结了好久，最后发现是这样，就是现在本地做好关卡，然后将其加入到关卡列表中，当本地关卡打包成AssetBundle后，从本地删除当前关卡，依然可以从服务器上加载这个场景。这是我自己做实验的结果，不知道对不对，希望有知道这个的朋友能够告诉我这样到底对不对，因为这种方法感觉有些猥琐啊，哈哈。 &emsp;&emsp;好了，今天的内容就是这样了，因为目前项目暂时就发现了这些问题，所以更多的关于Unity3D的内容需要等到项目慢慢推进的过程中去发现了，希望大家能够喜欢啊！","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"工作","slug":"工作","permalink":"https://qinyuanpei.github.io/tags/%E5%B7%A5%E4%BD%9C/"}]},{"title":"毕业就像指尖流沙","date":"2015-05-16T08:45:05.000Z","path":"posts/3461518355/","text":"&emsp;&emsp;毕业就像指尖流沙，而我是那从指尖流过的沙子。我不知道该怎样来总结我的大学，即使我努力地寻找、努力地回避，我依然觉得大学对我而言就是这样一个讽刺的过程，曾经努力地想要摆脱这个专业最后却留了下来，最初对这个专业的热情随着时间一天天地消逝，到最后却发现自己夹在某种缝隙中左右为难。 &emsp;&emsp;或许大家都认为我这个人比较冷淡，可是对我而言，我只是想做一个简简单单的人而已，我不会因为即将毕业就表现出某种殷切的神情，在我的心里我当做朋友的会一直当作朋友，即使以后大家都鲜有机会再聚在一起，我讨厌酒桌上的朋友，所以我不会用喝酒这件事情来作为我们彼此情感的见证。我是一个不善于卖弄和殷勤的人，可能我心直口快，可能我又爱又恨，可是那是因为我想做一个表里如一的人。朋友对我而言，一直是我所珍视的人，我觉得君子之交淡如水这样的关系就很好，我不是一个善于表演的人，不管是和大家一起拍VCR还是和大家在一起的时候，我想我喜欢的是大家在一起的时光，而不是在一起喝酒的时候。 &emsp;&emsp;我承认，因为长期做编程设计的这样一个习惯，让我的思维方式里只有0和1，只有对和错。可是人却是一种奇怪的感情动物，我有时候甚至会觉得自己更喜欢计算机而不是人，人在一个人的时候会感到孤独，可是当大家都聚在一起的时候真的会快乐吗？人与人之间的关系实在是微妙而复杂，即使是互联网甚至物联网都不能与之匹敌。我知道在中国人的思维里，这种想法特别地正常，因为中国就是这样一个人情社会，有时候我会听到别人跟我说，你自己怎么样并不重要，真正重要的是你处在一个什么样的圈子里。虽然在我阅读过的书籍里、接触过的人的话语里都有类似的结论，可是道理终究是道理，当你试图去将这个道理真正实践的时候，你会发现一切是如此的艰难。 &emsp;&emsp;大家或许觉得我对这个班没有什么感情，可是人和人相处不能单纯地看重对方目前、以后可能会对你有什么样的帮助，因为这不叫朋友叫做关系，我眼中的朋友是那种即使自身没有什么强大的社会资源，可当你需要帮助的时候，他仍然会真心实意地为你付出，我对于朋友和关系的界定实在是困难，因此当我面对这场不知是送别还是交友的毕业聚会的时候，我会突然陷入某种迷茫，即使麦克风音量开到最大、嗓子喊到声嘶力竭，当一切都结束了的时候能够留下什么呢？终有一天大家都会奔向各自的前程，去做自己想做的事情，就像慕容紫英一样，百年蹉跎岁月不过转瞬，当朋友们都不再需要他照顾的时候，他会义无反顾地踏上自己的路，他心里记得那句“承君此诺，必守一生”，可是千百年后当昆仑山上下起雪的时候，这世上留给他又有什么呢？他终究是一个人，上天怜悯他却不曾心疼他，当心中信念坍塌的时候，我不知道他是不是和我一样有过这种迷茫？ &emsp;&emsp;昨天我和班里大部分的人喝了酒，目的单纯而简单，就是想感谢大家在这四年里对我的帮助，就是想记住和大家在一起的这段时光，我是一个随和的人，所以我不会强迫别人喝多少酒，因为喝酒就是一种助兴的形式而已，真正让我们铭记于心的不是这顿酒，而是我们彼此在各自的生命里出现过。或许我就是这样一个尚不成熟的人吧，或许以后我会变成让大家、让每一个人都喜欢的样子，或许我以后依然会是这个样子……生命中有太多的或许让人无法预料，可你的生命会是什么样子完全取决于你的选择，我不想为未来埋下太多的伏笔，我就是一个普通的、平凡的人，仅此而已……","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"梦想","slug":"梦想","permalink":"https://qinyuanpei.github.io/tags/%E6%A2%A6%E6%83%B3/"},{"name":"人生","slug":"人生","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%BA%E7%94%9F/"},{"name":"毕业","slug":"毕业","permalink":"https://qinyuanpei.github.io/tags/%E6%AF%95%E4%B8%9A/"}]},{"title":"Unity3D游戏开发之MMD For Unity插件研究","date":"2015-04-19T23:31:30.000Z","path":"posts/4088452183/","text":"&emsp;&emsp;今天想来说说MMD。MMD是MikuMikuDance的简称，是由日本人樋口优开发的一组3D动画制作软件。该软件最初希望能够将3D建模软件完成的VOCALOID的初音未来等角色模型制作成可以随着音乐跳舞的动画，因此称为MMD。作者在此基础上开发了能够将歌曲让初音未来等角色歌唱的MikuMikuVoice。2011年9月11日，樋口优宣布停止MMD新版本的开发工作。不过人们对制作MMD的热情丝毫没有减少，在动漫、游戏等领域总是能够不断看到MMD的影子。例如MMD/宇月和千本樱/夏侯瑾轩都是较为典型的MMD。 &emsp;&emsp;好了，相信现在大家都对MMD有了一定的了解了，作为一名单机游戏爱好者，我目前最为遗憾的两件事情： 不会制作游戏MV(或者说视频) 不会制作MMD(因为我是个程序嘛) &emsp;&emsp;在我看来以同人形式去发掘一个作品中优秀的东西，这件事情本身就是一件让人觉得快乐的事情，因为可能某一个人和你有相同的想法，当它看到你的东西的时候，发觉你想表达的东西就是它想要表达的。我每次玩完一款游戏以后都会去网上搜集比较好的MV，因为我觉得随着人一天天地慢慢长大，有时候你发觉自己再没有时间去玩游戏的时候，通过看视频能让你想起很多的事情，有时候看着别人做的MV会哭，我便觉得当时的经历其实挺值的去回味的。好了，说了这么多毫不相干的事情，差点忘了今天的正事。首先我们来了解下一个完整的制作MMD的过程： 使用Maya、Blender或者3DsMax等3D软件建模(或者从游戏中提取) 使用PMDEditor或者PMXEditor对模型进行绑骨、动作和表情制作等操作 将处理过的.pmd或者.pmx模型导入MikuMikuDance完成场景、音乐完成动画制作 &emsp;&emsp;从这样一个过程我们了解到，制作MMD还是需要一定的技术门槛的，因为并不是每一个人都能够完成模型的绑骨、动画这些任务的。这篇文章不提供以上软件的下载和使用方法，因为我们接下来的内容基本与以上软件无关，我们的重点依然是Unity3D，因为我是一个游戏开发者嘛，哈哈。好了，下面的内容基于两点假设： 你有一个PMD或者PMX模型 你有一个VMD的动作文件 &emsp;&emsp;首先，第一步我们需要一个Unity3D插件MMD4Unity,将这个插件导入项目后，为了使整个项目结构较为清晰，我们将这个插件的文件夹命名为MMDPlugins。在MMDFiles文件中我们准备了三个文件: 模型文件：初音.pmd 动作文件：动作1.vmd和动作2.vmd &emsp;&emsp;好了，现在我们注意到Unity3D菜单栏上会增加一个Plugin菜单项，我们单击这个菜单项会发现MMD Loader和XFile Importer这两个项目，这里我们选择MMD Loader这个菜单项： MMD1 &emsp;&emsp;这两个子菜单项的意义十分地明确了，PMD Loader负责加载PMD模型并将其转化为Unity3D可以识别的模型文件，VMD负责将一个动作文件套用到一个模型上。所以： 1、通过PMD Loader打开加载PMD文件的窗口，建议这里将ShaderType设置为Default，因为如果使用MMD的Shader的话，待会转换出来的模型可能会存在找不到材质的问题。接下来我们点击Convert，稍等片刻就会在场景中看到一个模型(prefab)文件。 MMD2 MMD3 2、接下来通过VMD Loader打开加载VMD文件的窗口，选择场景中的模型文件和项目资源中的XMD动作文件，点击Convert，大概有1分钟多一点的样子就好了。此时我们选择场景中的模型文件，找到它的Animation组件，然后点击Animation右侧的按钮为其指定一个动画文件，因为刚刚我们已经为它添加了一个动作，所以我们可以很容易的在项目资源中找到名为初音_动作2的动画片段(AnimationClip)。 MMD4 &emsp;&emsp;好了，现在我们就来看看这个MMD的效果吧！ MMD5 &emsp;&emsp;哈哈，感觉效果还不错吧！ &emsp;&emsp;现在来说说我在使用这个插件过程中遇到的问题： 在转换PMD模型的时候如果选择Default转换出的模型可以找到对应的材质，可是模型是错误的；如果选择MMDShader，转换出的模型会找不到对应得材质，比如说我在尝试转换下面这个模型的时候，因为MMD对模型的精细程度的要求，所以模型会被分得很细，因此像这个模型当贴图数目较少的时候，就没有办法自动对应贴图，所以这快目前还是个问题吧！ 如果使用的是PMX模型，可以用PMEditor这个软件转换下格式，转成PMD格式后，后然后再按照本文的方法去做就可以了。 PMD转换出来的模型没有办法选择其中的某一个部分，因此在操作模型的时候可能会不太方便吧，以前都是选择某一部分然后给模型贴图，现在这招不行了啊。 &emsp;&emsp;好了，今天的内容就是这样了，有什么问题大家给我留言哦！","categories":[{"name":"单机游戏","slug":"单机游戏","permalink":"https://qinyuanpei.github.io/categories/%E5%8D%95%E6%9C%BA%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"单机游戏","slug":"单机游戏","permalink":"https://qinyuanpei.github.io/tags/%E5%8D%95%E6%9C%BA%E6%B8%B8%E6%88%8F/"},{"name":"MMD","slug":"MMD","permalink":"https://qinyuanpei.github.io/tags/MMD/"}]},{"title":"在Sublime Text3下安装Package Control","date":"2015-04-17T12:54:41.000Z","path":"posts/570137885/","text":"&emsp;&emsp;Sublime Text,是这个地球上最好的代码编辑器，没有之一。因为在过去的一段时间里，我使用的版本是SublimeText2，所以听说Sublime Text3版本稳定后，决定开始尝鲜。哈哈，我就是这么一个”喜新厌旧”的人！Sublime的强大不仅仅在它优雅的外表，更为重要的是她无可匹敌的扩展性，就是说我们可以通过插件来扩展它的功能，这对于一个喜欢DIY的人来说简直是无法抗拒的诱惑。不过在接收这些诱惑前，我们需要一个工具Package Control，它是Sublime里最为基础、最为重要的插件，好了，现在问题来了，Sublime怎么安装Package Control！ &emsp;&emsp;在Sublime Text2下我们可以通过CTRL+~打开控制台，然后输入代码： 12345678910import urllib2,os; pf='Package Control.sublime-package'; ipp = sublime.installed_packages_path(); os.makedirs( ipp ) if not os.path.exists(ipp) else None; urllib2.install_opener( urllib2.build_opener( urllib2.ProxyHandler( ))); open( os.path.join( ipp, pf), 'wb' ).write( urllib2.urlopen( 'http://sublime.wbond.net/' +pf.replace( ' ','%20' )).read()); print( 'Please restart Sublime Text to finish installation') &emsp;&emsp;可是到了Sublime Text3下，因为版本不同的关系，内部API发生变化，因此需要使用新的代码： 123456import urllib.request,os; pf = 'Package Control.sublime-package'; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), 'wb').write(urllib.request.urlopen( 'http://sublime.wbond.net/' + pf.replace(' ','%20')).read()) &emsp;&emsp;当代码因为某些原因无法正常工作的时候，我们可以手动安装Package Control： 下载PackageControl或者通过Github获取1git clone git@github.com:wbond/package_control.git 通过Preferences-&gt;Browser Packages进入Installed Packages目录 重新启动Sublime，然后Enjoy it！","categories":[{"name":"开发工具","slug":"开发工具","permalink":"https://qinyuanpei.github.io/categories/%E5%BC%80%E5%8F%91%E5%B7%A5%E5%85%B7/"}],"tags":[{"name":"编辑器","slug":"编辑器","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"},{"name":"Sublime","slug":"Sublime","permalink":"https://qinyuanpei.github.io/tags/Sublime/"},{"name":"IDE","slug":"IDE","permalink":"https://qinyuanpei.github.io/tags/IDE/"}]},{"title":"在Windows下使用Visual Studio编译Lua5.3","date":"2015-04-16T14:50:35.000Z","path":"posts/3642630198/","text":"&emsp;&emsp;Lua5.3已经发布好长时间了，可是因为LuaForWindows的Lua版本无法和官方保持一致，所以想尝试下编译Lua5.3的源代码，因为作为一名合格的程序员，是应该要懂得编译原理的相关内容的啊(可是我真的没有学过编译原理啊!…..)。好了，那么今天博主将在文章中和大家分享自己编译Lua5.3的过程，希望能够对大家学习和使用Lua有些帮助吧！ &emsp;&emsp;我们知道Lua由三部分组成，即 Lua链接库 Lua解释器 Lua编译器 &emsp;&emsp;因此，对于Lua源代码的编译主要就是编译Lua链接库、Lua解释器和Lua编译器 编译Lua链接库 使用Visual Studio创建一个VC++项目，项目命名为Lua53，项目类型为静态库、不设置预编译头。 删除Visual Studio自动创建的.cpp文件及其对应的.h文件。 将下载的Lua代码解压，将src目录下的全部文件拷贝到项目中，然后删除lua.c、luac.c和lua.hpp这三个文件。 编译项目会得到一个Lua53.lib的文件，这就是我们编译得到的Lua链接库。 编译Lua解释器&emsp;&emsp;我们知道Lua解释器是一个可以直接运行Lua代码的可执行文件，因此 在同一个解决方案下继续创建VC++项目，项目命名为Lua，项目类型为控制台应用程序、需设置预编译头。 删除Visual Studio自动创建的.cpp文件及其对应的.h文件。 将下载的Lua代码解压，将src目录下的全部文件拷贝到项目中，然后删除luac.c这个文件。 设置当前项目依赖于Lua53项目 编译项目会得到一个Lua.exe文件，这就是我们编译得到的Lua解释器。 &emsp;&emsp;运行该程序，我们可以看到下面的结果： Lua解释器程序 &emsp;&emsp;好了，现在我们来写一个简单的Lua程序： 12io.write(\"Hello I get a powerful program language called Lua \\n\")io.write(string.format(\"This Lua is %s and now is %s \\n\",_VERSION,os.date())) &emsp;&emsp;程序运行结果为： Hello I get a powerful program language called LuaThis Lua is Lua5.3 and now is 04/16/15 16:06:43 编译Lua编译器&emsp;&emsp;和Lua类似地， 在同一个解决方案下继续创建VC++项目，项目命名为Lua，项目类型为控制台应用程序、需设置预编译头。 删除Visual Studio自动创建的.cpp文件及其对应的.h文件。 将下载的Lua代码解压，将src目录下的全部文件拷贝到项目中，然后删除lua.c这个文件。 设置当前项目依赖于Lua53项目 编译项目会得到一个Luac.exe文件，这就是我们编译得到的Lua解释器。 &emsp;&emsp;使用Lua编译器需要在环境变量中增加对Lua编译器路径地引用，比如Luac.exe放在D:\\Program Files\\Lua\\build\\这个目录下，就在PATH这个变量中增加： 1D:\\Program Files\\Lua\\build; &emsp;&emsp;因为每个人的Lua编译器存放的位置都不同，所以这个就不再赘述了。 &emsp;&emsp;好了，今天的内容就是这样了。 链接 本文编译的Lua 官方编译的Lua","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Lua","slug":"Lua","permalink":"https://qinyuanpei.github.io/tags/Lua/"},{"name":"编译","slug":"编译","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E8%AF%91/"},{"name":"Visual Studio","slug":"Visual-Studio","permalink":"https://qinyuanpei.github.io/tags/Visual-Studio/"}]},{"title":"贝塞尔曲线学习笔记","date":"2015-04-08T12:25:28.000Z","path":"posts/2186770732/","text":"&emsp;&emsp;贝塞尔曲线(Bezier Curve)是由法国工程师皮埃尔·贝塞尔(Pierre Bezier)于1962年提出的一种曲线。在数学的数值分析领域中，贝塞尔曲线是计算机图形学中相当重要的参数曲线，其主要意义在于无论是直线还是曲线都能在数学上予以描述。最早贝塞尔曲线被用来对汽车主体进行设计，现在贝塞尔曲线被广泛地运用到计算机图形软件(如Photoshop、Flash等)中，是计算机图形领域重要的一个数学曲线。 贝塞尔曲线主要内容&emsp;&emsp;贝塞尔曲线就是这样的一条曲线，它是依据四个位置任意的点坐标绘制出的一条光滑曲线。在历史上，研究贝塞尔曲线的人最初是按照已知曲线参数方程来确定四个点的思路设计出这种矢量曲线绘制法。贝塞尔曲线的有趣之处更在于它的皮筋效应，也就是说，随着点有规律地移动，曲线将产生皮筋伸引一样的变换，带来视觉上的冲击。1962年，法国数学家Pierre Bezier第一个研究了这种矢量绘制曲线的方法，并给出了详细的计算公式，因此按照这样的公式绘制出来的曲线就用他的姓氏来命名是为贝塞尔曲线。贝塞尔曲线按照阶数可以从一次扩展到n次，这里例举出常见的一次贝塞尔曲线、二次贝塞尔曲线和三次贝塞尔曲线。 一次贝塞尔曲线&emsp;&emsp;一次贝塞尔曲线，即线性贝塞尔曲线，其定义是:给定点P0、P1，贝塞尔曲线是两点间的一条直线。线性贝塞尔曲线由下列公式给出： B(t)=P0+(P1-P0)t=(1-t)P0+tP1,其中t是一个0到1之间的数值 &emsp;&emsp;该公式等同于对P1,P0两点进行线性插值。 一次贝塞尔曲线 二次贝塞尔曲线&emsp;&emsp;二次贝塞尔曲线的路径由给定点P0、P1、P2的函数B(t)给出: B(t)=(1-t)^2 * P0+2t(1-t)P1+t^2P2,其中t是一个0到1之间的数值 &emsp;&emsp;为构建二次贝塞尔曲线，可以中介点Q0和Q1作为由0至1的t: 由P0至P1的连续点Q0，描述一条线性贝塞尔曲线。 由P1至P2的连续点Q1，描述一条线性贝塞尔曲线。 由Q0至Q1的连续点B(t)，描述一条二次贝塞尔曲线。 二次贝塞尔曲线原理图 二次贝塞尔曲线演示效果 三次贝塞尔曲线&emsp;&emsp;P0、P1、P2、P3四个点在平面或在三维空间中定义了三次方贝塞尔曲线。曲线起始于P0走向P1，并从P2的方向来到P3。P0和P1之间的间距，决定了曲线在转而趋进P3之前，走向P2方向的“长度有多长”。三次贝塞尔曲线的公式是: B(t)=P0(1-t)^3+3P1t(1-t)^2+3P2t^2(1-t)+P3t^3,其中t是一个0到1之间的数值 三次贝塞尔曲线原理图 &emsp;&emsp;三次贝塞尔曲线的绘制这里采取的是一种已知曲线参数方程来确定四个点的方法，这种方法称为矢量曲线绘制法。这里以二维平面为例(如需三维空间同理构造出z(t)即可): x(t)=axt^3+bxt^2+cxt+x0y(t)=ayt^3+byt^2+cyt+y0 &emsp;&emsp;因为x0、y0已知，因此我们可以用下列公式计算出剩余三个点的坐标: x1 = x0 + cx / 3x2 = x1 + ( cx + bx ) / 3x3 = x0 + cx + bx + ax y1 = y0 + cy / 3y2 = y1 + ( cy + by ) / 3y3 = y0 + cy + by + ay &emsp;&emsp;在x0、y0已知的前提下，可以通过变换得到: cx = 3 * ( x1 - x0 )bx = 3 * ( x2 - x1 ) - cxax = x3 - x0 - cx - bx cy = 3 * ( y1 - y0 )by = 3 * ( y2 - y1 ) - cyay = y3 - y0 - cy - by &emsp;&emsp;因此只要给定四个点，总能构造出一条三次贝塞尔曲线，这种方法是一种较为实用和可靠的方法。 三次贝塞尔曲线效果演示 &emsp;&emsp;下面我们来看一个简单的示例，该示例以Unity3D为基础建立，希望对大家理解贝塞尔曲线有所帮助。 代码示例(尝试着实现了下，发现暂时有些问题，等实现了再更新上来吧！) 2015年12月19日更新：在《CG Programming in Unity》一书中提到了贝塞尔曲线，实现了一个基础版本的贝塞尔曲线绘制，即在给定P0和P2的前提下，由用户通过滑杆对P1进行控制，可以实时预览当前曲线的样式，感兴趣的朋友可以阅读该书的第9章部分。下面给出代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182using UnityEngine;using System.Collections;public class QuadraticBezier : MonoBehaviour &#123; /// &lt;summary&gt; /// 3个基础点 /// &lt;/summary&gt; public Vector3 P0; public Vector3 P1; public Vector3 P2; /// &lt;summary&gt; /// 调整第二个参数的水平分量 /// &lt;/summary&gt; private float paramX = 0.5f; /// &lt;summary&gt; /// 调整第二个参数的垂直分量 /// &lt;/summary&gt; private float paramY = 0.5f; /// &lt;summary&gt; /// 线条宽度 /// &lt;/summary&gt; public float LineWidth = 0.15f; /// &lt;summary&gt; /// 线条颜色 /// &lt;/summary&gt; public Color LineColor = Color.white; /// &lt;summary&gt; /// 顶点数目 /// &lt;/summary&gt; public int PointsCount = 10; /// &lt;summary&gt; /// 线渲染器 /// &lt;/summary&gt; private LineRenderer lineRenderer; void Start () &#123; //初始化线渲染器 lineRenderer = this.GetComponent&lt;LineRenderer&gt;(); if(lineRenderer == null) lineRenderer = this.gameObject.AddComponent&lt;LineRenderer&gt;(); lineRenderer.useWorldSpace = true; lineRenderer.SetColors(LineColor,LineColor); lineRenderer.material = new Material(Shader.Find(\"Particles/Additive\")); lineRenderer.SetWidth(LineWidth,LineWidth); lineRenderer.SetVertexCount(PointsCount); &#125; void Update() &#123; //根据滑杆参数计算P1 P1 = new Vector3(Mathf.Abs(P0.x-P2.x) * paramX, Mathf.Abs(P0.x-P2.x) * paramY, 0); //绘制曲线 for (int i = 0; i &lt; PointsCount; i++) &#123; float t = i / (PointsCount - 1.0f); Vector3 position = (1.0f - t) * (1.0f - t) * P0 + 2.0f * (1.0f - t) * t * P1 + t * t * P2; lineRenderer.SetPosition(i, position); &#125; &#125; void OnGUI() &#123; GUILayout.Label(string.Format(\"第一个参数：P0=(&#123;0&#125;,&#123;1&#125;,&#123;2&#125;)\", P0.x, P0.y, P0.z)); GUILayout.Label(string.Format(\"第二个参数：P1=(&#123;0&#125;,&#123;1&#125;,&#123;2&#125;)\", P1.x, P1.y, P1.z)); GUILayout.Label(\"请拖动下面的滑杆调整第二个参数P1观察曲线变化\"); paramX = GUILayout.HorizontalSlider(paramX, 0, 1); paramY = GUILayout.HorizontalSlider(paramY, 0, 1); GUILayout.Label(string.Format(\"第三个参数：P2=(&#123;0&#125;,&#123;1&#125;,&#123;2&#125;)\", P2.x, P2.y, P2.z)); &#125;&#125; 在这段代码中通过两个参数来调整P1，这里取Z分量为0主要是方便研究，扩展到三维空间需要给定第三个参数来对应的调整。这个示例的运行效果如下：","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"贝塞尔曲线","slug":"贝塞尔曲线","permalink":"https://qinyuanpei.github.io/tags/%E8%B4%9D%E5%A1%9E%E5%B0%94%E6%9B%B2%E7%BA%BF/"},{"name":"计算机图形","slug":"计算机图形","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2/"}]},{"title":"Unity3D游戏开发之使用disunity提取Unity3D游戏资源","date":"2015-04-03T13:29:18.000Z","path":"posts/1082185388/","text":"&emsp;&emsp;各位朋友，大家好，我是秦元培。今天博主想和分享的是使用disunity提取Unity3D游戏素材。这个工具呢，博主在Unity3D游戏开发之反编译AssetBundle提取游戏资源这篇文章中其实已经提到过了，不过因为有些朋友对如何使用这个工具依然存在问题，所以博主决定特地写一篇文章来讲解如何使用disunity来提取Unity3D游戏中的素材。 准备工作 disunity:负责对Unity3D的数据文件进行解包 Unity3D:负责将导出的数据文件显示出来 Bleander或者3DsMax:负责Unity3D数据文件的转换处理，二选一即可。个人推荐Blender。 Java:负责为disunity提供编译环境 测试文件 《新仙剑OL》下载 《轩辕剑6外传穹之扉》 《雨血前传:蜃楼》下载 提取流程&emsp;&emsp;好了，在确定做好所有的准备工作后，我们就可以正式开始今天的内容了！ 编译disunity&emsp;&emsp;虽然我们可以从disunity的项目主页中下载release版本，不过为了保险起见，博主依然建议大家自行编译disunity。编译的方法是在命令行中切换到disunity的目录，然后执行命令: 1java -jar disunity.jar &emsp;&emsp;如果大家的Java环境没有任何问题的话，那么接下来我们就应该可以看到: 1[Info] DisUnity v0.3.4 &emsp;&emsp;以及各种关于这个工具的使用方法和参数选项。那么好了，现在我们就来熟悉下disunity这个工具的常用命令。disunity命令的基本形式是: 1disunity [CommandName] [CommandOptions] disunity命令 dump:将一个二进制的对象转化成人类可以阅读的文本信息。 dump-struct:将一个二进制的对象转化为结构化的信息。 extract:将Unity3D的数据文件转化为常见的文本、声音、图片等信息。 extract-raw:将Unity3D的数据文件转化为可序列化的对象，在extract命令不被支持的情况下使用。 extract-txt:和dump命令类似输出转换结果到命令行。 extract-struct:和dump-struct命令类似输出转换结果到命令行。 info:输出Unity3D的数据文件和AssetBundle文件的变量信息。 bundle-extract:释放所有的被打包到AssetBundle中的文件。 bundle-inject:将从AssetBundle中打包的文件重新打包 &emsp;&emsp;暂时先介绍这些，因为其它的命令我们基本用不到，如果需要深入研究这些命令，可以参考disunity项目中的README.md文件。 解析《新仙剑OL 》的AssetBundle文件&emsp;&emsp;这里我们以游戏目录/assetbundles/NPC/Models/下的s049.unity3d_CC9026FB为例来讲解游戏模型的提取。 模型文件提取&emsp;&emsp;首先我们将这个文件的扩展名改为s049.unity3d，因为这是它原始的扩展名，是Unity3D中导出AssetBundle的一种文件格式。好了，我们将这个文件放在一个无中文路径的目录下，这里以C:\\Users\\Robin\\Desktop即桌面为例。注意首先进入disunity的目录，然后执行命令： 1disunity extract C:\\Users\\Robin\\Desktop\\s049.unity3d &emsp;&emsp;接下来会在桌面生成一个名为s049的文件夹，在这个文件夹中找到Mesh的子文件夹，会得到一个s049.obj的文件，这个文件就是我们提取到的模型文件。 模型贴图提取好了，下面我们再来看看怎么提取这个模型文件对应的贴图，在游戏目录/assetbundles/NPC/Texture/下有一个名为s049_1.unity3d_1D2446B9的文件，这就是s049这个模型对应的贴图了。同样地，我们将其重命名为s049_1.unity3d然后执行命令： 1disunity extract C:\\Users\\Robin\\Desktop\\s049_1.unity3d &emsp;&emsp;接下来在桌面上生成一个名为s049_1的文件夹，在这个文件夹中找到Texture2D的子文件夹，会得到一个名为s049_1.dds的贴图文件，这就是我们要提取的模型s049的贴图文件。 将模型和贴图合并我们打开Blender并将s049.obj文件导入，然后将场景中默认的灯光和摄像机都删除，因为我们只需要一个模型文件，我们发现在Blender中已经可以看到模型了，因为Unity3D中使用的是FBX模型，所以我们这里将模型文件导出为FBX备用。因为Unity3D可以识别dds类型的贴图，所以对贴图我们不用做任何处理。 童年林月如的模型 &emsp;&emsp;打开Unity3D将童年林月如的模型和贴图一起导入，将童年林月如的模型拖入到游戏场景中，因为模型的尺寸没有经过调整，所以模型刚开始可能会比较小，我们可以在Unity3D进行局部的调整。接下来我们会发现模型没有贴图，只要选择这个模型然后在属性窗口为它附上s049_1.dds的贴图文件即可。下面是童年林月如的模型导入Unity3D以后的效果: 童年林月如导入Unity3D后的效果 解析《新仙剑OL》的assets文件&emsp;&emsp;和AssetBundle不同，assets文件是整个Unity3D项目中项目资源的打包集合，比如说Asset文件下的资源都会被打包到这里，所以说解析assets文件可能会有更大的收获吧！因为所有的Unity3D游戏都会有这样的文件，而AssetBundle文件只有在使用了这项技术的游戏项目中才有。比如说在Unity3D中有一个重要的Resource文件夹，这个文件夹打包后被被打包成resources.assets文件。这里我们以xianjian_Data/resources.assets文件为例。首先执行命名: 1disunity extract C:\\Users\\Robin\\Desktop\\resources.assets &emsp;&emsp;接下来会在桌面生成一个resources的文件夹，打开这个文件夹我们会发现三个子文件夹，分别是Shader、TextAsset和Texture2D。解析的结果似乎有点失望，不过在TextAsset文件夹下我们会找到一个叫做ResourceFiles.txt的文件，这是一个纯文本文件，我们可以直接打开，打开后我们发现它的内容是一个Xml文件，并且在这个Xml文件中定义了游戏中使用的各种资源的路径，不过这些资源都是以AssetBundle的形式来定义的。这说明什么呢？这说明《新仙剑OL》的场景和界面资源是通过动态加载的方式加载到游戏当中的，而这些资源则是通过这个Xml文件来配置和管理的，这符合我们平时在Unity3D游戏开发中的观点和方法。通过这个文件，我们找到了assetbundles/config/movieconfig.unity3d这个文件，这是一个负责维护游戏中场景过场动画的文件。下面我们就来尝试解析这个文件，不过游戏制作方对config文件夹下的内容进行了加密，因为在这个文件夹下面是两个AssetBundle文件，博主尝试用extract和bundle-extract两个命令进行解析，可是得到的只是些文本文件，对我们继续研究没有什么帮助。那么好了，现在我们能够进行解析的只有xinjian_Data/sharedassets0.assets文件了： 1disunity extract C:\\Users\\Robin\\Desktop\\sharedassets0.assets &emsp;&emsp;这个解出来的话是些没有什么用的贴图文件，看来如果要提取音乐或者图片的话，还需要进行更加深入的研究才行啊。 解析《雨血前传.蜃楼》的assets文件&emsp;&emsp;因为解析《新仙剑OL》的assets文件没有得到什么有用的东西，所以我们接下来来尝试解析《雨血前传.蜃楼》的assets文件。这款游戏是博主比较喜欢的一款游戏，基于Unity3DY引擎，而且这款游戏是作为Unity3D官方范例来推广的，因此研究这款游戏对我们提高Unity3D的资源打包机制会比较有帮助。好了，我们直接上手： 1disunity extract C:\\Users\\Robin\\Desktop\\resources.assets &emsp;&emsp;哈哈，这款游戏果然没有让我们失望，我们得到了什么呢？ 蜃楼中各种Boss的头像 蜃楼中游戏连招视频1 蜃楼中游戏连招视频2 #总结 不同的游戏采用的资源配置方案都不同，不过一般可以从resources.assets这个文件入手作为突破点。 如果能拿到游戏中数据配置方案，对于我们提取游戏中的素材会有较大的帮助，因为这样方向性会更强些。 通过AssetBundle动态加载到场景中最好还是采用一个配置表来进行配置，这样便于我们管理和维护整个游戏项目。 如果没有服务器段的干预，理论上只要修改了本地的AssetBundle文件就可以实现对游戏内容和数据的更改，换句话说，可以做外挂和修改器。","categories":[{"name":"单机游戏","slug":"单机游戏","permalink":"https://qinyuanpei.github.io/categories/%E5%8D%95%E6%9C%BA%E6%B8%B8%E6%88%8F/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"穹之扉","slug":"穹之扉","permalink":"https://qinyuanpei.github.io/tags/%E7%A9%B9%E4%B9%8B%E6%89%89/"},{"name":"disunity","slug":"disunity","permalink":"https://qinyuanpei.github.io/tags/disunity/"},{"name":"反编译","slug":"反编译","permalink":"https://qinyuanpei.github.io/tags/%E5%8F%8D%E7%BC%96%E8%AF%91/"}]},{"title":"Unity3D游戏开发之反编译AssetBundle提取游戏资源","date":"2015-04-02T20:37:52.000Z","path":"posts/2799263488/","text":"&emsp;&emsp;各位朋友，大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是http://www.qinyuanpei.com。今天我们来说说通过反编译Unity3D的AssetBundle来提取游戏资源，博主写这篇文章的目的并非是要教大家如何去破解一款基于Unity3D引擎开发的游戏，而是想通过今天这篇文章来告诉大家如何在开发Unity3D游戏的过程中保护自己的游戏资源。 漫话Unity3D的AssetBundle&emsp;&emsp;对于AssetBundle，其实博主是在以前的文章中是有提到的。不知道大家还记不记得，博主曾经在写游戏开发和Lua的不解之缘这个系列文章的时候，提到并且使用过AssetBundle这种技术。具体来说呢，AssetBundle在Unity3D中是一种用于资源打包盒资源动态加载的解决方法，比如我们平时玩的单机游戏容量一般都比较大，这是因为制作人员在制作游戏的时候将所有的项目资源都整合到了一起。可是如果我们用AssetBundle来做这个游戏的话，我们就可以只在发布的游戏中提供支持游戏功能的核心部分，而将游戏当中的场景、模型等资源以AssetBundle的形式打包然后放到服务器上，这样当游戏客户端处于联网的时候就可以从服务器上下载这些资源，从而实现游戏资源的动态加载，由此可见AssetBundle可以帮助我们减少游戏的容量。如果是在需要安装包的场合下，那么游戏包容量的大小无疑会为游戏加些印象分。 为什么这幅图总让我想起仙剑四里四人在即墨那晚的时光呢？ &emsp;&emsp;比如最近《轩辕剑6外传穹之扉》这部单机游戏发布了，从各大游戏网站的评测到和一样我喜欢单机游戏的各位朋友们的亲身体验，大家一致的认为这部游戏整体表现还不错，应该考虑玩一玩。这样难免让博主有些心动，可是看到17个G的游戏容量时还是犹豫了下。DOMO小组从《轩辕剑6》就开始使用Unity3D引擎，在经历了第一部游戏的失败后，或许此次DOMO小组会将游戏优化的比较好吧。这里如果有喜欢单机游戏的朋友不妨去玩玩看，毕竟我们学习游戏开发的初衷就是做出好游戏，如果不热爱游戏又怎么能做出好游戏呢？好了，扯得有点远了，这里我们注意到一个重要的因素就是游戏容量，如果DOMO采用AeestBundle的话，游戏的容量肯定会减少很多。可是这样一来，它就不是单机游戏了嘛，对吧！ &emsp;&emsp;在Unity3D中AssetBundle是专业版中的一个功能，在免费版的Unity3D中是无法使用这个功能的，不知道在Unity5中这个功能是不是划分到了个人版中。好了，下面我们来看看如何使用AssetBundle。我们主要从使用AssetBundle打包和加载AssetBundle这两个方面来说： 使用Assetbundle打包&emsp;&emsp;使用AssetBundle打包主要通过BuildPipeline.BuildAssetBundle()这个方法来实现，该方法原型为： 123bool BuildAssetBundle (Object mainAsset,Object[] assets,string pathName, BuildAssetBundleOptions optionsBuildAssetBundleOptions.CollectDependencies | BuildAssetBundleOptions.CompleteAssets,BuildTarget targetPlatform&#x3D; BuildTarget.WebPlayer) &emsp;&emsp;在这个方法中，第一个参数是一个Object类型，表示一个激活的物体;第二个参数是一个Object[]类型，表示所有选中的物体;第三个参数是一个string类型，表示要导出的资源包的路径，资源包的扩展名可以是assetbundle或者unity3d;第四个参数表示的是打包选项，默认是完全打包和依赖打包。这里重点解释下这两个概念，完全打包是指所有资源都参与打包，比如说一个模型带有贴图和动画，那么打包模型的时候贴图和动画都会被作为资源打包。而依赖打包是相对于Prefab来说的，比如说PrefabA中引用了PrefabB这个对象，那么打包的时候这两个对象都会被打包，并且它们之间的这种依赖关系会在打包后继续保持；第五个参数是平台的选择，因为Unity3D是一个跨平台的游戏引擎，而各个平台现在的情况又不尽相同，因此现在Unity3D采取的方案是各个平台只能使用自己平台对应的AssetBundle，这一点希望大家在使用的时候注意啊。好了，现在我们来看一个简单的例子： 12345678910111213141516171819&#x2F;&#x2F;&#x2F; &lt;summary&gt;&#x2F;&#x2F;&#x2F; 输出AssetBundle&#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt;&#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;type&quot;&gt;平台类型&lt;&#x2F;param&gt;static void ExportToAssetBundle(ExportType type,BuildTarget target)&#123; &#x2F;&#x2F;获取存储路径 string savePath&#x3D;EditorUtility.SaveFilePanel(&quot;输出为AssetBundle&quot;,&quot;&quot;,&quot;New Resource&quot;,&quot;unity3d&quot;); if(savePath&#x3D;&#x3D;string.Empty) return; &#x2F;&#x2F;获取选中的对象 Object[] selection&#x3D;Selection.GetFiltered(typeof(Object),SelectionMode.DeepAssets); if(selection.Length&#x3D;&#x3D;0) return; &#x2F;&#x2F;打包 if(type&#x3D;&#x3D;ExportType.All)&#123; BuildPipeline.BuildAssetBundle(null,selection,savePath,BuildAssetBundleOptions.CollectDependencies,target); &#125;else&#123; BuildPipeline.BuildAssetBundle(obj,null,savePath,BuildAssetBundleOptions.CollectDependencies,target); &#125;&#125; &emsp;&emsp;这是一个简单的导出AssetBundle资源包的方法，它有两个参数，第一个参数表示是一个枚举类型，定义为ExportType，取Single时表示打包一个特定的激活物体，比如说一个模型、一个场景等等;取All时表示打包所有选中的物体，比如一个场景。第二个参数表示打包的平台，这个不用多说了。因为博主的免费版的Unity3D不支持AssetBundle，所以这里没法给大家演示了，具体效果请自行测试，有问题的话给博主留言就是了。 加载AssetBundle&emsp;&emsp;加载AssetBundle是一个从网络中下载资源的过程，因此需要使用Unity3D的WWW功能，这是一个简单的网络协议的封装，可以像浏览器一样访问某个URL地址或者是本地地址，访问WEB地址需要使用HTTP协议，访问本地地址需要使用File协议。我们来看一个具体的例子： 12345678910111213141516&#x2F;&#x2F;&#x2F; &lt;summary&gt;&#x2F;&#x2F;&#x2F; 加载一个unity3d格式的文件&#x2F;&#x2F;&#x2F; WEB地址——http:&#x2F;&#x2F;server.com&#x2F;xxx.unity3d&#x2F;&#x2F;&#x2F; 本地地址——file:&#x2F;&#x2F;.unity3d文件的绝对路径&#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt;IEnumerator LoadUnity3DFile(string url)&#123; WWW www&#x3D;new WWW(url); yield return www; if(www.error!&#x3D;null)&#123; Debug.Log(www.error); &#125;else&#123; AssetBundle bundle&#x3D;www.assetBundle; Instantiate(bundle.mainAsset,Vector3.zero,Quaternion.identity); &#125;&#125; &emsp;&emsp;在这里我们直接使用bundle.assetBundle获取了全部的资源，如果只需要获取资源中的一部分，则只需要通过bundle.Load()方法就可以了，这里需要传入资源的名称。当我们使用完资源后可以通过bundle.Unload()方法来卸载资源，达到释放内存的目的。 #从反编译《新仙剑OL》看AssetBundle打包&emsp;&emsp;好了，下面我们以《新仙剑OL》这款游戏的AssetBundle的反编译来探索下在使用AssetBundle打包应该注意哪些问题。《新仙剑OL》这款游戏呢，是采用Unity3D引擎开发的一款横跨客户端游戏和网页游戏的网络游戏，游戏以《仙剑奇侠传》初代游戏剧情为主，玩家将第三人称视角再次跟随主人公展开一段荡气回肠的感人故事。这款游戏总体来说还不错吧，因为毕竟是网游，我们不能用单机游戏的视角去评价，具体的原因大家都是知道的。 &emsp;&emsp;好了，为什么我们要选择这款游戏呢？ 第一，这款游戏的客户端只有30余M,体积小适合拿来研究(这就是AssetBundle的好处啊)* 第二，博主是一位仙剑玩家，一直希望有一天《仙剑奇侠传1》能够用3D技术重现，这个游戏满足了博主的好奇心 第三，网络上已经有朋友对这个游戏的打包进行了研究，这里感谢网友朋友提供部分.unity3d文件及相关文件。 &emsp;&emsp;我们选择的解包工具是一款叫做disunity的命令行工具，经过博主的尝试，这个工具真心强悍啊，可以解开.unity3d文件和.assets文件，可以拿到的数据形式有贴图、声音、模型等。具体的情况大家可以在稍后看到。 &emsp;&emsp;首先我们找到《新仙剑OL》的安装目录，然后我们就能发现一个叫做assetbundles的文件夹，这是怕大家不知道吗？这太明显了吧！我们打开文件夹会发现Charachers、NPC、Scene等等文件夹，继续往下找我们发现了好多的.unity3d文件，不过这些文件都是以.unity3d然后跟些随机字符串的形式存在的。根据网友朋友们的提示，这些文件就是.unity3d文件，不过游戏制作组为了干扰我们故意接了下随机字符在后面(呵呵，还有比这更弱的加密方式吗？)。博主看到这里的第一感觉就是想先用加载AssetBundle的方式来看看能不能将这些AssetBundle读取出来，因此果断改了文件扩展名，然后开始在Unity3D中读取，结果程序报错看来是我们想的简单了啊。没办法的办法，强行解包吧！在命令行中输入： 1disunity extract C:\\Users\\Robin\\Desktop\\s049.unity3d &emsp;&emsp;接下来程序会在桌面上生成一个上s049的文件夹，打开文件夹一看，尼玛，竟然直接拿到了模型的网格数据(.obj)和贴图数据(.dds)以及相关的Shader。这让我突然间有点不能接受啊，马上打开Blender将网格数据导入，结果童年的林月如就出现在了我们的面前： 林月如灰模 &emsp;&emsp;因为博主不会在Blender中给模型贴图，所以我们到Unity3D中完成贴图，首先需要将模型导出为FBX格式。好了，将模型导入Unity3D后，将贴图赋给模型，童年的林月如就闪亮登场了，哈哈！ 林月如贴图效果 &emsp;&emsp;好了，再来一张，不过这张没有贴图，需要大家自己来辨别这是谁啊，哈哈！ 柳梦璃灰模 &emsp;&emsp;通过disunity这个工具我们还能获取更多的资源，剩下的内容就由大家自己去探索吧。通过这部分的研究，我们可以总结出以下观点，希望大家在使用AsssetBundle这项技术时注意： 尽量在一个AssetBundle中打包多个资源，这样做的好处是别人没法通过加载AssetBundle拿到你做好的Prefab。 尽量将一个预制件分割成不同的部分分别存放，这样做的好处是即使别人拿到了你的预制件却是不完整的。 尽量利用动态脚本来加载场景而不是将整个场景打包，即使将整个场景打包，要把贴图和模型分开放置(因此如此，我虽然拿到了游戏的场景贴图，可是没有用啊) 尽量利用加密的方法来隐藏本地的AssetBundle或者使用不易察觉的存储位置作为AssetBundle的存储位置，不要用明文数据进行存储。 &emsp;&emsp;好了，今天的内容就是这样了，希望大家喜欢，AssetBundle打包是一个值得去深入研究的问题，今天博主提出的这些观点不过是对《新仙剑OL》这个游戏的打包提出de一些看法，如果大家有不同的看法，欢迎一起来交流！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"AssetBundle","slug":"AssetBundle","permalink":"https://qinyuanpei.github.io/tags/AssetBundle/"},{"name":"资源提取","slug":"资源提取","permalink":"https://qinyuanpei.github.io/tags/%E8%B5%84%E6%BA%90%E6%8F%90%E5%8F%96/"}]},{"title":"Unity3D游戏开发之编辑器扩展程序开发实例","date":"2015-03-31T00:53:22.000Z","path":"posts/70687890/","text":"&emsp;&emsp;各位朋友大家好，欢迎关注我的博客，我的博客地址是http://www.qinyuanpei.com。今天我们来说说如何在Unity3D中为编辑器开发扩展程序。提到扩展程序，相信大家都不会陌生了。不管是Google的Chrome浏览器还是经典的FireFox，这些浏览器最为人所称道的就是它支持各种各样的扩展。扩展程序是一种插件，它遵循插件式设计的原则，可以随时在宿主程序中安装、卸载而不会影响宿主程序的正常运行。我们知道在Unity3D中有各种各样的插件，如NGUI、2DToolKit、EasyTouch等等都是一种扩展程序。扩展程序在丰富宿主程序功能的基础上，可以帮助宿主程序完成大量额外的工作。可以说正是因为Unity3D拥有大量的插件和资源支持，Unity3D才能够受到大家如此的追捧。可是作为一个有节操的程序员，如果仅仅会使用工具，那么我们和普通用户有什么区别啊，所以在今天的文章中博主将通过三个具体的实例来教大家如何为Unity3D的编辑器开发扩展程序，希望对大家学习Unity3D技术有所帮助！ 常用的命名空间和类&emsp;&emsp;开发Unity3D编辑器扩展程序的命名空间主要是UnityEditor，在该命名空间下常用的类有EditorGUI、EditorGUILayout、EditorWindow(可能还有其它的类，不过到目前为止博主就用过这些，如果有其它的类，欢迎大家来补充啊)。为Unity3D编辑器开发的扩展程序同样是一种脚本，通常需要将脚本文件放在项目资源文夹下的Editor文件夹中，即Assets/Editor。不过该脚本不再继承自MonoBehaviour，具体的内容我们会放到后面的实例中来讲Unity3D编辑器扩展程序的形式通常有两种，一种是没有界面的(如案例1)、一种是有界面的(如案例2、案例3)。对于没有界面的这种扩展程序，我们只需要定义一个类(无需继承任何父类)然后再这个类中定义一个静态的方法就可以了;而对于有界面的这种扩展程序，我们需要让定义的这个类继承EditorWindow并实现OnGUI()方法,因为在OnGUI()方法中我们将会对扩展程序的界面进行绘制，不过无需担心啦，因此扩展程序的界面绘制和Unity3D脚本中的OnGUI()方法是相似的，我们要做的就是要熟悉常见的控件。好了，下面进入今天的实战环节，大家准备好了吗？ Unity3D编辑器扩展程序开发实例案例1 快速修改贴图类型&emsp;&emsp;Unity3D4.6版本的一个重要更新就是UGUI和Unity2D的支持，因为有了对Unity2D的支持，所以Unity3D的贴图类型就增加了一个Sprite的类型。如果导入到Unity3D中的贴图是那种打好的小图的图集，那么Unity3D能够自动识别为Sprite类型。可是对于那种单张的贴图，Unity3D默认还是按照默认的设置来处理，因此如果每次需要用到这些图片，就必须手动地将其TextureType设为sprite，如果贴图数量比较少，那么手动修改也没有什么了。可是如果项目中的贴图数量较多的话，这样一张一张地去调整TextureType可能会浪费大量的时间啊！怎么办呢？简单！写代码！ 12345678910111213141516171819202122232425262728293031323334using UnityEngine;using UnityEditor;using System.Collections;public class ImportSprite&#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 批量将贴图格式转换为Sprite &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; [MenuItem(&quot;Tools&#x2F;ConvertToSprite&quot;)] static void ConvertToSprite() &#123; &#x2F;&#x2F;获取所有被选中的物体 Object[] selection&#x3D;(Object[])Selection.objects; &#x2F;&#x2F;合法性处理 if(selection.Length&#x3D;&#x3D;0) return; &#x2F;&#x2F;批量导入贴图 foreach(Object obj in selection) &#123; &#x2F;&#x2F;取得每一张贴图 Texture texture&#x3D;(Texture)obj; &#x2F;&#x2F;获得贴图路径 string localpath&#x3D;AssetDatabase.GetAssetPath(texture); &#x2F;&#x2F;贴图导入 TextureImporter importer&#x3D;(TextureImporter)AssetImporter.GetAtPath(localpath); &#x2F;&#x2F;设置贴图类型 importer.textureType&#x3D;TextureImporterType.Sprite; &#x2F;&#x2F;导入项目资源 AssetDatabase.ImportAsset(localpath); &#125; &#x2F;&#x2F;刷新项目资源 AssetDatabase.Refresh(); &#125;&#125; &emsp;&emsp;我们将这个脚本放到Editor文件夹中，如果不出现什么意外的话，Unity3D的菜单栏中会增加一个Tools的菜单项，该菜单项目前只有一个子菜单项ConvertToSprite。好了，现在我们要做的事情就是在项目资源文件夹中选中要转换成sprite类型的贴图，然后单击Tools-&gt;ConvertToSprite。很快(具体有多快可以自己在编辑器窗口中去尝试，总之就是很快就对了，哈哈)所有的贴图的都如我们所愿地被转换成了sprite类型，此时此刻你有没有懊悔当年手动创建的92个空物体，反正博主是后悔当初做塔防游戏的时候手动创建了92个空物体，如果那个时候我知道Unity3D可以做这些事情，我打死都不会手动去创建92个空物体的，现在想想都佩服当时自己的勇气啊。好了，作为第一个编辑器扩展程序，我们稍微总结下主要的内容： 在Unity3D中我们可以通过TextureImporter、ModelImporter、AudioImporter、MovieImporter等来分别向Unity3D中导入贴图、模型、音频、视频等等，经过设置后最终通过AssetDatabase.ImportAsset()来将其添加到项目中热完全，最后需要使用AssetDatabase.Refresh()方法来刷新本地资源，使导入的资源生效。 Selection.objects取得的物体无法区分是从场景中选取的还是从项目资源文件夹中选取的，如果需要从场景中来选取，建议使用Selection.transforms来代替。案例2 动态生成Prefab&emsp;&emsp;首先让我们来回顾一下大家平时制作Prefab的流程： 在项目资源文件夹中选取素材拖放到场景中 在场景中调整名称、位置、缩放、组件等等 将物体拖放到Prefabs文件夹下生成Prefab尽管这是Unity3D官方推荐的一种做法，可是如果我们现在有大量的Prefab要制作怎么办呢？一个最直观的例子就是游戏里的敌人。在一个中等规模的游戏中，敌人的种类通常很多，而且每一个敌人的行为可能都不相同。然后从宏观的角度来看，敌人的大部分特征都是相同的，因此我们这里考虑使用程序动态生成Prefab，这里假定Prefab不需要附加脚本，因为如何给Prefab附加脚本博主还没有研究出来。好了，下面我们来看代码：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778using UnityEngine;using UnityEditor;using System.Collections;public class PrefabWrap : EditorWindow &#123; &#x2F;&#x2F;预设物体名称 private string prefabName; &#x2F;&#x2F;预设物体tag private static string prefabTag; &#x2F;&#x2F;预设物体Layer private static int prefabLayer; &#x2F;&#x2F;当前插件窗口实例 private static PrefabWrap instance; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 显示插件窗口 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; [MenuItem(&quot;Tools&#x2F;PrefabWrapTool&quot;)] static void PrefabWrapTool() &#123; &#x2F;&#x2F;获取当前窗口实例 instance&#x3D;EditorWindow.GetWindow&lt;PrefabWrap&gt;(); &#x2F;&#x2F;显示窗口 instance.Show(); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 在OnGUI方法中实现界面定制 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void OnGUI() &#123; &#x2F;&#x2F;绘制一个文本框 prefabName&#x3D;EditorGUILayout.TextField(&quot;预设物体名称:&quot;,prefabName); &#x2F;&#x2F;绘制预设物体标签选择框 prefabTag&#x3D;EditorGUILayout.TagField(&quot;预设物体tag:&quot;,prefabTag); &#x2F;&#x2F;绘制预设物体层级选择框 prefabLayer&#x3D;EditorGUILayout.LayerField(&quot;预设物体Layer:&quot;,prefabLayer); &#x2F;&#x2F;绘制一个按钮 if(GUILayout.Button(&quot;生成预设物体&quot;,GUILayout.Height(20))) &#123; if(prefabName!&#x3D;string.Empty) &#123; CreatePrefab(prefabName); &#125; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 批量创建Prefab &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; static void CreatePrefab(string name) &#123; &#x2F;&#x2F;获取所有被选中的物体 Object[] selection&#x3D;(Object[])Selection.objects; &#x2F;&#x2F;合法性处理 if(selection.Length&#x3D;&#x3D;0) return; &#x2F;&#x2F;批量处理 foreach(Object obj in selection) &#123; &#x2F;&#x2F;生成预设 GameObject prefab&#x3D;(GameObject)PrefabUtility.CreatePrefab(&quot;Assets&#x2F;Prefabs&#x2F;&quot;+name+&quot;.prefab&quot;,(GameObject)obj); &#x2F;&#x2F;设置tag和Layer prefab.tag&#x3D;prefabTag; prefab.layer&#x3D;prefabLayer; &#x2F;&#x2F;导入项目 AssetDatabase.ImportAsset(AssetDatabase.GetAssetPath(prefab)); &#125; &#x2F;&#x2F;刷新本地资源 AssetDatabase.Refresh(); &#125; &#x2F;&#x2F;当界面发生变化时重绘 void OnInspectorUpdate() &#123; Repaint(); &#125;&#125; &emsp;&emsp;首先我们让这个脚本继承自EditorWindow，这样它将在Unity3D中显示一个窗口。在OnGUI()方法中我们定义了窗口需要绘制的内容为一个文本框、两个选择框和一个按钮，当单击按钮后会执行CreatePrefab()方法。当界面发生变化的时候，需要对窗口进行重绘。最终的程序演示效果如下： 动态生成Prefab效果演示 &emsp;&emsp;当我们在场景中选择好物体后，只要填好预设物体的名称、tag、Layer就可以直接生成Prefab了，不过这里有个问题，因为生成Prefab必须要传入一个GameObject，因此如果直接选择项目资源文件夹里的内容可能会报错，因为你选择的不是一个GameObject。博主做这样一个功能的初衷原本是想直接为每一个精灵图片生成预设文件，现在看来需要寻找其它的方法了，不过基本思路是创建一个空物体，然后向这个空物体中增加子物体，如果大家对此有兴趣的话，可以结合本文的方法自行去尝试。 案例3 快速为Sprite设置图集tag&emsp;&emsp;接下来这个案例呢，同样是和贴图有关的内容。我们知道在没有UGUI以前，我们使用NGUI的时候要做的第一件事情就是把要用到的贴图打成图集，现在在Unity3D里面我们可以通过贴图的Packing Tag来实现图集打包，就是说具有相同Packing Tag的物体会被打到一张大图上，这样做的好处是节省资源。如果大家对这部分内容不太熟悉，可以了解下我的这篇文章。既然明白了原理，那么我们为什么不来尝试着通过程序将这件事情一次完成呢？好了，直接给出代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081using UnityEngine;using UnityEditor;using System.Collections;public class PackageTools : EditorWindow &#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 图集标签 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private string tagName; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 当前实例 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private static PackageTools instance; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 在OnGUI方法中实现界面定制 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void OnGUI() &#123; &#x2F;&#x2F;绘制一个文本框 tagName&#x3D;EditorGUILayout.TextField(&quot;PackageTagName:&quot;,tagName); &#x2F;&#x2F;绘制一个按钮 if(GUILayout.Button(&quot;Package&quot;,GUILayout.Height(20))) &#123; if(tagName!&#x3D;string.Empty) &#123; PackgeTextureWidthTag(tagName); &#125; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 显示插件窗口 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; [MenuItem(&quot;Tools&#x2F;ShowPackageTools&quot;)] static void ShowPackageTools() &#123; &#x2F;&#x2F;获取当前窗口实例 instance&#x3D;EditorWindow.GetWindow&lt;PackageTools&gt;(); &#x2F;&#x2F;显示窗口 instance.Show(); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 快速为图片生成图集 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; static void PackgeTextureWidthTag(string tagName) &#123; &#x2F;&#x2F;获取所有被选中的物体 Object[] selection&#x3D;(Object[])Selection.objects; &#x2F;&#x2F;合法性处理 if(selection.Length&#x3D;&#x3D;0) return; &#x2F;&#x2F;批量处理贴图 foreach(Object obj in selection) &#123; &#x2F;&#x2F;取得每一张贴图 Texture texture&#x3D;(Texture)obj; &#x2F;&#x2F;获得贴图路径 string localpath&#x3D;AssetDatabase.GetAssetPath(texture); &#x2F;&#x2F;贴图导入 TextureImporter importer&#x3D;(TextureImporter)AssetImporter.GetAtPath(localpath); &#x2F;&#x2F;判断贴图类型,只有贴图类型为Sprite且精灵类型为SpriteMode if(importer.textureType&#x3D;&#x3D;TextureImporterType.Sprite) &#123; importer.spritePackingTag&#x3D;tagName; &#x2F;&#x2F;导入项目资源 AssetDatabase.ImportAsset(localpath); &#125; &#125; &#x2F;&#x2F;刷新本地资源 AssetDatabase.Refresh(); &#125; &#x2F;&#x2F;当界面发生变化时重绘 void OnInspectorUpdate() &#123; Repaint(); &#125;&#125; &emsp;&emsp;因为打包图集只需要一个参数，因此这个打包工具只需要一个文本框和一个按钮，整个过程和案例2是一样的，这里就不做分析了。这个扩展程序的演示效果如下： 图集打包效果演示 &emsp;&emsp;好了，这就是今天的内容了，今天的内容基本上涵盖了为Unity3D开发扩展程序的基本内容，我们接下来要做的就是积极地在平时生活、工作和学习中寻找问题和解决问题，”授人以鱼不如授人以渔”，向他人传授知识和技能，这件事情本身对博主而言就是是快乐的，博主希望今天的内容大家能够喜欢。好了，谢谢大家！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"扩展","slug":"扩展","permalink":"https://qinyuanpei.github.io/tags/%E6%89%A9%E5%B1%95/"},{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"编辑器","slug":"编辑器","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E8%BE%91%E5%99%A8/"}]},{"title":"从[复活]和[暂停/恢复]谈游戏数据配置管理","date":"2015-03-27T02:12:58.000Z","path":"posts/3356910090/","text":"&emsp;&emsp;随着游戏制作技术的不断发展，在经历了从2D到3D、从单机到网游、从PC游戏到移动游戏的种种演变后，玩家对于游戏质量的要求越来越高，游戏制作的难度相应地增加，整个游戏研发的体系开始变得庞大而复杂，由此就产生了游戏数据配置和管理的相关问题。本文将从游戏中的”复活”和”暂停/恢复”这两个应用场景的角度来谈谈在游戏开发中如何对游戏中的数据进行管理和配置。 为什么要谈游戏数据的配置和管理&emsp;&emsp;不知道大家是不是会和博主有一样的想法，就是当你回头来思考游戏开发的时候，你常常会发现，如果忽略游戏的画面、情节、特效等等这些游戏中的可视化的东西，那么其实游戏从本质上来说就是一个大型的有限状态机(FSM)，而我们通常所做的事情基本就是在维护这个有限状态机里面的各种状态，从游戏加载到游戏开始、从游戏开始到游戏中各种事件的发生再到各种事件影响到整个有限状态机的状态，我们通常所做的事情无外乎是在维护各种状态。这种感觉在RPG游戏中可能会更明显些，因为在RPG中玩家可能是在场景中行走或者奔跑、可能是在和场景中的某个NPC进行对话、可能是在和面前的敌人进行战斗、可能是在和杂货店的老板讨价还价……可以说在整个游戏当中无时无刻不在进行游戏状态的切换，那么在不同的状态间切换的时候，什么最为重要呢？答案是数据。什么是数据呢？玩家的生命值、魔法值、战斗力、防御力，物品的用途、价格、数量，游戏的剧情、对话、音乐等等这些都是数据。当我们在状态间进行切换的时候，其实真正改变的就是这些数据。由此可见，面对复杂而庞大的游戏体系，如何对游戏中的数据进行配置和管理是一件值得我们去思考的问题。 从应用场景来看游戏数据的配置与管理&emsp;&emsp;首先我们来从游戏当中的两个常见的应用场景:”复活”和”暂停/恢复”来看看游戏数据配置和管理的重要性。这里以博主的一款跑酷游戏为例： 游戏截图 应用场景——“复活”&emsp;&emsp;”复活”是一个在游戏中特别常见的功能，复活这一设定的好处在于无需重新开始游戏就能再次回到游戏当中，当然这只是我们最为直观的一个感受，更为深刻的原因是，游戏者巧妙地利用了玩家在游戏任务失败那一刻的心理。现在生活中每一个人都喜欢胜利，这种心理到了游戏世界中同样是适用的，因为游戏的目的无非就是让玩家有种成就感以获得快乐。可是当游戏任务失败的时候，玩家会竭尽全力不断尝试去打败Boss以获得游戏的胜利，因此在游戏中有这样一个设定，可以引导玩家在游戏中形成消费的习惯，这样游戏就能从玩家身上盈利。好了，我们来看看一个基本的”复活”的逻辑吧！ 12345678910111213141516171819private void Update()&#123; &#x2F;&#x2F;如果玩家的生命值大于0则游戏正常进行 if(Player.Hp&gt;0) &#123; &#x2F;&#x2F;游戏状态为Normal GameManager.Instance.GameState&#x3D;GameStateEnum.Normal; &#x2F;&#x2F;执行正常的游戏逻辑 DoNormalEvent(); &#125;else &#123; &#x2F;&#x2F;游戏状态为Over GameManager.Instance.GameState&#x3D;GameStateEnum.Over; &#x2F;&#x2F;显示GameOver ShowGameOver(); &#x2F;&#x2F;玩家复活 ReLive() &#125;&#125; &emsp;&emsp;玩家复活需要做两件事情： 将游戏的状态从Over调整到Normal 将玩家的状态从死亡调整到正常 &emsp;&emsp;调整游戏的状态特别容易，因为GameManager是一个典型的单例模式，因此我们可以直接将GameState从Over变成Noral。可是对于玩家状态的调整，我们却遇到了困难。问题出在什么地方呢？问题出在我们将玩家的生命值等一系列属性都写在了PlayerController这个类中，如果我们将玩家的属性全部都设为Private，那么我们将无法从外部来调整这些属性。比如我们想让玩家满血复活，可是因为这些属性都是私有的，我们无法从外部访问，所以我们在给玩家恢复生命值的时候，无法获得玩家当前的生命值以及最大生命值。可是如果我们将玩家的属性全部都设为Public，我们可能不得不去面对在编辑器窗口中为每一个属性去赋值，因为一旦我们试图调整游戏双方力量的平衡时，这将是我们不得不去面对的问题，更为致命的玩家的属性并不是永远不变的，比如在RPG游戏中玩家的生命值等属性会随着角色等级的提升而不断增加。因此不管我们将这些属性设为Public还是Private，我们都无法保证每次访问到的这些数据都是最新的数据。换句话说，我们不能想当然地在脚本中将玩家的属性写成一个不变的值，因为这些数据随时都在发生着变化，当然如果像敌人和Boss这种数值相对稳定的情况，我们可以直接在脚本中将其写成一个固定值，不过我并不推荐大家这样做。由此可见，游戏中数据配置和管理的一个重要作用是维持各个状态间的正常切换。如图是雨血前传.蜃楼中的复活界面，每次复活需要消耗一个复活玉： 2015-03-27 &emsp;&emsp;那么博主在这款跑酷游戏里面是怎样做这个复活的呢？因为博主当时在设计这个游戏的时候考虑不周，直接将玩家的生命值写成了100，所以在复活玩家时候，同样是先将游戏的状态调整过来，然后再将相关的GUI窗口隐藏，然后将玩家的生命值重新设置为100，重新生成玩家就好了。正是因为感觉这段时间做游戏缺乏一种良好的游戏架构，所以每次游戏做到最后都是自己把逼到了绝路上，留给了自己一个自己都不想再去维护的烂摊子，这样显然是不好的，所以以后需要在正式动手写代码前做好规划，相信这样就能够保证游戏的质量了吧！任何东西学习到一定阶段都会遭遇瓶颈，尽管打破这种瓶颈的过程是痛苦的，可是如果不去打破它，那么你永远都只能停留在这个位置。 应用场景——“暂停/恢复”&emsp;&emsp;和”复活”一样，”暂停/恢复”同样是一个在游戏中常见的功能，该功能是给了玩家暂时离开游戏的一种选择，可以保证玩家在做其它事情的时候不会影响到游戏的进程。比如在仙剑奇侠传、古剑奇谭等游戏中，玩家可以按下ESC键调出游戏设置界面，在玩家进入游戏设置界面的这段时间，游戏世界里的时间似乎是静止的，场景中的敌人不会因为玩家在查看系统设置界面就去主动偷袭玩家，因为这种情况下游戏是暂停的。而当玩家退出系统设置界面后，游戏恢复为正常状态。到了移动互联网时代，游戏中出现”暂停/恢复”的情况更为普遍，这是由移动互联网时代人们玩游戏更注重休闲和娱乐这样的性质来决定的。记得天天酷跑刚刚在微信上线的那段时间，我身边好多同学都在上课的时候玩，可是因为这游戏一跑起来就根本停不下来，所以经常是一次游戏玩下来一节课就结束了。博主不提倡这样啊，玩游戏归玩游戏，可是什么事情都要有个度啊，不然就会变成玩物丧志。好了，我们分析这个案例的目的无非就是想告诉大家在游戏里增加这样一个”暂停/恢复”的功能还是十分必要的。好了，现在我们来分析下在这个应用场景中发生状态转换的时候都会牵扯到那些数据吧！ &emsp;&emsp;首先游戏暂停后，场景内所有的物体都会停止运动，此时游戏中每个物体的状态都发生了变化，不过因为在Unity3D中控制游戏暂停/的恢复主要是通过调整Time.timeScale的值来实现的。当Time.timeScale取值为0时，游戏暂停；当Time.timeScale取值为1时，游戏恢复正常。不过需要注意的是Time.timeScale会对Unity3D中所有的时间产生影响如FixedUpdate()、协程、Destroy()、动画组件等等，所以如果对暂停后的游戏状态有特殊要求的话，建议还是通过其它的方法来实现吧！这里没有提到Update()和LaterUpdate()这是因为这两个方法不会受到影响。我们来看这样一段代码： 1234567891011121314&#x2F;&#x2F;游戏是否暂停private bool isPause&#x3D;false;&#x2F;&#x2F;暂停&#x2F;恢复游戏的方法private void Resume()&#123; if(!isPause)&#123; Time.timeScale&#x3D;0; isPause&#x3D;true; &#125;else&#123; Time.timeScale&#x3D;1; isPause&#x3D;false; &#125;&#125; &emsp;&emsp;通过这段代码我们就能够实现一个基本的游戏”暂停/恢复”的功能。在游戏管理类GameManager中我们定义了一个玩家的得分。正常情况下，当玩家没有死亡的时候会在GUI中更新玩家的得分，而玩家的得分是直接采用在Update()中累加的方式实现的，因此玩家的得分会在游戏暂停后继续更新，这当然是不符合实际情况的，因此可以在这个增量前乘上一个Time.deltaTime就可以解决这个问题了。博主举这个例子无非就是想告诉大家使用这种方法来暂停游戏会存在这样的问题，希望大家以后注意啊！ 跑酷游戏复活界面 游戏数据配置和管理的思路和方法&emsp;&emsp;既然我们在今天的的文章中主要阐述的就是游戏数据配置和管理，那么下面我们就来说说游戏数据配置和管理的常见的思路和方法。根据游戏中数据变动的相对大小，我们将游戏中的数据分为静态数据和动态数据两类。 静态数据&emsp;&emsp;静态数据是指在游戏中基本不变或者不需要变动的数据。比如游戏中Boss的等级和生命值一般都是确定的，因此这种类型的数据可以称为静态数据。同样地，游戏中NPC对话的内容是一种静态数据，因为NPC的对话内容是在设计剧情的时候就设计好的无需再对它进行修改。那么对于静态数据，我们可以考虑下列方法： 将静态数据作为常量定义在一个类中，这样做的好处是无需对每一个脚本进行修改。 将静态数据存储在文件当中，这样做的好处是可以对数据进行管理，缺点是需要针对不同的文件编写解析接口，游戏开发中常用的数据存储形式有：Json、Xml、Excel、CSV等。 将静态数据存储在数据库当中，如SQLIite等，可是这样做的缺点同样很明显，从本地读取数据库会消耗大量的资源，而且数据库文件一旦丢失，整个游戏都将无法运行。 动态数据&emsp;&emsp;动态数据是指在游戏中会不断变化的数据，比如玩家的得分、玩家的生命值、玩家的经验值等等。动态数据的处理方式除作为常量写在类中以外，其它的都和静态数据是一样的，在此就不再多说了。 #总结&emsp;&emsp;可能今天这篇文章显得唠叨些，甚至从技术的角度来看，这篇文章都没有讲到什么有价值的技术要点。可是在博主看来，不管一项技术有多么伟大，如果没有良好的架构或者说结构，那么当这个项目的规模到了一定程度以后，这个项目就会出现问题。因为根据破窗户理论，当你看到窗户破了而不去及时修补的话，那么时间一长你破掉的就是整个房子了。回顾博主这么长时间的游戏开发，其实做过的好多游戏到最后之所以没有做完，都是因为到最后项目基本失控、变成了一个连自己都不愿意去维护的项目，这样的情况是可怕的。平时是你一个人做项目，可能你觉得这些都没有什么，可是当你和别人一起去完成这样一个项目的时候，你的这些问题都会成为整个团队的问题。博主一直想知道自己做游戏和团队在一起做游戏会有什么不同，因为博主感觉自己在这一块确实不是掌握得很好。虽然说架构这种事情你做多了才会有经验，可是你现在发现了问题，为什么不在现在改掉呢？架构真的很重要，致那些因为架构死去的项目，真正的项目应该死在实践中，因为架构的问题最终变得不可收拾的，这件事情本身就是可耻的。好了，今天就说这么多了。","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"数据","slug":"数据","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E6%8D%AE/"},{"name":"状态","slug":"状态","permalink":"https://qinyuanpei.github.io/tags/%E7%8A%B6%E6%80%81/"}]},{"title":"为Hexo开发一个网易云音乐的文章插件","date":"2015-03-24T10:32:39.000Z","path":"posts/828223375/","text":"&emsp;&emsp;当你打开这篇文章的时候，你听到一首熟悉的旋律，那是因为在你的心里始终装着一张泛黄的CD，你从来不愿意打开它，即使外表早已积满了灰尘，你依然视它如新的一般，我们喜欢把它叫做时光或者说是青春。 &emsp;&emsp;正如你所看到的，我在博客文章中插入了网易云音乐的播放器。这是一个基于Flash技术实现的组件。因为博主特别喜欢网易云音乐这个音乐产品，所以博主想将这个播放器带入到我的博客。在博客中使用这个播放器，只要在文章中添加如下代码： 12&lt;embed src=\"http://music.163.com/style/swf/widget.swf?sid=29713754&amp;type=2&amp;auto=1&amp;width=278&amp;height=32\" width=\"298\" height=\"52\" allowNetworking=\"all\"&gt;&lt;/embed&gt; &emsp;&emsp;可是这样的结构对于一个写博客的人来说还是显得臃肿了，能不能让这个结构更简单写呢？简单到这样： 1[music:29713754] &emsp;&emsp;因为在这段代码中真正和音乐有关的只有sid这个参数，所以我们我们只需要关注这个参数就好了。那么，现在我们其实就是在做这样一件事情，我们在文章中插入这样一个[key:value]的结构，然后通过程序将它替换成相应的HTML结构，这样就实现了在Hexo的文章中使用[key:value]结构来编写简单插件的功能，如果经历过使用wordpress建站的朋友一定知道，在wordpress中存在许多这样的类似插件，可以帮助写作者简化某些输入内容。好了，那么今天我们就来试着为hexo编写这样一个小插件吧！为了避免将插件写到网页里的时候出现错误，我们首先在NodeJS中测试，测试程序如下： 12345678910111213141516171819202122232425//定义测试内容var str=\"这是一条测试内容以测试这个程序是否能够正确运行,现在让我们来听一首《匆匆那年》[music:29713754]\";//获得匹配内容var dicts=str.match(/\\[(.*?):(.*?)\\]/g);if(dicts.length==0) return;//对每一个匹配项进行处理for(var i=0;i&lt;dicts.length;i++)&#123; //对匹配项进行分割,拆分结果为'[music'和'29713754]' //我TM就郁闷了，在这里写成'/:/'报错 //可是写成/:/就顺利通过 var dict=dicts[i].split(/:/); //获得键名 var key=dict[0].substring(1,dict[0].length); //获得ID var id=dict[1].substring(0,dict[1].indexOf(']')); //判断键名的类型 if(key=='music') &#123; str=str.replace(dicts[i],'&lt;embed src=\"http://music.163.com/style/swf/widget.swf?sid='+ id + '&amp;type=2&amp;auto=1&amp;width=278&amp;height=32\" width=\"298\" height=\"52\" allowNetworking=\"all\"&gt;&lt;/embed&gt;'); &#125; &#125; //输出结果 console.log(str); &emsp;&emsp;这段代码主要就是通过正则表达式来匹配文章正文中所有的[key:value]结构，然后根据key来确定当前结构表什么类型，根据id来确定当前类型的参数，尽管这里只提到了一个music的类型，不过我相信只要大家开动脑筋、发挥想像相信会有更好的想法产生吧！这段代码博主在本地使用NodeJS测试了没有不过什么问题，大家可以在截图中清楚地看到[music:29713754]已经被替换称了网易云音乐的Flash组件，这样在网页中就会显示出网易云音乐的播放器，我们就能听到这熟悉而温暖的旋律了。 NodeJS程序演示效果 &emsp;&emsp;不过真的想要吐槽下JavaScript。本来JavaScript就是弱类型了吧，NodeJS再给弄一个除了报错什么都不会的命令行，因此在本地调试JavaScript代码实在是太困难了。昨天为了写出一个正确的正则表达式奋战到三点钟，后来终于给写出来了，实在压抑不住内心的喜悦匆匆忙忙地就往模板里面放，结果刚放进去再重新生成页面地时候博客就华丽地挂了，尝试了若干次无果后，果断放弃然后用备份地主题文件进行了覆盖替换。总之，经过这次事情，我是再不想接触Javacript了，你不让我面向对象我可以容忍，因为JavaScript本来就不是一门面向对象的语言。可是你总得让我知道我写的这个变量是个什么类型吧？因为这个插件的编写涉及到JavaScript、NodeJS、Hexo所以整个过程中编程的效率特别低，因为在没有文档、没有语法提示的情况下来写这样一段代码，在我看来完全就是摸着石头过河啊！ &emsp;&emsp;好了，停止吐槽！我们接下来看看这段代码怎样和Hexo整个到一起。按照博主的理解既然我们要对文章的内容中的[key:value]结构进行替换，我们首先应该知道文章的内容在哪里。经过这么长时间对Hexo的学(zhe)习(teng),我们知道文章的内容是定义在layout_partial下的article.ejs这个文件中，在这个文件中有一个叫做item的变量,这个item的真实身份其实是Hexo中定义的一个全局变量post。顾名思义，这个post就是我们发表的文章啦，它有一个重要的属性叫做content，就是我们这里要用到的东西了。我们来article.ejs这个文件中定义的一段代码： 1234567891011121314&lt;div class=\"entry\"&gt; &lt;% if (item.excerpt &amp;&amp; index)&#123; %&gt; &lt;%- item.excerpt %&gt; &lt;% &#125; else &#123; %&gt; &lt;% if (!index)&#123; %&gt; &lt;% if (!index &amp;&amp; item.toc)&#123; %&gt; &lt;%- partial('extra/toc') %&gt; &lt;% &#125; %&gt; &lt;%- item.content %&gt; &lt;% &#125; else &#123; %&gt; &lt;%- item.content.substring(0,item.content.indexOf('\\n')) %&gt; &lt;% &#125; %&gt; &lt;% &#125; %&gt;&lt;/div&gt; &emsp;&emsp;这段代码是关于文章的内容的，因此我们要对文章内容进行修改的话，就要先读懂这块儿的代码。这块儿代码首先判断文章是不是处于首页位置(index)，接着判断文章中有没有ReadMore标记(excerpt)。如果文章在首页位置(index)且存在ReadMore标记(excerpt)，那么文章显示的是ReadMore标记前的内容(item.excerpt);如果文章没有ReadMore标记(excerpt)且文章在首页位置(index)，那么文章显示的整篇文章(item.content);如果文章在首页(index)可是没有ReadMore标记(excerpt)，那么选取文章的第一段作为文章的摘要来显示。这就是博主的博客目前采用的方案了，如果大家对这部分感兴趣的话，可以看看自己的博客使用的主题是如何定义这部分内容的，然后在此基础上做些调整以满足个性化的需求。 &emsp;&emsp;好了，那么在了解了这部分内容后，我们应该马上就能想到，我们需要掉正的代码应该是在第9行这个位置，即当文章不在首页的时候要显示的内容。好了，按照我们在测试程序中的写法，我们可以写出如下代码： 1234567891011121314151617&lt;% var dicts&#x3D;item.content.match(&#x2F;\\[(.*?):(.*?)\\]&#x2F;g); %&gt;&lt;% if(dicts.length&#x3D;&#x3D;0)&#123; %&gt; &lt;%- item.content %&gt;&lt;% &#125; else &#123; %&gt; &lt;% for(i&#x3D;0;i&lt;dicts.length;i++) %&gt; &lt;% &#123; %&gt; &lt;% var dict&#x3D;dicts[i].split(&#x2F;:&#x2F;); %&gt; &lt;% var key&#x3D;dict[0].substring(1,dict[0].length); %&gt; &lt;% var id&#x3D;dict[1].substring(0,dict[1].length-1); %&gt; &lt;% if(key&#x3D;&#x3D;&#39;music&#39;) %&gt; &lt;% &#123; %&gt; item.content&#x3D;item.content.replace(dicts[i],&#39;&lt;embed src&#x3D;&quot;http:&#x2F;&#x2F;music.163.com&#x2F;style&#x2F;swf&#x2F;widget.swf?sid&#x3D;&#39;+ id + &#39;&amp;type&#x3D;2&amp;auto&#x3D;1&amp;width&#x3D;278&amp;height&#x3D;32&quot; width&#x3D;&quot;298&quot; height&#x3D;&quot;52&quot; allowNetworking&#x3D;&quot;all&quot;&gt;&lt;&#x2F;embed&gt;&#39;) &lt;% &#125; %&gt; &lt;% &#125; %&gt; &lt;%- item.content %&gt;&lt;% &#125; %&gt; &emsp;&emsp;相信经过博主的一番介绍，大家已经对这段代码相当熟悉了吧，这里就是先做判断，判断文章内容中是否有[key:vaule]这样的结构，如果没有就直接输出item.content;如果有就需要对其进行替换后再输出item.content。好了，现在我们用这段代码替换掉第9行代码，然后再次输出网页。可是结果让我们白忙活了一场，因为Hexo在输出网页的时候会报错，可能是因为博主写的JavaScript脚本Hexo无法解析吧！好了，从昨天下午开始差不多都在想着怎样解决这个问题，到现在还是没有一点头绪，文章里讲述的方法可以作为一种尝试，如果有兴趣、有精力、有能力解决这个问题的人，可以去进一步深入地探索这个问题。今天的内容就是这样了，睡觉！ 2015年11月10日更新:&emsp;&emsp;昨天抽空研究了下Hexo的插件机制，发现在Hexo中提供了一种标签插件，可以帮助我们快速完成这种需求，所以就记录在这里。首先，它的原理是根据这样一个简单的标记来进行处理，当我们输入默认的这样的标记的时候它会被渲染为普通的引用标记，当我们在这个标记内传入参数后就可以利用程序进行处理。例如我们编写这样的简单的JS文件： 1234567891011121314151617181920212223242526272829303132/*** hexo-tag-cloudmusic* https://github.com/qinyuanpei/hexo-tag-cloudmusic.git* Copyright (c) 2015, qinyuanpei* Licensed under the MIT license.*/hexo.extend.tag.register('cloudmusic', function(args)&#123; var sid = args[0]; var config = hexo.config.cloudmusic || &#123;&#125;; var widgetType = hexo.config.widgetType || 'flash'; var widgetSize = config.widgetSize || 'small'; var autoPlay = config.autoPlay || 1; var width = config.width || 278; var height = config.height || 32; if(widgetType == 'iframe')&#123; if(widgetSize=='small')&#123; return '&lt;iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=298 height=52 src=\"http://music.163.com/outchain/player?type=2&amp;id=' + sid + '&amp;auto=' + autoPlay +'&amp;height=32\"&gt;&lt;/iframe&gt;'; &#125;else if(widgetSize=='big')&#123; return '&lt;iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=351 height=86 src=\"http://music.163.com/outchain/player?type=2&amp;id=' + sid + '&amp;auto=' + autoPlay + '&amp;height=66\"&gt;&lt;/iframe&gt;'; &#125;else if(widgetSize=='custom')&#123; return '&lt;iframe frameborder=\"no\" border=\"0\" marginwidth=\"0\" marginheight=\"0\" width=' + width +' height=' + height +' src=\"http://music.163.com/outchain/player?type=2&amp;id=' + sid + '&amp;auto=' + autoPlay + '&amp;height=66\"&gt;&lt;/iframe&gt;'; &#125; &#125;else&#123; if(widgetSize=='small')&#123; return '&lt;embed src=\"http://music.163.com/style/swf/widget.swf?sid=' + sid + '&amp;type=2&amp;auto=' + autoPlay + '&amp;width=278&amp;height=32\" width=\"298\" height=\"52\" allowNetworking=\"all\"&gt;&lt;/embed&gt;'; &#125;else&#123; return '&lt;embed src=\"http://music.163.com/style/swf/widget.swf?sid=' + sid + '&amp;type=2&amp;auto=' + autoPlay + '&amp;width=320&amp;height=66\" width=\"340\" height=\"86\" allowNetworking=\"all\"&gt;&lt;/embed&gt;'; &#125; &#125;&#125;); &emsp;&emsp;大家可以看到这个JS文件本质上就是根据传入的sid来拼接生成网易云音乐的widget代码，这样当我们需要在博客中引用网易云音乐的时候只需要采用下面的标记： &emsp;&emsp;这个项目我目前发布在我的Github上，欢迎大家Start和Fork!","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"插件","slug":"插件","permalink":"https://qinyuanpei.github.io/tags/%E6%8F%92%E4%BB%B6/"},{"name":"网易","slug":"网易","permalink":"https://qinyuanpei.github.io/tags/%E7%BD%91%E6%98%93/"},{"name":"云音乐","slug":"云音乐","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%91%E9%9F%B3%E4%B9%90/"},{"name":"Hexo","slug":"Hexo","permalink":"https://qinyuanpei.github.io/tags/Hexo/"}]},{"title":"使用Coding.NET和Hexo实现网页游戏的发布","date":"2015-03-24T08:54:48.000Z","path":"posts/1150071886/","text":"&emsp;&emsp;本文将尝试借助Coding.NET的项目演示功能，通过对Hexo中支持的发布类型进行扩充，实现可以在Hexo中发布网页游戏，从而方便博主展示游戏作品和帮助读者了解游戏效果。 为什么要这样做&emsp;&emsp;博主是一名至今为止都还没有做出一款完整游戏(指已上线)的游戏开发者,可是即使这样，博主依然愿意将自己在游戏开发过程中的感悟和体会分享给大家，因为博主在学习编程的路上摸索了这么久，首先要感谢的就是那些愿意在互联网上分享技术的人们，不管是Github上愿意将项目开源的那些技术大牛，还是在博客圈子里不断探索追逐梦想的人们，如果没有他们不求回报的辛勤付出，我是绝对不可能在环境科学这样一个专业中学好编程技术的。作为一名开源技术的追逐者，我们应该抱着”既取之，必与之”来回馈开源社区。况且将自己的知识分享给其他人，不仅可以敦促自己不断地学习，更能促进相互之间的学习，所以说写博客其实本来就是一件百利而无一害的事情。 &emsp;&emsp;好了，说了这么多，其实博主的想法就是能够在博客中增加项目演示的需求。博主经常在博客上写一些游戏开发的技术文章，每次都会在文章最后给出这篇文章中具体实现了一种怎样的效果。如果是静态图片当然没有什么争议，可是我们知道游戏或者说程序是一种动态的东西，所以如果采用静态图片似乎不能完全展示出具体的效果。而游戏作为一种可互动的产品，它更加强调玩家的互动和代入感，所以能够为玩家提供一个可控的操作环境就显得特别重要。以往在CSDN博客都是利用GIFCam录制屏幕Gif动画来展示效果的，可是受制于CSDN每次上传图片必须小于2M的容量限制的要求，所以使用Gif基本只能让读者了解一个大概。现在博客采用七牛云存储来存储博客中的图片，这是在使用CSDN博客时所不能相提并论的，所以现在博主的博客基本上是以这个独立博客为主，CSDN博客只是负责将独立博客的内容更新过去，博主每隔一段时间会去维护下CSDN博客，所以如何有时候没有及时回复大家的评论，还希望大家能够谅解啊。 &emsp;&emsp;那么，在Gif动画的基础上，有没有比这个方案更好的方案呢？博主的想法是直接将游戏嵌入到博客当中，这样读者在学习了技术上的实现以后可以立即体验到实际到操作游戏的感觉，从而更快地了解游戏的实现。因为博主认为只有真正热爱游戏的人才能够设计出好的游戏，所以博主最近打算在博客中开设一个专门推荐好游戏的栏目，这样可以让我们一边玩游戏、一边学习技术，这样的想法可好？哈哈，好了下面我们来说说怎样实现这个目标！ 怎样实现这样的目标Coding.NET是一个类似于Github的网站，提供了免费的项目托管服务。和Github不同的是Coding.NET为所有的Web项目提供了提供一个在线的演示环境，就是说只要Coding.NET支持你的项目，那么你的项目就可以托管在这个网站上面进行演示。基于这样一种机制，博主便想到下面两种实现的思路： 思路1因为Unity3D可以将项目导出为WebPlayer项目，在Unity5.0中更是提供了WebGL的支持，可以将Unity3D游戏导出为网页游戏。既然可以导出网页游戏，那么我们就可以将网页项目托管到Coidng.NET上，然后iframe框架引用到博客当中。不过这种方法可能会影响到网页的加载速度和搜索引擎优化，因为所有的搜索引擎都讨厌iframe。所以这种思路果断放弃咯！ 思路2将Unity3D导出的.unity3d文件托管到七牛云存储上，然后通过在Hexo中增加一个新的模版，来实现.unity3d文件和模版文件的对接，模板文件采用Unity3D的WebPlayer插件进行编写，在实现目的的基础上保证整个页面布局美观大方。这种方法的优点是完全原生，没有第三方依赖关系。缺点是页面是针对某一个Hexo主题的，没有办法做到一次编写、完全通用的效果。好了，下面我们就以这种思路来开始实现这个伟(zhuang)大(bi)的目标吧！ 模板修改&emsp;&emsp;首先我们的目的是要实现在博客中集成游戏的功能，因此我们的游戏是不能作为博客的文章出现的首页，我们知道在Hexo中可以通过hexo new page[PageName]这个命令来生成一个自定义页面，而且生成的自定义页面不会出现在博客首页，只有通过链接才可以访问到这个页面，因此我们可以从这里作为突破口。在输入hexo new page[PageName]命令后我们发现在hexo的source文件夹下会生成一个以PageName命名的文件夹，在这个文件夹中有一个index.md的文件，通过修改这个文件的内容就能实现自定义页面。可是我们发现一个问题，每次生成一个新的页面就需要创建一个新的文件夹，这样的结构对我们管理游戏项目十分不便。怎么办呢？首先我们在source文件夹下创建一个games的文件夹，然后再该文件夹下创建一个子文件夹，子文件夹的命名可以任意(此处以example为例)关键是要在这个子文件夹里需要放置我们前面通过命令生成的index.md文件，此时我们就可以通过http://YourSite.com/games/example来访问这个页面了，此后如果需要发布新的游戏，可以将example文件夹复制一份然后重命名即可。好了，下面我们来重点说下这个index.md里的内容。通过查看Unity3D生成的网页文件我们了解到一个完整的Unity3D游戏需要两个东西，一个是描述页面结构的HTML，一个是.unity3d文件。这里面麻烦点的是HTML，开始觉得蛮容易的，后来发现修改模板实在困难，所以不得不放弃这种思路了。 思路3&emsp;&emsp;博主是最近了解到，Github除了可以用xxx.github.io这种方式搭建博客外，还可以通过gh-pages分支来实现，换句话说只要我们把静态的网页放到项目的gh-pages下，Github就能帮你把页面显示出来，因此我们就可以将Unity3D导出的网页版本游戏放到Github上，从而实现游戏的在线演示。好吧，满满的罪恶感啊，要是有一天Github被GFW了，我就是那个断送它的人啊！ 效果演示","categories":[{"name":"独立博客","slug":"独立博客","permalink":"https://qinyuanpei.github.io/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"Hexo","slug":"Hexo","permalink":"https://qinyuanpei.github.io/tags/Hexo/"},{"name":"部署","slug":"部署","permalink":"https://qinyuanpei.github.io/tags/%E9%83%A8%E7%BD%B2/"}]},{"title":"C#中Socket通信编程的异步实现","date":"2015-03-22T09:37:04.000Z","path":"posts/2041685704/","text":"&emsp;&emsp;本文将在C#中Socket同步通信的基础上，分析和研究Socket异步编程的实现方法，目的是深入了解Socket编程的基本原理，增强对网络游戏开发相关内容的认识。 什么是Socket编程的异步的实现&emsp;&emsp;所谓Socket编程的异步实现是指按照异步过程来实现Socket编程，那么什么是异步过程呢，我们把在完成了一次调用后通过状态、通知和回调来告知调用者的方式成为异步过程，换句话说，在异步过程中当调用一个方法时，调用者并不能够立刻得到结果，只有当这个方法调用完毕后调用者才能获得调用结果。这样做的好处是什么呢？答案是高效。相信大家还记得我们在《C#中Socket通信编程的同步实现》这篇文章中使用多线程来实现简单聊天的案例吧，在这个案例中我们需要开启两个线程来不断监听客户端的连接和客户端的消息，这样的效率肯定是很低的。那么现在好了，我们可以通过异步过程来解决这个问题，下面我们就来看看如何实现Socket的异步通信。 如何实现Socket异步通信服务端基本流程 创建套接字 绑定套接字的IP和端口号——Bind() 使套接字处于监听状态等待客户端的连接请求——Listen() 当请求到来后，使用BeginAccept()和EndAccept()方法接受请求，返回新的套接字 使用BeginSend()/EndSend和BeginReceive()/EndReceive()两组方法与客户端进行收发通信 返回，再次等待新的连接请求 关闭套接字 代码示例1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192using System;using System.Collections.Generic;using System.Text;using System.Net;using System.Net.Sockets;namespace AsyncServer&#123; public class AsyncTCPServer &#123; public void Start() &#123; &#x2F;&#x2F;创建套接字 IPEndPoint ipe &#x3D; new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;), 6065); Socket socket &#x3D; new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); &#x2F;&#x2F;绑定端口和IP socket.Bind(ipe); &#x2F;&#x2F;设置监听 socket.Listen(10); &#x2F;&#x2F;连接客户端 AsyncAccept(socket); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 连接到客户端 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;socket&quot;&gt;&lt;&#x2F;param&gt; private void AsyncAccept(Socket socket) &#123; socket.BeginAccept(asyncResult &#x3D;&gt; &#123; &#x2F;&#x2F;获取客户端套接字 Socket client &#x3D; socket.EndAccept(asyncResult); Console.WriteLine(string.Format(&quot;客户端&#123;0&#125;请求连接...&quot;, client.RemoteEndPoint)); AsyncSend(client, &quot;服务器收到连接请求&quot;); AsyncSend(client, string.Format(&quot;欢迎你&#123;0&#125;&quot;,client.RemoteEndPoint)); AsyncReveive(client); &#125;, null); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 接收消息 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;client&quot;&gt;&lt;&#x2F;param&gt; private void AsyncReveive(Socket socket) &#123; byte[] data &#x3D; new byte[1024]; try &#123; &#x2F;&#x2F;开始接收消息 socket.BeginReceive(data, 0, data.Length, SocketFlags.None, asyncResult &#x3D;&gt; &#123; int length &#x3D; socket.EndReceive(asyncResult); Console.WriteLine(string.Format(&quot;客户端发送消息:&#123;0&#125;&quot;, Encoding.UTF8.GetString(data))); &#125;, null); &#125; catch (Exception ex) &#123; Console.WriteLine(ex.Message); &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 发送消息 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;client&quot;&gt;&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;p&quot;&gt;&lt;&#x2F;param&gt; private void AsyncSend(Socket client, string p) &#123; if (client &#x3D;&#x3D; null || p &#x3D;&#x3D; string.Empty) return; &#x2F;&#x2F;数据转码 byte[] data &#x3D; new byte[1024]; data &#x3D; Encoding.UTF8.GetBytes(p); try &#123; &#x2F;&#x2F;开始发送消息 client.BeginSend(data, 0, data.Length, SocketFlags.None, asyncResult &#x3D;&gt; &#123; &#x2F;&#x2F;完成消息发送 int length &#x3D; client.EndSend(asyncResult); &#x2F;&#x2F;输出消息 Console.WriteLine(string.Format(&quot;服务器发出消息:&#123;0&#125;&quot;, p)); &#125;, null); &#125; catch (Exception e) &#123; Console.WriteLine(e.Message); &#125; &#125; &#125;&#125; 客户端基本流程 创建套接字并保证与服务器的端口一致 使用BeginConnect()和EndConnect()这组方法向服务端发送连接请求 使用BeginSend()/EndSend和BeginReceive()/EndReceive()两组方法与服务端进行收发通信 关闭套接字 代码示例12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182using System;using System.Collections.Generic;using System.Text;using System.Net;using System.Net.Sockets;namespace AsyncClient&#123; public class AsyncTCPClient &#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 连接到服务器 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public void AsynConnect() &#123; &#x2F;&#x2F;端口及IP IPEndPoint ipe &#x3D; new IPEndPoint(IPAddress.Parse(&quot;127.0.0.1&quot;), 6065); &#x2F;&#x2F;创建套接字 Socket client &#x3D; new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); &#x2F;&#x2F;开始连接到服务器 client.BeginConnect(ipe, asyncResult &#x3D;&gt; &#123; client.EndConnect(asyncResult); &#x2F;&#x2F;向服务器发送消息 AsynSend(client,&quot;你好我是客户端&quot;); AsynSend(client, &quot;第一条消息&quot;); AsynSend(client, &quot;第二条消息&quot;); &#x2F;&#x2F;接受消息 AsynRecive(client); &#125;, null); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 发送消息 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;socket&quot;&gt;&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;message&quot;&gt;&lt;&#x2F;param&gt; public void AsynSend(Socket socket, string message) &#123; if (socket &#x3D;&#x3D; null || message &#x3D;&#x3D; string.Empty) return; &#x2F;&#x2F;编码 byte[] data &#x3D; Encoding.UTF8.GetBytes(message); try &#123; socket.BeginSend(data, 0, data.Length, SocketFlags.None, asyncResult &#x3D;&gt; &#123; &#x2F;&#x2F;完成发送消息 int length &#x3D; socket.EndSend(asyncResult); Console.WriteLine(string.Format(&quot;客户端发送消息:&#123;0&#125;&quot;, message)); &#125;, null); &#125; catch (Exception ex) &#123; Console.WriteLine(&quot;异常信息：&#123;0&#125;&quot;, ex.Message); &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 接收消息 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;socket&quot;&gt;&lt;&#x2F;param&gt; public void AsynRecive(Socket socket) &#123; byte[] data &#x3D; new byte[1024]; try &#123; &#x2F;&#x2F;开始接收数据 socket.BeginReceive(data, 0, data.Length, SocketFlags.None, asyncResult &#x3D;&gt; &#123; int length &#x3D; socket.EndReceive(asyncResult); Console.WriteLine(string.Format(&quot;收到服务器消息:&#123;0&#125;&quot;, Encoding.UTF8.GetString(data))); AsynRecive(socket); &#125;, null); &#125; catch (Exception ex) &#123; Console.WriteLine(&quot;异常信息：&quot;, ex.Message); &#125; &#125; &#125;&#125; 从总体上来讲Socket异步编程的逻辑性更加明确了，因为我们只需要为每一个过程写好回调函数就好了。那么这个示例的效果如何呢？我们来看看它的演示效果： Socket异步编程效果演示 总结&emsp;&emsp;和Socket同步编程的案例相比，今天的这个案例可能只是对Socket异步编程内容的一个简单应用，因为博主到现在为止都还没有写出一个可以进行交互聊天的程序来。在Socket的异步编程中，服务端不需要为一个客户端单独创建一个线程来维护其连接，可是这样带来的一个问题就是博主不知道该如何实现一个多客户端的异步编程的实例。如果有朋友知道如何实现的话，还希望能够告诉我，毕竟学习就是一个相互促进的过程啊。好了，最后想说的是博主这段时间研究Socket异步编程中关于异步方法调用的写法问题。我们知道Socket异步编程中的方法是成对出现的，每一个方法都有一个回调函数，对于回调函数，这里有两种写法，以BeginConnect方法为例： 123m_Socket.BeginConnect(this.m_ipEndPoint, new AsyncCallback(this.ConnectCallBack), this.m_Socket);&#x2F;&#x2F;其中ConnectCallBack是一个回调函数 或者 1234m_Socket.BeginConnect(this.m_ipEndPoint,asyncResult&#x3D;&gt;&#123; &#x2F;&#x2F;在这里添加更多代码&#125;,null) &emsp;&emsp;博主为什么要在这里说这两种写法呢，有两个原因： 第二种写法更为简洁，无需去构造容器传递Socket和消息，因为它们都是局部变量。如果我们使用第一种方法，因为主函数和回调函数是两个不同的函数，因此如果想要共享变量就需要通过IAsyncResult接口来访问容器中的值，这样显然增加了我们的工作量。 第二种写法更为优雅，这似乎是C#语言中某种高级语法，具体叫什么我忘了，反正在Linq中经常看到这种写法的影子。 &emsp;&emsp;综合以上两个观点，博主还是建议大家使用第二种写法，博主打算有空的话将之前写的程序再重新写一遍，看看能不能找出代码中的问题。好了，今天的内容就是这样了，谢谢大家，希望大家喜欢！","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Socket","slug":"Socket","permalink":"https://qinyuanpei.github.io/tags/Socket/"},{"name":"通信","slug":"通信","permalink":"https://qinyuanpei.github.io/tags/%E9%80%9A%E4%BF%A1/"},{"name":"异步","slug":"异步","permalink":"https://qinyuanpei.github.io/tags/%E5%BC%82%E6%AD%A5/"},{"name":"编程","slug":"编程","permalink":"https://qinyuanpei.github.io/tags/%E7%BC%96%E7%A8%8B/"}]},{"title":"C#中Socket通信编程的同步实现","date":"2015-03-15T15:05:56.000Z","path":"posts/3959327595/","text":"&emsp;&emsp;本文通过分析和总结C#中Socket通信编程的关键技术，按照同步实现的方式实现了一个简单的Socket聊天程序，目的是通过这个程序来掌握Socket编程，为进一步开发Unity3D网络游戏打下一个坚实的基础。 Socket编程基础&emsp;&emsp;关于Socket编程基础部分的内容，主要是了解和掌握.NET框架下为Socket编程提供的相关类和接口方法。.NET中常见的网络相关的API都集中在System.Net和System.Net.Socket这两个命名空间下，大家可以通过MSDN去了解这两个命名空间下相关的类和方法。这里援引一位朋友总结的一篇文章http://www.cnblogs.com/sunev/archive/2012/08/05/2604189.html，大家可以从这里获得更为直观的认识。 什么是Socket编程的同步实现&emsp;&emsp;本文的目的是按照同步实现的方式来实现一个简单的Socket聊天程序，因此在解决这个问题前，我们首先来看看什么是Socket编程的同步实现。所谓Socket编程的同步实现就是指按照同步过程的方法来实现Socket通信。从编程来说，我们常用的方法或者函数都是同步过程。因为当我们调用一个方法或者函数的时候我们能够立即得到它的返回值。可是我们知道在Socket通信中，我们不能保证时时刻刻连接都通畅、更不能够保证时时刻刻都有数据收发，因为我们就需要不断去读取相应的值来确定整个过程的状态。这就是Socket编程的同步实现了，下面我们来看具体的实现过程。 如何实现Socket同步通信服务端&emsp;&emsp;服务端的主要职责是处理各个客户端发送来的数据，因此在客户端的Socket编程中需要使用两个线程来循环处理客户端的请求，一个线程用于监听客户端的连接情况，一个线程用于监听客户端的消息发送，当服务端接收到客户端的消息后需要将消息处理后再分发给各个客户端。 基本流程 创建套接字 绑定套接字的IP和端口号——Bind() 将套接字处于监听状态等待客户端的连接请求——Listen() 当请求到来后，接受请求并返回本次会话的套接字——Accept() 使用返回的套接字和客户端通信——Send()/Receive() 返回，再次等待新的连接请求 关闭套接字 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228using System;using System.Collections.Generic;using System.Text;using System.Net;using System.Net.Sockets;using System.Threading;namespace TCPLib&#123; public class TCPServer &#123; private byte[] result &#x3D; new byte[1024]; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 最大的监听数量 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private int maxClientCount; public int MaxClientCount &#123; get &#123; return maxClientCount; &#125; set &#123; maxClientCount &#x3D; value; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; IP地址 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private string ip; public string IP &#123; get &#123; return ip; &#125; set &#123; ip &#x3D; value; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 端口号 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private int port; public int Port &#123; get &#123; return port; &#125; set &#123; port &#x3D; value; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 客户端列表 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private List&lt;Socket&gt; mClientSockets; public List&lt;Socket&gt; ClientSockets &#123; get &#123; return mClientSockets; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; IP终端 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private IPEndPoint ipEndPoint; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 服务端Socket &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private Socket mServerSocket; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 当前客户端Socket &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private Socket mClientSocket; public Socket ClientSocket &#123; get &#123; return mClientSocket; &#125; set &#123; mClientSocket &#x3D; value; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 构造函数 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;port&quot;&gt;端口号&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;count&quot;&gt;监听的最大树目&lt;&#x2F;param&gt; public TCPServer(int port, int count) &#123; this.ip &#x3D; IPAddress.Any.ToString(); this.port &#x3D; port; this.maxClientCount&#x3D;count; this.mClientSockets &#x3D; new List&lt;Socket&gt;(); &#x2F;&#x2F;初始化IP终端 this.ipEndPoint &#x3D; new IPEndPoint(IPAddress.Any, port); &#x2F;&#x2F;初始化服务端Socket this.mServerSocket &#x3D; new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); &#x2F;&#x2F;端口绑定 this.mServerSocket.Bind(this.ipEndPoint); &#x2F;&#x2F;设置监听数目 this.mServerSocket.Listen(maxClientCount); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 构造函数 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;ip&quot;&gt;ip地址&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;port&quot;&gt;端口号&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;count&quot;&gt;监听的最大数目&lt;&#x2F;param&gt; public TCPServer(string ip,int port,int count) &#123; this.ip &#x3D; ip; this.port &#x3D; port; this.maxClientCount &#x3D; count; this.mClientSockets &#x3D; new List&lt;Socket&gt;(); &#x2F;&#x2F;初始化IP终端 this.ipEndPoint &#x3D; new IPEndPoint(IPAddress.Parse(ip), port); &#x2F;&#x2F;初始化服务端Socket this.mServerSocket &#x3D; new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); &#x2F;&#x2F;端口绑定 this.mServerSocket.Bind(this.ipEndPoint); &#x2F;&#x2F;设置监听数目 this.mServerSocket.Listen(maxClientCount); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 定义一个Start方法将构造函数中的方法分离出来 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; public void Start() &#123; &#x2F;&#x2F;创建服务端线程，实现客户端连接请求的循环监听 var mServerThread &#x3D; new Thread(this.ListenClientConnect); &#x2F;&#x2F;服务端线程开启 mServerThread.Start(); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 监听客户端链接 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void ListenClientConnect() &#123; &#x2F;&#x2F;设置循环标志位 bool flag &#x3D; true; while (flag) &#123; &#x2F;&#x2F;获取连接到服务端的客户端 this.ClientSocket &#x3D; this.mServerSocket.Accept(); &#x2F;&#x2F;将获取到的客户端添加到客户端列表 this.mClientSockets.Add(this.ClientSocket); &#x2F;&#x2F;向客户端发送一条消息 this.SendMessage(string.Format(&quot;客户端&#123;0&#125;已成功连接到服务器&quot;, this.ClientSocket.RemoteEndPoint)); &#x2F;&#x2F;创建客户端消息线程，实现客户端消息的循环监听 var mReveiveThread &#x3D; new Thread(this.ReceiveClient); &#x2F;&#x2F;注意到ReceiveClient方法传入了一个参数 &#x2F;&#x2F;实际上这个参数就是此时连接到服务器的客户端 &#x2F;&#x2F;即ClientSocket mReveiveThread.Start(this.ClientSocket); &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 接收客户端消息的方法 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void ReceiveClient(object obj) &#123; &#x2F;&#x2F;获取当前客户端 &#x2F;&#x2F;因为每次发送消息的可能并不是同一个客户端，所以需要使用var来实例化一个新的对象 &#x2F;&#x2F;可是我感觉这里用局部变量更好一点 var mClientSocket &#x3D; (Socket)obj; &#x2F;&#x2F; 循环标志位 bool flag &#x3D; true; while (flag) &#123; try &#123; &#x2F;&#x2F;获取数据长度 int receiveLength &#x3D; mClientSocket.Receive(result); &#x2F;&#x2F;获取客户端消息 string clientMessage &#x3D; Encoding.UTF8.GetString(result, 0, receiveLength); &#x2F;&#x2F;服务端负责将客户端的消息分发给各个客户端 this.SendMessage(string.Format(&quot;客户端&#123;0&#125;发来消息:&#123;1&#125;&quot;,mClientSocket.RemoteEndPoint,clientMessage)); &#125; catch (Exception e) &#123; &#x2F;&#x2F;从客户端列表中移除该客户端 this.mClientSockets.Remove(mClientSocket); &#x2F;&#x2F;向其它客户端告知该客户端下线 this.SendMessage(string.Format(&quot;服务器发来消息:客户端&#123;0&#125;从服务器断开,断开原因:&#123;1&#125;&quot;,mClientSocket.RemoteEndPoint,e.Message)); &#x2F;&#x2F;断开连接 mClientSocket.Shutdown(SocketShutdown.Both); mClientSocket.Close(); break; &#125; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 向所有的客户端群发消息 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;msg&quot;&gt;message&lt;&#x2F;param&gt; public void SendMessage(string msg) &#123; &#x2F;&#x2F;确保消息非空以及客户端列表非空 if (msg &#x3D;&#x3D; string.Empty || this.mClientSockets.Count &lt;&#x3D; 0) return; &#x2F;&#x2F;向每一个客户端发送消息 foreach (Socket s in this.mClientSockets) &#123; (s as Socket).Send(Encoding.UTF8.GetBytes(msg)); &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 向指定的客户端发送消息 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;ip&quot;&gt;ip&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;port&quot;&gt;port&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;msg&quot;&gt;message&lt;&#x2F;param&gt; public void SendMessage(string ip,int port,string msg) &#123; &#x2F;&#x2F;构造出一个终端地址 IPEndPoint _IPEndPoint &#x3D; new IPEndPoint(IPAddress.Parse(ip), port); &#x2F;&#x2F;遍历所有客户端 foreach (Socket s in mClientSockets) &#123; if (_IPEndPoint &#x3D;&#x3D; (IPEndPoint)s.RemoteEndPoint) &#123; s.Send(Encoding.UTF8.GetBytes(msg)); &#125; &#125; &#125; &#125;&#125; &emsp;&emsp;好了，现在我们已经编写好了一个具备接收和发送数据能力的服务端程序。现在我们来尝试让服务端运行起来： 12345678910111213141516171819202122232425using System;using System.Collections.Generic;using System.Text;using TCPLib;using System.Net;using System.Net.Sockets;namespace TCPLib.Test&#123; class Program &#123; static void Main(string[] args) &#123; &#x2F;&#x2F;指定IP和端口号及最大监听数目的方式 TCPLib.TCPServer s1 &#x3D; new TCPServer(&quot;127.0.0.1&quot;, 6001, 10); &#x2F;&#x2F;指定端口号及最大监听数目的方式 TCPLib.TCPServer s2 &#x3D; new TCPServer(6001, 10); &#x2F;&#x2F;执行Start方法 s1.Start(); &#125; &#125;&#125; &emsp;&emsp;现在我们来看看编写客户端Socket程序的基本流程 客户端&emsp;&emsp;客户端相对于服务端来说任务要轻许多，因为客户端仅仅需要和服务端通信即可，可是因为在和服务器通信的过程中，需要时刻保持连接通畅，因此同样需要两个线程来分别处理连接情况的监听和消息发送的监听。 基本流程 创建套接字保证与服务器的端口一致 向服务器发出连接请求——Connect() 和服务器端进行通信——Send()/Receive() 关闭套接字 代码示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158using System;using System.Collections.Generic;using System.Text;using System.Net;using System.Net.Sockets;using System.Threading;namespace TCPLib&#123; public class TCPClient &#123; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 定义数据 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private byte[] result &#x3D; new byte[1024]; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 客户端IP &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private string ip; public string IP &#123; get &#123; return ip; &#125; set &#123; ip &#x3D; value; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 客户端端口号 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private int port; public int Port &#123; get &#123; return port; &#125; set &#123; port &#x3D; value; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; IP终端 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private IPEndPoint ipEndPoint; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 客户端Socket &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private Socket mClientSocket; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 是否连接到了服务器 &#x2F;&#x2F;&#x2F; 默认为flase &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private bool isConnected &#x3D; false; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 构造函数 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;ip&quot;&gt;IP地址&lt;&#x2F;param&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;port&quot;&gt;端口号&lt;&#x2F;param&gt; public TCPClient(string ip, int port) &#123; this.ip&#x3D;ip; this.port&#x3D;port; &#x2F;&#x2F;初始化IP终端 this.ipEndPoint &#x3D; new IPEndPoint(IPAddress.Parse(this.ip), this.port); &#x2F;&#x2F;初始化客户端Socket mClientSocket &#x3D; new Socket(AddressFamily.InterNetwork, SocketType.Stream, ProtocolType.Tcp); &#125; public void Start() &#123; &#x2F;&#x2F;创建一个线程以不断连接服务器 var mConnectThread &#x3D; new Thread(this.ConnectToServer); &#x2F;&#x2F;开启线程 mConnectThread.Start(); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 连接到服务器 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void ConnectToServer() &#123; &#x2F;&#x2F;当没有连接到服务器时开始连接 while (!isConnected) &#123; try &#123; &#x2F;&#x2F;开始连接 mClientSocket.Connect(this.ipEndPoint); this.isConnected &#x3D; true; &#125; catch (Exception e) &#123; &#x2F;&#x2F;输出Debug信息 Console.WriteLine(string.Format(&quot;因为一个错误的发生，暂时无法连接到服务器，错误信息为:&#123;0&#125;&quot;,e.Message)); this.isConnected &#x3D; false; &#125; &#x2F;&#x2F;等待5秒钟后尝试再次连接 Thread.Sleep(5000); Console.WriteLine(&quot;正在尝试重新连接...&quot;); &#125; &#x2F;&#x2F;连接成功后 Console.WriteLine(&quot;连接服务器成功，现在可以和服务器进行会话了&quot;); &#x2F;&#x2F;创建一个线程以监听数据接收 var mReceiveThread &#x3D; new Thread(this.ReceiveMessage); &#x2F;&#x2F;开启线程 mReceiveThread.Start(); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 因为客户端只接受来自服务器的数据 &#x2F;&#x2F;&#x2F; 因此这个方法中不需要参数 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void ReceiveMessage() &#123; &#x2F;&#x2F;设置循环标志位 bool flag &#x3D; true; while (flag) &#123; try &#123; &#x2F;&#x2F;获取数据长度 int receiveLength &#x3D; this.mClientSocket.Receive(result); &#x2F;&#x2F;获取服务器消息 string serverMessage &#x3D; Encoding.UTF8.GetString(result, 0, receiveLength); &#x2F;&#x2F;输出服务器消息 Console.WriteLine(serverMessage); &#125; catch (Exception e) &#123; &#x2F;&#x2F;停止消息接收 flag &#x3D; false; &#x2F;&#x2F;断开服务器 this.mClientSocket.Shutdown(SocketShutdown.Both); &#x2F;&#x2F;关闭套接字 this.mClientSocket.Close(); &#x2F;&#x2F;重新尝试连接服务器 this.isConnected &#x3D; false; ConnectToServer(); &#125; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 发送消息 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; &#x2F;&#x2F;&#x2F; &lt;param name&#x3D;&quot;msg&quot;&gt;消息文本&lt;&#x2F;param&gt; public void SendMessage(string msg) &#123; if(msg&#x3D;&#x3D;string.Empty || this.mClientSocket&#x3D;&#x3D;null) return; mClientSocket.Send(Encoding.UTF8.GetBytes(msg)); &#125; &#125;&#125; &emsp;&emsp;同样地，我们现在来运行客户端程序，这样客户端就可以和服务端进行通信了： 1234567891011121314151617181920212223242526272829using System;using System.Collections.Generic;using System.Text;using TCPLib;using System.Net;using System.Net.Sockets;namespace TCPLib.Test&#123; class Program &#123; static void Main(string[] args) &#123; &#x2F;&#x2F;保证端口号和服务端一致 TCPLib.TCPClient c &#x3D; new TCPClient(&quot;127.0.0.1&quot;,6001); &#x2F;&#x2F;执行Start方法 c.Start(); while(true) &#123; &#x2F;&#x2F;读取客户端输入的消息 string msg &#x3D; Console.ReadLine(); &#x2F;&#x2F;发送消息到服务端 c.SendMessage(msg); &#125; &#125; &#125;&#125; &emsp;&emsp;注意要先运行服务端的程序、再运行客户端的程序，不然程序会报错，嘿嘿！好了，下面是今天的效果演示图： 聊天窗口效果演示 客户端下线效果演示 总结&emsp;&emsp;今天我们基本上写出了一个可以使用的用例，不过这个例子目前还存在以下问题： 这里仅仅实现了发送字符串的功能，如何让这个程序支持更多的类型，从基础的int、float、double、string、single等类型到structure、class甚至是二进制文件的类型？ 如何让这个用例更具有扩展性，我们发现所有的Socket编程流程都是一样的，唯一不同就是在接收到数据以后该如何去处理，因为能不能将核心功能和自定义功能分离开来？ 在今天的这个用例中，数据传输的缓冲区大小我们人为设定为1024，那么如果碰到比这个设定更大的数据类型，这个用例该怎么来写？ 好了，这就是今天的内容了，希望大家喜欢，同时希望大家关注我的博客！ 2016年1月24日更新：&emsp;&emsp;要解决“支持更多类型的问题”，可以从两种思路来考虑，即实现所有类型到byte[]类型的转换或者是实现所有类型到string类型的转换，对于第二种思路我们通常称之为序列化，序列化可以解决所有类型到string类型的转换问题，唯一可能需要考量的一个部分就是缓冲区的大小问题。 &emsp;&emsp;要解决“将核心功能和自定义功能分离”这个问题，可以考虑使用委托机制来实现，委托机制可以理解为一个函数的指针，在需要将函数的控制权交给用户来处理的场景中，委托都是一种有效而明智的选择。","categories":[{"name":"编程语言","slug":"编程语言","permalink":"https://qinyuanpei.github.io/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/"}],"tags":[{"name":"Socket","slug":"Socket","permalink":"https://qinyuanpei.github.io/tags/Socket/"},{"name":"通信","slug":"通信","permalink":"https://qinyuanpei.github.io/tags/%E9%80%9A%E4%BF%A1/"},{"name":"同步","slug":"同步","permalink":"https://qinyuanpei.github.io/tags/%E5%90%8C%E6%AD%A5/"},{"name":"多线程","slug":"多线程","permalink":"https://qinyuanpei.github.io/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/"}]},{"title":"使用Unity3D创建一个幸运转盘","date":"2015-03-12T19:13:38.000Z","path":"posts/3449402269/","text":"&emsp;&emsp;今天我们来做点和游戏无关的事情吧！博主最近情绪一直比较低落，因为在找工作的过程中遇到了些挫折。当一个人内心缺乏斗志的时候，通常会难以静下心来认真地做事情，所以这段时间博主并不打算再去为大家分享新的游戏案例，希望大家能够谅解啊。 &emsp;&emsp;好了，博主今天想和大家分享的是一个叫做幸运转盘的案例。我们知道平时在节假日商场为了促销商品，通常都会推出诸如转盘抽奖这样的游戏。在学了概率以后，虽然我们都知道中奖是一个小概率事件，可是人们对买彩票中奖这样的事情仍然乐此不疲。就像腾讯通过今年的春晚成功地为微信支付培养了大量忠实用户一样，虽然大家抢红包抢到的钱都不算多，可是大家都还是愿意去抢红包啊。为什么呢？呵呵，不就图一乐嘛。好了，那么下面我们一起乐一乐吧，因为激动人心的抽奖环节就要开始了！ &emsp;&emsp;首先我们来看看在Unity3D中如何实现转盘抽奖： 转盘游戏示意图 &emsp;&emsp;从这张图片我们可以看出，转盘抽奖有两部分组成：转盘是可以旋转的、转盘指针是固定不动的。那么，好了，抽奖无非就是让转盘转起来然后再停下来嘛，直接给出代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152using UnityEngine;using System.Collections;public class LuckyRoll : MonoBehaviour &#123; &#x2F;&#x2F;幸运转盘 private Transform mRoolPanel; &#x2F;&#x2F;初始旋转速度 private float mInitSpeed; &#x2F;&#x2F;速度变化值 private float mDelta&#x3D;0.5f; &#x2F;&#x2F;转盘是否暂停 private bool isPause&#x3D;true; void Start () &#123; &#x2F;&#x2F;获取转盘 mRoolPanel&#x3D;this.transform.FindChild(&quot;Background&quot;); &#125; &#x2F;&#x2F;开始抽奖 public void OnClick() &#123; if(isPause) &#123; &#x2F;&#x2F;随机生成一个初始速度 mInitSpeed&#x3D;Random.Range(100,500); &#x2F;&#x2F;开始旋转 isPause&#x3D;false; &#125; &#125; void Update() &#123; if(!isPause) &#123; &#x2F;&#x2F;转动转盘(-1为顺时针,1为逆时针) mRoolPanel.Rotate(new Vector3(0,0,-1) * mInitSpeed * Time.deltaTime); &#x2F;&#x2F;让转动的速度缓缓降低 mInitSpeed-&#x3D;mDelta; &#x2F;&#x2F;当转动的速度为0时转盘停止转动 if(mInitSpeed&lt;&#x3D;0) &#123; &#x2F;&#x2F;转动停止 isPause&#x3D;true; &#125; &#125; &#125;&#125; &emsp;&emsp;这里我们随机给出一个速度mInitSpeed，然后让它按照mDelta的速率缓慢的减少，当mInitSpeed的数值为0时表示转盘停止转动。好了，我们来看看最后的效果： 转盘游戏演示 &emsp;&emsp;从现在的效果来看，这个案例基本上成功了，所以以后如果碰到需要这种抽奖活动的场合，大家就可以跟美术协调好，快速地制作出这样一个幸运转盘来向身边的人们炫耀了。不过这个案例同样存在问题： 基于随机数的转盘转动不受玩家控制，玩家无法参与到互动当中，可以考虑触摸操作，这样可以根据玩家的操作来模拟转动，提高游戏的真实性和可玩性。 因为抽奖的结果是由美术设计在转盘上的，所以程序无法根据转盘停止后指针的位置直接判断出玩家抽奖的结果以及本次抽奖是否为有效的抽奖(指针恰好停留在两个扇形区域的分界线上)。 因为这里转盘的旋转并没有严格地按照实际情况下转盘的受力情况来设计，因此可以说这个游戏中的概率分布可能不是均匀的，因此计算机里使用的随机数是伪随机数。 &emsp;&emsp;好了，暂时就发现这些问题，如果有朋友知道如何模拟触屏操作和阻尼运动，可以在这篇文章后面给我留言，今天的内容就是这样了，希望大家会喜欢！ 2015年3月31日更新：&emsp;&emsp;今天找到了关于转盘游戏概率设计的相关内容，所以经过整理后补充在这里：首先这种转盘游戏概率设计的前提是转盘固定不动，转盘指针绕中心位置旋转，与这篇文章中的恰好相反。如下图所示，在这个转盘游戏的设计中主要遵循基本的三角函数,这里以指针默认位置朝上来讲解该原理。如果指针的默认位置在其它位置上的，可以此类推。 转盘游戏示意图 x+=xcosᶱy+=ycosᶱ &emsp;&emsp;好了，现在我们就可以通过调整指针的角度来实现抽奖游戏了。比如我们将转盘平均分成8份，指针角度为0表示奖品A,指针角度为45度表示奖品B等等，以此类推。这样的话，我们只要调整指针的角度就可以控制抽奖的结果。可是在实际生活中，指针不可能一次就指到对应的奖品上去，通常会在旋转若干圈后慢慢地停下来。因此我们可以使用下列公式： 指针角度=360*圈数+(目标角度与初始角度的差值) &emsp;&emsp;这里的圈数可以通过随机数来生成，这样可以让每次抽奖更加随机些，当然为了增加抽奖的真实感，我们可以采用这篇文章中提到的减速的方法来实现一个缓停的效果。那么问题来了，如果转盘上的奖项不是均匀分布的怎么呢？这种情况可以根据转盘上圆心角的大小为每一个奖项设定一个范围，然后在这个范围内随机生成一个角度来计算指针的角度，好了，下面给出代码实现： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980using UnityEngine;using System.Collections;using System.Collections.Generic;public class LuckyRoll2 : MonoBehaviour &#123; &#x2F;&#x2F;对奖项进行封装 private class WrapItem &#123; public WrapItem(string name,float rank,float ang1,float ang2) &#123; this.ItemName&#x3D;name; this.ItemRank&#x3D;rank; this.MinAngle&#x3D;ang1; this.MaxAngle&#x3D;ang2; &#125; &#x2F;&#x2F;奖项名称 public string ItemName&#123;get;set;&#125; &#x2F;&#x2F;奖项概率 public float ItemRank&#123;get;set;&#125; &#x2F;&#x2F;最大角度 public float MaxAngle&#123;get;set;&#125; &#x2F;&#x2F;最小角度 public float MinAngle&#123;get;set;&#125; &#125; &#x2F;&#x2F;全部的奖项 private List&lt;WrapItem&gt; allItems; void Start () &#123; &#x2F;&#x2F;初始化奖品 allItems&#x3D;new List&lt;WrapItem&gt;() &#123; &#x2F;&#x2F;圆心角为5°，概率为10%，以此类推 new WrapItem(&quot;奖品1&quot;,10,0,30), new WrapItem(&quot;奖品2&quot;,15,30,90), new WrapItem(&quot;奖品3&quot;,20,90,165), new WrapItem(&quot;奖品4&quot;,25,165,255), new WrapItem(&quot;奖品5&quot;,30,255,360), &#125;; &#x2F;&#x2F;模拟抽奖10次 for(int i&#x3D;0;i&lt;10;i++) &#123; Debug.Log(Roll()); &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 抽奖方法 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private string Roll() &#123; &#x2F;&#x2F;抽奖结果 string result&#x3D;&quot;&quot;; &#x2F;&#x2F;概率总精度为100 float totalRank&#x3D;100; foreach(WrapItem item in allItems) &#123; &#x2F;&#x2F;产生一个0到100之间的随机数 float random &#x3D;Random.Range(0,totalRank); &#x2F;&#x2F;将该随机数和奖品的概率比较 if(random&lt;&#x3D;item.ItemRank) &#123; &#x2F;&#x2F;抽奖结果 result&#x3D;item.ItemName; &#x2F;&#x2F;为转盘指针随机生成旋转角度 float angle&#x3D;Random.Range(item.MinAngle,item.MaxAngle); &#x2F;&#x2F;旋转转盘指针,此处略 break; &#125;else &#123; totalRank-&#x3D;item.ItemRank; &#125; &#125; return &quot;抽奖结果为:&quot;+result; &#125;&#125; &emsp;&emsp;好了，这里我们没有写转盘旋转的功能，这部分内容大家自己去实现好了，因为在Unity3D里面实现这样一个功能实在是太简单了。今天我们主要关注的内容是概率，所以我们重点对概率做了些研究，这里我们来讨论下算法中的概率计算问题，首先奖品1、奖品2、奖品2、奖品4、奖品5的概率分别为10%、15%、20%、25%、30%，其概率之和为100。因此 奖品1：从0~100中随机抽取一个数，这个数值小于10的概率显然是10%，这是第一轮数组遍历。 奖品2：在第一轮数组遍历没有返回的情况下，进入第二轮遍历，此时从0~90中随机抽取一个数，其概率为(1-(10/100)(15/(100-10))=15%。同样的，抽到奖品3的概率为(1-(25/100))(20/(100-25))=20%，以此类推。 好了，这部分内容终于补充到这篇文章里了，对于这个问题的研究基本上可以告一段落，不得不说概率对于游戏开发来说还是蛮重要的啊，有时间学习下数学吧，反正咱底子不弱啊，哈哈。 &emsp;&emsp;下面给出程序演示效果： 转盘游戏概率设计效果演示 参考资料大家快来玩转盘抽奖游戏(走在网页游戏开发的路上)(七)php+jquery实现转盘抽奖概率可任意调整","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"概率","slug":"概率","permalink":"https://qinyuanpei.github.io/tags/%E6%A6%82%E7%8E%87/"},{"name":"转盘","slug":"转盘","permalink":"https://qinyuanpei.github.io/tags/%E8%BD%AC%E7%9B%98/"}]},{"title":"使用Love2D引擎开发贪吃蛇游戏","date":"2015-03-10T10:51:19.000Z","path":"posts/426338252/","text":"&emsp;&emsp;今天来介绍博主最近捣腾的一个小游戏“贪吃蛇”。“贪吃蛇”这个游戏相信大家都不会感到陌生吧。今天博主将通过Love2D这款游戏引擎来为大家实现一个简单的贪吃蛇游戏,在本篇文章当中我们将会涉及到“贪吃蛇”的基本算法、Lua语言编程等基本的内容，希望能够对大家开发类似的游戏提供借鉴和思考，文章中如有不足之处，还希望大家能够谅解，因为博主的游戏开发基本就是这样慢慢摸索着学习，所以难免会有不足的地方。 游戏算法&emsp;&emsp;我们首先来看看贪吃蛇是怎么移动的？ 贪吃蛇游戏算法演示1 贪吃蛇游戏算法演示2 贪吃蛇游戏算法演示3 贪吃蛇游戏算法演示4 &emsp;&emsp;通过这四张图的演示，我们可以发现这样一个规律： 蛇的移动其实是将蛇身体的最后一个元素移动到第一个元素的位置 &emsp;&emsp;那么完成这样一个工作需要两个步骤： 1、将在蛇头位置插入一个新的元素2、移除蛇尾位置的最后一个元素 &emsp;&emsp;好了，了解了蛇的移动后我们再来考虑一个问题，怎样判断蛇吃到了食物？思路和蛇的移动类似，主要考虑在蛇头插入的这个元素和食物的关系，如果这个元素的坐标和食物的坐标是相同的，那么就可以认为蛇吃到了食物，此时蛇的身体应该是变长的，所以只要在蛇头位置插入一个元素就可以了。反之，如果蛇没有吃到食物，那么蛇应该是移动的，所以就可以按照移动的方法来处理了。那么在蛇头位置插入的这个元素该如何确定呢？我们来看下面这段程序： 1234567891011121314151617181920212223--计算下一个目标点function getNextPoint() --计算下一个目标点 snake=&#123;&#125; if(dir==0) then snake.x=snakes[1].x snake.y=snakes[1].y-20 end if(dir==1) then snake.x=snakes[1].x snake.y=snakes[1].y+20 end if(dir==2) then snake.x=snakes[1].x-20 snake.y=snakes[1].y end if(dir==3) then snake.x=snakes[1].x+20 snake.y=snakes[1].y end return snakeend &emsp;&emsp;这里定义了getNextPoint()的方法，目的是计算在蛇头位置添加的下一个元素，这里我们注意到根据蛇的移动方向(dir)的不同，其中0表示上、1表示下、2表示左、3表示右，计算出下一个元素的位置，因为在这个游戏中网格大小是20，所以这里可以直接根据坐标来计算一个元素的位置。snakes是一个table，保存的是当前的蛇的全部元素的坐标。通过维护这个table，我们就可以利用绘图的函数绘制出蛇的身体，这样蛇就可以移动起来了。我们来看看蛇是怎样移动的： 123456789101112131415161718--核心算法——蛇的移动function SnakeUpdate() --获取元素个数 local n=table.maxn(snakes) if(table.maxn(snakes)&gt;0) then if(getNextPoint().x==foodX and getNextPoint().y==foodY) then --将下一个目标点的位置插入表中 table.insert(snakes, 1, getNextPoint()) --将食物状态设置为BeEated foodState=\"BeEated\" else --将下一个目标点的位置插入表中 table.insert(snakes, 1, getNextPoint()) --移除最后一个元素 table.remove(snakes,n+1) end endend &emsp;&emsp;在这里我们定义了一个foodState变量以保存食物的状态，当食物的状态为BeEated的时候表示食物被蛇吃掉了，此时应该重新生成一个食物的坐标，此时事物的状态将变成WaitToEat。食物的坐标保存在foodX和foodY这两个变量中，大家可以到完整的代码中去查看。 游戏状态我们知道蛇碰到四周墙壁的时候就会死亡，此时游戏结束。这个比较简单，只要判断蛇头的坐标和屏幕的关系就可以了。因为在这个游戏中屏幕的尺寸为640X640，所以判断游戏是否结束的代码可以这样写： 123456--判断游戏状态 if(snakes[1].x&lt;=0 or snakes[1].x&gt;=640 or snakes[1].y&lt;=0 or snakes[1].y&gt;=640) then gameState=0 else gameState=1 end &emsp;&emsp;这里gameState为0表示游戏结束，gameState为1表示游戏正常进行。 完整代码&emsp;&emsp;在完成了这些核心的算法以后，剩下的事情就交给Love2D引擎来绘制吧，最后给出完整的程序代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176--定义窗口宽度和高度local w=640local h=640--定义网格单元大小local unitSize=20;--方块的初始位置local initX=320local initY=320--移动方向local dir=1--贪吃蛇集合local snakes=&#123;&#125;--食物状态--WaitToEat：绘制食物--BeEated：随机生成食物local foodState=\"WaitToEat\"--游戏状态--0：游戏结束--1：游戏正常local gameState=1--食物的位置local foodX=0local foodY=0--Love2D加载事件function love.load() --设置窗口标题 love.window.setTitle(\"Love2D-贪吃蛇游戏\") --设置窗口大小 love.window.setMode(w,h) --定义字体 myFont=love.graphics.newFont(30) --设置字体 love.graphics.setFont(myFont) --设置背景色 love.graphics.setBackgroundColor(255,255,255,255) --设置线条类型为平滑 love.graphics.setLineStyle(\"smooth\") --设置线宽 love.graphics.setLineWidth(0.1) --蛇的初始化(蛇的长度为5) for i=1,5 do snake=&#123;&#125; snake.x=initX +(i-1) * 20 snake.y=initY snakes[i]=snake end --食物初始化 foodX=love.math.random(32-1)*20 foodY=love.math.random(32-1)*20end--Love2D绘制事件function love.draw() --绘制竖线 love.graphics.setColor(0,0,0,255) for i=0,w,unitSize do love.graphics.line(0,i,h,i) end --绘制横线 for j=0,h,unitSize do love.graphics.line(j,0,j,w) end --绘制蛇 for i=1,table.maxn(snakes) do love.graphics.setColor(0,0,255,255) love.graphics.rectangle(\"fill\",snakes[i].x,snakes[i].y,20,20) end --绘制食物 if(foodState==\"WaitToEat\") then love.graphics.setColor(255,0,0,255) love.graphics.rectangle(\"fill\",foodX,foodY,20,20) end --如果游戏结束则显示GameOver if(gameState==0) then love.graphics.setColor(255,0,0,255) love.graphics.print(\"Game Over\",250,300) endend --function love.update(dt) --判断游戏状态 if(snakes[1].x&lt;=0 or snakes[1].x&gt;=640 or snakes[1].y&lt;=0 or snakes[1].y&gt;=640) then gameState=0 else gameState=1 end --如果游戏状态为正常 if(gameState==1) then SnakeUpdate() FoodUpdate() endend--核心算法——蛇的移动function SnakeUpdate() --获取元素个数 local n=table.maxn(snakes) if(table.maxn(snakes)&gt;0) then if(getNextPoint().x==foodX and getNextPoint().y==foodY) then --将下一个目标点的位置插入表中 table.insert(snakes, 1, getNextPoint()) --将食物状态设置为BeEated foodState=\"BeEated\" else --将下一个目标点的位置插入表中 table.insert(snakes, 1, getNextPoint()) --移除最后一个元素 table.remove(snakes,n+1) end endend--随机生成食物function FoodUpdate() --如果食物被蛇吃掉则重新生成食物 if(foodState==\"BeEated\") then foodX=love.math.random(32-1)*20 foodY=love.math.random(32-1)*20 foodState=\"WaitToEat\" endend--根据玩家按下的键位定义不同的方向function love.keypressed(key) if(key==\"a\") then dir=2 end if(key==\"d\") then dir=3 end if(key==\"w\") then dir=0 end if(key==\"s\") then dir=1 endend--计算下一个目标点function getNextPoint() --计算下一个目标点 snake=&#123;&#125; if(dir==0) then snake.x=snakes[1].x snake.y=snakes[1].y-20 end if(dir==1) then snake.x=snakes[1].x snake.y=snakes[1].y+20 end if(dir==2) then snake.x=snakes[1].x-20 snake.y=snakes[1].y end if(dir==3) then snake.x=snakes[1].x+20 snake.y=snakes[1].y end return snakeend &emsp;&emsp;将代码压缩成.love文件后就可以运行了，我们来看看最终的效果： Demo1 Demo2 &emsp;&emsp;本文的项目作为开源项目托管在Github上，可以通过Github来获取项目源代码。谢谢大家，今天的内容就是这样了。","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"Love2D","slug":"Love2D","permalink":"https://qinyuanpei.github.io/tags/Love2D/"},{"name":"贪吃蛇","slug":"贪吃蛇","permalink":"https://qinyuanpei.github.io/tags/%E8%B4%AA%E5%90%83%E8%9B%87/"}]},{"title":"当梦想照进现实","date":"2015-03-10T10:45:51.000Z","path":"posts/3321992673/","text":"&emsp;&emsp;回到学校将近一周了，工作依然没有着落。每天穿梭在校园里，看着身边熙熙攘攘的人群来来往往，面对着许许多多陌生的面孔，看着太阳每天的起起落落，听着校园广播吟唱那些恍若隔世的时光。我深切地感受到作为一名即将毕业的大四学生，此时此刻站在这里是多么的多余。 &emsp;&emsp;我一直想到外面去看看，因为我觉得只有到外面去才能找到让我梦想扎根的地方。我和家里人说了我的这个想法，家里建议我先在宁夏找工作，如果在宁夏实在找不到工作再考虑出去。我听从了这个建议，可是当我开始找工作的时候，我却突然发现自己错了。如果说以前想去外面是因为觉得外面的工作找起来容易的话，那么此时此刻当我在宿舍里写下这篇文章的时候，这无疑是一种赤裸裸的讽刺了，因此我发现我在银川都找不到合适的工作。第一次推开一家公司的门，我以为只要我的技术达到了应聘的要求我就可以胜任这份工作，可是我错了，环境科学这个专业会牢牢地拴住我一辈子。当我在网上投递简历的时候，我以为我的专业对我的求职不会产生什么影响，可是我又错了，我都没想到我的简历会因为专业不符合要求而被直接忽略。在这一瞬间，我突然好后悔当初的决定，我后悔选择了宁夏大学这样一个本地的211 ，我后悔选择了环境科学这样一个我从来没有喜欢过却要羁绊我一生的专业。 &emsp;&emsp;三叔从我大三的时候就开始关注我的工作问题，他当年农校毕业后工作辗转多次终于在镇上做了一个司法所的所长，有次他跟我说起当年农校里同学现在的情况时，提出了一个叫做不务正业的观点，就是说当年农校里的那些同学现在都是在做着和农校时候学到无关的工作。我不知道这样的现象是不是中国教育的一个缩影，因此我不能评价这种想法到底是对还是错。可是当我那天把去年买的教材送给一名前来借书的学弟的时候，我突然沉默了好久。我的父母含辛茹苦地供我上大学，即使是这样一个我从来没有喜欢的专业，可是我却轻而易举地将这种付出像丢垃圾一样撇在一边，到底环境科学专业对我意味着什么？到底这大学四年对我意味着什么？是我一直在努力想要想明白却始终想不明白的问题。 &emsp;&emsp;我就是想单纯地去解决技术上的问题，然后通过技术让我们的生活更加美好。我一直觉得这样的想法会成为我一生都去奋斗的信仰，可是当我回顾四周的时候看到有的人早已找到工作，我真的不明白，到底是我想要的太多不肯放下身段去做些没有技术含量的工作，还是这个世界的价值存在某种扭曲：一个人要花费四年的时光去做些一辈子里只能做一次的事情，可是当付出了那么多以后突然发现生命里早已有了定数，你想要试图改变的可能仅仅因为环境科学这四个字就变成空想，你最终踏上的注定是和大部分一样平凡的生命。 &emsp;&emsp;此时此刻，我处在环境科学和游戏的夹缝里，环境科学我本不喜欢，从来没有想要在这个领域谋生的打算，可是当我想要做些什么的时候，我却在这座城市里渐渐迷失了方向。网页开发、电子商务、设备维护这些仅仅是计算机行业中的一部分工作，可是大部分人都认为这就是我喜欢的计算机行业，这是吗？我在心里暗暗问自己。我去那家公司应聘的时候，公司里有个人建议我到外面去报个培训班，因为他觉得我在大学里学的和企业需求完全是两回事，可是我作为一个应届毕业生，我原本就是希望到公司里去学习实际的项目经验的，你为什么就要要求我有两到三年的经验呢，我想就算是研究生都不可能天天待在公司里慢慢积累经验吧。我没有抱怨的意思，我只是想让自己快些找到合适的工作，我实在不想继续在这样纠结下去了，希望明天到招聘会上会有所收获吧！","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"梦想","slug":"梦想","permalink":"https://qinyuanpei.github.io/tags/%E6%A2%A6%E6%83%B3/"},{"name":"现实","slug":"现实","permalink":"https://qinyuanpei.github.io/tags/%E7%8E%B0%E5%AE%9E/"},{"name":"毕业季","slug":"毕业季","permalink":"https://qinyuanpei.github.io/tags/%E6%AF%95%E4%B8%9A%E5%AD%A3/"}]},{"title":"HTML5游戏开发技术基础整理","date":"2015-03-08T19:14:44.000Z","path":"posts/2038378679/","text":"&emsp;&emsp;随着HTML5标准最终敲定，HTML5将有望成为游戏开发领域的的热门平台。HTML5游戏能够运行于包括iPhone系列和iPad系列在内的计算机、智能手机以及平板电脑上，是目前跨平台应用开发的最佳实施方案。本文系根据[HML5 Canvas游戏开发实战]一书中的内容整理而成，是了解和学习HTML5游戏开发的基础内容，希望能够帮助到那些和博主一样致力于游戏开发的朋友们！ JavaScript中的面向对象编程&emsp;&emsp;对于游戏开发来说，面向对象编程(OOP)是一种重要而且必要的方法，所以在了解HTML5游戏开发前，首先应该了解JavaScript中的面向对象编程。JavaScript是一种基于对象的语言，可它并不是一种真正的面向对象的编程语言，因为在JavaScript的语法中不存在类(Class)的概念。下面我们将分析和解决在JavaScript中实现封装、继承等面向对象的问题。 在JavaScript中函数(function)就是就是一个类(class)1234//声明一个函数function MyClass()&#123;&#125;//实例化一个对象var cls1 = new MyClass(); 使用this关键字就可以为类增加属性12345678910//声明一个类并定义其构造函数function MyClass(name,age)&#123; this.name = name; this.age = age;&#125;;//实例化一个对象var cls1 = new MyClass(\"张三\",20)//输出cls1的两个属性值alert(\"name=\" + cls1.name + \"&amp;\" + cls1.age) 使用prototype属性可以为类添加方法12345678910111213141516171819202122//声明一个类并定义其构造函数function MyClass(name,age)&#123; this.name = name; this.age = age;&#125;;//为MyClass增加方法MyClass.prototype=&#123; toString:function() &#123; alert(\"name=\" + this.name + \"&amp;\" + this.age) &#125;, getName:function() &#123; alert(\"name=\" + this.name) &#125;, getAge:function() &#123; alert(\"age=\" + this.age) &#125;&#125;; 使用apply方法实现属性和方法的继承12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455//定义一个父类Peoplefunction People()&#123; this.type=\"人\"&#125;;//为父类定义一个方法People.prototype=&#123; getType:function() &#123; alert(\"type=\" + this.type) &#125;&#125;;//定义一个子类Studentfunction Student(name,age,sex)&#123; //继承父类的属性type People.apply(this,arguments); this.name = name; this.age = age; this.sex = sex;&#125;;//声明一个Student实例var stu = new Student(\"张三\",20,\"男\")；//输出typealert(stu.type)//下面我们来了解下如何继承父类的方法，继承父类方法主要通过循环使用父对象的prototype进行复制来实现，如//重新定义子类Studentfunction Student(name,age,sex)&#123; //继承父类的属性type People.apply(this,arguments); //继承父类的方法，略显抽象 var prop; for(prop in People.prototype) &#123; var proto = this.constructor.prototype; if(!proto[prop]) &#123; proto[prop] = People.prototype[prop]; &#125; proto[prop][\"super\"] = People.prototype; &#125; //属性定义 this.name = name; this.age = age; this.sex = sex;&#125;;//实例化Student对象var stu = new Student(\"张三\",20,\"男\");stu.getType(); 静态类的实现1234567891011function staticClass()&#123; staticClass.name = \"张三\"; staticClass.toString=function &#123; alert(\"name=\" + staticClass.name ) &#125;;&#125;;alert(staticClass.name);staticClass.toString(); Canvas绘图基础HTML5提供了图像、视频、音频、表单、位置、本地数据库、离线存储、websocket等各种全新的特性，对于HTML游戏开发而言，我们主要关注图像、音频、本地数据库以及websocket等，首先我们来了解下Canavs绘图的基础内容。 &emsp;&emsp;Canvas是HTML5为我们提供的一张画布，可以让我们在HTML上直接绘制图形，因此Canvas可以作为HTML5游戏开发的基本元素，即HTML5游戏引擎的底层都是以Canvas元素来驱动的。Canvas本身没有绘图的能力，需要借助于JavaScript来实现绘图的功能。使用Canvas元素只需要在网页中添加canvas标记即可，如 1&lt;canvas id=\"myCanavs\" width=\"800\" height=\"480\"&gt;&lt;/canvas&gt; &emsp;&emsp;接下来我们通过JavaScript来获取这个Canvas并通过相关API实现绘图环境的初始化 12345678//获取Canvas元素var canvas = document.getElementById('myCanvas');//检查canvas合法性if(canvas &amp;&amp; canvas.getContext)&#123; //获取当前上下文 var ctx = canvas.getContext('2d') &#125; &emsp;&emsp;因为目前Canvas只支持2D绘图，因此，这里的参数暂时只能为2d。因为Cnavas绘图的API都封装在ctx这个实例中，因此下面的所有操作都是基于ctx来实现的： 使用Canvas绘制线123456789101112//设置线宽ctx.lineWidth = 10;//设置画笔颜色ctx.strokeStyle = \"red\";//创建一个路径ctx.beginPath();//路径起点ctx.moveTo(10,10);//路径终点ctx.lineTo(150,50);//绘制路径ctx.stroke(); 使用Cnavas绘制矩形12345678//设置线宽ctx.lineWidth=5;//设置画笔颜色ctx.strokeStyle-\"red\"//创建路径ctx.beginPath();//绘制矩形ctx.strokeRect(10,10,70,40); &emsp;&emsp;或者 1234//定义矩形ctx.rect(10,10,70,40);//绘制矩形ctx.stroke(); 如果需要对矩形进行填充 1234//创建路径ctx.beginPath()//绘制矩形ctx.fillRect(10,10,70,40) 使用Canvas绘制圆123456//创建路径ctx.beginPath();//定义圆ctx.arc(100,100,50,0,360*Math.PI/180,true);//绘制圆ctx.stroke(); &emsp;&emsp;同样地，可以使用fill进行填充绘制 123456//创建路径ctx.beginPath();//定义圆ctx.arc(100,100,50,0,360*Math.PI/180,true);//绘制圆ctx.fill(); 使用Canvas绘制圆角矩形绘制圆角矩形需要arcTo函数配合lineTo来完成 12345678910111213//创建路径ctx.beginPath();ctx.moveTo(40,20);ctx.lineTo(100,20);ctx.arcTo(100,20,120,40,20);ctx.lineTo(120,70);ctx.arcTo(120,90,100,90,20);ctx.lineTo(40,90);ctx.arcTo(20,90,100,70,20);ctx.lineTo(20,40);ctx.arcTo(20,20,40,20,20);//绘制圆角矩形ctx.stroke(); 使用Canvas绘制复杂图形&emsp;&emsp;在HTML5中可以通过quadraticCurveTo函数绘制二次贝塞尔曲线，通过bezierCurveTo函数绘制三次贝塞尔曲线,具体代码请参考API文档。 使用Canvas绘制文字1234//设置字体ctx.font=\"30px Arial\";//绘制文字ctx.strokeText(\"Hello HTML5\",100,50); 使用Canvas绘制图片&emsp;&emsp;绘制图片使用drawImage函数，其函数原型如下： 1drawImage(image,dx,dy); &emsp;&emsp;其中image可以是HTML中的标签或者是JavaScript中的Image对象。如 12//定义一个img标签&lt;img id=\"img_source\" src=\"source.jpg\" width=\"240\" height=\"240\"/&gt; &emsp;&emsp;接下来通过getElementById来取得图像数据，并将其绘制出来 12var img=document.getElementById(\"img_source\");ctx.draw(img,200,200); &emsp;&emsp;如果直接使用JavaScript代码 123var img=new Image();img.src=\"source.jpg\";ctx.draw(img,200,200) 图形的平移操作&emsp;&emsp;使用translate函数实现在水平和垂直方向上的平移 图形的旋转操作&emsp;&emsp;使用rotate函数实现旋转，需要注意的是传入的参数是弧度 图形的伸缩操作&emsp;&emsp;使用scale函数实现伸缩，当参数为负值时表示在该方向上翻转 图形高级特效&emsp;&emsp;这里主要介绍线性渐变、径向渐变、颜色反转、灰度。####线性渐变 1234567//创建一个线性渐变容器var grd=ctx.createLinearGradient(0,0,200,0);//添加颜色grd.addColorStop(0.2,\"#00ff00\");grd.addColorStop(0.8,\"#ff0000\");//应用渐变ctx.fillStyle=grd; ####径向渐变 1234567//创建一个径向渐变容器var grd=ctx.createRadialGradient(100,100,10,100,100,50);//添加颜色grd.addColorStop(0,\"#00ff00\");grd.addColorStop(,\"#ff0000\");//应用渐变ctx.fillStyle=grd; ####颜色反转&emsp;&emsp;遍历每个像素并对RGB值进行取反####灰度&emsp;&emsp;灰度计算公式：gary=red0.3+green0.59+blue*0.11 &emsp;&emsp;基础的内容就是这些了，以后如果碰到需要HTML5的地方可以回过头来看看。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"HTML5","slug":"HTML5","permalink":"https://qinyuanpei.github.io/tags/HTML5/"},{"name":"技术","slug":"技术","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"笔记","slug":"笔记","permalink":"https://qinyuanpei.github.io/tags/%E7%AC%94%E8%AE%B0/"}]},{"title":"互联网黑洞读书笔记(2)","date":"2015-02-11T15:50:55.000Z","path":"posts/1930050594/","text":"&emsp;&emsp;在移动互联网时代地大潮中，微信无疑是整个行业的弄潮儿。从“微信之父”张小龙最初定义微信这个产品的那一刻开始，就注定微信将走上一条平台化的道路，各种各样可能的商业模式成为人们开始不断探索微信的价值，可是这一切和你有关系吗？ 在中国这种人情社会，越来越脆弱的信任纽带，急需有微信这样的工具来加固；越来越高的交往成本，更急需微信这样的工具来降低。 &emsp;&emsp;微信给中国社会带来的强大震感和冲击，其实仅仅是一个很小的圈子。互联网讲究的是大格局，强调的是跨越时空。可是大部分的中国人都不在这个格局里，我们不具备穿越时空的条件。每个人都有自己的中国梦，可是你扪心自问：你跟别人的中国梦共同的有多少呢？换句话说，我们每一个人都很宅，而微信不过是让我们更宅而已，不管有没有微信，我们都是在过着柴米油盐酱醋茶这样的普通人的生活，而中国人性格里会不由自主的对外界进行自我戒备，我们的圈子其实就那么大。 每个人都不容易，不能再彼此伤害。互联网思维，是一种开明的思维，一种能看到大格局的思维，一种超越自我的思维。 &emsp;&emsp;就像大部分人所理解的互联网一样，互联网的自由精神在带给我们便利的生活的同时，给某些人以可乘之机，使得我们距离互联网近在咫尺而又遥不可及，我们都习惯于互联网带给我们的这种便利，可是在我们内心深处我们仍然将互联网视为洪水猛兽。 在世界范围内，全民制衡历来是种对社会有价值的力量。这种制衡一旦制度变化，就会变得持续而稳定，直接后果就是国家的回归。依次是三种境界：回归社会、回归国民、回归自然。 &emsp;&emsp;我从来不喜欢政治，因为是政治是一种极其微妙的东西，正直且单纯的人永远不适合政治，可是因为互联网的舆论作用，互联网所代表的全民制衡开始不断地和政治发生着反应，互联网精神的终极目标从来都不是取代和颠覆现有的模式，而是希望在和政治博弈的过程中让这个世界更加美好。 因为互联网文明将摧毁一切旧的东西，一切大家习以为常的东西。在互联网面前，每个人都是平等的，大家可以通过网络获取信息、获取服务，互联网发展到今天，当我们每个人都对身边的一切习以为常的时候，互联网却在不断地改变我们与世界接触的方式，这就是创新，这就是变革。 &emsp;&emsp;当互联网以一种新的模式去颠覆现有模式的时候，任何的以政治理由为出发点的干预在我看来都是徒然的，因为干预者之所以干预无非是因为这种变革影响到了其利益，可是不管怎样，政治本身并不具备互联网的思维，国家队的搜索在市场竞争中失败便是最好的例子。 不仅仅上流社会和主流社会漠视互联网，全社会都漠视互联网。 &emsp;&emsp;我们每个人每天都在使用互联网，可是我们真的了解互联网吗？我们不可或缺地依赖着互联网，却从来不对为这个行业努力付出的程序员们表示尊敬，如果有一天这个世界没有了互联网，有多少人的生活会变得混乱不堪？ 互联网的人文属性，决定了盈利模式的地域局限和社会差异。从互联网第一天进入中国，一直到今天，无数美国的盈利模式，都没在中国火起来，这就是互联网的人文属性。 &emsp;&emsp;每一个国家、每一个地区的互联网盈利模式都会存在差异，这就是互联网的人文属性。例如国外用户都有购买付费软件的习惯，可是在中国人们更喜欢盗版甚至破解。中国互联网的一个特点是免费，可是免费从来都是最贵的。如果你需要一个功能，国外用户会选择一个软件，国内用户则会选择XX助手，这就是人文上的差异。 张小龙给了我们三个启示 关系能为技术带来超乎想象的附加值 移动互联网的附加值压迫基于本土实现 新型移动应用在垄断用户数据方面更具魔力 &emsp;&emsp;当我们感慨移动互联网的时候，大数据时代已经悄然来临，在大数据时代每个人的数据都是一个数据云，如果我们能够将这些数据收集起来加以利用的话，那么这可能就是大数据时代留给我们的机会吧。 无论是什么思维，不能解决问题，便没有价值。 &emsp;&emsp;如果要问我为什么想去做一名程序员，我会说因为我喜欢解决问题。 马化腾的故事告诉我们：不回到原点，不立足初始化的逻辑，世界对你而言，将会越来越陌生。 &emsp;&emsp;以前我的叔叔告诉我，就算没有百度，这个世界仍会有千度甚至万度。可是此时此刻我终于明白，复制一种产品相对容易，可是如何发挥自我的优势将产品做到极致，这是制胜的关键，所以我仍然认为没有人可以比李彦宏更了解搜索、做好搜索。微信的成功并非是微信在技术上的成功，而是腾讯懂得重新审视自我、突破自我，这是用户关系上的成功。 其实人生如白驹过隙，到头来不过是关系这两个字而已。 &emsp;&emsp;正如儒家研究人与人间的关系、道家研究人与自己的关系、佛家研究人的今生与前世的关系，归根到底都是关系，人活着所以幸苦，不过是将大量的时间用到了维护人与人的关系上去，这就是互联网的本质——关系。 任何形式的大大小小的互联网，无非是让我们彼此、让我们跟世界无限趋近于无缝连接而已。这种连接，就是彼此的回归。 &emsp;&emsp;桌面互联网让我们更好地获取信息、移动互联网让我们更好地获取服务、大数据则让我们更好地获取关系。 有意无意间，机会会变得有限而无限。超越是以别人为目标的颠覆，就是想打垮对方;颠覆是以自己为目标的超越，首先是孵化自己。虽然都是有意的，目标很明确，结果却不同。 &emsp;&emsp;同一价值体系内的超越和颠覆，固然有意义，然而体系与体系间的超越和颠覆却更加致命。 搜索引擎，至今仍然是互联网的制高点，搜索决定访问，离开有效访问，就没有一切，因此搜索确定一切。 &emsp;&emsp;尊重自然搜索、搜索决定一切是现代网络营销的核心，离开这些一切都是徒劳的。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"互联网","slug":"互联网","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%92%E8%81%94%E7%BD%91/"},{"name":"哲学","slug":"哲学","permalink":"https://qinyuanpei.github.io/tags/%E5%93%B2%E5%AD%A6/"},{"name":"微信","slug":"微信","permalink":"https://qinyuanpei.github.io/tags/%E5%BE%AE%E4%BF%A1/"},{"name":"人文","slug":"人文","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%BA%E6%96%87/"}]},{"title":"使用Mecanim动画系统来控制2D动画","date":"2015-02-11T13:35:58.000Z","path":"posts/2583252123/","text":"各位朋友，大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://blog.csdn.net/qinyuanpei。今天我想和大家分享的话题是在Unity3D中使用Mecanim动画系统来控制2D动画。 相信在大家的印象中，Mecanim动画系统主要运用在3D动画中，因为Mecanim动画系统提供了像动画重定向、人体骨骼动画等3D动画的特性，那么Unity3D的Mecanim动画系统能不能用来控制2D动画呢？如果在以前，博主和大家的理解是一样的，认为Mecanim只能运用到3D动画中，对于2D动画只能使用传统的逐帧动画和骨骼动画。可是前不久有位朋友问我，为什么不使用动画组件来控制2D动画呢？博主心想啊，这Mecanim动画系统真的能控制2D动画吗？经过博主查找大量资料和亲身实践，发现Mecanim是可以用来控制2D动画的，而且由于状态机的引入，我们对动画状态的控制会变得更为简单，从写代码的角度来看，这样可以减少我们的代码量便于维护。那么好了，今天我们就来一起学习下如何使用Mecanim动画系统来控制2D动画吧！ #传统2D动画的实现方式在Unity3D中传统2D动画的实现方式是基于逐帧动画的原理实现的，这种实现方式在Unity3D没有推出Unity2D前甚至在Unity2D推出后相当长的一段时间内，基本上我们最为常用的实现方式，博主在刚开始学习Unity3D的时候通常是以2D形式来展开的，因为博主认为2D和3D在原理上基本是相通的，如果我们掌握了2D游戏的基本原理，那么在实现3D游戏的时候就会相对容易些。我们来看看一个最简单的2D动画的脚本实现： 12345678910111213141516171819202122232425262728293031323334353637&#x2F;&#x2F;精灵渲染器private SpriteRenderer mRenderer;&#x2F;&#x2F;精灵集合public Sprite[] Sprites;&#x2F;&#x2F;FPS,即每秒钟的画面帧数public float FPS &#x3D; 24;&#x2F;&#x2F;精灵索引private int index &#x3D; 0;&#x2F;&#x2F;当前时间private float currentTime &#x3D; 0;void Start () &#123; mRenderer &#x3D; GetComponent&lt;SpriteRenderer&gt;();&#125; void Update () &#123; &#x2F;&#x2F;获取当前时间 currentTime +&#x3D; Time.deltaTime; &#x2F;&#x2F;如果达到了更新画面的时间 if(currentTime &gt;&#x3D; 1 &#x2F; FPS) &#123; &#x2F;&#x2F;使索引增加 index +&#x3D; 1; &#x2F;&#x2F;清除时间记录 currentTime &#x3D; 0; &#x2F;&#x2F;当索引更新到最后一帧时,索引重置 if(index &gt;&#x3D; Sprites.Length) &#123; index &#x3D; 0; &#125; &#125; &#x2F;&#x2F;更新画面 mRenderer.sprite &#x3D; Sprites[index];&#125; 通过分析，我们可以发现这段脚本存在以下问题： 动画维护困难：每增加一个动画就需要添加一个数组，不仅增加了动画的维护难度，同时降低了脚本的效率。 状态维护困难：因为在Update方法里实现的是一个动画，因此当我们需要在各个动画状态间进行切换的时候，我们需要使用更多的代码来维护相关逻辑。 #使用Mecanim动画系统的实现方式为了解决传统的2D动画实现方式中存在的动画维护困难、状态维护困难这两个问题，我们需要一种更好的方案来实现2D动画的控制，这种方案需要提供较为方便的动画维护功能，即各个动画是独立的，当改变了某一个动画时，其余的动画不会发生改变。其次，这种方案需要提供较为方便的状态维护功能，即各个动画状态切换是方便的，我们可以更好地从这一种状态切换到另一种状态。关于动画状态切换，大家可以去了解下有限状态机(FSM)的概念，这里我们不做深入的探究，这里我们选择Unity3D的Mecanim动画系统，因为Mecanim动画系统正好解决了这两个问题。好了，下面我们来一起学习一个2D动画的实例：首先我们在场景中创建一个名为PlayerController的空物体，然后在该物体的下面增加一个精灵组件(Sprite),并将其命名为PlayerSprite，这样做的好处是Unity3D将为我们自动创建较为规范的命名。好了，现在我们选择PlayerController这个物体，然后通过Window-&gt;Animation菜单打开Animation窗口： 首先我们点击AddCurve按钮，此时将弹出一个对话框让我们保存动画文件，这里我们存储为Player@Idle.anim,并将其保存在项目目录下的Animations\\Player目录下，这样可以方便我们维护和查找特定的动画文件。在保存完动画文件后，此时会弹出如下的界面，我们选择PlayerSprite节点下的SpriteRenderer，然后选择Sprite，因为这里我们的2D动画主要是通过改变SpriteRenderer的Sprite属性来实现的，最后我们点击Sprite节点后面的加号来完成对象的选取。此时会在动画窗口中显示时间轴和刻度线，我们将在这里完成动画的编辑。大家可以注意到默认情况下，动画面板添加了两帧，即第1帧和最后一帧，其总时间是1秒，同时我们注意到这里有一个采样率(Sample),其实这就是当前动画的FPS了。好了，现在我们开始制作第一个动画： 在资源文件夹中，我们可以找到当前动画的图片素材，注意到这个图片中总共有12帧画面，因此我们可以按照0.05s的间隔来分配整个时间轴，所以我们可以这样添加帧： 好了，现在我们就完成了一个Idle动画的制作，现在打开角色的动画控制器PlayerController，这是Unity3D为我们自动创建的一个动画控制器，因为我们现在只有一个Idle动画，所以在Animaotr窗口中我们可以看到只有一个Idle状态，现在我们将这个状态设为默认状态。好了，现在我们可以直接运行游戏，发现在场景中角色开始循环播放Idle动画了。好了，现在让我们重复刚才的步骤，来完成角色的其余动画。 经过一番努力，我们现在已经完成了角色所有动画的制作，现在我们来设计角色的动画状态机： 设计好角色的动画状态机后我们开始来编写脚本，以实现角色动画的控制： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143using UnityEngine;using System.Collections;public class PlayerController : MonoBehaviour &#123; public enum PlayerState &#123; Idle, Move, LightAttack, WeightAttack &#125; public PlayerState State&#x3D;PlayerState.Idle; &#x2F;&#x2F;玩家移动速度 public float WalkSpeed &#x3D; 0.75f; public float RunSpeed &#x3D; 1.5f; &#x2F;&#x2F;玩家跳跃力的强度 public float JumpForce &#x3D; 200f; &#x2F;&#x2F;位置限制 public float MinX &#x3D; -5.80f; public float MaxX &#x3D; 5.80f; public float MinY &#x3D; -1.80f; public float MaxY &#x3D; 0.35f; &#x2F;&#x2F;玩家朝向，默认朝右 public bool isFaceRight &#x3D; true; &#x2F;&#x2F;动画组件 private Animator mAnim; &#x2F;&#x2F;2D刚体 private Rigidbody2D mRig2D; void Start () &#123; mAnim&#x3D;GetComponent&lt;Animator&gt;(); mRig2D&#x3D;GetComponent&lt;Rigidbody2D&gt;(); &#125; void Update() &#123; SpriteMove(); SpriteAttack(); SpriteJump(); SpriteIdle(); &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 精灵Idle &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void SpriteIdle() &#123; &#x2F;&#x2F;当玩家无任何操作时恢复到Idle状态 if (!Input.anyKey) &#123; mAnim.SetBool(&quot;Jump&quot;, false); mAnim.SetBool(&quot;Attack&quot;, false); mAnim.SetBool(&quot;BigAttack&quot;, false); mAnim.SetBool(&quot;Skill&quot;, false); mAnim.SetBool(&quot;BigSkill&quot;, false); State&#x3D;PlayerState.Idle; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 精灵攻击 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void SpriteAttack() &#123; &#x2F;&#x2F;轻击，键位J if(Input.GetKey(KeyCode.J)) &#123; mAnim.SetBool(&quot;Attack&quot;, true); State&#x3D;PlayerState.LightAttack; &#125; &#x2F;&#x2F;重击，键位K if(Input.GetKey(KeyCode.K)) &#123; mAnim.SetBool(&quot;BigAttack&quot;, true); State&#x3D;PlayerState.WeightAttack; &#125; &#125; &#x2F;&#x2F;&#x2F; &lt;summary&gt; &#x2F;&#x2F;&#x2F; 精灵跳跃 &#x2F;&#x2F;&#x2F; &lt;&#x2F;summary&gt; private void SpriteJump() &#123; if (Input.GetKey(KeyCode.I)) &#123; mAnim.SetBool(&quot;Jump&quot;, true); mRig2D.AddForce(new Vector2(0, Time.deltaTime * JumpForce), ForceMode2D.Impulse); &#125; &#125; private void SpriteMove() &#123; float h &#x3D; Input.GetAxis(&quot;Horizontal&quot;); float v &#x3D; Input.GetAxis(&quot;Vertical&quot;); Vector2 mPos &#x3D; mRig2D.position; mAnim.SetFloat(&quot;Speed&quot;, Mathf.Sqrt(h * h + v * v)); float mPosX, mPosY; if (Mathf.Sqrt(h * h + v * v) &gt; 0.5f)&#123; mPosX &#x3D; mPos.x + h * Time.deltaTime * RunSpeed; mPosY &#x3D; mPos.y + v * Time.deltaTime * RunSpeed; &#125;else&#123; mPosX &#x3D; mPos.x + h * Time.deltaTime * WalkSpeed; mPosY &#x3D; mPos.y + v * Time.deltaTime * WalkSpeed; &#125; mRig2D.MovePosition(new Vector2(mPosX, mPosY)); if (h &gt; 0 &amp;&amp; !isFaceRight) &#123; FlipSrite(); &#125; else if (h &lt; 0 &amp;&amp; isFaceRight) &#123; FlipSrite(); &#125; &#125; void FlipSrite() &#123; if(isFaceRight)&#123; transform.rotation&#x3D;Quaternion.Euler(0,180,0); isFaceRight&#x3D;false; &#125;else&#123; transform.rotation&#x3D;Quaternion.Euler(0,0,0); isFaceRight&#x3D;true; &#125; &#125;&#125; 好了，现在我们可以来看看最终的效果，博主这里是想利用这些素材来制作一个横板过关的游戏，可是因为文章篇幅有限，所以这部分内容只能留到以后再和大家分享了。 #Mecanim动画系统应用扩展好了，到现在为止，基于Mecanim动画系统的2D动画控制基本上讲解完了。下面我们说说Mecaanim动画系统应用扩展。通过前面的学习，我们知道Unity2D使用的Mecanim动画系统主要是通过改变游戏体的属性来实现某种特定的动画效果的，例如我们这里的动画是通过改变角色精灵附加的SpriteRenderer组件的Sprite属性来实现的，因此从本质上来说Unity2D的动画控制器是一种属性动画。总体来说，Unity2D可以实现以下类型的动画： 位移动画：通过Transform组件的Position属性实现 旋转动画：通过Transform组件的Rotation属性实现 伸缩动画：通过Transform组件的Scale属性实现 渐变动画：通过更改指定组件的颜色或材质实现 脚本动画：通过更改指定脚本的变量或字段实现 好了，这就是今天这篇文章的全部内容了，希望大家喜欢！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"Mecanim","slug":"Mecanim","permalink":"https://qinyuanpei.github.io/tags/Mecanim/"},{"name":"动画","slug":"动画","permalink":"https://qinyuanpei.github.io/tags/%E5%8A%A8%E7%94%BB/"}]},{"title":"脚本语言编程：Lua脚本编程入门","date":"2015-02-03T16:06:31.000Z","path":"posts/1940333895/","text":"Lua是一门简单而强大的语言，其本身强大的扩展性使得这门语言在游戏设计等领域发挥着重要的作用。博主曾在Unity3D中使用过这门语言，并且针对Lua和Unity、C++等方面的内容进行了学习和讨论。最近因为在【游戏脚本高级编程】这本书中详细介绍了Lua脚本的相关内容，因此在这里记录下博主的读书心得，方便以后在需要的时候查阅。 ###Lua系统构成Lua系统由Lua链接库、Luac编译器、Lua解释器三部分构成。 Lua链接库主要由lua.lib和lua.h这两个文件组成。Lua链接库主要负责对自身进行初始化及关闭操作、装载脚本与执行脚本、提供可调用交互接口。 Luac编译器是一个由命令行驱动的编译器，其名称为Luac。当我们需要使用Luac编译器来编译一个脚本时，只需输入1&gt;luac &lt;FileName&gt; //FileName为脚本名称 我们可以直接通过Lua链接库来装载脚本并在装载的过程中实现动态编译，可是这样会造成两个问题，即无法在动态编译过程中获取错误信息和动态编译使脚本加载速度变慢，在使用的时候应该注意到这个问题。 Lua解释器是一个由命令行驱动的代码运行环境，我们可以直接在这个环境中运行和测试脚本代码。 ###Lua脚本语法 注释：Lua脚本的注释以–开始，如 1&gt; --这是一句注释 当我们需要对多行脚本进行注释的时候，可以采取手动换行的方式进行多个单行的注释。 变量：Lua脚本中的变量是无类型的、隐式声明、首个字符必须是非数字字符、对大小写敏感。Lua脚本中变量的一个重要特性生支持多重赋值，即允许在赋值运算符的左边同时写下多个变量。如 123456-- 变量个数等于数值个数x,y,z=1,2,3-- 变量个数大于数值个数,z的值为nilx,y,z=1,2-- 变量个数小于数值个数,3这个数值将被忽略x,y=1,2,3 数据类型：在Lua中支持6种数据类型，即数字(number)、字符串(string)、函数(function)、表(table)、用户数据(userdata)、空值(nil)。 123456789101112131415161718192021222324252627282930313233343536373839404142434445数字(number)指整型和浮点型的数据。字符串(string)指字符串类型的数据。函数(function)指一个正式声明的函数的引用。如：function fib(n) if(n&lt;2) then return n else return fib(n-1)+fib(n-2) endend-- 在Lua中函数可以赋值给变量fib2=fib-- 调用fib函数print(fib2(5))表(table)是Lua语言中最简单同时是最复杂的数据结构：简单如普通数组，复杂如链表、字典、类等。-- 我们在构造一个数据集合时，不需要指定数据类型和数据大小-- 完成初始化后的数据集合默认索引从1开始，除非显示地声明索引0处的数值-- 构造一个数字类型的数组IntArray=&#123;1,2,3,4,5&#125;-- 构造一个字符串类型的数组StringArray=&#123;\"A\",\"B\",\"C\",\"D\"&#125;-- 打印IntArray的第一个元素,输出为1print(IntArray[1])-- 显示声明StringArray索引0处的数值StringArray[0]=\"E\"-- 打印StringArray的第一个元素和第二个元素，输出为E,Aprint(StringArray[0],StringArray[1])-- 打印一个越界的数组值，输出为nilprint(IntArray[10])-- 在Lua中表的数据类型可以是不同的table[0]=\"table\"table[1]=1-- 在Lua中表的索引可以是任意类型,因为表是基于键-值原理来工作的Enemy=&#123;&#125;Enemy[\"Name\"]=\"Enemy\"Enemy[\"HP\"]=100Enemy[\"Speed\"]=30-- 特别地，如果Key是一个合法的字符串类型，那么Table[Key]与Table.Key是等价的。Enemy=&#123;&#125;Enemy.Name=\"Enemy\"Enemy.HP=100Enemy.Speed=30用户数据(userdata)是Lua语言中一个特殊的数据类型，它允许在Lua脚本的变量中存放C语言中的指针。空值(nil)是各种语言中通用的一种数据类型，在此不再赘述。在Lua脚本中我们可以使用type()函数来获取任意数据的类型 逻辑与表达式：Lua和大部分的编程类似支持加减乘除等运算，不同的是在Lua中使用~=来表示不等关系。Lua支持的条件逻辑主要有if-then-else以及嵌套的if-then-else，Lua不支持switch结构。Lua支持的循环结构主要有while、for、repea三种结构，如： 12345678910111213141516171819202122-- 这是一个while循环i=0while(i&lt;10) do i++ print(i)end-- 这是一个for循环for i=0,10 do print(i)end -- 这是一个repeat循环repeat print(i) i++until(i&gt;10)-- 这是一个扩展的for循环，类似于Foreach结构,主要用来遍历表(table)for key,value in tables do print(k,value)end ###Lua与C/C++交互Lua与C/C++交互主要通过Lua 提供的C API来完成，其核心是Lua堆栈，一个简单的C++代码调用Lua脚本的示例代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192#include &lt;iostream&gt;using namespace std;#include &lt;iostream&gt;extern \"C\" &#123;#include \"lua.h\"#include \"lualib.h\"#include \"lauxlib.h\"&#125;using namespace std;int main()&#123; //创建Lua环境 lua_State* L=luaL_newstate(); //打开Lua标准库,常用的标准库有luaopen_base、luaopen_package、luaopen_table、luaopen_io、 //luaopen_os、luaopen_string、luaopen_math、luaopen_debug luaL_openlibs(L); //下面的代码可以用luaL_dofile()来代替 //加载Lua脚本 luaL_loadfile(L,\"script.lua\"); //运行Lua脚本 lua_pcall(L,0,0,0); //将变量arg1压入栈顶 lua_getglobal(L,\"arg1\"); //将变量arg2压入栈顶 lua_getglobal(L,\"arg2\"); //读取arg1、arg2的值 int arg1=lua_tonumber(L,-1); int arg2=lua_tonumber(L,-2); //输出Lua脚本中的两个变量 cout &lt;&lt;\"arg1=\"&lt;&lt;arg1&lt;&lt;endl; cout &lt;&lt;\"arg2=\"&lt;&lt;arg2&lt;&lt;endl; //将函数printf压入栈顶 lua_getglobal(L,\"printf\"); //调用printf()方法 lua_pcall(L,0,0,0); //将函数sum压入栈顶 lua_getglobal(L,\"sum\"); //传入参数 lua_pushinteger(L,15); lua_pushinteger(L,25); //调用printf()方法 lua_pcall(L,2,1,0);//这里有2个参数、1个返回值 //输出求和结果 cout &lt;&lt;\"sum=\"&lt;&lt;lua_tonumber(L,-1)&lt;&lt;endl; //将表table压入栈顶 lua_getglobal(L,\"table\"); //获取表 lua_gettable(L,-1); //输出表中第一个元素 cout &lt;&lt;\"table.a=\"&lt;&lt;lua_tonumber(L,-2)&lt;&lt;endl; //调用C++方法首先需要注册该方法 lua_register(L, \"AverageAndSum\", AverageAndSum);&#125;static int AverageAndSum(lua_State *L)&#123; //返回栈中元素的个数 int n = lua_gettop(L); //存储各元素之和 double sum = 0; for (int i = 1; i &lt;= n; i++) &#123; //参数类型处理 if (!lua_isnumber(L, i)) &#123; //传入错误信息 lua_pushstring(L, \"Incorrect argument to 'average'\"); lua_error(L); &#125; sum += lua_tonumber(L, i); &#125; //传入平均值 lua_pushnumber(L, sum / n); //传入和 lua_pushnumber(L, sum); //返回值的个数，这里为2 return 2;&#125; 请确保在计算机中安装了Lua环境，并在VC++目录中添加相关的头文件引用和库文件引用。相应的Lua脚本代码定义如下： 12345678910111213141516171819202122232425--在Lua中定义两个变量arg1=15arg2=20--在Lua中定义一个表table=&#123; a=25, b=30&#125;--在Lua中定义一个求和的方法function sum(a,b) return a+bend--在Lua中定义一个输出的方法function printf() print(\"This is a function declared in Lua\")end--在Lua中调用C++中定义并且注册的方法average,sum=AverageAndSum(20,52,75,14)print(\"Average=\".average)print(\"Sum=\".sum)","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"Lua","slug":"Lua","permalink":"https://qinyuanpei.github.io/tags/Lua/"},{"name":"脚本语言","slug":"脚本语言","permalink":"https://qinyuanpei.github.io/tags/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/"},{"name":"语法","slug":"语法","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%AD%E6%B3%95/"}]},{"title":"互联网黑洞读书笔记(1)","date":"2015-02-03T09:45:57.000Z","path":"posts/1478979553/","text":"&emsp;&emsp;互联网是什么？当我们都渐渐习惯将互联网当作生活的一部分的时候，面对这样一个问题，我们似乎是迷茫和困惑的。因为当互联网渐渐地开始改变我们生活的那一刻起，我们就在和互联网不断地发生着剧烈反应。 &emsp;&emsp;本书作者仲昭川在互联网经济这一章曾这样描述过互联网： 东方的先哲曾以“天人合一论”兴起了以道德为主线的农业文明，随后西方的民主法治和流水线分工率先把社会重新组合为以金钱为主线的工业文明。而Internet带来的信息革命，又极大地破坏了以这个分析为哲学、以垄断为目标、以金钱为动力的西方体系，人类世界的文明再次转向以神秘为哲学、以分享为目标、以道德为动力的东方体系。 &emsp;&emsp;这样的描述让我们开始重新审视互联网，互联网时代的本质是数据对数据、信息对信息交换，这种经济的特点是，在给了人们更多选择的自由的同时，让更多的东西逐渐从黑暗中走出来，成为公信力引导下的公开博弈，而更加不可思议的是，这种近乎原始时代的信誉体系却是人们主动地、自发地建立并维护的。社会的一切都是价格和价值，而到了互联网时代一切都变成了利益和兴趣。互联网时代更多的是在以价值为导向，而非以技术为导向。因为真正能改变甚至颠覆传统行业的互联网模式，可能并不是建立在一项伟大的技术的基础之上，而是这种新的模式能为人们的生活带来怎样的利用价值，互联网的本质是服务行业，这种属性到了移动互联网时代变得更加地明确了。 IT行业和互联网行业是完全不同的两个行业。这种界定，是科技与人文、技术与关系之间的分野。 &emsp;&emsp;具体的理解是，互联网是一个泛行业或者说全行业，因为对于任何一个行业，只要你有足够的线上用户就可以称之为互联网行业。而在不久的将来，任何行业都将具有互联网行业的属性，因为互联网将深刻地影响到各个行业。可以说互联网的本质就是关系，而且是全新的、广泛的关系、跨越时空的关系;而且是不管什么需求，都要发生关系;而且是跟任何人发生关系，不管是熟人还是陌生人;而且是随时随地发生关系，不管是此时此地还是彼时彼地。而IT是什么呢？IT是科技，解决技术问题，当所有的技术集成到一起并能成功运行的时候就是IT,当所有技术集成到一起而且足够轻的时候就是便携，便携就会产生移动，当人们使用这些便携的IT产品相互发生关系时就是移动互联网。 互联网本来就是要让不同兴趣的人分开，让不同利益的人早点各奔前程 &emsp;&emsp;互联网表面上没有边界，可是实际上互联网中的每个人都有自己的倾向和归属。因此互联网上不同的兴趣、不同的利益，使互联网上到处都输部落，不管聊天群还是网站，本质上都是一群兴趣相投的人组成的部落。 当大家都希望长期地、大范围地、频繁地、深入地发生关系的时候，就会产生对品牌的渴望和依赖。 &emsp;&emsp;因为品牌代表了一种稳定的关系，它包含了实用性、信任度、荣誉感，即品牌权威所说的三种关系：利益关系、情感关系、社会关系。 人类文明发展到今天，基本就分为两类：人文与科技。人文崇尚感受，科技崇尚数理 人文的东西，生来就是为了创造经典并流传后世，一到顶峰就很难被超越，给世人留下了恒久的享受或遗产。人文所对应的，是精神、道义、经验、规范、模式、规则等，诸如此类，人文是人们用来管理、调整并保持欲望的一种手段。 科技的东西，是人们用来满足旧欲望并刺激新欲望的，所以它注定昙花一现，随时准备离场、时刻等待淘汰。那些驻足在时光之海的科技发明，不是因为不伟大，而是因为存活时间太短。 互联网的本质是关系 &emsp;&emsp;你了解关系，就了解相互需求，就知道怎么让对象找你，而不是用大成本去寻找对象。 互联网思维有两个特点：与众不同、与己不同 &emsp;&emsp;与众不同就是要存同求异，因为多元共生的互联网才能有创新和活力。&emsp;&emsp;与己不同就是找出自己的优势和不足，和自己发生关系。","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"互联网","slug":"互联网","permalink":"https://qinyuanpei.github.io/tags/%E4%BA%92%E8%81%94%E7%BD%91/"},{"name":"哲学","slug":"哲学","permalink":"https://qinyuanpei.github.io/tags/%E5%93%B2%E5%AD%A6/"},{"name":"思维","slug":"思维","permalink":"https://qinyuanpei.github.io/tags/%E6%80%9D%E7%BB%B4/"},{"name":"价值","slug":"价值","permalink":"https://qinyuanpei.github.io/tags/%E4%BB%B7%E5%80%BC/"}]},{"title":"当Unity3D游戏开发遇上Excel","date":"2015-01-25T19:41:57.000Z","path":"posts/906436376/","text":"&emsp;&emsp;各位朋友，大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://blog.csdn.net/qinyuanpei。今天我们来聊聊常用办公软件Excel和游戏开发那不为人知的秘密。今天的内容将涉及到Excel在游戏开发中的应用以及如何利用程序解析Excel中的数据。 &emsp;&emsp;作为常用的办公软件的Excel相信大家都不陌生啦。可是如果我们认为Excel只是办公软件的话，那么这就不只是天真而是Out了。事实上Excel和游戏开发有着密切的联系，不知道大家还记不记得那款利用Excel开发出来的三国杀，这可能是Excel第一次以游戏开发的身份出现在大家面前吧。我们知道在游戏开发领域有一种工作叫做策划，就像在软件开发领域有一种工作叫做产品经理一样。而在诸多的策划工作中，数值策划是一个可以直接影响游戏进程的工作，因为数值策划体现了一个游戏在整体数值上的平衡，设计者需要维护好这样一个平衡，确保游戏外的玩家和游戏里的敌人面对的是同一个公平的虚拟世界。 &emsp;&emsp;例如《仙剑奇侠传四》这款游戏中，韩菱纱在游戏后期的速度可以说是完全打破了游戏的平衡性，因为韩菱纱本身的速度就比较快，再加上仙风云体术的加速效果完全对玄霄产生了戏剧性压制，导致在游戏结尾的Boss战中经常是韩菱纱出手N次后才挨到玄霄出手，我们知道韩菱纱的乾坤一掷每次消耗气15，可是因为韩菱纱的速度足够快，所以韩菱纱完全可以通过普通物理攻击快速地积满气进而施展乾坤一掷，这就是游戏的平衡性被打破了呀，更不要说这部游戏里最为经典的千方残光剑Bug了，这同样是游戏平衡性的问题，归根到底是紫英的这个技能在配置数据时出现了错误，这充分说明数据的正确合理与否是会对游戏产生重要影响的。尽管我们可以使用Xml、Json、ini、数据库等存储形式来存储这些数据，可是毫无疑问的是，Excel是Window平台上最好的数据处理软件，因此数值策划更倾向于使用Excel来设计游戏中的数据，面对如此重要的数值策划工作，我们自然希望在解析Excel文件时不会出现错误，可是我们总不能指望着策划把Excel数据转换成我们能处理的数据类型吧，因此就有了博主今天的这篇文章，所以在今天的文章中我们主要的内容就是如何通过程序来解析Excel文件。 ###1、项目需求&emsp;&emsp;最近博主一个朋友向我抱怨，说手头上有好几百个Excel工作表要处理，大概几十万条数据吧。原因是当时公司分配任务时交待不清，等到了向公司交接数据的时候，朋友忽然发现这些Excel文件的表格格式和公司规定的不一样啊。这可急坏了博主的这位朋友，博主的朋友只好不断地的复制、黏贴，因为这些数据是分布在不同的数据表里，朋友整天都忙得焦头烂额，可是即使这样效率还是得不到保证啊，朋友最后找到了博主这里，问我能不能编写程序帮他解决这个问题。因为平时经常与技术圈子里的朋友聊天，所以在博主印象里Excel的解析在游戏开发中还是较为常见的，而且博主知道对于微软的Office办公软件是可以通过VBA编程来实现某些功能的，可是因为博主一直在用国产的WPS，所以对于Excel的解析基本上是停留在一个概念性的认识上，可是朋友的忙不能不帮不是，所以博主决定借着这个机会好好研究下Excel文件的解析。 ###2、解决方案&emsp;&emsp;因为博主在之前并没有过解析Excel文件的经历，所以博主就到Github上淘了些开源项目。和很多人爱逛天猫、淘宝的经历类似，如果你发现有一个人经常喜欢到Github上晃荡、喜欢关注技术类的博客或者资讯、经常再看PDF版的技术文档或书籍，请千万不要怀疑，这个人绝对是程序员。哈哈，好了，玩笑就此打住啊。经过博主对这些开源项目的简单分析和整理，目前，对Excel文件解析的解决方案主要有以下三种： ####1、Microsoft.Office.Interop.Excel&emsp;&emsp;第一种解决方案是基于微软提供的Office API,这组API以COM组件的形式给出，我们可以通过调用该API实现对Excel文件的解析。使用这组API非常简单,博主稍后会为大家给出一个示例代码。微软的Office API特点是使用起来方便，可以使用C#、Visual Basic等语言进行相关开发。可是这种解决方案的的缺点同样很明显，因为COM组件主要依赖于系统，因此使用COM组件需要在系统中注册，这将对代码的可移植性产生影响，而且受制于COM技术，这种解决方案只能运行在Windows平台上，无法实现跨平台，加之解析速度较慢，因此这种方案通常只适合在解析速度要求不高，运行环境为Windows平台的应用场景。 ####2、ExcelReader&emsp;&emsp;第二种解决方案得益于OpenOffice标准,OpenOffice标准可以让我们使用一种标准来解析和处理Excel文件而无需关注Excel文件是来自微软的Misrosoft Office、金山的WPS还是其它的办公软件。如果说第一种解决方案是Windows平台上解析Excel文件的选择之一，那么ExcelRead就是跨平台目标下解析Excel文件的首选方案。尤其像Unity3D这样的跨平台解决方案下，选择一个跨平台的类库或者组件能够保证我们的游戏在各种平台下稳定地运行，所以ExcelRead是博主向大家推荐的一个跨平台的Excel解析方案。 ####3、FastExcel&emsp;&emsp;第三种解决方案FastExcel是博主在解决博主的这位朋友的问题时所采取的方案。FastExcel是一个在开源世界里比较著名的Excel读写的类库，因此使用这个类库可以得到较为广泛的社区支持，而且在FastExcel这个项目的源代码中，作者为我们提供了使用FastExel进行Excel解析的相关示例，具有较高的参考价值，基本上可以在这个示例的基础上写出可以运行的代码。根据示例代码的运行结果使用FastExcel单独读写100000行数据基本上维持在3~4秒，读写速度还是蛮快的。不过FastExcel使用的是迭代器和Linq to Xml来读取Excel文件的，所以当数据表中存在空白单元格时，读写的时候会比较诡异，这一点希望大家注意。 ###3、工程案例&emsp;&emsp;既然今天的主题是Unity3D游戏开发，所以无论我们在前面提出了什么样的解决方案，最后我们都要落实到游戏开发上，所以最后和大家分享的是一个Unity3D配合ExcelReader实现Excel解析的简单案例。为什么要选择ExcelReader呢？因为ExcelReader是一个跨平台的解决方案。好了，下面我们一起来学习这个案例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273using UnityEngine;using System.Collections;using System.IO;using Excel;using System.Data;public class ExcelScripts : MonoBehaviour &#123; void Start () &#123; FileStream m_Stream=File.Open(Application.dataPath + \"\\\\Excel\\\\UserLevel.xlsx\",FileMode.Open,FileAccess.Read); //使用OpenXml读取Excel文件 IExcelDataReader mExcelReader=ExcelReaderFactory.CreateOpenXmlReader(m_Stream); //将Excel数据转化为DataSet DataSet mResultSets=mExcelReader.AsDataSet(); //读取行数 int rowCount=mResultSets.Tables[0].Rows.Count; //逐行读取,从第一行读以跳过表头 for(int i=1;i&lt;rowCount;i++) &#123; //将读取的Excel数据转化成数据实体 UserLevel mUser=new UserLevel(); mUser.Name=mResultSets.Tables[0].Rows[i][0].ToString(); mUser.Level=mResultSets.Tables[0].Rows[i][1].ToString(); mUser.Description=mResultSets.Tables[0].Rows[i][2].ToString(); mUser.Skill=mResultSets.Tables[0].Rows[i][3].ToString(); //输出Debug信息 Debug.Log(mUser.ToString()); //ADD:更多逻辑 &#125; &#125; //定义一个数据实体类UserLevel private class UserLevel &#123; private string m_Name; public string Name &#123; get &#123; return m_Name;&#125; set &#123; m_Name = value;&#125; &#125; private string m_Level; public string Level &#123; get &#123; return m_Level;&#125; set &#123; m_Level = value;&#125; &#125; private string m_Description; public string Description &#123; get &#123; return m_Description;&#125; set &#123; m_Description = value;&#125; &#125; private string m_Skill; public string Skill &#123; get &#123; return m_Skill;&#125; set &#123; m_Skill = value;&#125; &#125; public override string ToString() &#123; return string.Format(\"Name=&#123;0&#125;&amp;Level=&#123;1&#125;&amp;Description=&#123;2&#125;&amp;Skill=&#123;3&#125;\", m_Name,m_Level,m_Description,m_Skill); &#125; &#125;&#125; &emsp;&emsp;好了，这就是今天这篇文章的全部内容了，希望大家喜欢！","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"游戏","slug":"游戏","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F/"},{"name":"Excel","slug":"Excel","permalink":"https://qinyuanpei.github.io/tags/Excel/"}]},{"title":"Unity3D塔防游戏开发项目讲解(下)","date":"2015-01-21T13:50:48.000Z","path":"posts/1176959868/","text":"各位朋友，大家好，我是秦元培，欢迎大家关注我的博客，我的博客地址是http://blog.csdn.net/qinyuanpei。我们知道一个完整的塔防游戏由地图、敌人、防守单位三个部分组成，在上一篇文章中我们已经对地图这块儿进行了全面的讲解，今天我们来说说敌人和防守单位。 敌人篇敌人自动寻路的实现敌人在游戏中有一个基本的行为，即沿着寻路路径向我方阵地移动并发起攻击。在地图篇中，我们详细地介绍了敌人寻路路径的生成原理。既然有了敌人寻路的路线，那么怎么让敌人沿着路线移动呢？其实只要指定敌人寻路的起点就可以了，因为在寻路路径的设计中，我们使用的是一个类似于链表的结构，这样我们就能根据每个结点获取它的目标结点，从而实现敌人沿着寻路路径移动的效果了。因为敌人寻路的路线是定义在PathNode类中的，因此我们可以写出下面这样的代码： 123456789101112131415161718192021222324void Move()&#123; Vector3 mPos1&#x3D;this.transform.position; Vector3 mPos2&#x3D;this.StartNode.transform.position; &#x2F;&#x2F;计算敌人与路径节点间的距离 float mDis&#x3D;Vector2.Distance(new Vector2(mPos1.x,mPos1.y),new Vector2(mPos2.x,mPos2.y)); if(mDis&lt;0.1F)&#123; if(StartNode.ThatNode&#x3D;&#x3D;null)&#123; &#x2F;&#x2F;对防守阵地进行摧毁 GameManager.Instance.PlayerHP-&#x3D;20; &#x2F;&#x2F;从敌人列表中移除自身 GameManager.Instance.Enemys.Remove(this); &#x2F;&#x2F;销毁自身 Destroy(this.gameObject); &#x2F;&#x2F;销毁血条 Destroy(mHPBar.gameObject); &#125;else&#123; StartNode&#x3D;StartNode.ThatNode; &#125; &#125; &#x2F;&#x2F;计算敌人的移动方向 Vector3 mDir&#x3D;new Vector3(mPos2.x-mPos1.x,mPos2.y-mPos1.y,0).normalized; transform.Translate(mDir * MoveSpeed * Time.deltaTime);&#125; 好了，现在我们来一起分析这段代码。首先，我们计算了敌人与路径结点间的距离，这里我们用0.1来近似地表示敌人已经到了路径结点上，此时如果该结点的目标结点为null则表示此时敌人已经到了最后一个结点处，所以敌人会对我方的阵地造成20点的伤害并销毁敌人。在GameManager我们使用了一个列表来管理和维护当前场景中的所有敌人，因此当当前敌人销毁时需要从列表中移除，GameManager类是一个静态类，负责对游戏的全局维护，这个类我们放到稍后来讲啊。那么如果敌人没有走到最后一个结点怎么办呢？我们只需要将StartNode指向StartNode的目标节点，这样我们就可以对整个路径结点实现遍历。这里是不是有种数据结构的感觉呢？哈哈，数据结构和算法是编程中最基础、最重要的内容，这些内容到了游戏开发领域同样是适用的。那么，好了，既然知道敌人是怎么移动的，现在我们就来对敌人进行移动吧，这里是采用计算移动方向的方式来实现，这个很简单啦。 好了，现在我们来说说敌人的血条吧，我们知道当怪物沿着寻路路径向我方阵地发起攻击的时候，我方防守单位会自动地对敌人进行防御性攻击，那么此时血条就可以显示敌人的实时血量，从而方便玩家根据战场的情况来调整兵力部署情况。我们知道从Unity4.6以后Unity开始使用全新的GUI系统UGUI，因为博主在之前的项目中一直使用NGUI，加上博主不是很喜欢做UI，所以每次用NGUI的时候整个人的心情都是不好的，有段时间被NGUI虐得体无完肤，感觉整个人都不好了。好了，既然现在我们有了新的选择UGUI，那么就让我们先睹为快吧！如图，全新的NGUI位于GameObect-&gt;UI菜单下，基本覆盖了常用的如Button、Image、Slider、ScrollBar等控件，因为UGUI刚推出不久，所以博主希望大家还是能客观、公正的对待UGUI和NGUI，博主认为在短期内这两个GUI系统将处于共存的状态，不存在相互替代的可能性。 好了，UGUI所有的控件都是放到一个叫做Canvas的父控件下的，这一点和NGUI的UIRoot有些类似吧！Canvas提供了三种模式的UI系统，即Screen Space-Overlay、Screen Space-Camera、World Space。第一种Screen Space-Overlay它是完全以当前屏幕的像素大小创建的一个矩形范围，即控件是以屏幕坐标来绘制的；第二种Screen Space-Camera它是根据相机的视线范围来确定的一个矩形范围，其控件是根据Camera的ViewPortPoint坐标来绘制的;第三种从名称我们就可以知道，它是完全3D化的UI,使用的是常用的世界坐标。博主是刚开始研究UGUI,如果有不对的地方还希望大家能够原谅啊。好了，下面我们正式来做血条吧，在这里我们使用的是默认的Slider控件，用Slider控件来制作血条需要将Slider控件自带的滑块删除，然后我们通过改变value就可以实现一个简单的血条了。在UGUI中所有的图片素材都是以Sprite的形式来出现的，所以UGUI可以自己生成图集，不需要像NGUI在做UI前首先要生成图集。这是博主做的一个简单的血条。现在血条做好了，可是问题来了：这UGUI的所有控件都必须要放到Canvas下面啊，所以我们没法像NGUI一样直接把做好的血条放到怪物下面。怎么办呢？既然不能放到怪物下面，那我们就放到Canvas下面吧，不过我们需要自己计算血条的位置。好了，下面来看代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105public class Enemy : MonoBehaviour &#123; &#x2F;&#x2F;敌人的生命值 public float MaxHP; public float HP; &#x2F;&#x2F;敌人的初始路径节点 public PathNode StartNode; &#x2F;&#x2F;敌人的移动速度 public float MoveSpeed&#x3D;0.15F; &#x2F;&#x2F;敌人的旋转速度 public float RotateSpeed&#x3D;0.3F; &#x2F;&#x2F;敌人血条预制件 public GameObject HPBar; &#x2F;&#x2F;敌人血条组件 private Slider mHPBar; &#x2F;&#x2F;public EnemySpawn mSpawn; void Awake() &#123; &#x2F;&#x2F;在敌人列表中增加一个敌人 GameManager.Instance.Enemys.Add(this.GetComponent&lt;Enemy&gt;()); &#x2F;&#x2F;查找UI Transform mUiRoot&#x3D;GameObject.Find(&quot;UIManager&quot;).transform; &#x2F;&#x2F;计算血条位置 Vector3 mPos&#x3D;this.transform.FindChild(&quot;EnemyHP&quot;).transform.position; &#x2F;&#x2F;mPos&#x3D;Camera.main.WorldToViewportPoint(mPos); mPos.z&#x3D;-5; &#x2F;&#x2F;生成血条 GameObject go&#x3D;(GameObject)Instantiate(HPBar,mPos,Quaternion.identity); &#x2F;&#x2F;使血条成为Canvas的子物体 go.transform.parent&#x3D;mUiRoot; &#x2F;&#x2F;对血条进行放缩 go.GetComponent&lt;RectTransform&gt;().localScale&#x3D;new Vector3(0.5F,0.30F,1); &#x2F;&#x2F;获取Slider mHPBar&#x3D;go.transform.GetComponent&lt;Slider&gt;(); &#125; void Move() &#123; Vector3 mPos1&#x3D;this.transform.position; Vector3 mPos2&#x3D;this.StartNode.transform.position; &#x2F;&#x2F;计算敌人与路径节点间的距离 float mDis&#x3D;Vector2.Distance(new Vector2(mPos1.x,mPos1.y),new Vector2(mPos2.x,mPos2.y)); if(mDis&lt;0.1F)&#123; if(StartNode.ThatNode&#x3D;&#x3D;null)&#123; &#x2F;&#x2F;对防守阵地进行摧毁 GameManager.Instance.PlayerHP-&#x3D;20; &#x2F;&#x2F;从敌人列表中移除自身 GameManager.Instance.Enemys.Remove(this); &#x2F;&#x2F;销毁自身 Destroy(this.gameObject); &#x2F;&#x2F;销毁血条 Destroy(mHPBar.gameObject); &#125;else&#123; StartNode&#x3D;StartNode.ThatNode; &#125; &#125; &#x2F;&#x2F;计算敌人的移动方向 Vector3 mDir&#x3D;new Vector3(mPos2.x-mPos1.x,mPos2.y-mPos1.y,0).normalized; transform.Translate(mDir * MoveSpeed * Time.deltaTime); &#125; void Rotate() &#123; &#x2F;&#x2F;初始角度 float mStartAngle&#x3D;this.transform.eulerAngles.z; transform.LookAt(StartNode.transform); &#x2F;&#x2F;目标角度 float mTargetAngle&#x3D;this.transform.eulerAngles.z; &#x2F;&#x2F;计算旋转量 float mAngle&#x3D;Mathf.MoveTowardsAngle(mStartAngle,mTargetAngle,RotateSpeed *Time.deltaTime); this.transform.eulerAngles &#x3D; new Vector3(0,0,mAngle); &#125; void Update () &#123; Move(); UpdateHPBar(); &#125; private void UpdateHPBar() &#123; &#x2F;&#x2F;更新血条位置 Vector3 mPos&#x3D;this.transform.FindChild(&quot;EnemyHP&quot;).transform.position; &#x2F;&#x2F;使血条位于顶层 mPos.z&#x3D;-5; mHPBar.transform.position&#x3D;mPos; &#x2F;&#x2F;更新血量 mHPBar.value&#x3D;(float)HP&#x2F;MaxHP; &#125; public void SetDamage(int mValue) &#123; HP-&#x3D;mValue; if(HP&lt;&#x3D;0)&#123; Destroy(this.gameObject); Destroy(mHPBar.gameObject); GameManager.Instance.Enemys.Remove(this.GetCopmonent&lt;Enemy&gt;()); &#125; &#125;&#125; 在这里我们做了三件事情： 第一，在Awake方法中我们首先计算出血条的位置然后在这个位置生成血条，并取得相关的变量备用。 第二，在Update方法中增加一个UpdateHPBar方法以实现对血条血量的更新。 第三，增加了一个SetDamage方法，当敌人血量为0时销毁自身、销毁血条、从敌人列表中移除敌人 敌人按波次进攻的实现好了，到现在为止，对于敌人的逻辑我们就全部实现了。可是我们知道在塔防游戏中敌人通常是一波一波出现的，所以我们需要一个敌人生成器EnemySpawn。那么，怎么来生成敌人呢，这里我们使用Xml文件来配置要生成的敌人列表，首先我们来构建一个Xml文件： 12345678910111213141516171819&lt;?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"yes\"?&gt;&lt;Enemies&gt; &lt;Enemy Wave=\"1\" EnemyName=\"Enemy\" Level=\"1\" Wait=\"0.5\"/&gt; &lt;Enemy Wave=\"2\" EnemyName=\"Enemy\" Level=\"2\" Wait=\"0.45\"/&gt; &lt;Enemy Wave=\"2\" EnemyName=\"Enemy\" Level=\"2\" Wait=\"0.45\"/&gt; &lt;Enemy Wave=\"3\" EnemyName=\"Enemy\" Level=\"3\" Wait=\"0.4\"/&gt; &lt;Enemy Wave=\"3\" EnemyName=\"Enemy\" Level=\"3\" Wait=\"0.4\"/&gt; &lt;Enemy Wave=\"3\" EnemyName=\"Enemy\" Level=\"3\" Wait=\"0.4\"/&gt; &lt;Enemy Wave=\"4\" EnemyName=\"Enemy\" Level=\"4\" Wait=\"0.35\"/&gt; &lt;Enemy Wave=\"4\" EnemyName=\"Enemy\" Level=\"4\" Wait=\"0.35\"/&gt; &lt;Enemy Wave=\"4\" EnemyName=\"Enemy\" Level=\"4\" Wait=\"0.35\"/&gt; &lt;Enemy Wave=\"4\" EnemyName=\"Enemy\" Level=\"4\" Wait=\"0.35\"/&gt; &lt;Enemy Wave=\"5\" EnemyName=\"Enemy\" Level=\"5\" Wait=\"0.3\"/&gt; &lt;Enemy Wave=\"5\" EnemyName=\"Enemy\" Level=\"5\" Wait=\"0.3\"/&gt; &lt;Enemy Wave=\"5\" EnemyName=\"Enemy\" Level=\"5\" Wait=\"0.3\"/&gt; &lt;Enemy Wave=\"5\" EnemyName=\"Enemy\" Level=\"5\" Wait=\"0.3\"/&gt; &lt;Enemy Wave=\"5\" EnemyName=\"Enemy\" Level=\"5\" Wait=\"0.3\"/&gt; &lt;Enemy Wave=\"6\" EnemyName=\"Enemy\" Level=\"99\" Wait=\"0.15\"/&gt;&lt;/Enemies&gt; 从这个Xml文件中我们可以看到这样一个结构： 1234567891011121314151617using UnityEngine;using System.Collections;using System.Collections.Generic;using System.Xml;public class SpawnData &#123; &#x2F;&#x2F;敌人进攻波数 public int Wave; &#x2F;&#x2F;&#x2F;敌人名称，我们将根据这个名称来生成不同的敌人 public string EnemyName; &#x2F;&#x2F;敌人等级，我们将根据这个值来调整敌人的生命值和移动速度 public int Level; public float Wait;&#125; 在SpawnData这个结构中，我们可以得到敌人攻击的波数、敌人的名称、敌人等级、敌人生成需要等待的时间，因为博主在游戏中只有一种敌人，所以敌人的名称都是一样的。好了，现在我们可以开始解析Xml了： 1234567891011121314151617181920212223&#x2F;&#x2F;解析Xml文件void ReadXml()&#123; &#x2F;&#x2F;创建一个字典以存储敌人列表 mEnemyDatas&#x3D;new List&lt;SpawnData&gt;(); &#x2F;&#x2F;加载Xml文档 XmlDocument mDocument&#x3D;new XmlDocument(); mDocument.LoadXml(ConfigFile.text); XmlElement mRoot&#x3D;mDocument.DocumentElement; &#x2F;&#x2F;解析Xml文档 XmlNodeList mNodes&#x3D;mRoot.SelectNodes(&quot;&#x2F;Enemies&#x2F;Enemy&quot;); foreach(XmlNode mNode in mNodes) &#123; &#x2F;&#x2F;为每一个SpawnData赋值 SpawnData mData&#x3D;new SpawnData(); mData.Wave&#x3D;int.Parse(mNode.Attributes[0].Value); mData.EnemyName&#x3D;mNode.Attributes[1].Value; mData.Level&#x3D;int.Parse(mNode.Attributes[2].Value); mData.Wait&#x3D;float.Parse(mNode.Attributes[3].Value); mEnemyDatas.Add(mData); &#125;&#125; 那么好了，在解析完Xml后我们得到了所有的敌人数据，接下来我们只需要按照顺序生成敌人就可以了。具体怎么做呢，我们知道在塔防游戏中生成敌人有两种情况： 一个是要生成的敌人和当前敌人是同一波的，这种情况只要继续生成就好了。 一个是要生成的敌人的波数大于当前波数，这种情况需要等待这一波敌人被消灭完。 好了，现在来写代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124using UnityEngine;using System.Collections;using System.Collections.Generic;using System.Xml;public class EnemySpawn : MonoBehaviour &#123; &#x2F;&#x2F;敌人寻路起点 public PathNode SpawnPath; &#x2F;&#x2F;敌人预制件 public GameObject Enemy; &#x2F;&#x2F;Xml文件 public TextAsset ConfigFile; &#x2F;&#x2F;存放敌人的数组 private List&lt;SpawnData&gt; mEnemyDatas; &#x2F;&#x2F;当前敌人进攻波数 private int mWave&#x3D;0; &#x2F;&#x2F;当前敌人索引 private int mIndex&#x3D;0; &#x2F;&#x2F;当前等待的时间 private float mWait; void Start() &#123; &#x2F;&#x2F;读取Xml数据 ReadXml(); Debug.Log(mEnemyDatas.Count); &#x2F;&#x2F;初始化攻击波数 SpawnData mData&#x3D;mEnemyDatas[mIndex]; &#x2F;&#x2F;设置攻击波数和等待时间 mWave&#x3D;mData.Wave; mWait&#x3D;mData.Wait; GameManager.Instance.AttackWave&#x3D;mWave; &#x2F;&#x2F;生成第一个敌人 CreateEnemy(mData); mIndex+&#x3D;1; &#125; void CreateEnemy(SpawnData mData) &#123; GameObject go&#x3D;(GameObject)Instantiate(Enemy,SpawnPath.transform.position,Quaternion.identity); Enemy _Enemy&#x3D;go.GetComponent&lt;Enemy&gt;(); &#x2F;&#x2F;根据Level计算敌人的生命值和移动速度 _Enemy.MaxHP&#x3D; (float)mData.Level*0.25F * 100; _Enemy.HP&#x3D; (float)mData.Level*0.25F * 100; go.GetComponent&lt;Enemy&gt;().MoveSpeed&#x3D;(float)mData.Level * 0.15F; go.GetComponent&lt;Enemy&gt;().StartNode&#x3D;SpawnPath; &#125; void Update () &#123; if(mIndex&lt;&#x3D;mEnemyDatas.Count-1)&#123; SpawnEnemy(); &#125;else &#123; &#x2F;&#x2F;当索引数目大于敌人列表中的数目时，表示所有敌人以及生成完毕，此时 &#x2F;&#x2F;如果所有的敌人都被消灭，则表示玩家获胜。 if(GameManager.Instance.Enemys.Count&#x3D;&#x3D;0)&#123; GameManager.Instance.IsWin&#x3D;true; Debug.Log(&quot;玩家胜&quot;); &#125; &#125; &#125; private void SpawnEnemy() &#123; &#x2F;&#x2F;取得下一个生成的敌人的数据 SpawnData mData&#x3D;mEnemyDatas[mIndex]; &#x2F;&#x2F;开始计时 mWait-&#x3D;Time.deltaTime; if(mWait&lt;&#x3D;0 )&#123; &#x2F;&#x2F;如果当前是同一波敌人，则继续生成敌人 if(mWave&#x3D;&#x3D;mData.Wave)&#123; &#x2F;&#x2F;设置等待时间 mWait&#x3D;mEnemyDatas[mIndex].Wait; &#x2F;&#x2F;设置进攻波数 mWave&#x3D;mEnemyDatas[mIndex].Wave; GameManager.Instance.AttackWave&#x3D;mWave; &#x2F;&#x2F;生成一个敌人 if(mData!&#x3D;null)&#123; CreateEnemy(mData); &#125; mIndex+&#x3D;1; &#125;&#x2F;&#x2F;如果是下一波敌人，则需要等待这一波敌人全部死亡后再生成 else if(mWave&lt;mData.Wave &amp;&amp; GameManager.Instance.Enemys.Count&#x3D;&#x3D;0)&#123; &#x2F;&#x2F;设置等待时间 mWait&#x3D;mData.Wait; &#x2F;&#x2F;设置进攻波数 mWave&#x3D;mData.Wave; GameManager.Instance.AttackWave&#x3D;mWave; &#x2F;&#x2F;生成一个敌人 CreateEnemy(mData); mIndex+&#x3D;1; &#125; &#125; &#125; &#x2F;&#x2F;解析Xml文件 void ReadXml() &#123; &#x2F;&#x2F;创建一个字典以存储敌人列表 mEnemyDatas&#x3D;new List&lt;SpawnData&gt;(); &#x2F;&#x2F;加载Xml文档 XmlDocument mDocument&#x3D;new XmlDocument(); mDocument.LoadXml(ConfigFile.text); XmlElement mRoot&#x3D;mDocument.DocumentElement; &#x2F;&#x2F;解析Xml文档 XmlNodeList mNodes&#x3D;mRoot.SelectNodes(&quot;&#x2F;Enemies&#x2F;Enemy&quot;); foreach(XmlNode mNode in mNodes) &#123; &#x2F;&#x2F;为每一个SpawnData赋值 SpawnData mData&#x3D;new SpawnData(); mData.Wave&#x3D;int.Parse(mNode.Attributes[0].Value); mData.EnemyName&#x3D;mNode.Attributes[1].Value; mData.Level&#x3D;int.Parse(mNode.Attributes[2].Value); mData.Wait&#x3D;float.Parse(mNode.Attributes[3].Value); mEnemyDatas.Add(mData); &#125; &#125;&#125; 我们可以注意到，到现在为止敌人相关的内容博主都已经为大家讲解完了，这里博主和大家开了一个小玩笑，不知道大家有没有发现，在敌人的Xml配置文件中博主最后设计了一个等级为99级的敌人，哈哈，这个敌人在游戏中的特点大家要自己从代码中来探索了，大家可以按照博主的思路做出这个塔防游戏然后自己去试试看，相信大家会更加深刻地理解数值平衡的重要性吧！ 防守单位篇防守单位是塔防游戏中玩家可以支配和控制的一种资源，玩家通过合理地分布防守单位的位置来对玩家的防守阵地进行防御，当玩家的防守阵地被摧毁时玩家将无法继续部署防守单位。这就是防守单位在游戏中的主要作用。通常为了增加游戏的可玩性，游戏设计者往往会设计多种防守单位，在博主的这个小游戏中，我们只设计了一种防守单位，更多的防守单位的设计大家可以参考《保卫萝卜》和《植物大战僵尸》这两个游戏。好了，说了这么多，那么防守单位在整个塔防游戏中主要的作用是什么呢？答案就是防守，哈哈，这是一句不折不扣的废话。可是就是这样一句废话，却足以让我们知道防守单位需要对敌人进行自动攻击，这就要涉及到简单的AI算法了。好了，我们来看下面的脚本： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116using UnityEngine;using System.Collections;public class Defender : MonoBehaviour &#123; &#x2F;&#x2F;目标敌人 private Enemy mTarget; &#x2F;&#x2F;攻击半径 public float AttackArea&#x3D;2.5F; &#x2F;&#x2F;与敌人的距离 private float mDistance&#x3D;0; &#x2F;&#x2F;防守单位的旋转速度 public float RotateSpeed&#x3D;1.5F; &#x2F;&#x2F;防守单位攻击间隔 public float AttakTime&#x3D;2.5F; &#x2F;&#x2F;防守单位攻击间隔 private float mTime&#x3D;0.0F; &#x2F;&#x2F;炮弹预设 public GameObject BulletObject; void Start () &#123; &#x2F;&#x2F;初始化防守单位攻击间隔 mTime&#x3D;AttakTime; &#125; &#x2F;&#x2F;查找攻击范围内的敌人 void FindEnemy() &#123; &#x2F;&#x2F;初始化目标敌人 mTarget&#x3D;null; &#x2F;&#x2F;获取敌人列表 ArrayList mEnemys&#x3D;GameManager.Instance.Enemys; &#x2F;&#x2F;遍历每个敌人 foreach(Enemy _enemy in mEnemys) &#123; &#x2F;&#x2F;忽略生命值为0的敌人 if(_enemy.HP&#x3D;&#x3D;0) continue; &#x2F;&#x2F;计算防守单位与敌人间的距离 Vector3 mPos1&#x3D;transform.position; Vector3 mPos2&#x3D;_enemy.transform.position; float mDis&#x3D;Vector2.Distance(new Vector2(mPos1.x,mPos1.y),new Vector2(mPos2.x,mPos2.y)); if(mDis&gt;AttackArea)&#123; &#x2F;&#x2F;Debug.Log(&quot;敌人&quot; + _enemy.transform.name + &quot;未进入攻击范围,距离为:&quot; + mDis); &#x2F;&#x2F;return; &#125;else&#123; &#x2F;&#x2F;Debug.Log(&quot;敌人&quot; + _enemy.transform.name + &quot;已进入攻击范围,距离为:&quot; + mDis); &#x2F;&#x2F;选择最近的敌人 if(mDistance&#x3D;&#x3D;0 || mDistance &gt; mDis)&#123; mTarget&#x3D;_enemy; mDistance&#x3D;mDis; &#125; &#x2F;*&#x2F;&#x2F;选择生命值最低的敌人 if(mLife&#x3D;&#x3D;0 || mLife &gt; _enemy.HP)&#123; mTarget&#x3D;_enemy; mLife&#x3D;_enemy.HP; &#125; *&#x2F; &#125; &#125; mDistance&#x3D;0; &#125; void RotateTo() &#123; &#x2F;&#x2F;判断目标敌人是否为空 if(mTarget&#x3D;&#x3D;null) return; &#x2F;&#x2F;计算要旋转到敌人方向的角度 Vector3 mPos1&#x3D;this.transform.position; Vector3 mPos2&#x3D;mTarget.transform.position; Vector3 mDir&#x3D;(mPos2-mPos1).normalized; &#x2F;&#x2F;使得两向量共面 mDir.z&#x3D;0; &#x2F;&#x2F;计算两向量角度 float mAngle&#x3D;getAngle(Vector3.up,mDir); this.transform.eulerAngles&#x3D;new Vector3(0,0,mAngle) * RotateSpeed; &#125; &#x2F;&#x2F;根据向量数学计算角度 private float getAngle(Vector3 v1,Vector3 v2) &#123; float mDot&#x3D;Vector3.Dot(v1,v2); float mv1&#x3D;Mathf.Sqrt(v1.x*v1.x+v1.y*v1.y+v1.z*v1.z); float mv2&#x3D;Mathf.Sqrt(v2.x*v2.x+v2.y*v2.y+v2.z*v2.z); if(v2.x&gt;v1.x)&#123; return -Mathf.Acos(mDot&#x2F;(mv1*mv2))* Mathf.Rad2Deg ; &#125;else&#123; return Mathf.Acos(mDot&#x2F;(mv1*mv2))* Mathf.Rad2Deg ; &#125; &#125; void Attack() &#123; RotateTo(); if(mTarget&#x3D;&#x3D;null) return; &#x2F;&#x2F;以下添加攻击逻辑 mTime-&#x3D;Time.deltaTime; if(mTime&lt;0)&#123; Vector3 _angle&#x3D;transform.Find(&quot;Bullet&quot;).eulerAngles; Vector3 _pos&#x3D;new Vector3(this.transform.position.x,this.transform.position.y,-2); Instantiate(BulletObject,_pos,Quaternion.Euler(_angle)); mTime&#x3D;AttakTime; &#125; &#125; void Update () &#123; FindEnemy(); Attack(); &#125;&#125; 防守单位的脚本定义在Defender这个类中，主要的行为有两个，即发现敌人后转向敌人、向敌人发射炮弹，这块的代码较为简单，大家自己去领会就好啦。我们知道在塔防游戏中玩家可以通过点击屏幕来自由地增加或移动防守单位，这部分的内容主要是和GUI相关的，因为目前博主对UGUI掌握地还不是很熟，所以就等以后博主有时间了再来补充吧！好了，这个塔防游戏的讲解教程就是这样了，希望大家能够喜欢，我知道大家等这篇下篇已经好久了，哈哈！最后想说的是，博主的独立博客http://qinyuanpei.github.io正式开始使用了，以后发表的文章会在独立博客和CSDN同时更新，希望大家能继续关注博主的博客！谢谢大家","categories":[{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/categories/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"}],"tags":[{"name":"Unity3D","slug":"Unity3D","permalink":"https://qinyuanpei.github.io/tags/Unity3D/"},{"name":"教程","slug":"教程","permalink":"https://qinyuanpei.github.io/tags/%E6%95%99%E7%A8%8B/"},{"name":"游戏开发","slug":"游戏开发","permalink":"https://qinyuanpei.github.io/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/"},{"name":"塔防","slug":"塔防","permalink":"https://qinyuanpei.github.io/tags/%E5%A1%94%E9%98%B2/"}]},{"title":"剑指Offer读书笔记(1)","date":"2015-01-20T10:04:41.000Z","path":"posts/123663202/","text":"&emsp;&emsp;在此将【剑指Offer】中的经典问题和重要内容整理出来，便于以后遇到类似的问题再次查阅。博主强烈为大家推荐这本书，因为这本书中的题目都来自真实的公司笔试，对于大家求职、找工作会有很大的帮助。 1、在定义一个赋值运算符时，通常需要考虑以下四点： 是否将返回值的类型声明为该类型的引用，并在函数结束前返回实例自身的引用(即*this)。只有一个返回引用，才可以允许连续赋值，否则如果函数的返回值是void，应用该赋值运算符将不能做连续赋值。 是否将传入的参数类型声明为常量引用。如果传入的参数不是引用而是实例，那么从形参到实参会调用一次复制构造函数，把参数声明为引用可以避免这样的无谓消耗，能提高代码的效率。同时，我们在赋值运算函数内部不会改变传入的实例状态，因此应该在传入的引用参数前加上const关键字。 是否释放实例已有的内存，如果我们忘记在分配新内存之前释放自身已有的空间，恒旭将出现内存泄漏。 是否判断传入的参数和当前的实例是否是同一个实例。如果是同一个，则不进行赋值运算，直接返回，如果事先不判断就进行赋值，那么在释放实例自身内存的时候就会导致严重的问题，当*this和传入的参数是同一个实例时，一旦释放了自身的内存，传入的参数的内存将同时被释放，因此将再也找不到需要赋值的内容了。 &emsp;&emsp;当我们完整的考虑了上述四个方面以后，我们可以写出如下的代码： 1234567891011CMyString&amp; CMyString::operator = (const CMyString &amp;str)&#123; if(this==&amp;str) return; delete []m_pData; m_pData=NULL; m_pData=new char[strlen(str.m_pData)+1]; strcpy(m_pData,str.m_pData); return *this;&#125; 2、要想在赋值运算符函数中实现异常安全性，我们有两种方法 方法一：先用new分配新内容再用delete释放已有内容。这样只有当分配内容成功后再释放原来的内容，换句话说当分配内存失败时我们可以确定CMyString的实例不会被修改。 方法二：先创建一个临时实例，再交换临时实例和原来的实例 &emsp;&emsp;下面给出第二种方法的实现代码： 12345678910111213CMyString&amp; CMyString::operator = (const CMyString &amp;str)&#123; if(this！=&amp;str)&#123; CMyString strTemp(str); char* pTemp=strTemp.m_pData; strTemp.m_pData=m_pData; m_pData=pTemp; &#125; return *this&#125; 3、对于C++和C#中的struct和class的认识 C++:在C++中如果没有标明成员函数或者成员变量的访问权限级别，则在struct中默认的是public，在class中的默认的private。 C#:在C#中如果没有标明成员函数或者成员变量的访问级别，则struct和class默认都是private，不同的是struct定义的是值类型，其实例在栈上分配内存；class定义的是引用类型，其实例在堆上分配内存。 4、在C#中实现单例模式 原理：在C#语法中C#是在调用静态函数时初始化静态变量，.NET运行时可以保证只调用一次静态构造函数，这样我们就可以保证仅初始化一次Instance;下面给出代码示例：12345678910111213public sealed class Singleton&#123; private Singleton() &#123; &#125; private static Singleton instance=new Singleton(); public static Singleton Instance &#123; get&#123; return instance;&#125; &#125;&#125; 5、C++数组重要概念 数组是最简单的一种数据结构，它占据一块连续的内存并按照顺序存储数据。 在C/C++中，数组和指针是相互关联又有区别的两个概念。当我们声明一个数组时，其数组的名字同时是一个指针，该指针指向数组的第一个元素，因此我们可以使用一个指针来访问数组。可是值得注意的是，C/C++并没有记录数组的大小，因此使用指针访问数组中的元素时要注意不能超出数组的边界。 使用sizeof计算指针的大小时，在32位操作系统中，对于任意指针结果都是4。 二维数组在内存中占据连续的空间。在内存中从上到下存储各行元素，在同一行中按照从左到右的顺序存储。因此我们可以根据行号和列号计算出相对于数组首地址的偏移量，从而找到对应的元素。 6、C#中的String类型 在C#中封装字符串的类型Sysytem.String有一个非常特殊的性质，即String中的内容是不能改变的。当尝试改变String中的内容，就会产生一个新的实例。 如果要连续多次修改字符串内容，可以考虑使用StringBuilder。 当我们需要在函数或者方法中返回一个String实例时，我们需要在传入的参数前加上ref或者out标记 7、链表 链表是一种动态数据结构，因为在创建链表的时候，不需要知道链表的长度。当插入一个结点时，我们只需要为新结点分配内存，然后调整指针的指向来确保新结点被链接到链表当中。内存分配不是在创建链表时一次性完成，而是每添加一个结点分配一次内存。由于没有闲置的内存，因此链表的空间效率比数组要高。 因为链表中的内存不是一次性分配的，所以我们不能确定链表的内存和数组一样是连续的，因此如果想在链表中找到第i个结点，我们只能从头结点开始，沿着指向下一个结点的指针遍历链表，其效率是O(n)。而在数组中，我们可以根据下标i直接找到第i个元素，其效率是O(1)。 当我们需要从尾到头输出链表时，第一个遍历到的结点最后一个输出，而最后一个遍历到的结点第一个输出，这是典型的后进先出，因此我们可以考虑使用栈来实现这种顺序。下面是具体的代码实现：123456789101112131415161718void PrintListReversingly_Iteratively(ListNode* pHead)&#123; std::stack&lt;ListNode*&gt; nodes; ListNode* pNode=pHead; while(pNode!=NULL) &#123; nodes.push(pNode); pNode=pNode-&gt;m_pNext; &#125; while(!nodes.empty()) &#123; pNode=nodes.top(); printf(\"%d\\t\",pNode-&gt;m_nValue); nodes.pop(); &#125;&#125; 8、树 除了根节点之外每个结点只有一个父结点，根节点没有父结点。 除了叶节点以外所有结点都有一个或者多个子结点，叶结点没有子结点。父结点和子结点间用指针链接。 二叉树是树的一类特殊结构，在二叉树的每个结点最多只能有两个子结点。二叉树有三种主要的遍历方式，即前序遍历(根、左、右)、中序遍历(左、根、右)、后序遍历(左、右、根)。 二叉搜索树是二叉树的一个特例，其特点是左子节点总是小于或等于根节点，右子结点总是大于或等于根节点。 9、栈和队列 栈的特点是后进先出，即最后一个被压入(Push)栈的元素会第一个被弹出(Pop)。 队列的特点是先进先出，即第一个进入队列(入队)的元素将会第一个出来(出队)。 10、递归与循环 递归实现的效率无法和循环相比，因此函数调用会造成时间和空间的损失、会造成重复计算、可能会造成栈溢出。在经典的斐波那契数列问题中，我们可以采用下面的方法来代替传统的递归方法：123456789101112131415161718int Fiboncci(int n)&#123; int[] result=new int[]&#123;0,1&#125;; if(n&lt;2) return result[n]; int m=1; int n=0; int k=0; for(int i=2;i&lt;=n;i++) &#123; k=m+n; n=m; m=k; &#125; return k;&#125; 11、位运算 左移m&lt;&lt;n表示把m左移n位。左移n位的时候，最左边的n位将被丢弃，同时在最右边补上n个0。如： 00001010&lt;&lt;2=00101000 10001010&lt;&lt;3=01010000 右移m&gt;&gt;n表示把m右移n位。右移n位的时候，最右边的n位将被丢弃。此时如果数字是一个无符号数值，则用0填补最左边的n位;如果数字是一个正数，则在右移之后在左边补n个0;如果数字是一个负数，则右移之后在左边补n个1。如： 00001010&gt;&gt;2=00000010 10001010&gt;&gt;3=11110001","categories":[{"name":"读书笔记","slug":"读书笔记","permalink":"https://qinyuanpei.github.io/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://qinyuanpei.github.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"技术","slug":"技术","permalink":"https://qinyuanpei.github.io/tags/%E6%8A%80%E6%9C%AF/"},{"name":"读书","slug":"读书","permalink":"https://qinyuanpei.github.io/tags/%E8%AF%BB%E4%B9%A6/"},{"name":"剑指Offer","slug":"剑指Offer","permalink":"https://qinyuanpei.github.io/tags/%E5%89%91%E6%8C%87Offer/"}]},{"title":"写给永远单纯的自己","date":"2015-01-01T21:36:24.000Z","path":"posts/2752169106/","text":"&emsp;&emsp;即将到来的是新的一天，我却不能在疲惫中很快入睡，听着耳边再熟悉不过的歌，即使不是大家都喜欢的那种慷慨激昂的曲调，然而在这安静得无从察觉一个人内心世界的夜晚，这样温婉柔和的小调反而更容易让人静下心来想些事情。今天新住的宾馆简约而整洁，最为重要的是终于有了一张属于自己的桌子。以前每次趴在床上画图斑，等到再站起来时背部便开始痛起来。偶尔盘腿坐在床上录数据，等到再站起来时脚已经麻了。这样做的一个坏处是每次都会把中性笔的墨水弄到床单上，虽然顾客是上帝，可是上帝不断地给人类制造麻烦，这样真的好吗？与此同时，开始意识到一个良好的姿势对于健康是多么的重要了。 &emsp;&emsp;此时此刻，床上已经堆满了各种各样的图纸，那些来自我上个星期处理过的内业。所谓内业就是在室内加班，如果公司上下一致通过，理论上是符合SA8000社会责任标准体系的，所以内业是可以借休息的名义来进行的。这两天想了很多的问题，从什么地方说起呢？我想我可以从这些地方来谈谈我的想法吧。 &emsp;&emsp;首先是交流，我承认我是一个不喜欢说话的人。我不喜欢说话，从来不是因为我不敢而是因为我不愿意。我不喜欢看选秀节目、我不喜欢娱乐八卦、我不喜欢猎奇找刺激。我平时最为喜欢的是科技报道、技术博客和游戏资讯，因为此时此刻我站在科技和游戏的一个十字路口。我喜欢古香古色的传统文化，喜欢在书籍中寻找精神的依托，我就是这样一个传统而现代的人。可是这样一个时代注定是一个娱乐化的时代，当你打开电视，你会发现到处都是导师、到处都是明星、到处都是嘉宾，因为我们生活在一个每天都在造星的浮躁时代。我承认再这样一个时代充满了机会，可是当我们每一个人都缺乏耐心来专注于一件事情的时候，这样的机会对于我们又有什么意义呢？ &emsp;&emsp;我今天早上看《我是演说家》这个节目，我觉得这是一个比较有品位的节目，如乐嘉所说，这个节目的收视率可能不会像其它的娱乐节目那样高，可它能让你的内心真正有所触动，因为讲故事的人可能是一个你素不相识的人，可是它讲的故事可能会是你身上正在发生的事情。我从来不怀疑语言的力量，从春秋战国的张仪、苏秦等纵横家到三国时期诸葛亮舌战群儒再到世界上著名的营销专家，语言可以说世界上最锋利的武器，可是当大家都在讨论时下最为流行的娱乐节目时，我忽然觉得自己实在没有开口的必要了。那次领导说我分不清书记和主任，因为我觉得人与人之间的交流应该是随着时间的推移而不断深入的，所谓慢工出细活，我觉得交朋友应该像喝茶一样慢慢地品，像喝酒一样交朋友只能交到酒肉朋友。我们为了赶上工作进度，可能一周会去三四个地方，因此和许多人都只是一面之缘，所以我觉得分不清主任和书记尚属情有可原。 &emsp;&emsp;我每隔一段时间就会去我的博客看看，每次碰到问我问题的朋友我都很热心的回答，因为我觉得人与人之间真的存在某种特殊的联系。我特别喜欢和技术圈子里的这些朋友聊天，因为我觉得在这些人中间可以找到共同的话题，或许大家的经济状况都不宽裕，可是听着每一个人的故事都是一部奋斗史，没有人能随随便便成功，可是每一个人都在用一种近乎纯粹的信仰去努力实现，而不是随波逐流。或许这就是我喜欢这行的真正原因吧，每一天都充满新的挑战，每一天都是在不断创造，我就是喜欢这样的创造性工作，而不繁琐单调的机械重复。回到交流这个问题上，人是一种麻烦的动物，所以在和人打交道的这个问题上，我们把大量的时间浪费在了交流上。我承认团队间的交流十分重要，可是因为人的惰性和私欲，交流有时候会占用大量的时间成本，在这一点上计算机更值得人类学习，因为它忠诚可靠而且一视同仁。 &emsp;&emsp;接下来是工作，我一直坚信伟大的工作和平庸的工作间的区别就是能否让工作的人感到自豪。我的理想并不伟大，我只想某天朋友们聚到一起时候，我惊讶地发现你们的手机或者智能设备上运行着我设计的应用程序或者游戏，然后我平静地告诉你这些都是我设计的，这时候轮到你们惊讶：天啊，它简直堪称完美！在舜土实习已经快一个月了，可是我并没有对自己的工作感到自豪过，即使我能将10个左右的自然村在一个下午全部做完，可是我依然感到这是一份平庸的工作。首先，为了追赶进度，将一个行政村集中到一天来做，相比土地确权工作两天一个自然村的进度，整体质量较为粗放。其次，将希望完全寄托在队长身上，队长如果不配合，工作很难开展，如果队长失去耐心，工作会变得更加艰难。说实话，这些村民生活在山区生活困顿不堪，可是每次到村里都很热心地招待我们，这让我在感受到他们的质朴时更加自责，我们所做的工作从本质上来讲根本没有什么意义，每次和这些队长交流，他们最关心的问题就是他们的土地会不会被收回去，可是他们视如生命的土地却往往只是国土局任意划定的一个范围。作为一个实习生，或许抱怨工作是不合适的，因为无论到任何一个企业，前3~5年所做的始终都是些基础而琐碎的东西，可是不管让员工做什么，都要让员工觉得他此刻的这份工作是有意义的，因为这关系到一个企业的品位。工作固然是为了挣钱，可是如果工作能带给人幸福感和自豪感，那么我相信对于工作和人都是会有好处的吧，因为兴趣才是最好的老师啊。 &emsp;&emsp;今天搬到宾馆准备处理上周没处理完的事情，领导说明天要去的地方已经联系好了，可是公司的图纸还没有打印出来，他问我怎么处理，我就说跟人家实话实说吧，问题出在我们这边啊。然后他就说我傻，可是我觉得很多问题不是想掩盖就能掩盖的了的，就像我们所做的这个工作，一旦那些队长明白过来我们所做的事情的真正意图，那么整个结果就完全取决于对方，因为如果队长本身就告诉你错误的信息，那么你是无法辨别的。很多的技术公司都会形成自己公司内部的框架或者工具类，因为过度依赖第三方的组件很容易受到被动影响。或许乔布斯的专制和傲慢让很多苹果的员工和用户都曾受到伤害，可是他不过是使用了一个最基本的原则，要想不受制于别人，就必须掌控一切的主动权，所以苹果用自己的软件和自己的硬件打造了一个无可匹敌的强大壁垒。当然，逝者长已，可能苹果的产品中那些属于乔布斯个人标志的风格已经渐渐地淡出了我们的视野，可是我们依然会对这位智者表示无比崇高的敬意。 &emsp;&emsp;回到我的工作，这是一个完全没有追求的工作，昨天下午坐在车上和一个刚认识的朋友，他问我为什么不去找个和开发相关的实习工作啊，突然沉默了好半天，最后只能含糊其辞地糊弄过去。记得上次回银川，和一个实习生一起到楼下的打印店裁剪图册，结果半路上问我是什么专业？结果环境科学再次被鄙视了啊，哈哈，我不知道这样是喜还是悲，总之工作还是喜欢的好。以前我爸说我不喜欢这不喜欢那的，我到底喜欢什么啊？那个时候我没有说什么。可是这一刻我想告诉他我喜欢的就是开发。 &emsp;&emsp;最后要说的是做人，在同学的生日上，突然被人说我单纯，我不知道这该庆幸呢还是该感慨啊。今年的我22岁了，可我还是喜欢简简单单的生活。我不喜欢带着面具生活、我不喜欢口是心非、我不喜欢心机深重。我从来不觉得穿上大人的衣服、梳起大人的发型就能让你成熟起来，真正的成熟是要有责任、有担当。虽然不是每一个人都值得你敞开心扉去交往，可是做人坦诚、正直有什么不对吗？难道你希望每天面对人的时候都盘算着怎么玩弄那些可笑的伎俩吗？我承认在这个世界上有太多的事情我都还不懂，可我会努力去尝试着了解。我不喜欢抽烟、不喜欢喝酒，到现在不会划拳等那些酒场上应该会的东西。如果真想喝酒了，围炉小酌几杯便可以了，何必要让饮酒变成这样一件麻烦的事情呢？ &emsp;&emsp;我承认人生在成长的过程中难免会变得世故圆滑，可是难道这就是我们变得不再单纯的理由吗？这个世界上有两样永远不会变的东西，一样是我们头顶灿烂的星空，一样是我们心中崇高的道德准则。我并不觉得成长就要放弃那些曾经坚持过的东西，如果这些东西注定有一天要丢弃掉，那么何苦要将这些观念从小就灌输给我们，一旦有一天当你发现以前坚守的东西都被自己推翻，而你变成了原来自己不喜欢的哪种人，这将无异于信仰的大厦的坍塌，人的成长竟然要以抛弃自己的过去为代价，这未免过于残酷了吧。我从来都不傻，我看得出每个人心中的想法，只是我不愿意那样做，不管这个社会再怎么变，我不会背叛自己，我只是想让自己在这个浮躁的时代里保持自己的这颗简简单单的心。 &emsp;&emsp;众生虽苦，请诸恶莫作。我并不觉得自己比别人高贵多少，所以我始终像保留一份善良，不管是餐厅的服务员还是酒店的保洁员，每一个出来讨生活的人都不容易，所以多一份尊重比上帝的高傲更容易让人接受。而明天毕业后的我同样会有这一天，我真的不想小河变成大楼，我真的不想单纯变成冷漠，许嵩的这首《秋千坠》很多人都没有用心地听，因此这首歌轻快的节奏只会让人记得那段重复的飘啊飘…以单纯的心去面对这个世界，可能会受到伤害。可是事实上，任何伤害都不足摧毁你，伤害和磨练在你自省和反思过后，只能让你的阅历更丰富，看人更包容，生活更感恩。有人靠着阿谀奉承、靠着耍心机生活，可你不必这样，因为坦荡真诚同样是一种人生，在这个世界上能真正改变你的只有你自己，人出于本能对人存有戒备之心固然无可厚非，可是在保护好自我的情况下以坦荡真诚的胸襟去面对这个世界则更加难能可贵。因为我们不能生活给了你一个杯具就随波逐流，只有你和别人不一样，你才能将这个杯具变成洗具，这就是我想要的生活。最后送上杨绛先生的一段话与大家分享： 一个人经过不同程度的锻炼，就获得不同程度的修养、不同程度的效益。好比香料，捣得愈碎，磨得愈细，香得愈浓烈。我们曾如此渴望命运的波澜，到最后才发现：人生最曼妙的风景，竟是内心的淡定与从容……我们曾如此期盼外界的认可，到最后才知道，世界是自己的，与他人毫无关系。 &emsp;&emsp;已经凌晨三点了，可是写完这篇文字我很开心，这些话总是要经过些事情才能领悟出来，没有一个人能突然成长起来，我希望自己能一直单纯下去，单纯的人生不是痴傻无明，而是大智若愚，更好地爱这个父母送给我们的世界。","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"数学","slug":"数学","permalink":"https://qinyuanpei.github.io/tags/%E6%95%B0%E5%AD%A6/"},{"name":"贝塞尔曲线","slug":"贝塞尔曲线","permalink":"https://qinyuanpei.github.io/tags/%E8%B4%9D%E5%A1%9E%E5%B0%94%E6%9B%B2%E7%BA%BF/"},{"name":"计算机图形","slug":"计算机图形","permalink":"https://qinyuanpei.github.io/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2/"}]},{"title":"在平凡中蜕变，我的2014","date":"2014-12-30T19:34:34.000Z","path":"posts/124807650/","text":"&emsp;&emsp;如果生命可以轻到像一枚羽毛，我愿意飞过那片时间的海，突然造访那些曾经让我怀念过的日子，看看那时的我是不是和现在一样，从来不曾后悔过当初的选择。2014年12月31日，面对即将到来的2015，我相信这将是我在平凡中蜕变的一年。回首2014，从年初开始学习Unity3D游戏开发到现在，我的博客共积累了230335次访问量和700名粉丝的关注。首先要感谢各位长期以来关注和支持我的博客的朋友，因为你们的关注和支持就是我不断写下去的动力。2014年，当我渐渐地从一名大四学生的角色转换到一个社会人的时候，我开始认识到原来生活的本质就是平凡。或许我们都只是在做着普普通通的工作，或许我们都只是一个普普通通的人，可是因为我们有一颗不甘于平凡的心，所以我们选择在追逐梦想的路上完成一次次的蜕变。整个2014年基本上可以分成三个阶段： 2014年1月 ~ 2014年6月&emsp;&emsp;这段时间是大三的第二学期，基本上就是上课看各种各样的技术类书籍，下课有时间就编程，因为这学期有CAD课程，所以有时候会练习画图。在这段时间。第一次接触到了Linux，因为厌倦了在Windows平台上使用盗版和破解软件的现状，我曾一度想换到Linux平台，不过考虑到我仍然有大量的工作要依赖于Windows，所以这样的愿望只能成为一种奢望。在这段时间，我喜欢上了一个叫做Sublime的代码编辑器，通过各种各样的插件，我将它扩展成了一个万能的编辑器，我会用它来写C#、C++、Java、Lua和Python的小程序，现在我依然很喜欢这个代码编辑器。前几天我给它装上了Markdown Preview插件，这样我便可以使用它来编写Markdown文件。五一的时候和同学骑自行车去了滚钟口，这大概是大三的时候最后一次和同学出去玩啦。大概4月底左右，我将《古剑奇谭》系列的第二部游戏通关。6月份我萌生了利用Unity来开发仙剑同人游戏的想法。 2014年7月 ~ 2014年10月&emsp;&emsp;在结束了这学期的考试后，7月份我们在西安和上海进行了为期半个月的野外课程实习。7月份的西安正值酷暑，整个实习过程总是与汗水为伴。不过因为我不喜欢本科的专业，所以这个实习除了让我有机会看看外面的世界开阔眼界以外，并不会有太实际的意义。在实习期间，我研究了动作类游戏中的三连击效果，这是我在实习中做过的唯一一件与专业无关的事情。8月份回到家里，基本上天天宅在家里做游戏，做了两个射击类的小游戏和一个RPG游戏。9月份到了学校，为了给我的仙剑同人游戏项目寻找素材，我研究了《仙剑奇侠传》、《古剑奇谭》等游戏的解包，并从中提取了大量的游戏模型。为了给模型添加动画，开始学习学习Blender软件，不过后来发现给模型绑骨是件相当麻烦的事情，所以只好放弃3D建模的学习。到目前为止，我只能利用CAD和SU建些简单的模型，希望以后有机会再学习这部分的知识吧。然后剩下的时间基本上都是在捣鼓Linux和Github，剩下的就是做游戏啦。期间研究了Unity与Android平台、Lua脚本的交互等问题，根据这些问题写成的文章深受大家的喜爱，这里再次对大家的支持表示感谢。 2014年11月 ~ 2014年12月&emsp;&emsp;这段时间按照双11来划分的话，双11以前是考试，双11以后是实习。考试没什么值得说的，永远是记忆的内容比实用的内容多。不过当我面对最后一次考试的时候，我的心情极其复杂，因为我真的不知道如果再给我四年，我是不是还会这样选择我的人生。实习的过程是段暂的，可是在实习中我收获的东西却很多，我收获了为人处世的道理，同时收获了一份珍贵的友谊，我想这就是我想去经历和体验的东西吧。在实习过程中，我利用空闲时间研究了塔防游戏和静态博客系统Hexo，我的感觉就是编程环境还是Linux操作系统比较给力，像Ruby这样的环境在Windows下安装简直就是在找虐。好了，不吐槽了，我利用Hexo和Github Page搭建了我的独立博客http://qinyuanpei.github.io/以后我的文章会同时在这两个博客上发布，希望喜欢我的文章的朋友能一如既往的关注和支持我！ &emsp;&emsp;2014年即将过去，面对即将到来的2015年，我想做到5件事情： 认真完成本科毕业设计——做好大学里的最后一件事情 找一份自己喜欢的工作——脚踏实地的追逐自己的梦想 努力做一个有责任感的人——给她想要的温暖 努力做一个善良的人——众生虽苦，诸恶莫作 努力做一个有内涵的人——读书、写作、编程、游戏 &emsp;&emsp;欢迎大家关注我的博客： CSDN博客：http://blog.csdn.net/qinyuanpei 独立博客：http://qinyuanpei.github.io/ &emsp;&emsp;最后祝大家在新的一年里事业有成、梦想成真！","categories":[{"name":"生活感悟","slug":"生活感悟","permalink":"https://qinyuanpei.github.io/categories/%E7%94%9F%E6%B4%BB%E6%84%9F%E6%82%9F/"}],"tags":[{"name":"感悟","slug":"感悟","permalink":"https://qinyuanpei.github.io/tags/%E6%84%9F%E6%82%9F/"},{"name":"平凡","slug":"平凡","permalink":"https://qinyuanpei.github.io/tags/%E5%B9%B3%E5%87%A1/"},{"name":"2014","slug":"2014","permalink":"https://qinyuanpei.github.io/tags/2014/"}]}]