<!doctype html><html lang=zh-cn><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="ie=edge"><meta name=referrer content="no-referrer"><title>使用 llama.cpp 在本地部署 AI 大模型的一次尝试 - 元视角</title>
<meta name=description content="2023 年被誉为 AIGC 元年，随着技术浪潮，人们开始对人工智能的发展产生担忧。文章介绍了使用 llama.cpp 在本地部署AI大模型的过程，包括编译、量化和模型下载。通过对不同模型的体验，展示了其运行效果和评估。最后，将 ChatGPT-Next-Web 与 llama.cpp 结合，展示了本地部署 AI 大模型的潜力。整体讲述了私有化部署AI大模型的重要性和实践过程。"><link rel="shortcut icon" href type=image/x-icon><link rel=icon type=image/x-icon href=/images/favicon.ico><link rel=icon type=image/png href=/images/favicon.png><meta property="og:title" content="使用 llama.cpp 在本地部署 AI 大模型的一次尝试"><meta property="og:description" content="2023 年被誉为 AIGC 元年，随着技术浪潮，人们开始对人工智能的发展产生担忧。文章介绍了使用 llama.cpp 在本地部署AI大模型的过程，包括编译、量化和模型下载。通过对不同模型的体验，展示了其运行效果和评估。最后，将 ChatGPT-Next-Web 与 llama.cpp 结合，展示了本地部署 AI 大模型的潜力。整体讲述了私有化部署AI大模型的重要性和实践过程。"><meta property="og:type" content="article"><meta property="og:url" content="https://qinyuanpei.github.io/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/"><link rel=stylesheet href=/styles/main.min.2c77edfe155005c41cf8cefed2d412617a105f62cf1d21036e0c9167beddbb2d.css><link rel=stylesheet crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/misans@4.1.0/lib/Normal/MiSans-Medium.min.css><link rel=stylesheet crossorigin=anonymous href=https://cdn.jsdelivr.net/npm/misans@4.1.0/lib/Normal/MiSans-Bold.min.css><link rel=stylesheet href=/styles/iconfont.css><link rel=stylesheet href=/styles/iconfont-patch.css></head><body><div class="background patterns"><div class=bg-mask></div></div><style>.background{position:fixed;top:0;left:0;width:100vw;height:100vh;display:flex;align-items:center;justify-content:center;z-index:-2;&.patterns { background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='192' height='192' viewBox='0 0 192 192'%3E%3Cpath fill='%23494849' fill-opacity='0.08' d='M192 15v2a11 11 0 0 0-11 11c0 1.94 1.16 4.75 2.53 6.11l2.36 2.36a6.93 6.93 0 0 1 1.22 7.56l-.43.84a8.08 8.08 0 0 1-6.66 4.13H145v35.02a6.1 6.1 0 0 0 3.03 4.87l.84.43c1.58.79 4 .4 5.24-.85l2.36-2.36a12.04 12.04 0 0 1 7.51-3.11 13 13 0 1 1 .02 26 12 12 0 0 1-7.53-3.11l-2.36-2.36a4.93 4.93 0 0 0-5.24-.85l-.84.43a6.1 6.1 0 0 0-3.03 4.87V143h35.02a8.08 8.08 0 0 1 6.66 4.13l.43.84a6.91 6.91 0 0 1-1.22 7.56l-2.36 2.36A10.06 10.06 0 0 0 181 164a11 11 0 0 0 11 11v2a13 13 0 0 1-13-13 12 12 0 0 1 3.11-7.53l2.36-2.36a4.93 4.93 0 0 0 .85-5.24l-.43-.84a6.1 6.1 0 0 0-4.87-3.03H145v35.02a8.08 8.08 0 0 1-4.13 6.66l-.84.43a6.91 6.91 0 0 1-7.56-1.22l-2.36-2.36A10.06 10.06 0 0 0 124 181a11 11 0 0 0-11 11h-2a13 13 0 0 1 13-13c2.47 0 5.79 1.37 7.53 3.11l2.36 2.36a4.94 4.94 0 0 0 5.24.85l.84-.43a6.1 6.1 0 0 0 3.03-4.87V145h-35.02a8.08 8.08 0 0 1-6.66-4.13l-.43-.84a6.91 6.91 0 0 1 1.22-7.56l2.36-2.36A10.06 10.06 0 0 0 107 124a11 11 0 0 0-22 0c0 1.94 1.16 4.75 2.53 6.11l2.36 2.36a6.93 6.93 0 0 1 1.22 7.56l-.43.84a8.08 8.08 0 0 1-6.66 4.13H49v35.02a6.1 6.1 0 0 0 3.03 4.87l.84.43c1.58.79 4 .4 5.24-.85l2.36-2.36a12.04 12.04 0 0 1 7.51-3.11A13 13 0 0 1 81 192h-2a11 11 0 0 0-11-11c-1.94 0-4.75 1.16-6.11 2.53l-2.36 2.36a6.93 6.93 0 0 1-7.56 1.22l-.84-.43a8.08 8.08 0 0 1-4.13-6.66V145H11.98a6.1 6.1 0 0 0-4.87 3.03l-.43.84c-.79 1.58-.4 4 .85 5.24l2.36 2.36a12.04 12.04 0 0 1 3.11 7.51A13 13 0 0 1 0 177v-2a11 11 0 0 0 11-11c0-1.94-1.16-4.75-2.53-6.11l-2.36-2.36a6.93 6.93 0 0 1-1.22-7.56l.43-.84a8.08 8.08 0 0 1 6.66-4.13H47v-35.02a6.1 6.1 0 0 0-3.03-4.87l-.84-.43c-1.59-.8-4-.4-5.24.85l-2.36 2.36A12 12 0 0 1 28 109a13 13 0 1 1 0-26c2.47 0 5.79 1.37 7.53 3.11l2.36 2.36a4.94 4.94 0 0 0 5.24.85l.84-.43A6.1 6.1 0 0 0 47 84.02V49H11.98a8.08 8.08 0 0 1-6.66-4.13l-.43-.84a6.91 6.91 0 0 1 1.22-7.56l2.36-2.36A10.06 10.06 0 0 0 11 28 11 11 0 0 0 0 17v-2a13 13 0 0 1 13 13c0 2.47-1.37 5.79-3.11 7.53l-2.36 2.36a4.94 4.94 0 0 0-.85 5.24l.43.84A6.1 6.1 0 0 0 11.98 47H47V11.98a8.08 8.08 0 0 1 4.13-6.66l.84-.43a6.91 6.91 0 0 1 7.56 1.22l2.36 2.36A10.06 10.06 0 0 0 68 11 11 11 0 0 0 79 0h2a13 13 0 0 1-13 13 12 12 0 0 1-7.53-3.11l-2.36-2.36a4.93 4.93 0 0 0-5.24-.85l-.84.43A6.1 6.1 0 0 0 49 11.98V47h35.02a8.08 8.08 0 0 1 6.66 4.13l.43.84a6.91 6.91 0 0 1-1.22 7.56l-2.36 2.36A10.06 10.06 0 0 0 85 68a11 11 0 0 0 22 0c0-1.94-1.16-4.75-2.53-6.11l-2.36-2.36a6.93 6.93 0 0 1-1.22-7.56l.43-.84a8.08 8.08 0 0 1 6.66-4.13H143V11.98a6.1 6.1 0 0 0-3.03-4.87l-.84-.43c-1.59-.8-4-.4-5.24.85l-2.36 2.36A12 12 0 0 1 124 13a13 13 0 0 1-13-13h2a11 11 0 0 0 11 11c1.94 0 4.75-1.16 6.11-2.53l2.36-2.36a6.93 6.93 0 0 1 7.56-1.22l.84.43a8.08 8.08 0 0 1 4.13 6.66V47h35.02a6.1 6.1 0 0 0 4.87-3.03l.43-.84c.8-1.59.4-4-.85-5.24l-2.36-2.36A12 12 0 0 1 179 28a13 13 0 0 1 13-13zM84.02 143a6.1 6.1 0 0 0 4.87-3.03l.43-.84c.8-1.59.4-4-.85-5.24l-2.36-2.36A12 12 0 0 1 83 124a13 13 0 1 1 26 0c0 2.47-1.37 5.79-3.11 7.53l-2.36 2.36a4.94 4.94 0 0 0-.85 5.24l.43.84a6.1 6.1 0 0 0 4.87 3.03H143v-35.02a8.08 8.08 0 0 1 4.13-6.66l.84-.43a6.91 6.91 0 0 1 7.56 1.22l2.36 2.36A10.06 10.06 0 0 0 164 107a11 11 0 0 0 0-22c-1.94 0-4.75 1.16-6.11 2.53l-2.36 2.36a6.93 6.93 0 0 1-7.56 1.22l-.84-.43a8.08 8.08 0 0 1-4.13-6.66V49h-35.02a6.1 6.1 0 0 0-4.87 3.03l-.43.84c-.79 1.58-.4 4 .85 5.24l2.36 2.36a12.04 12.04 0 0 1 3.11 7.51A13 13 0 1 1 83 68a12 12 0 0 1 3.11-7.53l2.36-2.36a4.93 4.93 0 0 0 .85-5.24l-.43-.84A6.1 6.1 0 0 0 84.02 49H49v35.02a8.08 8.08 0 0 1-4.13 6.66l-.84.43a6.91 6.91 0 0 1-7.56-1.22l-2.36-2.36A10.06 10.06 0 0 0 28 85a11 11 0 0 0 0 22c1.94 0 4.75-1.16 6.11-2.53l2.36-2.36a6.93 6.93 0 0 1 7.56-1.22l.84.43a8.08 8.08 0 0 1 4.13 6.66V143h35.02z'%3E%3C/path%3E%3C/svg%3E"); } &.dark { &.patterns { background-image: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' width='192' height='192' viewBox='0 0 192 192'%3E%3Cpath fill='%23fcfcfc' fill-opacity='0.08' d='M192 15v2a11 11 0 0 0-11 11c0 1.94 1.16 4.75 2.53 6.11l2.36 2.36a6.93 6.93 0 0 1 1.22 7.56l-.43.84a8.08 8.08 0 0 1-6.66 4.13H145v35.02a6.1 6.1 0 0 0 3.03 4.87l.84.43c1.58.79 4 .4 5.24-.85l2.36-2.36a12.04 12.04 0 0 1 7.51-3.11 13 13 0 1 1 .02 26 12 12 0 0 1-7.53-3.11l-2.36-2.36a4.93 4.93 0 0 0-5.24-.85l-.84.43a6.1 6.1 0 0 0-3.03 4.87V143h35.02a8.08 8.08 0 0 1 6.66 4.13l.43.84a6.91 6.91 0 0 1-1.22 7.56l-2.36 2.36A10.06 10.06 0 0 0 181 164a11 11 0 0 0 11 11v2a13 13 0 0 1-13-13 12 12 0 0 1 3.11-7.53l2.36-2.36a4.93 4.93 0 0 0 .85-5.24l-.43-.84a6.1 6.1 0 0 0-4.87-3.03H145v35.02a8.08 8.08 0 0 1-4.13 6.66l-.84.43a6.91 6.91 0 0 1-7.56-1.22l-2.36-2.36A10.06 10.06 0 0 0 124 181a11 11 0 0 0-11 11h-2a13 13 0 0 1 13-13c2.47 0 5.79 1.37 7.53 3.11l2.36 2.36a4.94 4.94 0 0 0 5.24.85l.84-.43a6.1 6.1 0 0 0 3.03-4.87V145h-35.02a8.08 8.08 0 0 1-6.66-4.13l-.43-.84a6.91 6.91 0 0 1 1.22-7.56l2.36-2.36A10.06 10.06 0 0 0 107 124a11 11 0 0 0-22 0c0 1.94 1.16 4.75 2.53 6.11l2.36 2.36a6.93 6.93 0 0 1 1.22 7.56l-.43.84a8.08 8.08 0 0 1-6.66 4.13H49v35.02a6.1 6.1 0 0 0 3.03 4.87l.84.43c1.58.79 4 .4 5.24-.85l2.36-2.36a12.04 12.04 0 0 1 7.51-3.11A13 13 0 0 1 81 192h-2a11 11 0 0 0-11-11c-1.94 0-4.75 1.16-6.11 2.53l-2.36 2.36a6.93 6.93 0 0 1-7.56 1.22l-.84-.43a8.08 8.08 0 0 1-4.13-6.66V145H11.98a6.1 6.1 0 0 0-4.87 3.03l-.43.84c-.79 1.58-.4 4 .85 5.24l2.36 2.36a12.04 12.04 0 0 1 3.11 7.51A13 13 0 0 1 0 177v-2a11 11 0 0 0 11-11c0-1.94-1.16-4.75-2.53-6.11l-2.36-2.36a6.93 6.93 0 0 1-1.22-7.56l.43-.84a8.08 8.08 0 0 1 6.66-4.13H47v-35.02a6.1 6.1 0 0 0-3.03-4.87l-.84-.43c-1.59-.8-4-.4-5.24.85l-2.36 2.36A12 12 0 0 1 28 109a13 13 0 1 1 0-26c2.47 0 5.79 1.37 7.53 3.11l2.36 2.36a4.94 4.94 0 0 0 5.24.85l.84-.43A6.1 6.1 0 0 0 47 84.02V49H11.98a8.08 8.08 0 0 1-6.66-4.13l-.43-.84a6.91 6.91 0 0 1 1.22-7.56l2.36-2.36A10.06 10.06 0 0 0 11 28 11 11 0 0 0 0 17v-2a13 13 0 0 1 13 13c0 2.47-1.37 5.79-3.11 7.53l-2.36 2.36a4.94 4.94 0 0 0-.85 5.24l.43.84A6.1 6.1 0 0 0 11.98 47H47V11.98a8.08 8.08 0 0 1 4.13-6.66l.84-.43a6.91 6.91 0 0 1 7.56 1.22l2.36 2.36A10.06 10.06 0 0 0 68 11 11 11 0 0 0 79 0h2a13 13 0 0 1-13 13 12 12 0 0 1-7.53-3.11l-2.36-2.36a4.93 4.93 0 0 0-5.24-.85l-.84.43A6.1 6.1 0 0 0 49 11.98V47h35.02a8.08 8.08 0 0 1 6.66 4.13l.43.84a6.91 6.91 0 0 1-1.22 7.56l-2.36 2.36A10.06 10.06 0 0 0 85 68a11 11 0 0 0 22 0c0-1.94-1.16-4.75-2.53-6.11l-2.36-2.36a6.93 6.93 0 0 1-1.22-7.56l.43-.84a8.08 8.08 0 0 1 6.66-4.13H143V11.98a6.1 6.1 0 0 0-3.03-4.87l-.84-.43c-1.59-.8-4-.4-5.24.85l-2.36 2.36A12 12 0 0 1 124 13a13 13 0 0 1-13-13h2a11 11 0 0 0 11 11c1.94 0 4.75-1.16 6.11-2.53l2.36-2.36a6.93 6.93 0 0 1 7.56-1.22l.84.43a8.08 8.08 0 0 1 4.13 6.66V47h35.02a6.1 6.1 0 0 0 4.87-3.03l.43-.84c.8-1.59.4-4-.85-5.24l-2.36-2.36A12 12 0 0 1 179 28a13 13 0 0 1 13-13zM84.02 143a6.1 6.1 0 0 0 4.87-3.03l.43-.84c.8-1.59.4-4-.85-5.24l-2.36-2.36A12 12 0 0 1 83 124a13 13 0 1 1 26 0c0 2.47-1.37 5.79-3.11 7.53l-2.36 2.36a4.94 4.94 0 0 0-.85 5.24l.43.84a6.1 6.1 0 0 0 4.87 3.03H143v-35.02a8.08 8.08 0 0 1 4.13-6.66l.84-.43a6.91 6.91 0 0 1 7.56 1.22l2.36 2.36A10.06 10.06 0 0 0 164 107a11 11 0 0 0 0-22c-1.94 0-4.75 1.16-6.11 2.53l-2.36 2.36a6.93 6.93 0 0 1-7.56 1.22l-.84-.43a8.08 8.08 0 0 1-4.13-6.66V49h-35.02a6.1 6.1 0 0 0-4.87 3.03l-.43.84c-.79 1.58-.4 4 .85 5.24l2.36 2.36a12.04 12.04 0 0 1 3.11 7.51A13 13 0 1 1 83 68a12 12 0 0 1 3.11-7.53l2.36-2.36a4.93 4.93 0 0 0 .85-5.24l-.43-.84A6.1 6.1 0 0 0 84.02 49H49v35.02a8.08 8.08 0 0 1-4.13 6.66l-.84.43a6.91 6.91 0 0 1-7.56-1.22l-2.36-2.36A10.06 10.06 0 0 0 28 85a11 11 0 0 0 0 22c1.94 0 4.75-1.16 6.11-2.53l2.36-2.36a6.93 6.93 0 0 1 7.56-1.22l.84.43a8.08 8.08 0 0 1 4.13 6.66V143h35.02z'%3E%3C/path%3E%3C/svg%3E"); } .cover { filter: brightness(0.6); } } .cover { width: auto; height: auto; min-height: 100%; opacity: 0; transition: filter 0.3s, opacity 0.3s; &.loaded { opacity: 1; } }}</style><header class=main-header><nav class="main-nav up top"><div class=nav-all><div class=left-nav><div class=site-name onclick='location.href="/"'>元视角</div></div><div class=nav-center><div class=site-menu><div class=site-menu><div class=menu-item><span class=link-btn>文库</span><div class=link-child><span class=link-child-btn onclick='window.location.href="/archives"'><i class="iconfont icon-guidang"></i>
归档
</span><span class=link-child-btn onclick='window.location.href="/categories"'><i class="iconfont icon-folder"></i>
全部分类
</span><span class=link-child-btn onclick='window.location.href="/tags"'><i class="iconfont icon-hashtag"></i>
全部标签</span></div></div><div class=menu-item><span class=link-btn>书影音</span><div class=link-child><span class=link-child-btn onclick='window.location.href="/books"'><i class="iconfont icon-book-fill"></i>
读书
</span><span class=link-child-btn onclick='window.location.href="/movies"'><i class="iconfont icon-movies"></i>
观影
</span><span class=link-child-btn onclick='window.location.href="/musics"'><i class="iconfont icon-music"></i>
听歌</span></div></div><div class=menu-item><span class=link-btn>页面</span><div class=link-child><span class=link-child-btn onclick='window.location.href="/links"'><i class="iconfont icon-people"></i>
友情链接
</span><span class=link-child-btn onclick='window.location.href="/works"'><i class="iconfont icon-people"></i>
个人作品
</span><span class=link-child-btn onclick='window.location.href="/statics"'><i class="iconfont icon-tongji"></i>
站点统计</span></div></div><div class=menu-item><span class=link-btn>更多</span><div class=link-child><span class=link-child-btn onclick='window.location.href="/comments"'><i class="iconfont icon-chat"></i>
留言板
</span><span class=link-child-btn onclick='window.location.href="/about"'><i class="iconfont icon-contacts"></i>
关于本站</span></div></div></div></div><span class=site-title>使用 llama.cpp 在本地部署 AI 大模型的一次尝试</span></div><div class=right-nav><a class="menu-btn nav-btn travellings" title=开往-友链接力 href=https://www.travellings.cn/go.html target=_blank><i class="iconfont icon-subway"></i></a><div class="menu-btn nav-btn" title=随机前往一篇文章><i class="iconfont icon-shuffle"></i></div><div class="menu-btn nav-btn" title=全站搜索><i class="iconfont icon-search"></i></div><div class="menu-btn nav-btn" id=themeToggle title=切换主题模式><i class="iconfont icon-sun" id=themeIcon></i></div><div id=open-control class="menu-btn nav-btn pc" title=打开中控台><i class="iconfont icon-dashboard"></i></div><div class="to-top menu-btn hidden" title=返回顶部><div class=to-top-btn><span class=num>0</span>
<i class="iconfont icon-up"></i></div></div><div class="menu-btn nav-btn mobile" title=打开菜单><i class="iconfont icon-toc"></i></div></div></div></nav><div class=mobile-menu id=mobileMenu><div class=menu-mask></div><div class="menu-content s-card"><div class=close-control><i class="iconfont icon-close"></i></div><div class=menu-list><div class=menu-item><span class=link-title>文库</span><div class=link-child><div class=link-child-btn onclick='window.location.href="/archives"'><i class="iconfont icon-guidang"></i>
<span class=name>归档</span></div><div class=link-child-btn onclick='window.location.href="/categories"'><i class="iconfont icon-folder"></i>
<span class=name>全部分类</span></div><div class=link-child-btn onclick='window.location.href="/tags"'><i class="iconfont icon-hashtag"></i>
<span class=name>全部标签</span></div></div></div><div class=menu-item><span class=link-title>书影音</span><div class=link-child><div class=link-child-btn onclick='window.location.href="/books"'><i class="iconfont icon-book-fill"></i>
<span class=name>读书</span></div><div class=link-child-btn onclick='window.location.href="/movies"'><i class="iconfont icon-movies"></i>
<span class=name>观影</span></div><div class=link-child-btn onclick='window.location.href="/musics"'><i class="iconfont icon-music"></i>
<span class=name>听歌</span></div></div></div><div class=menu-item><span class=link-title>页面</span><div class=link-child><div class=link-child-btn onclick='window.location.href="/links"'><i class="iconfont icon-people"></i>
<span class=name>友情链接</span></div><div class=link-child-btn onclick='window.location.href="/works"'><i class="iconfont icon-people"></i>
<span class=name>个人作品</span></div><div class=link-child-btn onclick='window.location.href="/statics"'><i class="iconfont icon-tongji"></i>
<span class=name>站点统计</span></div></div></div><div class=menu-item><span class=link-title>更多</span><div class=link-child><div class=link-child-btn onclick='window.location.href="/comments"'><i class="iconfont icon-chat"></i>
<span class=name>留言板</span></div><div class=link-child-btn onclick='window.location.href="/about"'><i class="iconfont icon-contacts"></i>
<span class=name>关于本站</span></div></div></div></div></div></div><style>.mobile-menu{position:fixed;top:0;left:0;width:100vw;height:100vh;z-index:3000;display:none}.mobile-menu .menu-mask{position:absolute;top:0;left:0;width:100%;height:100%;z-index:-1;background-color:var(--main-mask-background)}.mobile-menu .menu-content{position:absolute;top:0;right:0;height:100%;width:100%;max-width:300px;border-radius:12px 0 0 12px;padding:20px;overflow:auto}.mobile-menu .close-control{position:absolute;top:10px;right:20px;display:flex;align-items:center;justify-content:center;width:35px;height:35px;padding:0;transition:background-color .3s,opacity .3s;border-radius:50%;cursor:pointer}.mobile-menu .close-control .iconfont{font-size:18px;line-height:1;color:var(--main-font-second-color);transition:color .3s,opacity .3s}.mobile-menu .close-control:hover{background-color:var(--main-color)}.mobile-menu .close-control:hover .iconfont{color:var(--main-card-background)}.mobile-menu .menu-list{margin-top:40px}.mobile-menu .menu-item{margin-bottom:12px}.mobile-menu .menu-item .link-title{font-size:14px;margin-bottom:12px;display:inline-block;color:var(--main-font-second-color)}.mobile-menu .menu-item .link-child{display:grid;gap:12px;grid-template-columns:1fr 1fr}.mobile-menu .menu-item .link-child-btn{display:flex;flex-direction:row;justify-content:flex-start;align-items:center;border-radius:8px;padding:10px 12px;background-color:var(--main-card-background);border:1px solid var(--main-card-border);box-shadow:0 8px 16px -4px var(--main-border-shadow);font-size:15px;cursor:pointer;transition:all .3s}.mobile-menu .menu-item .link-child-btn:hover{background-color:var(--main-color);color:var(--main-card-background)}.mobile-menu .menu-item .link-child-btn .iconfont{margin-right:6px;opacity:.6}.mobile-menu .menu-item .link-child-btn .name{max-width:80px;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}</style><script>function toggleMobileMenu(){const e=document.getElementById("mobileMenu");e&&(e.style.display=e.style.display==="none"?"block":"none")}</script><div class=modal id=search-modal><div class=modal-mask></div><div class="modal-main s-card" style=max-width:800px><div class=title><div class=title-left><i class="iconfont icon-search"></i>
<span class=title-text>全局搜索</span></div><i class="iconfont icon-close close" id=modal-close></i></div><div class=modal-content style=--height:80vh><div class=search-modal><div class=search-input><input type=text id=search-input placeholder=今天你想搜点什么？ autocomplete=off></div><div class=search-results><div class=search-list></div><div class=search-empty><i class="iconfont icon-search"></i><p>输入关键字，开始搜索</p></div></div><div class=search-hint><span class=text id=search-hint-text></span>
<span class=text><a class=powered_by href=https://www.fusejs.io/ target=_blank>Fuse.js</a></span></div></div></div></div></div></header><main class=main-layout><div class=post><div class=post-meta><div class=meta><div class=categories><a href=/categories/%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80 class=cat-item><i class="iconfont icon-folder"></i>
<span class=name>编程语言</span></a></div><div class=tags><a href=/tags/llama.cpp class=tag-item><i class="iconfont icon-hashtag"></i>
<span class=name>llama.cpp</span>
</a><a href=/tags/chatgpt class=tag-item><i class="iconfont icon-hashtag"></i>
<span class=name>ChatGPT</span>
</a><a href=/tags/qwen-7b-chat class=tag-item><i class="iconfont icon-hashtag"></i>
<span class=name>Qwen-7B-Chat</span>
</a><a href=/tags/llama class=tag-item><i class="iconfont icon-hashtag"></i>
<span class=name>LLaMA</span></a></div></div><h1 class=title>使用 llama.cpp 在本地部署 AI 大模型的一次尝试</h1><div class=other-meta><span class="meta date"><i class="iconfont icon-date"></i>
2024-02-04
</span><span class="update meta"><i class="iconfont icon-time"></i>
2024-02-04
</span><span class="hot meta"><i class="iconfont icon-fire"></i>
<span id=twikoo_visitors class=artalk-pv-count>0</span>
</span><span class="chat meta hover" data-scroll-to=comments><i class="iconfont icon-chat"></i>
<span id=twikoo_comments class=artalk-comment-count>0</span></span></div></div><div class=post-content><article class="post-article s-card"><div class="expired s-card">本文发表于 <strong>430</strong> 天前，其中的信息可能已经事过境迁</div><div class="article-gpt s-card"><div class=title><span class=name><i class="iconfont icon-robot"></i>
文章摘要
<i class="iconfont icon-up"></i>
</span><span class=logo>FakeGPT</span></div><div class="content s-card"><span class=text></span></div><div class=meta></div></div><script src=https://npm.elemecdn.com/typeit@8.7.1/dist/index.umd.js></script><script>document.addEventListener("DOMContentLoaded",function(){new TypeIt(".article-gpt .content .text",{strings:"2023 年被誉为 AIGC 元年，随着技术浪潮，人们开始对人工智能的发展产生担忧。文章介绍了使用 llama.cpp 在本地部署AI大模型的过程，包括编译、量化和模型下载。通过对不同模型的体验，展示了其运行效果和评估。最后，将 ChatGPT-Next-Web 与 llama.cpp 结合，展示了本地部署 AI 大模型的潜力。整体讲述了私有化部署AI大模型的重要性和实践过程。",speed:10,lifeLike:!0,waitUntilVisible:!0}).go()})</script><div id=page-content class=markdown-main-style><p>对于刚刚落下帷幕的2023年，人们曾经给予其高度评价——AIGC元年。随着 ChatGPT 的火爆出圈，大语言模型、AI 生成内容、多模态、提示词、量化&mldr;等等名词开始相继频频出现在人们的视野当中，而在这场足以引发第四次工业革命的技术浪潮里，人们对于人工智能的态度，正从一开始的惊喜慢慢地变成担忧。因为 AI 在生成文字、代码、图像、音频和视频等方面的能力越来越强大，强大到需要 <strong>“冷门歌手”</strong> 孙燕姿亲自发文<a href=http://www.makemusic.sg/new-blog/wodeai>回应</a>，强大到连山姆·奥特曼都被 OpenAI 解雇。在经历过 OpenAI 套壳、New Bing、GitHub Copilot 以及各式 AI 应用、各类大语言模型的持续轰炸后，我们终于迎来了人工智能的 <strong>“安卓时刻”</strong>，即除了 ChatGPT、Gemini 等专有模型以外，我们现在有更多的开源大模型可以选择。可这难免会让我们感到困惑，人工智能的尽头到底是什么呢？2013年的时候，我以为未来属于提示词工程(<strong>Prompt Engineering</strong>)，可后来好像是 RAG 以及 GPTs 更受欢迎？</p><h1 id=从哪里开始>从哪里开始</h1><p>在经历过早期调用 OpenAI API 各种障碍后，我觉得大语言模型，最终还是需要回归到私有化部署这条路上来。毕竟，连最近新上市的手机都开始内置大语言模型了，我先后在手机上体验了有大语言模型加持的小爱同学，以及抖音的豆包，不能说体验有多好，可终归是聊胜于无。目前，整个人工智能领域大致可以分为三个层次，即：算力、模型和应用。其中，算力，本质上就是芯片，对大模型来说特指高性能显卡；模型，现在在 <a href=https://huggingface.co/>Hugging Face</a> 可以找到各种开源的模型，即便可以节省训练模型的成本，可对这些模型的微调和改进依然是 <strong>“最后一公里”</strong> 的痛点；应用，目前 GPTs 极大地推动了各类 AI 应用的落地，而像 <a href=https://poe.com/>Poe</a> 这类聚合式的 AI 应用功能要更强大一点。最终，我决定先在 CPU 环境下利用 <a href=https://github.com/ggerganov/llama.cpp>llama.cpp</a> 部署一个 AI 大模型，等打通上下游关节后，再考虑使用 GPU 环境实现最终落地。从头开始训练一个模型是不大现实的，可如果通过 LangChain 这类框架接入本地知识库还是有希望的。</p><h1 id=编译-llamacpp>编译 llama.cpp</h1><p>llama.cpp 是一个纯 C/C++ 实现的 LLaMA 模型推理工具，由于其具有极高的性能，因此，它可以同时在 GPU 和 CPU 环境下运行，这给了像博主这种寻常百姓可操作的空间。在 Meta 半开源了其 LLaMA 模型以后，斯坦福大学发布了其基于 LLaMA-7B 模型微调而来的模型 Alpaca，在开源社区的积极响应下，在 Hugging Face 上面相继衍生出了更多的基于 LLaMA 模型的模型，这意味着这些由 LLaMA 衍生而来的模型，都可以交给 llama.cpp 这个项目来进行推理。对硬件要求低、可供选择的模型多，这是博主选择 llama.cpp 的主要原因。在这篇文章里，博主使用的是一台搭配 i7-1360P 处理器、32G 内存的笔记本，按照 LLaMA 的性能要求，运行 GGML 格式的 7B 模型至少需要 13G 内存，而运行 GGML 格式的 13B 模型至少需要 24G 内存，大家可以根据自身配置选择合适的模型，个人建议选择 7B 即可，因为 13B 运行时间一长以后还是会感到吃力，哎😰。</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-system-requirement.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-system-requirement.png data-caption="llama.cpp 在不同尺寸模型下对内存的要求"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-system-requirement.png alt="llama.cpp 在不同尺寸模型下对内存的要求" class=post-img loading=lazy>
<span class=post-img-tip>llama.cpp 在不同尺寸模型下对内存的要求</span></a></p><h2 id=准备工作>准备工作</h2><p>在正式开始前，请确保你可以熟练使用 Git，以及具备科学上网的条件，因为我们需要从 <a href=https://huggingface.co/>Hugging Face</a> 上下载模型。此外，你还需要下载并安装以下软件：</p><ul><li>Python: <a href=https://www.python.org/downloads/>官方网站</a>、<a href=https://mirrors.huaweicloud.com/python>华为镜像</a>，建议选择 3.9 及其以上版本</li><li><a href=https://github.com/skeeto/w64devkit/releases>w64devkit</a>：便携式 C/C++ 编译环境，集成了 gcc、make 等常见的工具</li><li><a href=https://github.com/OpenMathLib/OpenBLAS/releases>OpenBLAS</a>(可选): 可以提供 CPU 加速的高性能矩阵计算库，建议安装</li></ul><p>w64devkit 和 OpenBLAS 下载下来都是压缩包，直接解压即可，建议将 w64devkit 解压在一个不含空格和中文的路径下，例如：C:\w64devkit。接下来，我们还需要 OpenBLAS 的库文件和头文件，请将其 <code>include</code> 目录下的内容，全部复制到 <code>C:\w64devkit\x86_64-w64-mingw32\include</code> 目录下；请将其 <code>lib</code> 目录下的 <code>libopenblas.a</code> 文件复制到 <code>C:\w64devkit\x86_64-w64-mingw32\lib</code> 目录下。保险起见，个人建议将 <code>C:\w64devkit</code> 目录添加到 <code>Path</code> 环境变量中，如下图所示：</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/environment-variables.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/environment-variables.png data-caption=请检查你的系统环境变量><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/environment-variables.png alt=请检查你的系统环境变量 class=post-img loading=lazy>
<span class=post-img-tip>请检查你的系统环境变量</span></a></p><p>至此，我们就完成了全部的准备工作。需要说明的是，这里是以 Windows + Make + OpenBLAS 为例进行演示和写作。如果你是 Mac 或者 Linux 系统用户，或者你想 <code>CMake</code> 或者 CUDA，请参考官方文档：<a href=https://github.com/ggerganov/llama.cpp>https://github.com/ggerganov/llama.cpp</a>，虽然这份文档是纯英文的，但是我相信这应该难不倒屏幕前的各位程序员朋友，哈哈😄。</p><h2 id=编译过程>编译过程</h2><p>好的，对于 llama.cpp 而言，其实官方提供了预编译的可执行程序，具体请参考这里：<a href=https://github.com/ggerganov/llama.cpp/releases>https://github.com/ggerganov/llama.cpp/releases</a>。通常情况下，普通的 Windows 用户只需要选择类似 <a href=https://github.com/ggerganov/llama.cpp/releases/download/b2084/llama-b2084-bin-win-openblas-x64.zip>llama-b2084-bin-win-openblas-x64.zip</a> 这样的发行版本即可。如果你拥有高性能显卡，可以选择类似 <a href=https://github.com/ggerganov/llama.cpp/releases/download/b2084/llama-b2084-bin-win-cublas-cu12.2.0-x64.zip>llama-b2084-bin-win-cublas-cu12.2.0-x64.zip</a> 这样的发行版即可，其中的 <code>cu</code> 表示 CUDA，这是由显卡厂商 Nvdia 推出的运算平台。什么样的显卡算高性能显卡呢？就我朴实无华的游戏史观点而言，只要能流畅运行育碧旗下的《刺客信条：大革命》及其后续作品的，都可以算得上高性能显卡。这里，我们选择手动编译，因为通读整个文档你就会发现，llama.cpp 里面提供了大量的编译参数，这些参数或多或少地会影响到你编译的产物。所以，如果你喜欢折腾，品味独特，我还是建议你手动编译 llama.cpp，平时使用 Visual Studio 编译程序多少有点温水煮青蛙啦🐸。</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/AI-Generated-Assassin%27s-Creed.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/AI-Generated-Assassin%27s-Creed.png data-caption="一张由 AI 应用 Poe 生成的刺客信条图片"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/AI-Generated-Assassin%27s-Creed.png alt="一张由 AI 应用 Poe 生成的刺客信条图片" class=post-img loading=lazy>
<span class=post-img-tip>一张由 AI 应用 Poe 生成的刺客信条图片</span></a></p><p>首先，我们使用 Git 克隆一份 llama.cpp 的源代码：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>git clone https://github.com/ggerganov/llama.cpp
</span></span></code></pre></div><p>接下来，打开一开始准备好的 w64devkit.exe 工具，在这里其路径为：<code>C:\w64devkit\w64devkit.exe</code>，它将打开一个单独的命令行窗口。此时，我们需要进入上一步中克隆下来的 llama.cpp 源代码目录。在本文示例中，其路径为：
<code>D:\Projects\llama.cpp</code>。下面是对应的命令行语句：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> d:<span class=se>\
</span></span></span><span class=line><span class=cl><span class=se></span><span class=nb>cd</span> projects/llama.cpp
</span></span></code></pre></div><p>至此，我们就进入了 llama.cpp 的源代码目录，还记得在准备工作阶段，我们提到过的 OpenBLAS 及其 CPU 加速功能吗？如果你不需要 CPU 加速功能，那么，你可以直接输入 <code>make</code> 命令，否则你需要输入 <code>make LLAMA_OPENBLAS=1</code>。博主这里选择的是后者，没有 GPU 当然要精打细算地过日子，你说对不对？</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>make <span class=nv>LLAMA_OPENBLAS</span><span class=o>=</span><span class=m>1</span>
</span></span></code></pre></div><p>此时，如果编译成功的话，你会在当前目录下看到编译出来的各种可执行文件：</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-build-result.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-build-result.png data-caption="llama.cpp 编译结果展示"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-build-result.png alt="llama.cpp 编译结果展示" class=post-img loading=lazy>
<span class=post-img-tip>llama.cpp 编译结果展示</span></a></p><p>如果没有的话，请按照下面的方式尝试重新生成，直至编译成功：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>make clean 
</span></span><span class=line><span class=cl>make <span class=nv>LLAMA_OPENBLAS</span><span class=o>=</span><span class=m>1</span>
</span></span></code></pre></div><p>坦白地讲，本来我一开始是打算从 <a href=https://github.com/abetlen/llama-cpp-python>llama-cpp-python</a> 这个项目着手的，可惜通过 <code>pip</code> 安装的时候终于还是遇到了各种 C/C++ 的问题，最终决定还是返璞归真从 llama.cpp 本体入手。个人感觉 w64devkit 这个懒人包还是挺不错的，以前在 Windows 上想用 Make 或者 CMake 编译程序何其痛苦啊，现在总算是舒服了不少啊😏</p><h1 id=大模型尝鲜>大模型尝鲜</h1><p>OK，llamp.cpp 编译成功以后，我们就可以用它来跑各种各样的 AI 大模型了，它支持哪些模型呢？在官方文档里作者给出了说明，这里仅仅截取了其中一部分，而对对于我们接下来的探索已经完全足够啦：</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-supported-models.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-supported-models.png data-caption="llama.cpp 支持哪些 AI 大模型？"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-supported-models.png alt="llama.cpp 支持哪些 AI 大模型？" class=post-img loading=lazy>
<span class=post-img-tip>llama.cpp 支持哪些 AI 大模型？</span></a></p><p>在当下的这场 AI 大模型追逐赛中，国内的大模型大多在模仿由 Meta 开源的 LLaMA 架构，无非是有些选择了从头开始训练，而有些选择了用中文语料做各种微调优化。如果一定追本溯源的话，LLaMA 参考了 GPT，GPT 参考了 Transformer，而 Transformer 则最早出现在 Google 于 2017 年发表的论文 <a href=https://arxiv.org/abs/1706.03762>Attention Is All You Need</a>。说来有一点戏剧性，Google 在这场追逐赛中起了个大早，可目前看起来好像是投资了 OpenAI 的微软占据了上风，特别是 OpenAI 前 CEO 山姆·奥特曼已经加入微软，并且微软的 Copilot 在浏览器、桌面以及 Github 上都有着挺不错的表现。当然，历来代表着技术先进性的 Google 当然不会束手待毙，虽然目前的 Gemini Pro 还不及 ChatGPT，但终归可以讲一句未来可期。只有 OpenAI 一家独大，不管是对人工智能领域还是普通用户而言，绝对不是一件好事。</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/How-To-Use-LLM-Model.drawio.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/How-To-Use-LLM-Model.drawio.png data-caption="llama.cpp 使用大模型的基本流程"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/How-To-Use-LLM-Model.drawio.png alt="llama.cpp 使用大模型的基本流程" class=post-img loading=lazy>
<span class=post-img-tip>llama.cpp 使用大模型的基本流程</span></a></p><h2 id=转换与量化>转换与量化</h2><p>在接触大模型的过程中，除了提示词以外，你可能还会经常听到一个词：量化，下面我们就来聊一聊量化。如图所示，llama.cpp 使用大模型的基本流程，主要分为两步，分别是转化和量化。首先，来考虑第一个问题，为什么需要转化？前面提到过，现阶段 AI 大模型的起源都是 Transformer 模型，而 llama.cpp 使用的则是 GGML 模型，所以，当我们从 Hugging Face 上下载了某个大模型以后，第一件事情就是将其转化为 GGML 模型，这样，llama.cpp 便可以正确读取并使用这些模型进行推理。当然，更深层次的原因是，GGML 是和 llama.cpp 一起被设计出来的，其目的就是为了在 CPU 上运行量化后的模型，事实上，它们都出自同一个作者 <a href=https://github.com/ggerganov>Georgi Gerganov</a>，GGML 由此得名，你可以将其理解为一个使用 C/C++ 实现的机器学习库。</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ggerganov-github-profile.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ggerganov-github-profile.png data-caption="Georgi Gerganov 大佬的 Github 主页"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ggerganov-github-profile.png alt="Georgi Gerganov 大佬的 Github 主页" class=post-img loading=lazy>
<span class=post-img-tip>Georgi Gerganov 大佬的 Github 主页</span></a></p><p>接下来，我们来考虑第二个问题，什么是量化？根据知乎上的相关话题，ChatGPT-3 的模型参数最多高达 1750亿，而 ChatGPT-4 的模型参数则将近20000亿，你或许无法理解这些参数具体是什么，如果我们换一种方式来表示呢？根据估算，ChatGPT-3 的磁盘占用大约为 332G，而 ChatGPT-4 的参数规模大概是 ChatGPT-3 的 10 倍以上，这到底会给未来留下多少想象空间，我们始终无法得知，但如此庞大的规模哪怕对 GPU 来说依然是种负担。回想一下平时你玩过的那些 3A 大作的游戏目录你就知道了，这样一种体量的模型文件对人类来说，是完全不亚于奥特曼这般庞然大物的存在。至此，量化这种可以显著缩小模型体积的技术应运而生。</p><p><a href=https://stackoverflow.blog/2023/08/23/fitting-ai-models-in-your-pocket-with-quantization/><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/how-quantize-works.gif data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/how-quantize-works.gif data-caption=模型量化的类比展示><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/how-quantize-works.gif alt=模型量化的类比展示 class=post-img loading=lazy>
<span class=post-img-tip>模型量化的类比展示</span></a></a></p><p>该如何解释这种技术呢？我们知道，一般的机器学习模型都使用单精度浮点型数值来表示，当我们使用一个有符号整型数值来近似替代的时候，虽然它会丢失部分精度，但是好处是这串数字的长度变短了。大模型量化采用了类似的原理，它会将模型中的权重和激活值表示为低精度的数据类型，这样，便可以减少模型的储存空间、能耗和计算时间，从而使其可以在资源受限的设备上高效运行。如上图所示，同一张图片在不同位数的颜色值下形态各异，可这副画的基本轮廓还是能看清楚的，这就是量化过程的形象化展示。显然，这是一种牺牲精度来换取性能的方案。</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama_quantize.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama_quantize.png data-caption="llama.cpp 不同量化方法下的模型文件体积与推理速度(已过期)"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama_quantize.png alt="llama.cpp 不同量化方法下的模型文件体积与推理速度(已过期)" class=post-img loading=lazy>
<span class=post-img-tip>llama.cpp 不同量化方法下的模型文件体积与推理速度(已过期)</span></a></p><h2 id=模型下载>模型下载</h2><p>现在，我们来聊聊模型下载问题，因为目前 Hugging Face 在国内基本处于不可访问的状态，但如果我们打算学习或者研究人工智能的话，这个网站始终是一个绕不过去的点，所以，这里来专门介绍下如何从 Hugging Face 上下载 AI 大模型。这里介绍三种方法：脚本下载、手动下载 以及 Git 下载。</p><h3 id=脚本方式>脚本方式</h3><p>如果你经常光顾 Hugging Face ，那么，你会在许多模型文件的 README 里见到下面的代码片段：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoTokenizer</span><span class=p>,</span> <span class=n>AutoModelForCausalLM</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Qwen/Qwen-7B-Chat&#34;</span><span class=p>,</span> <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Qwen/Qwen-7B-Chat&#34;</span><span class=p>,</span> <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span> <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>response</span><span class=p>,</span> <span class=n>history</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>tokenizer</span><span class=p>,</span> <span class=s2>&#34;你好&#34;</span><span class=p>,</span> <span class=n>history</span><span class=o>=</span><span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>)</span>
</span></span></code></pre></div><p>这其实是一个用来测试预训练模型的脚本，不过它会缓存模型文件到本地，所以，这个方案一定程度上可行的，不过，经过我的测试，它一直在报 SSL 错误，即使挂着代理一样无法解决这个问题。在官方文档中一番折腾后，我发现了 <code>hf_hub_download()</code> 这个函数：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>huggingface_hub</span> <span class=kn>import</span> <span class=n>hf_hub_download</span>
</span></span><span class=line><span class=cl><span class=n>hf_hub_download</span><span class=p>(</span><span class=n>repo_id</span><span class=o>=</span><span class=s2>&#34;Qwen/Qwen-7B-Chat&#34;</span><span class=p>,</span> <span class=n>filename</span><span class=o>=</span><span class=s2>&#34;config.json&#34;</span><span class=p>)</span>
</span></span></code></pre></div><p>非常遗憾，这个方法还是行不通，还是提示 SSL 错误，而且它一次只能下载一个文件，如果你想下载整个仓库，你需要使用 <code>snapshot_download()</code>。你知道在中国做程序员最痛苦的是什么吗？就是你对着官方文档一顿疯狂输出，结果最后输给了源、代理、加速器、镜像网站🙄</p><h3 id=手动方式>手动方式</h3><p>手动下载这个方案虽然非常的低效，可你不得不承认，这居然是最靠谱的方案。如图所示，我们只需要依次点击图中的下载按钮即可。建议下载时单独建一个文件夹，将同一个仓库内的文件都放在不起，这样，更利于你管理不同的模型文件。当然，这些模型文件都挺大的，所以，需要你的磁盘足够大，网络足够好，同时要有足够的耐心：</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/manual-download-llm-models.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/manual-download-llm-models.png data-caption="从 Hugging Face 上手动下载模型"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/manual-download-llm-models.png alt="从 Hugging Face 上手动下载模型" class=post-img loading=lazy>
<span class=post-img-tip>从 Hugging Face 上手动下载模型</span></a></p><p>我才不会告诉你，除了通义千问是用 Git 下载的，剩下的模型都是我手动下载的😕</p><h3 id=git-方式>Git 方式</h3><p>作为程序员，Git 不单单是一个工具，更是一种信仰。这里博主重点点名表扬阿里的<a href=https://tongyi.aliyun.com/qianwen/>通义千问</a>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Make sure you have git-lfs installed (https://git-lfs.com)</span>
</span></span><span class=line><span class=cl>git lfs install
</span></span><span class=line><span class=cl>git clone git@hf.co:Qwen/Qwen-7B-Chat
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># if you want to clone without large files – just their pointers</span>
</span></span><span class=line><span class=cl><span class=c1># prepend your git clone with the following env var:</span>
</span></span><span class=line><span class=cl><span class=nv>GIT_LFS_SKIP_SMUDGE</span><span class=o>=</span><span class=m>1</span>
</span></span></code></pre></div><p>当然，还有从镜像网站 <a href=https://hf-mirror.com/>https://hf-mirror.com/</a> 下载模型的方法，这里就不再详细展开讲啦！此处的模型统一放在 llama.cpp 的 <code>models</code> 子目录下面，每个文件夹是一个模型，后续展开同样遵循这个原则。为了公平起见，我们使用同一个问题来向这些不同的模型进行提问，<strong>“昨天的当天是明天的什么”</strong>，看看 AI 大模型会作何反应。</p><h2 id=chinese-llama-2-7b-体验>Chinese-Llama-2-7B 体验</h2><p>Step-1：完成模型的转换和量化：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python convert.py models/chinese-llama-2-7b/ --outfile models/chinese-llama-2-7b/chinese-llama-2-7b-ggml.bin
</span></span><span class=line><span class=cl>./quantize models/chinese-llama-2-7b/chinese-llama-2-7b-ggml.bin models/chinese-llama-2-7b/chinese-llama-2-7b-ggml-model-q4_0.bin q4_0
</span></span></code></pre></div><p>Step-2：以命令行交互的方式运行模型:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./main -m models/chinese-llama-2-7b/chinese-llama-2-7b-ggml-model-q4_0.bin -n <span class=m>256</span> --repeat_penalty 1.0 --color -i -r <span class=s2>&#34;User:&#34;</span> -f prompts/chat-with-bob.txt
</span></span></code></pre></div><p>此时，运行结果如下：
<a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-llama-2-7b-talk.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-llama-2-7b-talk.png data-caption="Chinese-Llama-2-7B 运行效果展示"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-llama-2-7b-talk.png alt="Chinese-Llama-2-7B 运行效果展示" class=post-img loading=lazy>
<span class=post-img-tip>Chinese-Llama-2-7B 运行效果展示</span></a></p><p>或许是这个问题太难，AI 被直接问出了母语，哈哈🤣</p><h2 id=chinese-llama-2-13b-体验>Chinese-Llama-2-13B 体验</h2><p>Step-1：完成模型的转换和量化：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python convert.py models/chinese-llama-2-13b/ --outfile models/chinese-llama-2-13b/chinese-llama-2-13b-ggml.bin
</span></span><span class=line><span class=cl>./quantize models/chinese-llama-2-13b/chinese-llama-2-13b-ggml.bin models/chinese-llama-2-13b/chinese-llama-2-13b-ggml-model-q4_0.bin q4_0
</span></span></code></pre></div><p>Step-2：以命令行交互的方式运行模型:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./main -m models/chinese-llama-2-13b/chinese-llama-2-13b-ggml-model-q4_0.bin -n <span class=m>256</span> --repeat_penalty 1.0 --color -i -r <span class=s2>&#34;User:&#34;</span> -f prompts/chat-with-bob.txt
</span></span></code></pre></div><p>此时，运行结果如下：
<a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-llama-2-13b-talk.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-llama-2-13b-talk.png data-caption="Chinese-Llama-2-13B 运行效果展示"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-llama-2-13b-talk.png alt="Chinese-Llama-2-13B 运行效果展示" class=post-img loading=lazy>
<span class=post-img-tip>Chinese-Llama-2-13B 运行效果展示</span></a></p><p>果然，13B 要比 7B 聪明一点，可这句话完全不通顺啊🤣</p><h2 id=chinese-alpaca-2-7b-体验>Chinese-Alpaca-2-7B 体验</h2><p>Step-1：完成模型的转换和量化：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python convert.py models/chinese-alpaca-2-7b/ --outfile models/chinese-alpaca-2-7b/chinese-alpaca-2-7b-ggml.bin
</span></span><span class=line><span class=cl>./quantize models/chinese-alpaca-2-7b/chinese-alpaca-2-7b-ggml.bin models/chinese-alpaca-2-7b/chinese-alpaca-2-7b-ggml-model-q4_0.bin q4_0
</span></span></code></pre></div><p>Step-2：以命令行交互的方式运行模型:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./main -m models/chinese-alpaca-2-7b/chinese-alpaca-2-7b-ggml-model-q4_0.bin -n <span class=m>256</span> --repeat_penalty 1.0 --color -i -r <span class=s2>&#34;User:&#34;</span> -f prompts/chat-with-bob.txt
</span></span></code></pre></div><p>此时，运行结果如下：
<a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-alpaca-2-7b-talk.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-alpaca-2-7b-talk.png data-caption="Chinese-Alpaca-2-7B 运行效果展示"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/chinese-alpaca-2-7b-talk.png alt="Chinese-Alpaca-2-7B 运行效果展示" class=post-img loading=lazy>
<span class=post-img-tip>Chinese-Alpaca-2-7B 运行效果展示</span></a></p><p>嗯，Alpaca 不愧是 LLaMA 的微调版本，这回答没有任何问题，甚至带着点哲学家的意味🤔</p><h2 id=qwen-1_8b-chat-体验>Qwen-1_8B-Chat 体验</h2><p>Step-1：完成模型的转换和量化：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>python convert-hf-to-gguf.py models/Qwen-1_8B-Chat/
</span></span><span class=line><span class=cl>./quantize models/Qwen-1_8B-Chat/ggml-model-f16.gguf models/Qwen-1_8B-Chat/ggml-model-q5_k_m.gguf q5_k_m
</span></span></code></pre></div><p>Step-2：以命令行交互的方式运行模型:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./main -m models/Qwen-1_8B-Chat/ggml-model-q5_k_m.gguf -n <span class=m>256</span> --repeat_penalty 1.0 --color -i -r <span class=s2>&#34;User:&#34;</span> -f prompts/chat-with-bob.txt
</span></span></code></pre></div><p>此时，运行结果如下：
<a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/Qwen-1_8B-Chat-Talk.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/Qwen-1_8B-Chat-Talk.png data-caption="Qwen-1_8B-Chat 运行效果展示"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/Qwen-1_8B-Chat-Talk.png alt="Qwen-1_8B-Chat 运行效果展示" class=post-img loading=lazy>
<span class=post-img-tip>Qwen-1_8B-Chat 运行效果展示</span></a></p><p>还是你最诚实，一不留神就暴漏了训练数据集的时间范围，整体对比下来，感觉还是阿里的 Qwen-1_8B-Chat 模型效果更好一点，实际如何呢，我们可以通过下面的命令来评估模型的好坏。其中，<a href=https://paperswithcode.com/dataset/wikitext-2>wikitext</a> 是一个用来测试的数据集，可以从网上免费获得。这里以 Qwen-1_8B-Chat 模型为例，跑一次评估大概需要 2 个小时左右 ：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./perplexity -m models/Qwen-1_8B-Chat/ggml-model-q5_k_m.gguf -f wikitext-2-raw/wiki.test.raw
</span></span></code></pre></div><p>下面是 Qwen-1_8B-Chat 的评估结果：</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-perplexity.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-perplexity.png data-caption="Qwen-1_8B-Chat 评估结果"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-perplexity.png alt="Qwen-1_8B-Chat 评估结果" class=post-img loading=lazy>
<span class=post-img-tip>Qwen-1_8B-Chat 评估结果</span></a></p><h1 id=对接-chatgpt-next-web>对接 ChatGPT-Next-Web</h1><p>除了以上面这种命令行交互的方式运行模型，我们还可以使用下面的<a href=https://github.com/ggerganov/llama.cpp/blob/master/examples/server/README.md>命令</a>在本地运行一个 OpenAI 服务：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>./server -m models/Qwen-1_8B-Chat/ggml-model-q5_k_m.gguf -c <span class=m>2048</span>
</span></span></code></pre></div><p>默认端口为 8080，llama.cpp 提供了一个相对简陋的聊天界面:</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-talk-with-ui.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-talk-with-ui.png data-caption="llama.cpp 默认提供的聊天界面"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-talk-with-ui.png alt="llama.cpp 默认提供的聊天界面" class=post-img loading=lazy>
<span class=post-img-tip>llama.cpp 默认提供的聊天界面</span></a></p><p>此外，llama.cpp 提供了完全与 OpenAI API 兼容的 API 接口，因此，我们可以使用 Postman 或者 Apifox 来请求本地的 AI 接口。当然，因为是使用 CPU 进行推理，所以，目前生成文本的速度非常感人：</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-talk-with-api.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-talk-with-api.png data-caption="llama.cpp 提供的 API 接口"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/llama-cpp-talk-with-api.png alt="llama.cpp 提供的 API 接口" class=post-img loading=lazy>
<span class=post-img-tip>llama.cpp 提供的 API 接口</span></a></p><p>既然现在有了与 OpenAI API 完全兼容的接口，那么，我们就可以考虑将其接入支持 OpenAI API 的前端页面。这里，博主选择的是市面上最为流行的 <a href=https://github.com/ChatGPTNextWeb/ChatGPT-Next-Web>ChatGPT-Next-Web</a>。方便起见，这里我们直接使用 Docker 来进行演示：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># OPENAI_API_KEY 和 CODE 两个环境变量随便写即可</span>
</span></span><span class=line><span class=cl><span class=c1># 因为我们并不需要去调用真正的 OpenAI API</span>
</span></span><span class=line><span class=cl>docker run -d -p 3000:3000 -e <span class=nv>OPENAI_API_KEY</span><span class=o>=</span>xxxx -e <span class=nv>CODE</span><span class=o>=</span>1qaz2wsx3edc yidadaa/chatgpt-next-web
</span></span></code></pre></div><p>接下来，我们在设置里维护一下接口地址，因为我们要使用自定义的接口，虽然文档里提到可以用 <code>BASE_URL</code> 以及 <code>PROXY_URL</code> 两个变量来配置，但我一直没有尝试成功，程序员每天起起落落的人生啊！</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ChatGPT-Next-Web-1.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ChatGPT-Next-Web-1.png data-caption="配置本地 AI 接口"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ChatGPT-Next-Web-1.png alt="配置本地 AI 接口" class=post-img loading=lazy>
<span class=post-img-tip>配置本地 AI 接口</span></a></p><p>一切就绪以后，接下来，就是见证奇迹的时刻：</p><p><a class=img-fancybox href=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ChatGPT-Next-Web-2.png data-fancybox=gallery data-src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ChatGPT-Next-Web-2.png data-caption="使用本地 AI 接口"><img src=/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ChatGPT-Next-Web-2.png alt="使用本地 AI 接口" class=post-img loading=lazy>
<span class=post-img-tip>使用本地 AI 接口</span></a></p><p>至此，我们成功地将 ChatGPT-Next-Web 和 llama.cpp 两个项目结合起来，初步达成了在本地部署 AI 大模型的小目标。按照这个思路，理论上你只要有台服务器，就可以构建出一个自己的 AI 聊天工具。当然，目前这个模型里的知识都来自阿里通义千问，如果你希望它更贴近自己的上下文，就可以考虑对现有模型进行微调或者使用 LangChain 这类框架接入本地知识库，因为 llama.cpp 里同样提供了 Embeddings 等功能的 API ，并且它与 OpenAI 的 API 完全兼容，这意味着它完全可以利用 OpenAI 周边的生态。显然，这是下一个阶段的规划啦！</p><h1 id=本文小结>本文小结</h1><p>本文旨在尝试使用 llama.cpp 在本地部署 AI 大模型，随着人工智能的快速发展，我们逐渐认识到私有化部署的重要性和潜力。在此背景下，llama.cpp 作为一个纯 C/C++ 实现的 LLaMA 模型推理工具，提供了在本地环境下高性能的 AI 推理能力。在这篇文章中，我们可以了解到 llama.cpp 具有在 GPU 和 CPU 环境下运行的灵活性，满足私有化部署的需求。文章详细介绍了 llama.cpp 编译和部署的过程，为读者提供了一份在本地部署 AI 大模型的教程。私有化部署的 AI 大模型，相比于 ChatGPT 这类通用大模型，更注重数据隐私和安全性，对云服务的依赖更少，可以做到更好的本地化控制。虽然编译 llama.cpp 有一定的复杂性，AI 大模型的下载、转化、量化需要一定的耐心，可当本地的 AI 应用运行起来的那一刻，博主觉得这一切完全值得，以上就是本文的全部内容，下期再见！</p></div><div class="copyright s-card"><div class=title><span class=post-name>使用 llama.cpp 在本地部署 AI 大模型的一次尝试</span>
<a :href=https://qinyuanpei.github.io/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/ class=post-link target=_blank>https://qinyuanpei.github.io/posts/an-attempt-to-deploy-a-large-ai-model-locally-using-llama.cpp/</a></div><div class=post-meta><div class=meta-item><span class=tip>作者</span>
<span class=name>飞鸿踏雪</span></div><div class=meta-item><span class=tip>发布于</span>
<span class=name>2024-02-04</span></div><div class=meta-item><span class=tip>更新于</span>
<span class=name>2024-02-04</span></div><div class="meta-item cc"><span class=tip>许可协议</span>
<a class=name href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans target=_blank>CC BY-NC-SA 4.0</a></div></div><span class=meta-tip>署名-非商业性使用-相同方式共享 4.0 国际</span></div><div class=other-meta><div class=all-tags><a href=/tags/llama.cpp class=tag-item><i class="iconfont icon-hashtag"></i>
<span class=name>llama.cpp</span>
</a><a href=/tags/chatgpt class=tag-item><i class="iconfont icon-hashtag"></i>
<span class=name>ChatGPT</span>
</a><a href=/tags/qwen-7b-chat class=tag-item><i class="iconfont icon-hashtag"></i>
<span class=name>Qwen-7B-Chat</span>
</a><a href=/tags/llama class=tag-item><i class="iconfont icon-hashtag"></i>
<span class=name>LLaMA</span></a></div><a href=https://eqnxweimkr5.feishu.cn/share/base/form/shrcnCXCPmxCKKJYI3RKUfefJre class=report target=_blank><i class="iconfont icon-report"></i>
反馈与投诉</a></div><div class=reward><div class=reward-btn onclick='window.$Modal.show("reward-modal")'><i class="iconfont icon-reward"></i>
<span class=text>赞赏博主</span></div></div><div class=modal id=reward-modal><div class=modal-mask></div><div class="modal-main s-card" style=max-width:430px><div class=title><div class=title-left><i class="iconfont icon-reward"></i>
<span class=title-text>赞赏博主</span></div><i class="iconfont icon-close close" id=modal-close></i></div><div class=modal-content style=--height:80vh><div class=reward-card><div class=thank>🙏 请博主喝一杯咖啡</div><div class=qr><a class=qr-img href=/images/reward/alipay.jpg target=_blank><img src=/images/reward/alipay.jpg alt=支付宝赞赏码><div class=tip><i class="iconfont icon-alipay"></i>
<span>支付宝</span></div></a><a class=qr-img href=/images/reward/wechat.jpg target=_blank><img src=/images/reward/wechat.jpg alt=微信赞赏码><div class=tip><i class="iconfont icon-wechat"></i>
<span>微信</span></div></a></div><div class="all-list s-card hover"><div class=title>赞赏记录</div><div class=tip>赞赏金额将全部用于开源项目维护，以及服务器、域名及各类云服务的开销</div></div></div></div></div></div><div class=related-post><div class=title><span class=name><i class="iconfont icon-star"></i>
相关推荐
</span><span class=shuffle onclick='window.location.href="/posts/2414960312/"'>随便逛逛</span></div><div class=post-lists><article class="post-item s-card simple hover" style=animation-delay:.4s onclick='window.location.href="/posts/everything-you-need-to-know-about-streaming-with-chatgpt/"'><div class=post-content><span class=post-title>关于 ChatGPT 的流式传输，你需要知道的一切</span>
<span class=post-desc>本文深入探讨了生成式 AI 产品如 ChatGPT 的流式输出效果，阐释了其目的在于减少用户等待时间，而非简单模仿人类行为。文章详细介绍了 Server-Sent Events（SSE）技术在实现流式传输中的应用，并通过代码示例展示了服务端配置和客户端数据接收的方法。同时，讨论了 WebSocket 技术作为 SSE 的替代方案，强调了在 AI 应用开发中实现流式传输的重要性。此外，文中还介绍了 .NET 中的 IAsyncEnumerable 接口，并讨论了在生成式 AI 中实现取消/停止生成功能的挑战，提出了基于 WebSocket 的双向通信机制来解决这一问题。最后，文章总结了流式传输在 AI 与人类交互中的重要性，并提出了对 AI 智能本质的思考。</span></div></article><article class="post-item s-card simple hover" style=animation-delay:.4s onclick='window.location.href="/posts/practice-local-ai-knowledg-base-based-on-llama-and-langchain/"'><div class=post-content><span class=post-title>基于 LLaMA 和 LangChain 实践本地 AI 知识库</span>
<span class=post-desc>本文讨论了人工智能领域的最新发展，主要围绕着基于 Transformer 和 MoE 架构的多模态模型 Gemini 1.5 Pro，以及 OpenAI 推出的支持从文字生成视频的模型 Sora。文章提到通用人工智能（AGI）的实现正在加速，指出 AI 应用落地的主要实践围绕大模型微调、提示词工程和知识增强展开。在介绍 LangChain 中的知识库构建过程中，涉及Loader、Splitter、Embeddings 和 VectorStore 等步骤。此外，还讨论了 RAG 和 GPTs 在实践中的应用，以及LangChain 中的 Chain 概念，以及如何将其与大语言模型和知识库结合以实现 Q&amp;A 和 对话式检索。文章最后呼吁关注LangChain 的最新发展和替代品 AutoChain、Embedchain。</span></div></article></div><style>.post-lists{width:100%}.post-lists .post-item{padding:0!important;display:flex;margin-bottom:1rem;animation:fade-up .6s backwards;cursor:pointer;overflow:hidden;height:200px}.post-lists .post-item .post-cover{flex:0 0 35%;overflow:hidden;transform:translateZ(0)}.post-lists .post-item .post-cover img{width:100%;height:100%;object-fit:cover;transform-origin:center center;transition:transform .5s ease-out,filter .5s ease-out;backface-visibility:hidden}.post-lists .post-item .post-content{flex:1;padding:1.6rem 2rem;display:flex;flex-direction:column;justify-content:space-between}.post-lists .post-item .post-category{display:flex;flex-wrap:wrap;width:100%;color:var(--main-font-second-color);font-size:14px}.post-lists .post-item .post-category .cat-name{display:flex;flex-direction:row;align-items:center}.post-lists .post-item .post-category .cat-name .iconfont{opacity:.8;margin-right:6px;color:var(--main-font-second-color)}.post-lists .post-item .post-category .top{margin-left:12px;color:var(--main-color)}.post-lists .post-item .post-category .top .iconfont{opacity:.8;color:var(--main-color)}.post-lists .post-item .post-title{font-size:20px;line-height:30px;font-weight:700;margin:.6rem 0;transition:color .3s;display:-webkit-box;overflow:hidden;word-break:break-all;-webkit-box-orient:vertical;-webkit-line-clamp:2}.post-lists .post-item .post-desc{margin-top:-.4rem;margin-bottom:.8rem;opacity:.8;line-height:30px;display:-webkit-box;overflow:hidden;word-break:break-all;-webkit-box-orient:vertical;-webkit-line-clamp:2}.post-lists .post-item .post-meta{display:flex;flex-direction:row;align-items:center;justify-content:space-between;color:var(--main-font-second-color)}.post-lists .post-item .post-tags{display:flex;flex-wrap:wrap;opacity:.8;margin-right:20px;overflow:hidden;mask:linear-gradient(90deg,#fff 0,#fff 90%,hsla(0,0%,100%,.6) 95%,hsla(0,0%,100%,0) 100%)}.post-lists .post-item .post-tags .tags-name{display:flex;flex-direction:row;align-items:center;margin-right:12px;white-space:nowrap;transition:color .3s}.post-lists .post-item .post-time{opacity:.6;font-size:13px;white-space:nowrap}.post-lists .post-item:hover .post-cover img{filter:brightness(.8);transform:scale(1.05)}.post-lists .post-item:hover .post-title{color:var(--main-color)}.post-lists .post-item:active{transform:scale(.98)}.post-lists .post-item.cover-left{flex-direction:row}.post-lists .post-item.cover-right{flex-direction:row-reverse}.post-lists .post-item.cover-both:nth-child(odd){flex-direction:row}.post-lists .post-item.cover-both:nth-child(even){flex-direction:row-reverse}.post-lists.layout-grid{display:grid;grid-template-columns:repeat(var(--grid-columns,2),1fr);gap:var(--grid-gap,1rem)}.post-lists.layout-grid .post-item{margin:0;flex-direction:column;height:auto}.post-lists.layout-grid .post-item .post-cover{flex:none;width:100%;height:225px}@media(max-width:768px){.post-lists .post-item{flex-direction:column;height:auto}.post-lists .post-item .post-cover{flex:none;width:100%;height:200px}.post-lists .post-item.cover-left,.post-lists .post-item.cover-right,.post-lists .post-item.cover-both{flex-direction:column!important}.post-lists.layout-grid{grid-template-columns:1fr}.post-lists .post-item .post-tags{flex-wrap:nowrap}}.post-lists .post-item .simple{animation:none;padding:.5rem 1.4rem!important;background-color:var(--main-card-second-background);height:auto;margin-bottom:.5rem}.post-lists .post-item .simple .post-content{padding:.5rem 0}.post-lists .post-item .simple .post-title{margin:0;font-size:16px}.post-lists .post-item .simple .post-desc{margin:.3rem 0 0;font-size:14px;opacity:.6}</style></div><style>.related-post{margin-top:1rem}.related-post .title{display:flex;flex-direction:row;align-items:center;justify-content:space-between;width:100%;margin:3rem 0 1rem;padding:0 6px}.related-post .title .name{display:flex;align-items:center;font-size:24px;font-weight:700}.related-post .title .name .iconfont{font-size:26px;font-weight:400;margin-right:8px}.related-post .title .shuffle{opacity:.6;font-size:14px;transition:color .3s,opacity .3s;cursor:pointer}.related-post .title .shuffle:hover{opacity:1;color:var(--main-color)}</style><div id=comments><div id=main-comment class=comment><div v-if=!fill class=title><span class=name><i class="iconfont icon-chat"></i>
评论
</span><span class=tool>隐私政策</span></div><link rel=stylesheet href=https://unpkg.com/@waline/client@v3/dist/waline.css><div id=waline class=waline-container></div><style>.waline-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}.waline-container .vcount{color:var(--card-text-color-main)}</style><script type=module>
        import { init } from 'https://unpkg.com/@waline/client@v3/dist/waline.js';
        init({
            el: '#waline',
            serverURL: 'https:\/\/waline.yuanpei.me\/',
            lang: 'zh',
            dark: 'auto',
            path: window.location.href,
            requiredMeta: ['nick','mail'],
            emoji: [
                '//unpkg.com/@waline/emojis@1.2.0/weibo'
            ],
            reaction: false,
        });
      </script></div></div><div class="next-post s-card" id=next-post data-is-next=true><a href=/posts/practice-local-ai-knowledg-base-based-on-llama-and-langchain/ class=next-post-link><span class=post-tip>下一篇阅读
</span><span class=post-title>基于 LLaMA 和 LangChain 实践本地 AI 知识库</span></a></div></article><aside class=main-aside><div class="hello s-card weidgets"><span class=tip>中午好，吃饱了精神好！</span><div class=content><div class=site-logo><div class=avatar><img src=/images/avatar.jpg alt=avatar loading=lazy></div></div><span class=site-desc></span></div><div class=info><div class=name><span class=author>飞鸿踏雪</span>
<span class=desc>纵有疾风起，人生不言弃</span></div><div class=link><a href=https://github.com/qinyuanpei target=_blank class=social-link><i class="iconfont icon-github"></i>
</a><a href=mailto:qinyuapei@163.com target=_blank class=social-link><i class="iconfont icon-email"></i></a></div></div></div><div class=sticky><div class="toc s-card weidgets" id=weidget-toc><div class=toc-title><i class="iconfont icon-toc"></i>
<span class=name>目录</span></div><div id=toc-all class=toc-list></div></div><script>document.addEventListener("DOMContentLoaded",function(){const o=[];let e=null,t=null,n=0;const s=document.getElementById("toc-all"),i=()=>{try{if(e=document.getElementById("page-content"),!e)return!1;const t=Array.from(e.querySelectorAll("h1, h2, h3, h4")).filter(e=>e.parentElement.tagName.toLowerCase()==="div");return t}catch(e){console.error("获取所有目录数据出错：",e)}},r=()=>{const e=i();if(!e)return!1;s.innerHTML="",e.forEach((e,t)=>{const n={id:e.id,type:e.tagName,text:e.textContent?.replace(/\u200B/g,"").trim()},i=document.createElement("span");i.id="toc-"+n.id,i.className=`toc-item ${n.type} ${t===0?"active":""}`,i.textContent=n.text,i.addEventListener("click",()=>d(n.id)),s.appendChild(i),o.push(n)}),e&&e.length>0&&(t=e[0].id)},c=(e,t)=>{let n;return function(){const s=arguments,o=this;n||(e.apply(o,s),n=!0,setTimeout(()=>n=!1,t))}},l=c(()=>{if(!o.length)return!1;const e=i();if(!e)return!1;const s=120;if(window.scrollY===0){n=0,t=e[0]?.id,a();return}for(let n of e){const o=n.getBoundingClientRect();o.top-s<=0&&o.bottom+s>=0&&t!==n.id&&(t=n.id,a())}},100),a=()=>{document.querySelectorAll(".toc-item.active").forEach(e=>{e.classList.remove("active")});const e=document.getElementById("toc-"+t);if(!e)return!1;e.classList.add("active"),n=e.offsetTop-2||0,s.style.setProperty("--height",n+"px"),s.scrollTo({top:n-80,behavior:"smooth"})},d=t=>{try{const n=document.getElementById(t);if(!n||!e)return!1;const s=n.offsetTop,o=s+e.offsetTop-80;window.scroll({top:o,behavior:"smooth"})}catch(e){console.error("目录滚动失败：",e)}};r(),window.addEventListener("scroll",l)})</script><style lang=scss scoped>.toc{position:relative;padding:0!important;overflow:hidden;.toc-title { display: flex; flex-direction: row; align-items: center; padding: 18px; height: 58px; .iconfont { margin-right: 8px; font-weight: bold; opacity: 0.6; } .name { font-weight: bold; } } .toc-list { position: relative; padding: 20px; padding-top: 0; padding-left: 24px; display: flex; flex-direction: column; max-height: calc(70vh - 58px); overflow: auto; .toc-item { margin: 4px 0; padding: 6px 12px; border-radius: 8px; opacity: 0.6; transition: color 0.3s, opacity 0.3s, font-size 0.3s, background-color 0.3s; cursor: pointer; &:first-child { margin-top: 0; } &:last-child { margin-bottom: 0; } &.H1 { font-weight: bold; } &.H2 { font-size: 14px; margin-left: 15px; font-weight: normal; } &.H3 { font-size: 12px; margin-left: 25px; } &.active { opacity: 1; color: var(--main-color); background-color: var(--main-color-bg); &.H2 { font-size: 14px; } &.H3 { font-size: 12px; } } &:hover { opacity: 1; color: var(--main-color); background-color: var(--main-color-bg); } } &::after { content: ""; position: absolute; left: 12px; top: var(--height); width: 4px; height: 20px; margin: 8px 0; background-color: var(--main-color); border-radius: 8px; transition: top 0.3s; } } &::before { content: ""; position: absolute; left: 12px; bottom: 20px; width: 4px; height: calc(100% - 78px); background-color: var(--main-card-border); border-radius: 8px; }}</style><div class="tags-cloud s-card weidgets"><div class=title><i class="iconfont icon-hashtag"></i>
<span class=title-name>热门标签</span></div><div class=all-tags><a href=/tags/unity3d/ class=tags><span class=name>Unity3D</span>
<sup class=num>27</sup>
</a><a href=/tags/%E6%84%9F%E6%82%9F/ class=tags><span class=name>感悟</span>
<sup class=num>23</sup>
</a><a href=/tags/python/ class=tags><span class=name>Python</span>
<sup class=num>22</sup>
</a><a href=/tags/%E9%9A%8F%E7%AC%94/ class=tags><span class=name>随笔</span>
<sup class=num>16</sup>
</a><a href=/tags/.net-core/ class=tags><span class=name>.NET Core</span>
<sup class=num>15</sup>
</a><a href=/tags/%E5%BD%B1%E8%AF%84/ class=tags><span class=name>影评</span>
<sup class=num>14</sup>
</a><a href=/tags/%E6%B8%B8%E6%88%8F/ class=tags><span class=name>游戏</span>
<sup class=num>13</sup>
</a><a href=/tags/%E7%94%B5%E5%BD%B1/ class=tags><span class=name>电影</span>
<sup class=num>12</sup>
</a><a href=/tags/grpc/ class=tags><span class=name>GRPC</span>
<sup class=num>10</sup>
</a><a href=/tags/%E6%B8%B8%E6%88%8F%E5%BC%80%E5%8F%91/ class=tags><span class=name>游戏开发</span>
<sup class=num>10</sup>
</a><a href=/tags/%E7%94%9F%E6%B4%BB/ class=tags><span class=name>生活</span>
<sup class=num>10</sup>
</a><a href=/tags/.net/ class=tags><span class=name>.NET</span>
<sup class=num>9</sup>
</a><a href=/tags/http/ class=tags><span class=name>HTTP</span>
<sup class=num>9</sup>
</a><a href=/tags/redis/ class=tags><span class=name>Redis</span>
<sup class=num>9</sup>
</a><a href=/tags/%E5%89%8D%E7%AB%AF/ class=tags><span class=name>前端</span>
<sup class=num>9</sup>
</a><a href=/tags/envoy/ class=tags><span class=name>Envoy</span>
<sup class=num>8</sup>
</a><a href=/tags/hexo/ class=tags><span class=name>Hexo</span>
<sup class=num>8</sup>
</a><a href=/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/ class=tags><span class=name>微服务</span>
<sup class=num>8</sup>
</a><a href=/tags/%E6%8A%80%E5%B7%A7/ class=tags><span class=name>技巧</span>
<sup class=num>8</sup>
</a><a href=/tags/%E6%95%99%E7%A8%8B/ class=tags><span class=name>教程</span>
<sup class=num>8</sup>
</a><a href=/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/ class=tags><span class=name>数据库</span>
<sup class=num>8</sup>
</a><a href=/tags/%E7%AC%94%E8%AE%B0/ class=tags><span class=name>笔记</span>
<sup class=num>8</sup>
</a><a href=/tags/aop/ class=tags><span class=name>AOP</span>
<sup class=num>7</sup>
</a><a href=/tags/c%23/ class=tags><span class=name>C#</span>
<sup class=num>7</sup>
</a><a href=/tags/docker/ class=tags><span class=name>Docker</span>
<sup class=num>6</sup>
</a><a href=/tags/linux/ class=tags><span class=name>Linux</span>
<sup class=num>6</sup>
</a><a href=/tags/vue/ class=tags><span class=name>Vue</span>
<sup class=num>6</sup>
</a><a href=/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/ class=tags><span class=name>服务器</span>
<sup class=num>6</sup>
</a><a href=/tags/%E7%BC%96%E7%A8%8B/ class=tags><span class=name>编程</span>
<sup class=num>6</sup>
</a><a href=/tags/%E8%AF%BB%E4%B9%A6/ class=tags><span class=name>读书</span>
<sup class=num>6</sup>
</a><a href=/tags/ef/ class=tags><span class=name>EF</span>
<sup class=num>5</sup>
</a><a href=/tags/opencv/ class=tags><span class=name>OpenCV</span>
<sup class=num>5</sup>
</a><a href=/tags/ugui/ class=tags><span class=name>UGUI</span>
<sup class=num>5</sup>
</a><a href=/tags/%E5%AE%B9%E5%99%A8/ class=tags><span class=name>容器</span>
<sup class=num>5</sup>
</a><a href=/tags/%E6%80%9D%E8%80%83/ class=tags><span class=name>思考</span>
<sup class=num>5</sup>
</a><a href=/tags/%E6%95%B0%E5%AD%A6/ class=tags><span class=name>数学</span>
<sup class=num>5</sup>
</a><a href=/tags/%E6%97%A5%E5%BF%97/ class=tags><span class=name>日志</span>
<sup class=num>5</sup>
</a><a href=/tags/%E6%BA%90%E7%A0%81/ class=tags><span class=name>源码</span>
<sup class=num>5</sup>
</a><a href=/tags/%E7%BC%93%E5%AD%98/ class=tags><span class=name>缓存</span>
<sup class=num>5</sup>
</a><a href=/tags/git/ class=tags><span class=name>Git</span>
<sup class=num>4</sup>
</a><a href=/tags/mono/ class=tags><span class=name>Mono</span>
<sup class=num>4</sup>
</a><a href=/tags/restful/ class=tags><span class=name>RESTful</span>
<sup class=num>4</sup>
</a><a href=/tags/web/ class=tags><span class=name>Web</span>
<sup class=num>4</sup>
</a><a href=/tags/webapi/ class=tags><span class=name>WebApi</span>
<sup class=num>4</sup>
</a><a href=/tags/%E5%8E%86%E5%8F%B2/ class=tags><span class=name>历史</span>
<sup class=num>4</sup>
</a><a href=/tags/%E5%A2%9E%E5%BC%BA%E7%8E%B0%E5%AE%9E/ class=tags><span class=name>增强现实</span>
<sup class=num>4</sup>
</a><a href=/tags/%E6%89%A9%E5%B1%95/ class=tags><span class=name>扩展</span>
<sup class=num>4</sup>
</a><a href=/tags/%E7%A8%8B%E5%BA%8F%E5%91%98/ class=tags><span class=name>程序员</span>
<sup class=num>4</sup>
</a><a href=/tags/%E7%BC%96%E8%BE%91%E5%99%A8/ class=tags><span class=name>编辑器</span>
<sup class=num>4</sup>
</a><a href=/tags/ar/ class=tags><span class=name>AR</span>
<sup class=num>3</sup>
</a><a href=/tags/bash/ class=tags><span class=name>Bash</span>
<sup class=num>3</sup>
</a><a href=/tags/chatgpt/ class=tags><span class=name>ChatGPT</span>
<sup class=num>3</sup>
</a><a href=/tags/dapper/ class=tags><span class=name>Dapper</span>
<sup class=num>3</sup>
</a><a href=/tags/kindle/ class=tags><span class=name>Kindle</span>
<sup class=num>3</sup>
</a><a href=/tags/nginx/ class=tags><span class=name>Nginx</span>
<sup class=num>3</sup>
</a><a href=/tags/nlp/ class=tags><span class=name>NLP</span>
<sup class=num>3</sup>
</a><a href=/tags/rabbitmq/ class=tags><span class=name>RabbitMQ</span>
<sup class=num>3</sup>
</a><a href=/tags/travis/ class=tags><span class=name>Travis</span>
<sup class=num>3</sup>
</a><a href=/tags/websocket/ class=tags><span class=name>WebSocket</span>
<sup class=num>3</sup>
</a><a href=/tags/%E4%B8%AD%E9%97%B4%E4%BB%B6/ class=tags><span class=name>中间件</span>
<sup class=num>3</sup>
</a><a href=/tags/%E5%93%B2%E5%AD%A6/ class=tags><span class=name>哲学</span>
<sup class=num>3</sup>
</a><a href=/tags/%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/ class=tags><span class=name>图像处理</span>
<sup class=num>3</sup>
</a><a href=/tags/%E5%9B%BE%E5%BD%A2/ class=tags><span class=name>图形</span>
<sup class=num>3</sup>
</a><a href=/tags/%E5%A4%9A%E7%BA%BF%E7%A8%8B/ class=tags><span class=name>多线程</span>
<sup class=num>3</sup>
</a><a href=/tags/%E5%B7%A5%E4%BD%9C/ class=tags><span class=name>工作</span>
<sup class=num>3</sup>
</a><a href=/tags/%E5%BC%82%E5%B8%B8/ class=tags><span class=name>异常</span>
<sup class=num>3</sup>
</a><a href=/tags/%E5%BE%AE%E5%8D%9A/ class=tags><span class=name>微博</span>
<sup class=num>3</sup>
</a><a href=/tags/%E6%88%90%E9%95%BF/ class=tags><span class=name>成长</span>
<sup class=num>3</sup>
</a><a href=/tags/%E6%8F%92%E4%BB%B6/ class=tags><span class=name>插件</span>
<sup class=num>3</sup>
</a><a href=/tags/%E6%97%B6%E9%97%B4/ class=tags><span class=name>时间</span>
<sup class=num>3</sup>
</a><a href=/tags/%E6%A2%A6%E6%83%B3/ class=tags><span class=name>梦想</span>
<sup class=num>3</sup>
</a><a href=/tags/%E6%B1%82%E8%81%8C/ class=tags><span class=name>求职</span>
<sup class=num>3</sup>
</a><a href=/tags/%E6%B8%A9%E6%95%85%E7%9F%A5%E6%96%B0/ class=tags><span class=name>温故知新</span>
<sup class=num>3</sup>
</a><a href=/tags/%E7%9B%91%E6%8E%A7/ class=tags><span class=name>监控</span>
<sup class=num>3</sup>
</a><a href=/tags/%E8%A5%BF%E5%AE%89/ class=tags><span class=name>西安</span>
<sup class=num>3</sup>
</a><a href=/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/ class=tags><span class=name>设计模式</span>
<sup class=num>3</sup>
</a><a href=/tags/%E8%B7%A8%E5%B9%B3%E5%8F%B0/ class=tags><span class=name>跨平台</span>
<sup class=num>3</sup>
</a><a href=/tags/%E9%9D%A2%E8%AF%95/ class=tags><span class=name>面试</span>
<sup class=num>3</sup>
</a><a href=/tags/abp/ class=tags><span class=name>ABP</span>
<sup class=num>2</sup>
</a><a href=/tags/agent/ class=tags><span class=name>Agent</span>
<sup class=num>2</sup>
</a><a href=/tags/aigc/ class=tags><span class=name>AIGC</span>
<sup class=num>2</sup>
</a><a href=/tags/api/ class=tags><span class=name>API</span>
<sup class=num>2</sup>
</a><a href=/tags/assetbundle/ class=tags><span class=name>AssetBundle</span>
<sup class=num>2</sup>
</a><a href=/tags/binlog/ class=tags><span class=name>Binlog</span>
<sup class=num>2</sup>
</a><a href=/tags/ci/ class=tags><span class=name>CI</span>
<sup class=num>2</sup>
</a><a href=/tags/cors/ class=tags><span class=name>CORS</span>
<sup class=num>2</sup>
</a><a href=/tags/csharp/ class=tags><span class=name>CSharp</span>
<sup class=num>2</sup>
</a><a href=/tags/di/ class=tags><span class=name>DI</span>
<sup class=num>2</sup>
</a><a href=/tags/dlib/ class=tags><span class=name>Dlib</span>
<sup class=num>2</sup>
</a><a href=/tags/easyar/ class=tags><span class=name>EasyAR</span>
<sup class=num>2</sup>
</a><a href=/tags/elk/ class=tags><span class=name>ELK</span>
<sup class=num>2</sup>
</a><a href=/tags/github/ class=tags><span class=name>Github</span>
<sup class=num>2</sup>
</a><a href=/tags/html5/ class=tags><span class=name>HTML5</span>
<sup class=num>2</sup>
</a><a href=/tags/httpclient/ class=tags><span class=name>HttpClient</span>
<sup class=num>2</sup>
</a><a href=/tags/javascript/ class=tags><span class=name>JavaScript</span>
<sup class=num>2</sup>
</a><a href=/tags/jeager/ class=tags><span class=name>Jeager</span>
<sup class=num>2</sup>
</a><a href=/tags/kafka/ class=tags><span class=name>Kafka</span>
<sup class=num>2</sup>
</a><a href=/tags/lambda/ class=tags><span class=name>Lambda</span>
<sup class=num>2</sup>
</a><a href=/tags/llama/ class=tags><span class=name>LLaMA</span>
<sup class=num>2</sup>
</a><a href=/tags/lua/ class=tags><span class=name>Lua</span>
<sup class=num>2</sup>
</a><a href=/tags/mock/ class=tags><span class=name>Mock</span>
<sup class=num>2</sup>
</a><a href=/tags/mysql/ class=tags><span class=name>MySQL</span>
<sup class=num>2</sup>
</a><a href=/tags/rag/ class=tags><span class=name>RAG</span>
<sup class=num>2</sup>
</a><a href=/tags/sdl/ class=tags><span class=name>SDL</span>
<sup class=num>2</sup>
</a><a href=/tags/selenium/ class=tags><span class=name>Selenium</span>
<sup class=num>2</sup>
</a><a href=/tags/signalr/ class=tags><span class=name>SignalR</span>
<sup class=num>2</sup>
</a><a href=/tags/socket/ class=tags><span class=name>Socket</span>
<sup class=num>2</sup>
</a><a href=/tags/sse/ class=tags><span class=name>SSE</span>
<sup class=num>2</sup>
</a><a href=/tags/streaming/ class=tags><span class=name>Streaming</span>
<sup class=num>2</sup>
</a><a href=/tags/swagger/ class=tags><span class=name>Swagger</span>
<sup class=num>2</sup>
</a><a href=/tags/tracing/ class=tags><span class=name>Tracing</span>
<sup class=num>2</sup>
</a><a href=/tags/vscode/ class=tags><span class=name>VSCode</span>
<sup class=num>2</sup>
</a><a href=/tags/wsl/ class=tags><span class=name>WSL</span>
<sup class=num>2</sup>
</a><a href=/tags/%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/ class=tags><span class=name>主从复制</span>
<sup class=num>2</sup>
</a><a href=/tags/%E4%BA%8B%E4%BB%B6%E8%AE%A2%E9%98%85/ class=tags><span class=name>事件订阅</span>
<sup class=num>2</sup>
</a><a href=/tags/%E4%BA%92%E8%81%94%E7%BD%91/ class=tags><span class=name>互联网</span>
<sup class=num>2</sup>
</a><a href=/tags/%E4%BA%BA%E6%96%87/ class=tags><span class=name>人文</span>
<sup class=num>2</sup>
</a><a href=/tags/%E4%BA%BA%E7%94%9F/ class=tags><span class=name>人生</span>
<sup class=num>2</sup>
</a><a href=/tags/%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/ class=tags><span class=name>人脸识别</span>
<sup class=num>2</sup>
</a><a href=/tags/%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5/ class=tags><span class=name>依赖注入</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%88%86%E5%B8%83%E5%BC%8F/ class=tags><span class=name>分布式</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%8A%A0%E5%AF%86/ class=tags><span class=name>加密</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/ class=tags><span class=name>动态代理</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%8A%A8%E6%BC%AB/ class=tags><span class=name>动漫</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%8F%AF%E8%A7%86%E5%8C%96/ class=tags><span class=name>可视化</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%90%8E%E7%AB%AF/ class=tags><span class=name>后端</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%90%91%E9%87%8F/ class=tags><span class=name>向量</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%AE%9E%E4%BD%93/ class=tags><span class=name>实体</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%B7%A5%E5%85%B7/ class=tags><span class=name>工具</span>
<sup class=num>2</sup>
</a><a href=/tags/%E5%BC%82%E6%AD%A5/ class=tags><span class=name>异步</span>
<sup class=num>2</sup>
</a><a href=/tags/%E6%80%BB%E7%BB%93/ class=tags><span class=name>总结</span>
<sup class=num>2</sup>
</a><a href=/tags/%E6%83%85%E6%84%9F/ class=tags><span class=name>情感</span>
<sup class=num>2</sup>
</a><a href=/tags/%E6%83%B3%E6%B3%95/ class=tags><span class=name>想法</span>
<sup class=num>2</sup>
</a><a href=/tags/%E6%89%93%E5%8D%B0/ class=tags><span class=name>打印</span>
<sup class=num>2</sup>
</a><a href=/tags/%E6%8A%80%E6%9C%AF/ class=tags><span class=name>技术</span>
<sup class=num>2</sup>
</a><a href=/tags/%E6%9E%B6%E6%9E%84/ class=tags><span class=name>架构</span>
<sup class=num>2</sup>
</a><a href=/tags/%E6%A6%82%E7%8E%87/ class=tags><span class=name>概率</span>
<sup class=num>2</sup>
</a><a href=/tags/%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E/ class=tags><span class=name>模板引擎</span>
<sup class=num>2</sup>
</a><a href=/tags/%E7%88%AC%E8%99%AB/ class=tags><span class=name>爬虫</span>
<sup class=num>2</sup>
</a><a href=/tags/%E7%88%B1%E6%83%85/ class=tags><span class=name>爱情</span>
<sup class=num>2</sup>
</a><a href=/tags/%E7%94%BB%E5%AE%B6/ class=tags><span class=name>画家</span>
<sup class=num>2</sup>
</a><a href=/tags/%E7%AE%97%E6%B3%95/ class=tags><span class=name>算法</span>
<sup class=num>2</sup>
</a><a href=/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA%E5%9B%BE%E5%BD%A2/ class=tags><span class=name>计算机图形</span>
<sup class=num>2</sup>
</a><a href=/tags/%E8%AE%A4%E8%AF%81/ class=tags><span class=name>认证</span>
<sup class=num>2</sup>
</a><a href=/tags/%E8%AE%BE%E8%AE%A1/ class=tags><span class=name>设计</span>
<sup class=num>2</sup>
</a><a href=/tags/%E8%B4%9D%E5%A1%9E%E5%B0%94%E6%9B%B2%E7%BA%BF/ class=tags><span class=name>贝塞尔曲线</span>
<sup class=num>2</sup>
</a><a href=/tags/%E8%B7%A8%E5%9F%9F/ class=tags><span class=name>跨域</span>
<sup class=num>2</sup>
</a><a href=/tags/%E9%80%9A%E4%BF%A1/ class=tags><span class=name>通信</span>
<sup class=num>2</sup>
</a><a href=/tags/%E9%85%8D%E7%BD%AE/ class=tags><span class=name>配置</span>
<sup class=num>2</sup>
</a><a href=/tags/%E9%87%8D%E8%AF%95/ class=tags><span class=name>重试</span>
<sup class=num>2</sup>
</a><a href=/tags/%E9%98%85%E8%AF%BB/ class=tags><span class=name>阅读</span>
<sup class=num>2</sup>
</a><a href=/tags/%E9%BB%91%E5%AE%A2/ class=tags><span class=name>黑客</span>
<sup class=num>2</sup>
</a><a href=/tags/2014/ class=tags><span class=name>2014</span>
<sup class=num>1</sup>
</a><a href=/tags/2019/ class=tags><span class=name>2019</span>
<sup class=num>1</sup>
</a><a href=/tags/ado.net/ class=tags><span class=name>ADO.NET</span>
<sup class=num>1</sup>
</a><a href=/tags/ai/ class=tags><span class=name>AI</span>
<sup class=num>1</sup>
</a><a href=/tags/any/ class=tags><span class=name>Any</span>
<sup class=num>1</sup>
</a><a href=/tags/apache/ class=tags><span class=name>Apache</span>
<sup class=num>1</sup>
</a><a href=/tags/blazor/ class=tags><span class=name>Blazor</span>
<sup class=num>1</sup>
</a><a href=/tags/c++/ class=tags><span class=name>C++</span>
<sup class=num>1</sup>
</a><a href=/tags/castle/ class=tags><span class=name>Castle</span>
<sup class=num>1</sup>
</a><a href=/tags/cdn/ class=tags><span class=name>CDN</span>
<sup class=num>1</sup>
</a><a href=/tags/cg/ class=tags><span class=name>CG</span>
<sup class=num>1</sup>
</a><a href=/tags/channel/ class=tags><span class=name>Channel</span>
<sup class=num>1</sup>
</a><a href=/tags/consul/ class=tags><span class=name>Consul</span>
<sup class=num>1</sup>
</a><a href=/tags/cts/ class=tags><span class=name>CTS</span>
<sup class=num>1</sup>
</a><a href=/tags/dbeaver/ class=tags><span class=name>DBeaver</span>
<sup class=num>1</sup>
</a><a href=/tags/ddd/ class=tags><span class=name>DDD</span>
<sup class=num>1</sup>
</a><a href=/tags/delayqueue/ class=tags><span class=name>DelayQueue</span>
<sup class=num>1</sup>
</a><a href=/tags/diagnostics/ class=tags><span class=name>Diagnostics</span>
<sup class=num>1</sup>
</a><a href=/tags/disunity/ class=tags><span class=name>Disunity</span>
<sup class=num>1</sup>
</a><a href=/tags/dottrace/ class=tags><span class=name>DotTrace</span>
<sup class=num>1</sup>
</a><a href=/tags/dynamic/ class=tags><span class=name>Dynamic</span>
<sup class=num>1</sup>
</a><a href=/tags/dynamic-proxy/ class=tags><span class=name>Dynamic Proxy</span>
<sup class=num>1</sup>
</a><a href=/tags/echarts/ class=tags><span class=name>ECharts</span>
<sup class=num>1</sup>
</a><a href=/tags/efcore/ class=tags><span class=name>EFCore</span>
<sup class=num>1</sup>
</a><a href=/tags/es6/ class=tags><span class=name>ES6</span>
<sup class=num>1</sup>
</a><a href=/tags/eventbus/ class=tags><span class=name>EventBus</span>
<sup class=num>1</sup>
</a><a href=/tags/excel/ class=tags><span class=name>Excel</span>
<sup class=num>1</sup>
</a><a href=/tags/flv/ class=tags><span class=name>FLV</span>
<sup class=num>1</sup>
</a><a href=/tags/fody/ class=tags><span class=name>Fody</span>
<sup class=num>1</sup>
</a><a href=/tags/form/ class=tags><span class=name>Form</span>
<sup class=num>1</sup>
</a><a href=/tags/fp/ class=tags><span class=name>FP</span>
<sup class=num>1</sup>
</a><a href=/tags/function-calling/ class=tags><span class=name>Function Calling</span>
<sup class=num>1</sup>
</a><a href=/tags/gdi+/ class=tags><span class=name>GDI+</span>
<sup class=num>1</sup>
</a><a href=/tags/gephi/ class=tags><span class=name>Gephi</span>
<sup class=num>1</sup>
</a><a href=/tags/gpt/ class=tags><span class=name>GPT</span>
<sup class=num>1</sup>
</a><a href=/tags/gpts/ class=tags><span class=name>GPTs</span>
<sup class=num>1</sup>
</a><a href=/tags/grafana/ class=tags><span class=name>Grafana</span>
<sup class=num>1</sup>
</a><a href=/tags/hangfire/ class=tags><span class=name>Hangfire</span>
<sup class=num>1</sup>
</a><a href=/tags/hashset/ class=tags><span class=name>HashSet</span>
<sup class=num>1</sup>
</a><a href=/tags/hls/ class=tags><span class=name>HLS</span>
<sup class=num>1</sup>
</a><a href=/tags/https/ class=tags><span class=name>HTTPS</span>
<sup class=num>1</sup>
</a><a href=/tags/hyperlog/ class=tags><span class=name>Hyperlog</span>
<sup class=num>1</sup>
</a><a href=/tags/ide/ class=tags><span class=name>IDE</span>
<sup class=num>1</sup>
</a><a href=/tags/importlib/ class=tags><span class=name>Importlib</span>
<sup class=num>1</sup>
</a><a href=/tags/jaeger/ class=tags><span class=name>Jaeger</span>
<sup class=num>1</sup>
</a><a href=/tags/java/ class=tags><span class=name>Java</span>
<sup class=num>1</sup>
</a><a href=/tags/jetbrain/ class=tags><span class=name>JetBrain</span>
<sup class=num>1</sup>
</a><a href=/tags/jexus/ class=tags><span class=name>Jexus</span>
<sup class=num>1</sup>
</a><a href=/tags/js/ class=tags><span class=name>JS</span>
<sup class=num>1</sup>
</a><a href=/tags/jsdelivr/ class=tags><span class=name>JsDelivr</span>
<sup class=num>1</sup>
</a><a href=/tags/json/ class=tags><span class=name>JSON</span>
<sup class=num>1</sup>
</a><a href=/tags/jsonp/ class=tags><span class=name>JSONP</span>
<sup class=num>1</sup>
</a><a href=/tags/jupyter/ class=tags><span class=name>Jupyter</span>
<sup class=num>1</sup>
</a><a href=/tags/jwt/ class=tags><span class=name>JWT</span>
<sup class=num>1</sup>
</a><a href=/tags/k-means/ class=tags><span class=name>K-Means</span>
<sup class=num>1</sup>
</a><a href=/tags/keycloak/ class=tags><span class=name>Keycloak</span>
<sup class=num>1</sup>
</a><a href=/tags/langchain/ class=tags><span class=name>LangChain</span>
<sup class=num>1</sup>
</a><a href=/tags/lazyload/ class=tags><span class=name>LazyLoad</span>
<sup class=num>1</sup>
</a><a href=/tags/ldap/ class=tags><span class=name>LDAP</span>
<sup class=num>1</sup>
</a><a href=/tags/lfs/ class=tags><span class=name>LFS</span>
<sup class=num>1</sup>
</a><a href=/tags/libusbdotnet/ class=tags><span class=name>LibUsbDotNet</span>
<sup class=num>1</sup>
</a><a href=/tags/linq/ class=tags><span class=name>Linq</span>
<sup class=num>1</sup>
</a><a href=/tags/liquid/ class=tags><span class=name>Liquid</span>
<sup class=num>1</sup>
</a><a href=/tags/llama.cpp/ class=tags><span class=name>Llama.cpp</span>
<sup class=num>1</sup>
</a><a href=/tags/logger/ class=tags><span class=name>Logger</span>
<sup class=num>1</sup>
</a><a href=/tags/love2d/ class=tags><span class=name>Love2D</span>
<sup class=num>1</sup>
</a><a href=/tags/mapreduce/ class=tags><span class=name>MapReduce</span>
<sup class=num>1</sup>
</a><a href=/tags/markdown/ class=tags><span class=name>Markdown</span>
<sup class=num>1</sup>
</a><a href=/tags/matplotlib/ class=tags><span class=name>Matplotlib</span>
<sup class=num>1</sup>
</a><a href=/tags/mcp/ class=tags><span class=name>MCP</span>
<sup class=num>1</sup>
</a><a href=/tags/mecanim/ class=tags><span class=name>Mecanim</span>
<sup class=num>1</sup>
</a><a href=/tags/milvus/ class=tags><span class=name>Milvus</span>
<sup class=num>1</sup>
</a><a href=/tags/mmd/ class=tags><span class=name>MMD</span>
<sup class=num>1</sup>
</a><a href=/tags/moq/ class=tags><span class=name>Moq</span>
<sup class=num>1</sup>
</a><a href=/tags/msbuild/ class=tags><span class=name>MSBuild</span>
<sup class=num>1</sup>
</a><a href=/tags/mvc/ class=tags><span class=name>MVC</span>
<sup class=num>1</sup>
</a><a href=/tags/mvvm/ class=tags><span class=name>MVVM</span>
<sup class=num>1</sup>
</a><a href=/tags/nlog/ class=tags><span class=name>NLog</span>
<sup class=num>1</sup>
</a><a href=/tags/obj/ class=tags><span class=name>OBJ</span>
<sup class=num>1</sup>
</a><a href=/tags/openai/ class=tags><span class=name>OpenAI</span>
<sup class=num>1</sup>
</a><a href=/tags/opentelemetry/ class=tags><span class=name>OpenTelemetry</span>
<sup class=num>1</sup>
</a><a href=/tags/oracle/ class=tags><span class=name>Oracle</span>
<sup class=num>1</sup>
</a><a href=/tags/orm/ class=tags><span class=name>ORM</span>
<sup class=num>1</sup>
</a><a href=/tags/pg_jieba/ class=tags><span class=name>Pg_jieba</span>
<sup class=num>1</sup>
</a><a href=/tags/pgvector/ class=tags><span class=name>Pgvector</span>
<sup class=num>1</sup>
</a><a href=/tags/pl/sql/ class=tags><span class=name>PL/SQL</span>
<sup class=num>1</sup>
</a><a href=/tags/polly/ class=tags><span class=name>Polly</span>
<sup class=num>1</sup>
</a><a href=/tags/postgresql/ class=tags><span class=name>PostgreSQL</span>
<sup class=num>1</sup>
</a><a href=/tags/postsharp/ class=tags><span class=name>PostSharp</span>
<sup class=num>1</sup>
</a><a href=/tags/printdocument/ class=tags><span class=name>PrintDocument</span>
<sup class=num>1</sup>
</a><a href=/tags/prometheus/ class=tags><span class=name>Prometheus</span>
<sup class=num>1</sup>
</a><a href=/tags/protobuf/ class=tags><span class=name>Protobuf</span>
<sup class=num>1</sup>
</a><a href=/tags/pwa/ class=tags><span class=name>PWA</span>
<sup class=num>1</sup>
</a><a href=/tags/quartz/ class=tags><span class=name>Quartz</span>
<sup class=num>1</sup>
</a><a href=/tags/queue/ class=tags><span class=name>Queue</span>
<sup class=num>1</sup>
</a><a href=/tags/qwen-7b-chat/ class=tags><span class=name>Qwen-7B-Chat</span>
<sup class=num>1</sup>
</a><a href=/tags/rasa/ class=tags><span class=name>Rasa</span>
<sup class=num>1</sup>
</a><a href=/tags/react/ class=tags><span class=name>React</span>
<sup class=num>1</sup>
</a><a href=/tags/referrer/ class=tags><span class=name>Referrer</span>
<sup class=num>1</sup>
</a><a href=/tags/rerank/ class=tags><span class=name>Rerank</span>
<sup class=num>1</sup>
</a><a href=/tags/retrofit/ class=tags><span class=name>Retrofit</span>
<sup class=num>1</sup>
</a><a href=/tags/rewrite/ class=tags><span class=name>Rewrite</span>
<sup class=num>1</sup>
</a><a href=/tags/rfc/ class=tags><span class=name>RFC</span>
<sup class=num>1</sup>
</a><a href=/tags/rpg/ class=tags><span class=name>RPG</span>
<sup class=num>1</sup>
</a><a href=/tags/rsetful/ class=tags><span class=name>RSETful</span>
<sup class=num>1</sup>
</a><a href=/tags/rtmp/ class=tags><span class=name>RTMP</span>
<sup class=num>1</sup>
</a><a href=/tags/scikit-learn/ class=tags><span class=name>Scikit-Learn</span>
<sup class=num>1</sup>
</a><a href=/tags/script/ class=tags><span class=name>Script</span>
<sup class=num>1</sup>
</a><a href=/tags/semantic-kernel/ class=tags><span class=name>Semantic Kernel</span>
<sup class=num>1</sup>
</a><a href=/tags/server-%E9%85%B1/ class=tags><span class=name>Server 酱</span>
<sup class=num>1</sup>
</a><a href=/tags/shader/ class=tags><span class=name>Shader</span>
<sup class=num>1</sup>
</a><a href=/tags/sklearn/ class=tags><span class=name>Sklearn</span>
<sup class=num>1</sup>
</a><a href=/tags/sonar/ class=tags><span class=name>Sonar</span>
<sup class=num>1</sup>
</a><a href=/tags/sourcetree/ class=tags><span class=name>SourceTree</span>
<sup class=num>1</sup>
</a><a href=/tags/sqlite/ class=tags><span class=name>SQLite</span>
<sup class=num>1</sup>
</a><a href=/tags/ssh-key/ class=tags><span class=name>SSH-Key</span>
<sup class=num>1</sup>
</a><a href=/tags/sublime/ class=tags><span class=name>Sublime</span>
<sup class=num>1</sup>
</a><a href=/tags/svg/ class=tags><span class=name>SVG</span>
<sup class=num>1</sup>
</a><a href=/tags/svn/ class=tags><span class=name>SVN</span>
<sup class=num>1</sup>
</a><a href=/tags/testserver/ class=tags><span class=name>TestServer</span>
<sup class=num>1</sup>
</a><a href=/tags/text2sql/ class=tags><span class=name>Text2SQL</span>
<sup class=num>1</sup>
</a><a href=/tags/thoughtworks/ class=tags><span class=name>ThoughtWorks</span>
<sup class=num>1</sup>
</a><a href=/tags/trace/ class=tags><span class=name>Trace</span>
<sup class=num>1</sup>
</a><a href=/tags/unity/ class=tags><span class=name>Unity</span>
<sup class=num>1</sup>
</a><a href=/tags/usb/ class=tags><span class=name>USB</span>
<sup class=num>1</sup>
</a><a href=/tags/valine/ class=tags><span class=name>Valine</span>
<sup class=num>1</sup>
</a><a href=/tags/visual-studio/ class=tags><span class=name>Visual Studio</span>
<sup class=num>1</sup>
</a><a href=/tags/web-api/ class=tags><span class=name>Web API</span>
<sup class=num>1</sup>
</a><a href=/tags/webassembly/ class=tags><span class=name>WebAssembly</span>
<sup class=num>1</sup>
</a><a href=/tags/webview2/ class=tags><span class=name>WebView2</span>
<sup class=num>1</sup>
</a><a href=/tags/wechat/ class=tags><span class=name>Wechat</span>
<sup class=num>1</sup>
</a><a href=/tags/windows/ class=tags><span class=name>Windows</span>
<sup class=num>1</sup>
</a><a href=/tags/wmi/ class=tags><span class=name>WMI</span>
<sup class=num>1</sup>
</a><a href=/tags/ztree/ class=tags><span class=name>ZTree</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%B8%80%E5%87%BA%E5%A5%BD%E6%88%8F/ class=tags><span class=name>一出好戏</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%B8%83%E7%89%9B/ class=tags><span class=name>七牛</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%B8%89%E4%BD%93/ class=tags><span class=name>三体</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%B8%8A%E4%BC%A0/ class=tags><span class=name>上传</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%B8%8B%E8%BD%BD/ class=tags><span class=name>下载</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%8B%E4%BB%B6/ class=tags><span class=name>事件</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%8C%E7%BB%B4%E7%A0%81/ class=tags><span class=name>二维码</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%91%E5%8E%9F%E7%94%9F/ class=tags><span class=name>云原生</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%91%E9%9F%B3%E4%B9%90/ class=tags><span class=name>云音乐</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%A4%E4%BA%92/ class=tags><span class=name>交互</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%B2%E6%83%85/ class=tags><span class=name>亲情</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD/ class=tags><span class=name>人工智能</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%BA%E8%84%B8%E5%88%86%E7%B1%BB/ class=tags><span class=name>人脸分类</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BA%BA%E8%84%B8%E6%A3%80%E6%B5%8B/ class=tags><span class=name>人脸检测</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BB%99%E5%89%91%E5%A5%87%E4%BE%A0%E4%BC%A0/ class=tags><span class=name>仙剑奇侠传</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BB%A3%E7%A0%81%E8%A7%A3%E9%87%8A%E5%99%A8/ class=tags><span class=name>代码解释器</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BB%B7%E5%80%BC/ class=tags><span class=name>价值</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BC%98%E5%8C%96/ class=tags><span class=name>优化</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BD%8E%E4%BB%A3%E7%A0%81/ class=tags><span class=name>低代码</span>
<sup class=num>1</sup>
</a><a href=/tags/%E4%BD%90%E8%97%A4%E5%81%A5/ class=tags><span class=name>佐藤健</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%81%A5%E5%BA%B7%E6%A3%80%E6%9F%A5/ class=tags><span class=name>健康检查</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%81%A5%E5%BA%B7%E7%A0%81/ class=tags><span class=name>健康码</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%85%A8%E6%96%87%E6%A3%80%E7%B4%A2/ class=tags><span class=name>全文检索</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%85%A8%E6%99%BA%E8%B4%A4/ class=tags><span class=name>全智贤</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%85%AB%E5%8D%A6/ class=tags><span class=name>八卦</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%85%AC%E4%BC%97%E5%8F%B7/ class=tags><span class=name>公众号</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%85%B3%E5%8D%A1%E7%B3%BB%E7%BB%9F/ class=tags><span class=name>关卡系统</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%87%BD%E6%95%B0%E5%BC%8F%E7%BC%96%E7%A8%8B/ class=tags><span class=name>函数式编程</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%88%86%E9%A1%B5/ class=tags><span class=name>分页</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%88%AB%E7%A6%BB/ class=tags><span class=name>别离</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%88%BA%E5%AE%A2%E4%BF%A1%E6%9D%A1/ class=tags><span class=name>刺客信条</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%89%8D%E4%BB%BB/ class=tags><span class=name>前任</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%89%91%E6%8C%87offer/ class=tags><span class=name>剑指Offer</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8A%A8%E6%80%81%E5%8A%A0%E8%BD%BD/ class=tags><span class=name>动态加载</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8A%A8%E6%80%81%E5%AF%BC%E5%85%A5/ class=tags><span class=name>动态导入</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8A%A8%E7%94%BB/ class=tags><span class=name>动画</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8D%83%E5%AF%BB%E5%B0%8F%E5%A7%90/ class=tags><span class=name>千寻小姐</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8D%8A%E6%B3%BD%E7%9B%B4%E6%A0%91/ class=tags><span class=name>半泽直树</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8D%95%E4%BD%8D/ class=tags><span class=name>单位</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8D%95%E5%85%83%E6%B5%8B%E8%AF%95/ class=tags><span class=name>单元测试</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8D%95%E6%9C%BA%E6%B8%B8%E6%88%8F/ class=tags><span class=name>单机游戏</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8D%B0%E5%BA%A6/ class=tags><span class=name>印度</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8F%82%E5%B7%AE/ class=tags><span class=name>参差</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8F%8C%E5%8D%81%E4%B8%80/ class=tags><span class=name>双十一</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/ class=tags><span class=name>反向代理</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8F%8D%E7%BC%96%E8%AF%91/ class=tags><span class=name>反编译</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%8F%96%E6%B6%88/ class=tags><span class=name>取消</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%90%8C%E6%AD%A5/ class=tags><span class=name>同步</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%91%BD%E4%BB%A4/ class=tags><span class=name>命令</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%92%8C%E5%B9%B3/ class=tags><span class=name>和平</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%93%8D%E5%BA%94%E5%BC%8F/ class=tags><span class=name>响应式</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%93%AA%E5%90%92/ class=tags><span class=name>哪吒</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%9B%9B%E6%9C%88/ class=tags><span class=name>四月</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%9B%9E%E5%AE%B6/ class=tags><span class=name>回家</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%9B%9E%E5%BF%86/ class=tags><span class=name>回忆</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%9B%9E%E9%A1%BE/ class=tags><span class=name>回顾</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%9B%9E%E9%A6%96/ class=tags><span class=name>回首</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%9B%BE%E5%BA%8A/ class=tags><span class=name>图床</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%9B%BE%E5%BD%A2%E5%AD%A6/ class=tags><span class=name>图形学</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%9C%B0%E5%9B%BE/ class=tags><span class=name>地图</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A1%94%E9%98%B2/ class=tags><span class=name>塔防</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A3%81%E7%BA%B8/ class=tags><span class=name>壁纸</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A4%87%E5%BF%98/ class=tags><span class=name>备忘</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A4%8F%E7%9B%AE%E6%BC%B1%E7%9F%B3/ class=tags><span class=name>夏目漱石</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A4%95%E9%9B%BE%E8%8A%B1%E5%9B%AD/ class=tags><span class=name>夕雾花园</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A4%9A%E7%A7%9F%E6%88%B7/ class=tags><span class=name>多租户</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A4%A7%E6%8A%A4%E6%B3%95/ class=tags><span class=name>大护法</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/ class=tags><span class=name>大数据</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A4%A7%E6%A8%A1%E5%9E%8B/ class=tags><span class=name>大模型</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A5%87%E6%8A%80%E6%B7%AB%E5%B7%A7/ class=tags><span class=name>奇技淫巧</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%A7%94%E6%89%98/ class=tags><span class=name>委托</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%AD%A4%E7%8B%AC/ class=tags><span class=name>孤独</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%AE%A1%E8%AE%A1/ class=tags><span class=name>审计</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%AE%AB%E5%B4%8E%E9%AA%8F/ class=tags><span class=name>宫崎骏</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%AF%B9%E8%B1%A1%E6%B1%A0/ class=tags><span class=name>对象池</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%B0%81%E7%A5%9E/ class=tags><span class=name>封神</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%B0%8F%E7%88%B1%E5%90%8C%E5%AD%A6/ class=tags><span class=name>小爱同学</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%B1%95%E6%9C%9B/ class=tags><span class=name>展望</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%B9%B3%E5%87%A1/ class=tags><span class=name>平凡</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%B9%B4%E5%8D%8E/ class=tags><span class=name>年华</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%B9%B4%E5%BA%A6/ class=tags><span class=name>年度</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%B9%B6%E5%8F%91/ class=tags><span class=name>并发</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%BB%BA%E7%AD%91/ class=tags><span class=name>建筑</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%BC%80%E6%BA%90/ class=tags><span class=name>开源</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%BC%95%E6%93%8E/ class=tags><span class=name>引擎</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%BE%AE%E4%BF%A1/ class=tags><span class=name>微信</span>
<sup class=num>1</sup>
</a><a href=/tags/%E5%BF%83%E6%83%85/ class=tags><span class=name>心情</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%80%9D%E7%BB%B4/ class=tags><span class=name>思维</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%80%A7%E8%83%BD/ class=tags><span class=name>性能</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%87%92%E5%8A%A0%E8%BD%BD/ class=tags><span class=name>懒加载</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%88%91%E6%98%AF%E7%8C%AB/ class=tags><span class=name>我是猫</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%89%A9%E5%B1%95%E6%96%B9%E6%B3%95/ class=tags><span class=name>扩展方法</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%8A%80%E6%9C%AF%E6%80%9D%E8%80%83/ class=tags><span class=name>技术思考</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%8B%96%E6%8B%BD/ class=tags><span class=name>拖拽</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%8E%A2%E7%B4%A2/ class=tags><span class=name>探索</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%8E%A8%E8%8D%90/ class=tags><span class=name>推荐</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%8F%90%E7%BA%B2/ class=tags><span class=name>提纲</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%8F%92%E4%BB%B6%E5%8C%96/ class=tags><span class=name>插件化</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%95%B0%E5%AD%97/ class=tags><span class=name>数字</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%95%B0%E6%8D%AE/ class=tags><span class=name>数据</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%95%B0%E6%8D%AE%E4%BA%A4%E6%8D%A2/ class=tags><span class=name>数据交换</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%96%87%E4%BB%B6/ class=tags><span class=name>文件</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/ class=tags><span class=name>文本分类</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%96%87%E6%A1%A3/ class=tags><span class=name>文档</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%97%A0%E9%97%AE%E8%A5%BF%E4%B8%9C/ class=tags><span class=name>无问西东</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%97%A5%E5%89%A7/ class=tags><span class=name>日剧</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%97%A5%E5%B8%B8/ class=tags><span class=name>日常</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%97%A5%E6%9C%AC/ class=tags><span class=name>日本</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%97%A5%E6%9C%AC%E6%96%87%E5%AD%A6/ class=tags><span class=name>日本文学</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%97%B6%E5%8C%BA/ class=tags><span class=name>时区</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85/ class=tags><span class=name>智能家居</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%9C%89%E6%9D%91%E6%9E%B6%E7%BA%AF/ class=tags><span class=name>有村架纯</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%9C%8D%E5%8A%A1/ class=tags><span class=name>服务</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%9C%8D%E5%8A%A1%E7%BC%96%E6%8E%92/ class=tags><span class=name>服务编排</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%9C%9D%E5%9C%A3/ class=tags><span class=name>朝圣</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/ class=tags><span class=name>朴素贝叶斯</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/ class=tags><span class=name>机器学习</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%9F%A5%E8%AF%A2/ class=tags><span class=name>查询</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%A0%87%E6%B3%A8/ class=tags><span class=name>标注</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%A0%A1%E9%AA%8C/ class=tags><span class=name>校验</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%A0%BC%E5%BC%8F/ class=tags><span class=name>格式</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%A0%BC%E5%BC%8F%E5%8C%96/ class=tags><span class=name>格式化</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%A1%8C%E9%9D%A2/ class=tags><span class=name>桌面</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%A8%A1%E5%9E%8B/ class=tags><span class=name>模型</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%A8%A1%E6%9D%BF/ class=tags><span class=name>模板</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%AF%95%E4%B8%9A/ class=tags><span class=name>毕业</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%AF%95%E4%B8%9A%E5%AD%A3/ class=tags><span class=name>毕业季</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%B2%99%E7%AE%B1/ class=tags><span class=name>沙箱</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%B5%81%E5%AA%92%E4%BD%93/ class=tags><span class=name>流媒体</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%B5%81%E5%BC%8F%E4%BC%A0%E8%BE%93/ class=tags><span class=name>流式传输</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%B5%AA%E5%AE%A2%E5%89%91%E5%BF%83/ class=tags><span class=name>浪客剑心</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%B6%88%E6%81%AF/ class=tags><span class=name>消息</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%B8%B8%E6%88%8F%E5%BC%95%E6%93%8E/ class=tags><span class=name>游戏引擎</span>
<sup class=num>1</sup>
</a><a href=/tags/%E6%B8%B8%E8%AE%B0/ class=tags><span class=name>游记</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%83%AD%E6%90%9C/ class=tags><span class=name>热搜</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%86%B5%E5%A2%9E%E5%AE%9A%E5%BE%8B/ class=tags><span class=name>熵增定律</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%89%88%E6%9C%AC%E6%8E%A7%E5%88%B6/ class=tags><span class=name>版本控制</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%89%88%E6%9D%83/ class=tags><span class=name>版权</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%89%B9%E6%80%A7/ class=tags><span class=name>特性</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%8A%B6%E6%80%81/ class=tags><span class=name>状态</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%8E%B0%E5%AE%9E/ class=tags><span class=name>现实</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%94%9F%E6%AD%BB/ class=tags><span class=name>生死</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%9C%9F%E5%AE%9E/ class=tags><span class=name>真实</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%9F%A5%E8%AF%86%E5%85%B1%E4%BA%AB/ class=tags><span class=name>知识共享</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%9F%AB%E6%83%85/ class=tags><span class=name>矫情</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%A0%94%E5%8F%91/ class=tags><span class=name>研发</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%A1%AC%E4%BB%B6/ class=tags><span class=name>硬件</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%A7%91%E5%B9%BB%E5%B0%8F%E8%AF%B4/ class=tags><span class=name>科幻小说</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%A9%B9%E4%B9%8B%E6%89%89/ class=tags><span class=name>穹之扉</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%A9%BF%E6%90%AD/ class=tags><span class=name>穿搭</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%AB%A5%E8%AF%9D/ class=tags><span class=name>童话</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%AD%BE%E5%90%8D/ class=tags><span class=name>签名</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%AE%A1%E9%81%93/ class=tags><span class=name>管道</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%B1%B3%E8%8A%B1%E4%B9%8B%E5%91%B3/ class=tags><span class=name>米花之味</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%BC%96%E8%AF%91/ class=tags><span class=name>编译</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%BD%91%E5%85%B3/ class=tags><span class=name>网关</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%BD%91%E6%98%93/ class=tags><span class=name>网易</span>
<sup class=num>1</sup>
</a><a href=/tags/%E7%BE%8E%E6%9C%AF/ class=tags><span class=name>美术</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%81%9A%E7%B1%BB/ class=tags><span class=name>聚类</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%84%9A%E6%9C%AC/ class=tags><span class=name>脚本</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%84%9A%E6%9C%AC%E8%AF%AD%E8%A8%80/ class=tags><span class=name>脚本语言</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/ class=tags><span class=name>自动化</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%87%AA%E6%88%91%E5%92%8C%E8%A7%A3/ class=tags><span class=name>自我和解</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%8B%8F%E8%BD%BC/ class=tags><span class=name>苏轼</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%99%9A%E6%8B%9F%E6%91%87%E6%9D%86/ class=tags><span class=name>虚拟摇杆</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%9B%8B%E7%82%92%E9%A5%AD/ class=tags><span class=name>蛋炒饭</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%A1%8C%E4%B8%9A/ class=tags><span class=name>行业</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%A1%A8%E5%8D%95/ class=tags><span class=name>表单</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%A1%A8%E8%BE%BE%E5%BC%8F%E6%A0%91/ class=tags><span class=name>表达式树</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%A3%85%E9%A5%B0%E5%99%A8/ class=tags><span class=name>装饰器</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%A5%BF%E6%BC%82/ class=tags><span class=name>西漂</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AE%AD%E7%BB%83/ class=tags><span class=name>训练</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AE%B0%E5%BD%95/ class=tags><span class=name>记录</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AE%BF%E9%97%AE%E9%87%8F/ class=tags><span class=name>访问量</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AF%81%E4%B9%A6/ class=tags><span class=name>证书</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AF%84%E8%AE%BA/ class=tags><span class=name>评论</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AF%8D%E4%BA%91/ class=tags><span class=name>词云</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AF%97%E4%BA%BA/ class=tags><span class=name>诗人</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AF%AD%E6%B3%95/ class=tags><span class=name>语法</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AF%AD%E8%A8%80/ class=tags><span class=name>语言</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AF%B7%E8%AE%B0%E4%BD%8F%E6%88%91/ class=tags><span class=name>请记住我</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%AF%BB%E5%86%99%E5%88%86%E7%A6%BB/ class=tags><span class=name>读写分离</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%B0%83%E4%BC%98/ class=tags><span class=name>调优</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%B0%83%E8%AF%95/ class=tags><span class=name>调试</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/ class=tags><span class=name>负载均衡</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%B4%AA%E5%90%83%E8%9B%87/ class=tags><span class=name>贪吃蛇</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%B4%BE%E7%BB%B4%E6%96%AF/ class=tags><span class=name>贾维斯</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%B5%84%E6%BA%90%E6%8F%90%E5%8F%96/ class=tags><span class=name>资源提取</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%B5%B0%E8%B5%B0%E5%81%9C%E5%81%9C/ class=tags><span class=name>走走停停</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%B7%AF%E7%94%B1/ class=tags><span class=name>路由</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%BD%AC%E7%9B%98/ class=tags><span class=name>转盘</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%BD%AF%E4%BB%B6/ class=tags><span class=name>软件</span>
<sup class=num>1</sup>
</a><a href=/tags/%E8%BF%81%E7%A7%BB/ class=tags><span class=name>迁移</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%82%AA%E4%B8%8D%E5%8E%8B%E6%AD%A3/ class=tags><span class=name>邪不压正</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%83%A8%E7%BD%B2/ class=tags><span class=name>部署</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83/ class=tags><span class=name>配置中心</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%85%8D%E8%BD%BD/ class=tags><span class=name>配载</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%95%BF%E5%AE%89/ class=tags><span class=name>长安</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%95%BF%E5%AE%89%E5%8D%81%E4%BA%8C%E6%97%B6%E8%BE%B0/ class=tags><span class=name>长安十二时辰</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%95%BF%E6%88%AA%E5%9B%BE/ class=tags><span class=name>长截图</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%98%B2%E7%96%AB/ class=tags><span class=name>防疫</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%98%BF%E9%87%8C/ class=tags><span class=name>阿里</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%99%90%E6%B5%81/ class=tags><span class=name>限流</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%9B%86%E6%88%90%E6%B5%8B%E8%AF%95/ class=tags><span class=name>集成测试</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%9B%86%E7%BE%A4/ class=tags><span class=name>集群</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%9C%8D%E9%87%91/ class=tags><span class=name>霍金</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%9D%92%E6%98%A5/ class=tags><span class=name>青春</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%9D%99%E6%80%81%E7%BC%96%E7%BB%87/ class=tags><span class=name>静态编织</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%9F%A9%E5%AF%92/ class=tags><span class=name>韩寒</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%A2%86%E5%9F%9F%E4%BA%8B%E4%BB%B6/ class=tags><span class=name>领域事件</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%A9%AC%E5%B0%94%E5%85%8B%E6%96%AF/ class=tags><span class=name>马尔克斯</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%AA%8C%E8%AF%81/ class=tags><span class=name>验证</span>
<sup class=num>1</sup>
</a><a href=/tags/%E9%AC%BC%E6%BB%85%E3%81%AE%E5%88%83/ class=tags><span class=name>鬼滅の刃</span>
<sup class=num>1</sup></a></div><a href=/tags class=more-tags>查看全部</a></div><div class="site-data s-card weidgets"><div class=title><i class="iconfont icon-chart"></i>
<span class=title-name>站点数据</span></div><div class=all-data><div class=data-item><span class=name><i class="iconfont icon-article"></i>
文章总数
</span><span class=num>277 篇</span></div><div class=data-item><span class=name><i class="iconfont icon-date"></i>
建站天数
</span><span class=num>3753 天</span></div><div class=data-item><span class=name><i class="iconfont icon-visibility"></i>
总访问量
</span><span class=num id=busuanzi_value_site_pv>0</span></div><div class=data-item><span class=name><i class="iconfont icon-account"></i>
总访客数
</span><span class=num id=busuanzi_value_site_uv>0</span></div></div></div></div></aside><style>.main-aside{padding-left:1rem;display:flex;flex-direction:column;animation:fade-up .6s .3s backwards;.weidgets { padding: 18px; margin-bottom: 1rem; :deep(.title) { margin-bottom: 12px; font-weight: bold; display: flex; align-items: center; opacity: 0.75; .iconfont { opacity: 0.6; margin-right: 6px; } .title-name { opacity: 0.8; } } } .sticky { position: sticky; top: calc(60px + 1rem); .weidgets { animation: fade-up 0.6s 0.4s backwards; &:last-child { margin-bottom: 0; } } }}</style></div></div></main><div class=footer-link><div class=footer-bar><span class=site-title>元视角</span>
<span class=site-desc>纵有疾风起，人生不言弃</span>
<a href=/ class=to-home>了解更多</a></div><div class=footer-social><a href=https://github.com/qinyuanpei target=_blank class=social-link><i class="iconfont icon-github"></i>
</a><a href=mailto:qinyuanpei@163.com target=_blank class=social-link><i class="iconfont icon-email"></i>
</a><a href=/index.xml target=_blank class=social-link><i class="iconfont icon-rss"></i></a><div class=logo title=返回顶部 onclick='window.scrollTo({top:0,behavior:"smooth"})'><img src=/images/icons8-stellar-128.png alt=author class=author></div><a href=https://weibo.com/1278609231 target=_blank class=social-link><i class="iconfont icon-weibo"></i>
</a><a href=https://www.douban.com/people/60029335/ target=_blank class=social-link><i class="iconfont icon-douban"></i>
</a><a href=https://www.zhihu.com/people/qinyuanpei target=_blank class=social-link><i class="iconfont icon-zhihu"></i></a></div><div class=footer-sitemap><div class=sitemap-item><span class=title>博客</span><div class=links><a href=/ class=link-text>近期文章
</a><a href=/categories class=link-text>全部分类
</a><a href=/tags class=link-text>全部标签
</a><a href=/archives class=link-text>文章归档</a></div></div><div class=sitemap-item><span class=title>项目</span><div class=links><a href=https://github.com/qinyuanpei/mcp-server-weibo target=_blank class=link-text>mcp-server-weibo</a></div></div><div class=sitemap-item><span class=title>专栏</span><div class=links><a href=https://blog.csdn.net/qinyuanpei/category_10852603.html target=_blank class=link-text>.NET 源代码探案系列
</a><a href=https://blog.csdn.net/qinyuanpei/category_7444699.html target=_blank class=link-text>Python 数据挖掘系列
</a><a href=https://blog.csdn.net/qinyuanpei/category_11484903.html target=_blank class=link-text>分布式丛林探险系列
</a><a href=https://blog.csdn.net/qinyuanpei/category_1708629.html target=_blank class=link-text>Unity3D 游戏开发系列</a></div></div><div class=sitemap-item><span class=title>页面</span><div class=links><a href=/comments class=link-text>留言板
</a><a href=/books class=link-text>读书
</a><a href=/movies class=link-text>观影
</a><a href=/musics class=link-text>听歌</a></div></div><div class=sitemap-item><span class=title>友情链接</span><div class=links><a href=https://blog.zhheo.com/ class=link-text>张洪
</a><a href=https://blog.zhheo.com/ class=link-text>张洪
</a><a href=https://blog.zhheo.com/ class=link-text>张洪
</a><a href=https://blog.zhheo.com/ class=link-text>更多</a></div></div></div></div><footer id=main-footer class=main-footer><div class=footer-content><div class=footer-copyright><span class=time data-v-6001e979>@ 2014 - 2025 By </span><a href=https://www.imsyy.top class="author link" target=_blank>飞鸿踏雪</a></div><div class=meta><a class="power link" href=https://vitepress.dev/ target=_blank><span class=by>Powered by</span>
<span class=name>Hugo</span>
</a><a class="theme link" href=/pages/theme><span class=name>主题</span>
</a><a class="rss link" href=https://blog.imsyy.top/rss.xml target=_blank><i class="iconfont icon-rss"></i>
<span class=name data-v-6001e979>订阅</span>
</a><a class="cc link" href=https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh-hans target=_blank><i class="iconfont icon-line"></i>
<i class="iconfont icon-by-line"></i>
<i class="iconfont icon-nc-line"></i><i class="iconfont icon-nd-line"></i></a></div></div></footer><script type=module src=/scripts/main.js></script><script src=https://cdn.jsdelivr.net/npm/fuse.js@7.1.0></script><script src=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.11.1/build/highlight.min.js></script><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.11.1/build/styles/github-dark.min.css media="(prefers-color-scheme: dark)"><link rel=stylesheet href=https://cdn.jsdelivr.net/gh/highlightjs/cdn-release@11.11.1/build/styles/github.min.css media="(prefers-color-scheme: light)"><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.css><script src=https://cdn.jsdelivr.net/npm/@fancyapps/ui@5.0/dist/fancybox/fancybox.umd.js></script></body></html>