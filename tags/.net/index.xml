<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>.NET on 元视角</title><link>http://example.org/tags/.net/</link><description>Recent content in .NET on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Thu, 15 Sep 2022 12:52:10 +0000</lastBuildDate><atom:link href="http://example.org/tags/.net/index.xml" rel="self" type="application/rss+xml"/><item><title>.NET 进程内队列 Channel 的入门与应用</title><link>http://example.org/posts/getting-started-with-the-.net-in-process-queue-channel/</link><pubDate>Thu, 15 Sep 2022 12:52:10 +0000</pubDate><guid>http://example.org/posts/getting-started-with-the-.net-in-process-queue-channel/</guid><description>最近，博主为 FakeRPC 增加了 WebSocket 协议的支持。这意味着，我们可以借助其全双工通信的特性，在一个连接请求内发送多条数据。FakeRPC 目前最大的遗憾是，建立在 HTTP 协议上而不是 TCP/IP 协议上。因此，考虑 WebSocket 协议，更多的是为了验证 JSON-RPC 的可行性，以及为接下来的要支持的 TCP/IP 协议铺路。也许，你从未意识到这些概念间千丝万缕的联系，可如果我们把每一次 RPC 调用都理解为一组消息，你是不是就能更加深刻地理解 RPC 这个稍显古老的事物了呢？在编写 FakeRPC 的过程中，我使用了 .NET 中的全新数据结构 Channel 来实现消息的转发。以服务端为例，每一个 RPC 请求经过 CallInvoker 处理以后，作为 RPC 响应的结果其实并不是立即发回给客户端，而是通过一个后台线程从 Channel 取出消息再发回客户端。 那么，博主为什么要舍近求远呢？我希望，这篇文章可以告诉你答案。
Channel 入门 Channel 是微软在 .NET Core 3.0 以后推出的新的集合类型，该类型位于 System.Threading.Channels 命名空间下，具有异步 API 、高性能、线程安全等等的特点。目前，Channel 最主要的应用场景是生产者-消费者模型。如下图所示，生产者负责向队列中写入数据，消费者负责从队列中读出数据。在此基础上，通过增加生产者或者消费者的数目，对这个模型做进一步的扩展。我们平时使用到的 RabbitMQ 或者 Kafka，都可以认为是生产者-消费者模型在特定领域内的一种应用，甚至于我们还能从中读出一点广义上的读写分离的味道。
生产者-消费者模型示意图罗曼·罗兰曾说过，世界上只有一种真正的英雄主义，那就是在认清生活的真相后，依然热爱生活。此时此刻，看着眼前的这幅示意图若有所思，你也许会想到下面的做法：
class Producer&amp;lt;T&amp;gt; { private readonly Queue&amp;lt;T&amp;gt; _queue; public Producer(Queue&amp;lt;T&amp;gt; queue) { _queue = queue; } } class Consumer&amp;lt;T&amp;gt; { private readonly Queue&amp;lt;T&amp;gt; _queue; public Consumer(Queue&amp;lt;T&amp;gt; queue) { _queue = queue; } } 我承认，这个思路理论上是没有问题的，可惜实际操作起来槽点满满。譬如，生产者应该只负责写，消费者应该只负责读，可当你亲手把一个队列传递给它们的时候，想要保持这种职责上的纯粹属实是件困难的事情，更不必说，在使用队列的过程中，生产者会有队列“满”的忧虑，消费者会有队列“空”的烦恼，如果再考虑多个生产者、多个消费者、多线程/锁等等的因素，显然，这并不是一个简单的问题。为了解决这个问题，微软先后增加了 BlockingCollection 和 BufferBlock 两种数据结构，这里以前者为例，下面是一个典型的生产者-消费者模型：</description></item><item><title>gRPC 流式传输极简入门指南</title><link>http://example.org/posts/grpc-streaming-transmission-minimalist-guide/</link><pubDate>Fri, 18 Feb 2022 09:34:36 +0000</pubDate><guid>http://example.org/posts/grpc-streaming-transmission-minimalist-guide/</guid><description>最近一直在研究 gRPC 的 ServerReflection，顾名思义，这是 gRPC 里提供的反射接口，当你需要获取某个接口的描述信息，或者是希望动态调用 gRPC 的时候，这一切就会变得非常有用，如果你经常使用 gRPC UI 这款工具来调试 gRPC 接口，那么，你一定会注意到一件事情，即它要求服务端必须支持 ServerReflection API，而这一点在 ASP.NET Core 中已经得到支持，对此感兴趣的朋友可以参考官方文档。当然，这并不是我想表达的重点(我就知道)。重点是什么呢？在使用 ServerReflection API 的过程中，我发现它采用了 gRPC 双向流的方式来进行交互，在过去的日子里，我研究过诸如 WebSocket、Server-Sent Events 等等服务器推送的技术，我意识到这是一个非常接近的技术，所以，今天这篇文章，我们来一起聊聊 gRPC 中的流式传输。
从 HTTP/2 说起 首先，我想说，流式传输并不是一个新的概念，这一切就好像，即使你从来没有听过流媒体的概念，可这并不妨碍你追剧、刷短视频，隐隐然有种“不识庐山真面目，只缘身在此山中”的感觉。随着网络带宽和硬件水平的不断提升，越来越多的云服务变得像水、电、天然气一样寻常，以此作喻，流式传输，就像你打开水龙头，此时，水就会源源不断地流出来，并且可以做到随用随取。因此，流式传输实际上就是指通过网络传输媒体，例如音频、视频等的技术统称，服务器可以连续地、实时地向客户端发送数据，而客户端不必等所有数据发送完就可以访问这些数据。按照实现方式的不同，流式传输可以分为 实时流式传输 和 顺序流式传输 两种，前者通常指RTP/RTCP，典型的场景是直播；后者通常是指由 Nginx、Apache 等提供支持的顺序下载。
HTTP/1.1 vs HTTP/2如果你对 HTTP/2 有一定了解的话，就会知道它最为人所知的特性是多路复用。在 HTTP/1.1 的时代，同一个时刻只能对一个请求进行处理或者响应，换句话说，下一个请求必须要等当前请求处理完才能继续进行，与此同时，浏览器为了更快地加载页面资源，对同一个域名下的请求并发数进行了限制，所以，你会注意到一个有趣的现象，部分网站会使用多个 CDN 加速的域名，而这正是为了规避浏览器的这一限制，HTTP/1.1 时代，可以称为“半双工模式”。到了 HTTP/2 的时代，多路复用的特性让一次同时处理多个请求成为了现实，并且同一个 TCP 通道中的请求不分先后、不会阻塞，是真正的“全双工通信”。一个和本文更贴近的概念是流，HTTP/2 中引入了流(Stream) 和 帧(Frame) 的概念，当 TCP 通道建立以后，后续的所有操作都是以流的方式发送的，而二进制帧则是组成流的最小单位，属于协议层上的流式传输。
gRPC 中的流式传输 OK，现在我们正式开始 gRPC 流式传输的话题。首先，对于一个 gRPC 接口而言，它的起源是 Protobuf 定义。所以，一个最为直观的认识是从 Protobuf 定义入手：</description></item><item><title>EFCore 实体命名约定库：EFCore.NamingConventions</title><link>http://example.org/posts/3219639636/</link><pubDate>Thu, 17 Jun 2021 16:37:11 +0000</pubDate><guid>http://example.org/posts/3219639636/</guid><description>在软件开发过程中，数据库永远都是绕不开的一个话题。有时候，我们甚至会因此而获得一个名字——“CURD Boy”。虽然不过是朴实无华的“增删查改”，可隐隐然早已分出了无数的流派。在这些不同的流派中，有的人坚持“我手写我心”，认为手写SQL才是真正的王道，没有读过/写过成百上千行的存储过程，便不足以谈论程序员的人生。而有的人喜欢ORM的清晰、整洁，认为数据库和面向对象存在着天然抗阻，ORM更有利于推进DDD和微服务的落地。相信大家都听说过Java里的SSH框架，从Hibernate到Mybatis再到Spring Data JPA，可以说这种争论一直没有停止过。这里我们不打算讨论这个问题，我们平时使用EF或者EFCore的过程中，作为连接数据库和面向对象两个异世界的桥梁，ORM需要我们来告诉它，实体数据与数据库表字段的映射关系，所以，经常需要通过数据注解或者Fulent API来写各种配置。那么，有没有什么方案可以让我们偷这个懒呢？下面隆重请出本文的主角：EFCore.NamingConventions。
使用方法 EFCore. NamingConventions，目前由一个非官方的组织进行维护，代码托管在 Github 上，100％的开源项目。
如果你希望直接使用它的话，可以直接通过NuGet进行安装：
Install-Package EFCore.NamingConventions 接下来，我们只需要在DbContext的 OnConfiguring()方法中，调用它提供的扩展方法即可：
protected override void OnConfiguring(DbContextOptionsBuilder optionsBuilder) =&amp;gt; optionsBuilder .UseSqlite(&amp;#34;Data Source=Chinook.db&amp;#34;) .UseSnakeCaseNamingConvention(); 或者，你可以使用依赖注入的方式：
services.AddDbContext&amp;lt;ChinookContext&amp;gt;(options =&amp;gt; options.UseSqlite(&amp;#34;Data Source=Chinook.db&amp;#34;) .UseSnakeCaseNamingConvention() ); 这里我以SQLite数据库为例，来展示它的具体使用细节。事实上，它提供了 4 种命名约定的策略：
UseSnakeCaseNamingConvention: FullName -&amp;gt; full_name UseLowerCaseNamingConvention: FullName -&amp;gt; fullname UseCamelCaseNamingConvention: FullName -&amp;gt; fullName UseUpperCaseNamingConvention: FullName -&amp;gt; FULLNAME 简单来说，就是当我们的实体中存在一个属性FullName时，它会告诉EF或者EFCore，这个属性FullName对应的表字段是什么。
虽然，在大多数的场景中，我们都希望属性名称和表字段一致，可你要知道，像Oracle这种对大小写敏感的数据库，特别喜欢自作聪明地帮你全部改成大写。
所以，在上家公司工作的时候，为了兼容Oracle这病态的癖好，公司里有个不成文的规定，那就是：所有实体的属性名称最好都大写。
本来大家用驼峰命名就是为了好认单词，好家伙！这下全部大写了，一眼望过去简直就是灾难，因为没有办法做到“望文生义”，如果那个时候知道这个库的存在，是不是就能解决这个问题了呢？
第一个示例 下面我们以UseSnakeCaseNamingConvention为例，结合SQLite来做一个简单的例子。
首先，我们定义必要的实体，并为DbContext配置实体命名约束规则：
// Album public class Album { public int AlbumId { get; set; } public string Title { get; set; } public int ArtistId { get; set; } public string TenantId { get; set; } } // Artist public class Artist { public int ArtistId { get; set; } public string Name { get; set; } public string TenantId { get; set; } } 接下来，通过迁移命令来生成数据库架构：</description></item><item><title>ASP.NET Core gRPC 集成 Polly 实现优雅重试</title><link>http://example.org/posts/2742255459/</link><pubDate>Mon, 07 Jun 2021 15:19:11 +0000</pubDate><guid>http://example.org/posts/2742255459/</guid><description>在上一篇 博客 中，我们一起探索和实现了gRPC的健康检查。从服务治理的角度来看，健康检查保证的是被调用的服务“健康”或者“可用”。可即使如此，我们依然会遇到，因为网络不稳定等原因而造成的服务调用失败的情形，就如同我们赖以生存的这个真实世界，本身就充满了各种不确定的因素一样，“世间唯一不变的只有变化本身”。不管是面对不稳定的服务，还是面对不确定的人生，任何时候我们都需要有一个 B 计划，甚至我们人生中的一切努力，本质上都是为了多一份自由，一份选择的自由。在微服务的世界里，我们将这种选择称之为“降级(Fallback)”，如果大家有接触过 Hystrix 或者 Polly 这类框架，就会明白我这里的所说的“降级”具体是什么。在众多的“降级”策略中，重试是一种非常朴素的策略，尤其是当你调用一个不稳定的服务的时候。
重试引言 在此之前，博主曾经介绍过 HttpClient 的重试。所以，今天这篇博客我们来聊聊gRPC的客户端重试，因为要构建一个高可用的微服务架构，除了需要高可用的服务提供者，同样还需要高可用的服务消费者。下面，博主将由浅入深地为大家分享 4 种重试方案的实现，除了 官方 内置的方案，基本上都需要搭配 Polly 来使用，所以，到这里你可以理解这篇博客的标题，为什么博主会 毁人不倦 地尝试不同的重试方案，因为每一种方案都有它自身的局限性，博主想要的是一种更优雅的方案。具体来讲，主要有：基于 gRPC RetryPolicy、基于 HttpClientFactory、基于 gRPC 拦截器 以及 基于 CallInvoker 4 种方案。如果大家还有更好的思路，欢迎大家在博客评论区积极留言、参与讨论。
基于 gRPC RetryPolicy 所谓的 gRPC RetryPolicy，其实是指 官方 提供的暂时性故障处理方案，它允许我们在创建GrpcChannel的时候，去指定一个重试策略：
var defaultMethodConfig = new MethodConfig { Names = { MethodName.Default }, RetryPolicy = new RetryPolicy { MaxAttempts = 5, InitialBackoff = TimeSpan.FromSeconds(1), MaxBackoff = TimeSpan.FromSeconds(5), BackoffMultiplier = 1.5, RetryableStatusCodes = { StatusCode.</description></item><item><title>ASP.NET Core gRPC 拦截器的使用技巧分享</title><link>http://example.org/posts/1679688265/</link><pubDate>Wed, 26 May 2021 09:03:35 +0000</pubDate><guid>http://example.org/posts/1679688265/</guid><description>gRPC是微软在.NET Core 及其后续版本中主推的 RPC 框架，它使用 Google 的 Protocol Buffers 作为序列化协议，使用 HTTP/2 作为通信协议，具有跨语言、高性能、双向流式调用等优点。考虑到，接下来要参与的是，一个以gRPC为核心而构建的微服务项目。因此，博主准备调研一下gRPC的相关内容，而首当其冲的，则是从 .NET Core 3.1 开始就有的拦截器，它类似于ASP.NET Core中的过滤器和中间件，体现了一种面向切面编程(AOP)的思想，非常适合在 RPC 服务调用的时候做某种统一处理，譬如参数校验、身份验证、日志记录等等。在今天这篇博客中，博主主要和大家分享的是，利用 .NET Core gRPC 中的拦截器实现日志记录的简单技巧，希望能给大家带来一点启发。
开源、多语言、高性能的 gRPC关于 Interceptor 类 Interceptor类是 gRPC 服务拦截器的基类，它本身是一个抽象类，其中定义了下面的虚方法：
public virtual AsyncClientStreamingCall&amp;lt;TRequest, TResponse&amp;gt; AsyncClientStreamingCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual AsyncDuplexStreamingCall&amp;lt;TRequest, TResponse&amp;gt; AsyncDuplexStreamingCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual AsyncUnaryCall&amp;lt;TResponse&amp;gt; AsyncUnaryCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual TResponse BlockingUnaryCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual Task&amp;lt;TResponse&amp;gt; ClientStreamingServerHandler&amp;lt;TRequest, TResponse&amp;gt;(); public virtual AsyncServerStreamingCall&amp;lt;TResponse&amp;gt; AsyncServerStreamingCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual Task DuplexStreamingServerHandler&amp;lt;TRequest, TResponse&amp;gt;(); public virtual Task ServerStreamingServerHandler&amp;lt;TRequest, TResponse&amp;gt;(); public virtual Task&amp;lt;TResponse&amp;gt; UnaryServerHandler&amp;lt;TRequest, TResponse&amp;gt;(); 整体而言，如果从通信方式上来划分，可以分为：流式调用 和 普通调用；而如果从使用方来划分，则可以分为：客户端 和 服务端。进一步讲的话，针对流式调用，它还分为：&amp;quot;单向流&amp;quot; 和 &amp;ldquo;双向流&amp;quot;。关于这些细节上的差异，大家可以通过 gRPC 的 官方文档 来了解，这里我们给出的是每一种方法对应的用途：</description></item><item><title>从 C# 1.0 到 C# 9.0，历代 C# 语言特性一览</title><link>http://example.org/posts/3918433482/</link><pubDate>Mon, 01 Feb 2021 22:36:47 +0000</pubDate><guid>http://example.org/posts/3918433482/</guid><description>C# 版本历史记录 从 C# 1.0 到 C# 9.0，历代 C# 语言特性一览说明：因为Markdown下维护这样复杂的表格有一点麻烦，故，这里以图片形式展示出来，如后续内容有更新，请点击 这里 访问原始笔记链接。为知笔记 的表格渲染在移动端表现不佳，为了获得更好的阅读体验，请在电脑端访问查看。
C# 版本特性说明 现在是 2021 年，相信 C# 7.0 以前的版本大家都应该没有什么问题，因为像博主这样的 90 后“中年”男人，接触的都是这个版本的 C#。所以，在这里我们主要讲解大家C# 7.0、8.0 以及 9.0 的语法特性。考虑到文章篇幅有限，这里选取的都是博主个人比较喜欢的语法特性，如果这里没有你喜欢的特性，请参考文章末尾的参考链接。如果这里的特性你都不喜欢，请你马上关掉这个网页，愿这个世界：Love &amp;amp; Peace。可能你会感觉到我说话变得小心翼翼起来，因为这个世界上有种叫做“杠精”的生物，当它从我的只言片语里读出那些挫败感的时候，终于有了嘲笑我们这批步入30岁行列的90后的底气，没错，我在最近的博客评论中被读者“嘲讽”了，让暴风雨来得更猛烈一些吧！
C# 7.0 在 C# 7.0 中，我个人比较喜欢的特性主要有以下几个：元组和弃元、更多的 expression-bodied 成员、out 变量、异步 Main 方法、模式匹配 和 引发表达式。
元组和弃元 这个概念乍听起来可能会有一点陌生，其实，按我的理解，这就是增强的元组语法，终于可以摆脱Item1、Item2&amp;hellip;&amp;hellip;啦：
//示例1 (string Alpha, string Beta) namedLetters = (&amp;#34;a&amp;#34;, &amp;#34;b&amp;#34;); Console.WriteLine($&amp;#34;{namedLetters.Alpha}, {namedLetters.Beta}&amp;#34;); //示例2 var alphabetStart = (Alpha: &amp;#34;a&amp;#34;, Beta: &amp;#34;b&amp;#34;); Console.WriteLine($&amp;#34;{alphabetStart.Alpha}, {alphabetStart.Beta}&amp;#34;); //示例3 int count = 5; string label = &amp;#34;Colors used in the map&amp;#34;; var pair = (count, label); Console.</description></item><item><title>基于 Docker 构建 .NET 持续集成环境</title><link>http://example.org/posts/3995512051/</link><pubDate>Tue, 12 Jun 2018 17:53:59 +0000</pubDate><guid>http://example.org/posts/3995512051/</guid><description>最近在考虑将整个项目组的产品，努力向着持续集成(CI)/持续部署(CD)的方向靠拢，因为目前我们仅仅实现了基于 Docker 的自动化部署，而部署包的构建依然依赖于人工打包，而每个版本的测试和部署，基本上都要给所有相关人员发一遍邮件，而写邮件无非是填写版本号和变更历史。身处在这样一个社会化分工逐渐加剧的『摩登时代』，我们唯一的希望就追求技能的多元化，你越是担心有一天会被 AI 所替代，就越是应该去追求灵动与美。这个世界何尝不是一个运行中的大型机器，可恰恰就是这种掺杂了情感的冰冷法则，让我们意识到需要更多的理解和宽容。管理者常常迷信敏捷开发的人月神话，希望人可以像零件一样按部就班，在这场噩梦到来以前，为何不去做一点更有用的事情，让云计算帮我们解放双手。
背景说明 我们的产品，从结构上来讲，分为后端、前端和客户端三个部分，其中，后端提供了从认证到上传、查询和下载等主要的 AP 接口；前端提供了基于后端 API 接口的页面，主要功能是监控和管理；客户端承担了主要的业务交互能力，主要功能是整合常用的硬件资源。从技术上来讲，后端是基于 Spring Cloud 的微服务架构，前端是基于 node.js 的典型前端工具链，而客户端是基于 .NET / Win32 的技术体系。所以，即使我们的客户端是运行在 Window 平台上，我们依然有大量的服务是运行在 Linux 环境下。负责部署的同事不愿意单独再构建一套持续集成(CI)环境，所以我们决定借助 Docker 完成整个持续集成(CI)环境的构建。
构建过程 完成整个项目的构建，需要覆盖到代码编译、单元测试、静态检查、版本发布这四个基本环节，我们整体上使用 Jenkins 作为内部持续集成的平台，这意味着我们只需要在提交代码或者合并代码的时候，触发一个构建指令即可。这里我们考虑通过 Docker 来完成这些工作，一个整体上的设计思路如下图所示：
构建思路MSBuild 首先是 MSBuild，它是我们整个构建流程中最重要的环节，我们平时通过 Visual. Studio 编译一个项目，背后其实就是由 MSBuild 这个构建工具来驱动，而通过 MSBuild 我们定义更多的构建流程，例如执行单元测试、实现 Zip 打包等等的流程。在 Window 平台下我们安装 Visual Studio 后就可以使用 MSBuild ，那么在 Linux 平台下呢？目前， MSBuild 已经被微软开源并托管在 Github 上，大家可以通过这个地址：https://github.com/Microsoft/msbuild来访问。通过阅读 MSBuild 的文档，我们了解到，目前 MSBuild 实际上有三个流向，分别是目前官方主推的 .Net Core 、传统的 .Net Framework以及由 Mono 托管的部分。
.Net Core 中 MSBuild 实际上被集成在 .</description></item><item><title>使用 Mono 打造轻量级的.NET 程序运行时</title><link>http://example.org/posts/907824546/</link><pubDate>Fri, 25 Mar 2016 12:47:58 +0000</pubDate><guid>http://example.org/posts/907824546/</guid><description>&lt;p>在&lt;a href=".">使用 Mono 让.NET 程序跨平台运行&lt;/a>这篇文章中，我们已经对 Mono 以及.NET 程序的运行机制有了初步的理解。今天我想来谈谈&amp;quot;使用 Mono 打造轻量级的.NET 运行时&amp;quot;这样一个话题。为什么我会有这样一种想法呢？因为 Mono 和.NET 都可以执行 IL 代码，所以我用 Mono 来作为.NET 程序的运行时是一个顺理成章的想法。由于.NET 程序需要.NET Framework 提供运行支持，所以当目标设备没有安装.NET Framework 或者.NET Framework 版本不对的时候，我们的程序都无法顺利运行。强迫用户安装.NET 框架无疑会影响用户体验，在 Windows XP 尚未停止服务前，国内软件厂商为了兼容这些用户，通常会选择 C++这类语言来编写原生应用，这就造成了国内.NET 技术长期不被重视的现状。&lt;/p></description></item><item><title>使用 Mono 让.NET 程序跨平台运行</title><link>http://example.org/posts/1836680899/</link><pubDate>Sun, 06 Mar 2016 12:20:09 +0000</pubDate><guid>http://example.org/posts/1836680899/</guid><description>&lt;p>众所周知，Unity3D 引擎凭借着强大的跨平台能力而备受开发者的青睐，在跨平台应用开发渐渐成为主流的今天，具备跨平台开发能力对程序员来说就显得特别重要。传统的针对不同平台进行开发的方式常常让开发者顾此失彼，难以保证应用程序在不同的平台都有着相同的、出色的体验，这种情况下寻找到一种跨平台开发的方式将会为解决这个问题找到一种思路。从目前的开发环境来看，Web 应该是最有可能成为跨平台开发的神兵利器，可是长期以来 Web 开发中前端和后端都有各自不同的工作流，虽然现在出现了前端和后端逐渐融合的趋势，可在博主看来想让 Web 开发变得像传统开发这样简单还需要一定的过渡期。&lt;/p></description></item></channel></rss>