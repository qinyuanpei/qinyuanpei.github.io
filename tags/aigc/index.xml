<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>AIGC on 元视角</title><link>https://qinyuanpei.github.io/tags/aigc/</link><description>Recent content in AIGC on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Thu, 15 Aug 2024 12:52:10 +0000</lastBuildDate><atom:link href="https://qinyuanpei.github.io/tags/aigc/index.xml" rel="self" type="application/rss+xml"/><item><title>浅议 CancellationToken 在前后端协同取消场景中的应用</title><link>https://qinyuanpei.github.io/posts/cancellation-mechanism-cancellationtoken-cooperative-scene/</link><pubDate>Thu, 15 Aug 2024 12:52:10 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/cancellation-mechanism-cancellationtoken-cooperative-scene/</guid><description>两个月前，我写过一篇题为为《关于 ChatGPT 的流式传输，你需要知道的一切》的文章。当时，我主要聚焦于 “流式传输” 这个概念。因此，Server-Sent Events、WebSocket 等技术，便顺理成章地成为了我的写作内容。然而，当我们将视野扩展到整个生成式 AI 领域时，我们会发现 “取消” 是一个非常普遍的业务场景。尽管我曾在这篇文章中提到了 AbortController 和 CancellationToken，但我并不认为我完全解决了当时的问题，即：如何让前、后端的取消动作真正地协同起来？言下之意，我希望前端的 AbortController 发起取消请求以后，后端的 CancellationToken 能够及时感知并响应这一变化。这一切就好比，AI 智能体固然可以通过 “观察” 来感知外部的变化，可当用户决定停止生成的时候，一切都应该戛然而止，无论你是不是为了节省那一点点 token。所以，当两个月前的子弹正中眉心时，我决定继续探讨这个话题。由此，便有了今天这篇稍显多余的博客。
前后端协同取消 我必须承认，在推崇前后端分离的当下，我这个想法难免显得不合时宜。可什么是合时宜呢？在刚刚落幕的巴黎奥运会上，35 岁的 “龙队” 马龙，斩获了个人第 6 枚奥运金牌。对此，这个被誉为 “六边形战士” 的男人表示，“只要心怀热爱，永远都是当打之年”。这是否说明，一切的不合时宜都是自我设限，而年龄不过是个数字。在以往的工作中，我接触的主要是 “Fire and Forget” 这类场景。特别是当一个任务相对短暂时，有没有真正地取消从来都不会成为讨论的重点。直到最近做 Agent 的时候，我发觉这一切其实可以做得更好，即便我的原动力是为了省钱。
async Task Main() { Console.WriteLine(&amp;#34;[HeartBeat] 服务运行中，请按 Ctrl + C 键取消...&amp;#34;); var cts = new CancellationTokenSource(); Console.CancelKeyPress += (sender, e) =&amp;gt; { e.Cancel = true; cts.Cancel(); }; try { await HeartBeatAsync(cts.Token); } catch (OperationCanceledException) { Console.</description></item><item><title>Semantic Kernel 视角下的 Text2SQL 实践与思考</title><link>https://qinyuanpei.github.io/posts/semantic-kernel-driven-text2sql-practice/</link><pubDate>Mon, 15 Jul 2024 20:42:23 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/semantic-kernel-driven-text2sql-practice/</guid><description>《诗经》有言：七月流火，九月授衣，这句话常被用来描绘夏秋交替、天气由热转凉的季节变化。西安的雨季，自六月下旬悄然而至、连绵不绝，不由地令人感慨：古人诚不欺我。或许，七月注定是个多事之“秋”，前有萝卜快跑及其背后的无人驾驶引发热议，后有特朗普在宾夕法尼亚州竞选集会时遇刺，更遑论洞庭湖决口、西二环塌方。杨绛先生说，成长就是学会心平气和地去面对这世界的兵荒马乱，可真正的战争“俄乌冲突”至今已经持续800多天。有时候，我不免怀疑，历史可是被诅咒了的时间？两年前的此时此刻，日本前首相安倍晋三遇刺身亡，我专门写过一篇文章《杂感·七月寄望》 。现在，回想起两人长达19秒的史诗级握手画面，一时间居然有种“一笑泯恩仇”的错觉。因为，从某种意义上来说，他们似乎成为了共患难的“战友”。雍正之于万历，如同特朗普之于肯尼迪，虽时过境迁，而又似曾相识，大概世间万物总逃不出某种循环。最近一个月，从 RAG 到 Agent，再到微软 GraphRAG 的爆火，诸如 Graph、NER、知识图谱等知识点再次被激活。我突然觉得，我需要一篇文章来整理我当下的思绪。
实现 Agent 以后 参照复旦大学的 RAG 综述论文实现 Advance RAG 以后，我开始将目标转向 Agent。一般来说，一个 Agent 至少应该具备三种基本能力：规划(Planning)、记忆(Memory)以及工具使用(Tool Use)，即：Agent = LLM + Planning + Memory + Tool Use。如果说，使用工具是人类文明的起点，那么，Agent 则标志着大模型从 “说话” 进化到 “做事”。目前的 Agent 或者是说智能体，本质上都是将大模型视作数字大脑，通过反思、CoT、ReAct 等提示工程模拟人类思考过程，再通过任务规划、工具使用来扩展其能力的边界，使其能够感知和连接真实世界。从早期的 AutoGPT 到全球首个 AI 程序员智能体 Devin，人们对于 AI 的期望值，正肉眼可见地一路水涨船高。
Agent 的基本概念目前，市场上主流新能源汽车的智驾系统都大多处于 L2 或 L3 级别，萝卜快跑则率迈进 L4 级别。尽管我可以理解这一发展趋势的必然性，可当我意识到碳基生命自身的偶然性，我想知道，那些可能导致成千上万的人失业的失业的科技创新，是否是显得过于残酷和冰冷？在2024年的上半年，我接触到了多种 Agent 产品，例如 FastGPT、Coze、Dify 等等。这些产品基本都是基于工作流编排的思路，这实际上是一种对大型模型不稳定输出和多轮对话调用成本的妥协。受到过往工作经历影响，我对于工作流和低代码非常反感。因此，我坚信大模型动态地规划和执行任务的能力才是未来。在实现 Agent 的过程中，我参考 Semantic Kernel 的一个 PR 实现了一个支持 ReAct 模式的 Planner，这证明了我从去年开始接触大型模型时的种种想法，到目前为止基本上都是正确的。
当下生成式 AI 的优化方向我主张采用小模型结合插件的方式，推进 AI 服务的本地化，因为一味地追求参数规模或上下文长度，只会陷入永无休止的百模大战。在技术和成本之间，你必须要找到一个平衡点。例如，最近大火的 GraphRAG，知识图谱结合大模型的理念虽好，但构建知识图谱的成本相对较高，运行一个简单示例的费用大约在5到10美元左右。在实现 Agent 的过程中，我发现，使用阿里的 Qwen2-7B 模型完全可以支持任务规划以及参数提取，唯一的问题是 Ollama 推理速度较慢，尤其是在纯 CPU 推理的情况下。此外，目前的 Agent 的反思功能大多依赖于多轮对话，其效果易受上下文长度的影响。即便使用 OpenAI、Moonshot 等厂商的服务，它们的 TPM/RPM 通常不会太高，导致公共 API 难以满足 Agent 的运行需求。如果增加接口调用间隔，无疑又会让屏幕前的用户失去耐心。因此，即便是在 token 价格越来越便宜的情况下，以任务为导向的 Agent，其 token 消耗量依然是一笔不小的开销。</description></item></channel></rss>