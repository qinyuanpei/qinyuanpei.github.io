<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>后端 on 元视角</title><link>http://example.org/tags/%E5%90%8E%E7%AB%AF/</link><description>Recent content in 后端 on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Mon, 23 Sep 2024 12:52:10 +0000</lastBuildDate><atom:link href="http://example.org/tags/%E5%90%8E%E7%AB%AF/index.xml" rel="self" type="application/rss+xml"/><item><title>温故而知新：后端通用查询方案的再思考</title><link>http://example.org/posts/review-and-rethink-backend-universal-query-solutions/</link><pubDate>Mon, 23 Sep 2024 12:52:10 +0000</pubDate><guid>http://example.org/posts/review-and-rethink-backend-universal-query-solutions/</guid><description>最近，我一直在体验 Cursor 这款产品，与先前的 CodeGeex、通义灵码 等 “插件类” 产品相比，Cursor 在产品形态上更接近 Github Copilot。在多项测评中，Cursor 甚至一度超越了 Github Copilot。尽管我没有体验过 Github Copilot，但从用户体验的角度来看，Cursor 基于 VS Code 进行了深度定制。除了基础的代码自动补全功能外，它还可以允许你从原型图生成代码、将整个工程作为 Codebase、一键应用代码到本地。最令我印象深刻的是，它指导我完成了一个 Vue 的小项目，从零开始。诚然，“幻觉” 的存在让它在 Vue 2 和 Vue 3 之间反复横跳，其编程能力的提升主要得益于 Claude 3.5 系列模型，可我还是像《三体》中的杨冬一样感到震惊：物理学不存在了，那前端呢？有人说，程序员真正的护城河是沟通能力，因为执行层面的工作可以交给 AI。实际上，我并不担心 AI 取代人类，我更倾向于与 AI 沟通和合作，你可能想象不到，这篇文章中的思考正是来自于我和 Claude 老师的日常交流。
CRUD Boys 的日常 程序员普遍喜欢自嘲，以博主为例，作为一名后端工程师，我的日常工作主要就是 CRUD，因此，你可以叫我们 CRUD Boys。鲁迅先生曾作《自嘲》一诗，“破帽遮颜过闹市，漏船载酒泛中流”。面对软件世界里里的复杂性和不确定性，如果没有乐观的心态和耐心，哪怕是最基础的 CRUD，你不见得就能做到得心应手。你可能听说过这样一句话，“上岸第一剑，先斩意中人”，AI 领域的第一把火，永远烧向程序员自己，自打一众 AI 辅助编程工具问世以来，各种程序员被 AI 取代的声音不绝于耳，甚至 Cursor 可以在 45 分钟内让一个 8 岁小孩搭建出聊天网站，更不必说，在 OpenAI 发布全新的 o1 模型后，很多人觉得连提示工程、Agent 这些东西都不存在了。其实，代码生成、低代码/无代码相关的技术一直都存在，在很久以前，我们就在通过 T4 模板生成业务代码，自不必说各种代码生成器。截止到目前，Excel 依然是这个地球上最强大的低代码工具，可又有谁能掌握 Excel 的全部功能呢?
你猜用 Cursor 写一个这样的页面需要多久？退一步讲，即使的最简单的 CRUD，虽然业务的推进会不断地演化出新的问题。譬如，当你为了加快查询效率引入了缓存，你需要去解决数据库和缓存一致性、缓存失效等问题；当你发现数据库读/写不平衡引入读写分离、分库分表，你就需要去解决主从一致、分布式事务、跨库查询等问题；当你发现单点性能不足引入了多机器、多线程，你需要去解决负载均衡、线程同步等问题……单单一个查询就如此棘手，你还会觉得后端的 CRUD 简单吗？我承认，后端的确都是 CRUD，可在不同的维度上这些 CRUD 并不完全相同，譬如，分布式的相关算法如 Paxos、Raft 等，难道不是针对分布式环境中的节点做 CRUD 吗？可此时你还会觉得它简单吗？Cursor 的确可以帮你生成代码，但真正让它出圈的是背后的 Claude 模型。我始终相信某位前辈曾经讲过的话：“没有银弹”，在软件行业里，复杂度永远不会消失，它只会以一种新的方式出现。如果你觉得 CRUD 简单，或许是你从未接触过那些千姿百态的查询接口：</description></item><item><title>基于 Server-Sent Events 实现服务端消息推送</title><link>http://example.org/posts/3175881014/</link><pubDate>Fri, 18 Jan 2019 13:46:44 +0000</pubDate><guid>http://example.org/posts/3175881014/</guid><description>前段时间，为客户定制了一个类似看板的东西，用户可以通过看板了解任务的处理情况，通过 APP 扫面页面上的二维码就可以领取任务，而当任务被领取以后需要通知当前页面刷新。原本这是一个相对简单的需求，可是因为 APP 端和 PC 端是两个不同的 Team 在维护，换句话说，两个 Team 各自有一套自己的 API 接口，前端页面永远无法知道 APP 到底什么时候扫描了二维码，为此前端页面不得不通过轮询的方式去判断状态是否发生了变化。这种方式会发送大量无用的 HTTP 请求，因此在最初的版本里，无论是效率还是性能都不能满足业务要求，最终博主采用一种称为 服务器推送事件(Server-Sent Events) 的技术，所以，在今天这篇文章里，博主相和大家分享下关于 服务器推送事件(Server-Sent Events) 相关的内容。
什么是 Server-Sent Events 我们知道，严格地来讲，HTTP 协议是无法做到服务端主动推送消息的，因为 HTTP 协议是一种 “请求-响应” 模型，这意味着在服务器返回响应信息以后，本次请求就已经结束了。可是，我们有一种变通的做法，即首先是服务器端向客户端声明，然后接下来发送的是流信息。换句话说，此时发送的不是一个一次性的数据包，而是以数据流的形式不断地发送过来，在这种情况下，客户端不会关闭连接，会一直等着服务器端发送新的数据过来，一个非常相似而直观的例子是视频播放，它其实就是在利用流信息完成一次长时间的下载。那么，Server-Sent Events(以下简称SSE)，就是利用这种机制，使用流信息像客户端推送信息。
说到这里，可能大家会感到疑惑：WebSocket 不是同样可以实现服务端向客户端推送信息吗？那么这两种技术有什么不一样呢？首先，WebSocket 和 SSE 都是在建立一种浏览器与服务器间的通信通道，然后由服务器向浏览器推送信息。两者最为不同的地方在于，WebSocket 建立的是一个全双工通道，而 SSE 建立的是一个单工通道。所谓单工和双工，是指数据流动的方向上的不同，对 WebSocket 而言，客户端和服务端都可以发送信息，所以它是双向通信；而对于SSE而言，只有服务端可以发送消息，故而它是单向通信。从下面的图中我们可以看得更为直观，在 WebSocket 中数据&amp;quot;有来有往&amp;quot;，客户端既可以接受信息亦可发送信息，而在 SSE 中数据是单向的，客户端只能被动地接收来自服务器的信息。所以，这两者在通信机制上不同到这里已经非常清晰啦！
WebSocket与SSE对比SSE 服务端 下面我们来看看SSE是如何通信的，因为它是一个单工通道的协议，所以协议定义的都是在服务端完成的，我们就从服务端开始吧！协议规定，服务器向客户端发送的消息，必须是 UTF-8 编码的，并且提供如下的 HTTP 头部信息：
Content-Type: text/event-stream Cache-Control: no-cache Connection: keep-alive 这里出现了一个一种新的MIME类型，text/event-stream。协议规定，第一行的 Content-Type 必须是text/event-stream，这表示服务端的数据是以信息流的方式返回的，Cache-Control 和 Connection 两个字段和常规的HTTP 一致，这里就不再展开说啦！OK，现在客户端知道这是一个 SSE 信息流啦，那么客户端怎么知道服务端发送了什么消息呢？这就要说到 SSE 的消息格式，在 SSE 中消息的基本格式是：</description></item></channel></rss>