<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>容器 on 元视角</title><link>http://example.org/tags/%E5%AE%B9%E5%99%A8/</link><description>Recent content in 容器 on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Mon, 28 Oct 2024 12:52:10 +0000</lastBuildDate><atom:link href="http://example.org/tags/%E5%AE%B9%E5%99%A8/index.xml" rel="self" type="application/rss+xml"/><item><title>容器技术驱动下的代码沙箱实践与思考</title><link>http://example.org/posts/container-technology-driven-code-sandbox-practice-and-reflection/</link><pubDate>Mon, 28 Oct 2024 12:52:10 +0000</pubDate><guid>http://example.org/posts/container-technology-driven-code-sandbox-practice-and-reflection/</guid><description>最近，我一直在尝试复刻 OpenAI 的 Canvas 功能，它与 Claude 的 Artifacts 功能非常相似。当然，两者在侧重点上有所不同——Artifacts 更注重于 “预览” 功能，而 Canvas 则专注于编程和写作领域。尽管 Artifacts 珠玉在前，可 Canvas 无疑为交互式体验带来更多可能性。对此，OpenAI 研究主管 Karina Nguyen 曾表示：我心目中的终极 AGI 界面是一张空白画布（Canvas）。在当前推崇 “慢思考” 的背景下，我有时会觉得下半年的大语言模型（LLM）发展 “不温不火”，给人一种即将停滞不前的的感觉。我想，这可能与四季更迭、万物枯荣的规律有关，正所谓 “环球同此凉热”。直到这两天，Claude 发布了 Computer Use，智谱发布了 AutoGLM，这个冬天再次变得热闹起来，为了不辜负这份幸运，我决定更新一篇博客，这次的主题是：容器技术驱动下的代码沙箱实践与思考。
LangChain 开源的 OpenCanvas为什么需要代码解释器？ 在当前生成式 AI 的浪潮中，代码生成首当其冲，从 CodeGeex 到通义灵码，从 Github Copilot 到 Cursor，可谓是层出不穷，其交互方式亦从代码补全逐渐过渡到代码执行。你会注意到，在 OpenAI 的 Canvas 以及 Claude 的 Artifacts 中，都支持前端代码的实时预览，这意味着 AI 生成的不再是冷冰冰的代码，而是所见即所得的、可交互的成果。其实，早在 ChatGPT-3.5 中，OpenAI 就提供了 Code Interpreter 插件，可见让 AI 生成代码并执行代码的思路由来已久。究其本质，编程是一项持续改进的活动，必须根据反馈不断地完善代码。如果你使用过 Cursor 这个编辑器，相信你会对这一过程印象深刻，你可以实时地看到修改代码带来的变化，快速验证想法，加快调试和迭代的速度。毫无疑问，这种即时反馈的交互模式大大提高了编程的效率和趣味。
OpenAI 的 Canvas 功能在实现 AI 智能体的过程中，我尝试为 Semantic Kernel 开发过一个 Code Interpreter 插件，我觉得这对于扩展（LLM）的能力边界意义重大。以 “9.</description></item><item><title>关于 Docker 容器配置信息的渐进式思考</title><link>http://example.org/posts/progressive-thinking-about-docker-container-configuration-information/</link><pubDate>Thu, 01 Dec 2022 12:30:47 +0000</pubDate><guid>http://example.org/posts/progressive-thinking-about-docker-container-configuration-information/</guid><description>作为一名软件工程师，不，或许应该叫做 YAML 工程师、Markdown 工程师、Dockerfile 工程师……等等，这绝非自谦，更多的是一种自嘲。毕竟，从入行的那一天开始，追求配置上的动态灵活，就如同思想一般刻进每个程序员的 DNA 里。可当你意识到，在这个世界上，提出主张的人和解决问题的人，并不是同一群人时，你或许会心头一紧，接着便是直呼上当，我甚至不能理解，为什么程序员提交完代码，还要像运维一样折腾各种配置文件。特别是在 DevOps 的理念流行开以后，程序员们简直就是在通过各种配置文件互相折磨对方。如果程序员不能通过程序变得懒惰，那是不是说明，我们早已忘记了当初学习编程时的初心？我们都以为代码可以不用修改，可有哪一次代码能逃过面目全非的结局？每当这个时候，我就特别想怼那些主张配置文件的人，要不您来？言归正传，今天我想聊聊容器、配置文件和环境变量，为什么称为渐进式思考呢？因为它更像是一种不同人生阶段的回顾。
从何说起 故老相传，鸿蒙初开，天地混沌。上帝说，要有光。于是，盘古抄起那把传说中的开天神斧，对着虚空世界就是一通输出。那一刻，这位创世神周围就像发生了奇点大爆炸一样迅速扩张。最终，它的身体化作了世间万物，推动这个世界从无到有的进化历程。屏幕前的你，无需纠结这段融合了东/西方神话、现代物理学的表述是否严谨，因为我想说的是，在一个事物发展的初期，一定是朴素而且原始的。相信大家开始写 Dockerfile 的时候，一定没少写过下面这样的脚本：
COPY /config/nginx.conf /etc/nginx/nginx.conf 如你所见，该命令会复制主机上的配置文件到容器的指定目录，而这其实是符合我们一开始对容器的预期的，即：我们只需要将程序打包到镜像里，就可以快速地完成程序的部署。可是，我们显然忽略了一个问题，当程序部署到不同的环境中时，它需要的配置文件自然是不同的。此时，你可能会采用下面的做法：
docker exec -it &amp;lt;容器Id&amp;gt; sh vim /etc/nginx/nginx.conf 环境变量 果然，大道至简，没有任何技巧，简直真诚到极致。常言道：智者不入爱河，这个做法辛不辛苦姑且不论，关键是容器一旦重启，你连慨叹镜花水月的时间都没有啦。所以，这个方案可谓是劳心劳力，为我所不取也！再后来，你发现容器里可以使用环境变量，于是你就灵机一动，为什么不能让这个配置文件支持动态配置呢？于是，你尝试使用下面的做法：
server { listen ${NGINX_PORT}; listen [::]:${NGINX_PORT}; server_name ${NGINX_HOST}; location / { root /usr/share/nginx/html; index index.html index.htm; } } 此时，我们只需要在 .env 文件或者 docker-compose.yml 文件里指定这些环境变量即可。对于这个思路，我们可以使用 envsubst 这个工具来实现：
export NGINX_PORT=80 export NGINX_HOST=xyz.com apt-get update &amp;amp;&amp;amp; apt-get install -y gettext-base envsubst &amp;lt; /config/nginx.conf &amp;gt; /etc/nginx/nginx.conf 此时，我们会发现，它可以实现环境变量的“注入”：
环境变量的“注入”当然，如果这段脚本是写在 RUN 指令后面，那么，这个改进是非常有限的。因为如果你希望更新配置，你必须要重新构建一个镜像，一个更好的做法是，将这段脚本放到 CMD 或者 ENTRYPOINT 指令里。这样，我们更新配置时只需要重启容器即可，这是不是就符合配置上的动态灵活了呢？事实上，这正是博主公司一直采用的做法。不过，运维同事大概率是没听说过 envsubst 这个工具，他使用的是更朴素的 sed 命令：</description></item><item><title>在 Docker 容器内集成 Crontab 定时任务</title><link>http://example.org/posts/integrate-crontab-scheduled-tasks-inside-docker-containers/</link><pubDate>Thu, 24 Nov 2022 12:30:47 +0000</pubDate><guid>http://example.org/posts/integrate-crontab-scheduled-tasks-inside-docker-containers/</guid><description>有时候，我们需要在容器内执行某种定时任务。譬如，Kerberos 客户端从 KDC 中获取到的 TGT 默认有效期为 10 个小时，一旦这个票据失效，我们将无法使用单点登录功能。此时，我们就需要一个定时任务来定时刷新票据。此前，博主为大家介绍过 Quartz 和 Hangfire 这样的定时任务系统，而对于 Linux 来说，其内置的 crontab 是比以上两种方案更加轻量级的一种方案，它可以定时地去执行 Linux 中的命令或者是脚本。对应到 Kerberos 的这个例子里面，从 KDC 申请一个新的票据，我们只需要使用 kinit 这个命令即可。因此，在今天这篇博客里，我想和大家分享一下，如何在 Docker 容器内集成 Crontab 定时任务，姑且算是在探索 Kerberos 过程中的无心插柳，Kerberos 认证这个话题博主还需要再消化一下，请大家拭目以待，哈哈！
Crontab 基础知识 众所周知，Linux 中的所有内容都是以文件的形式保存和管理的，即：一切皆为文件。那么，自然而然的地，Linux 中的定时任务同样遵循这套丛林法则，因此，当我们谈论到在 Linux 中执行定时任务这个话题的时候，本质上依然是在谈论某种特定格式的文件。事实上，这类文件通常被称为 crontab 文件，这是一个来源于希腊语 chronos 的词汇，其含义是时间。Linux 会定时(每分钟)读取 crontab 文件中的指令，检查是否有预定任务需要执行。下面是一个 crontab 文件的示例：
# 每分钟执行一次 ls 命令 * * * * * /bin/ls # 周一到周五的下午5点发邮件 0 17 * * 1-5 mail -s &amp;#34;hi&amp;#34; alex@162.com # 每月1号和15号执行脚本 0 0 1,15 * * /var/www/newbee/check.</description></item><item><title>Vue.js 前端项目容器化部署实践极简教程</title><link>http://example.org/posts/a-simplified-tutorial-on-containerized-deployment-of-front-end-projects-for-vue/</link><pubDate>Tue, 17 May 2022 13:30:47 +0000</pubDate><guid>http://example.org/posts/a-simplified-tutorial-on-containerized-deployment-of-front-end-projects-for-vue/</guid><description>大概一周前，在某个「微雨燕双飞」的下午，我正穿梭于熙熙攘攘的车流人海当中，而被雨水濯洗过的天空略显灰白，傍晚亮起的路灯恍惚中有种朝阳初升的错觉，内心更是涌现出一种「一蓑烟雨任平生」的豁达，我还没来得及给这场内心戏添油加醋，兴哥的电话突然打断了我的思绪。一番攀谈交心，我了解到，他想问的是前端容器化部署的相关问题。虽然，靠着兴哥的睿智、果敢，他第二天就想明白了整个事情的来龙去脉；但是，这完全不影响我水一篇博客出来。所以，今天这篇文章，我们来聊聊前端项目的容器化部署，并提供一个极简的实践教程，这里以 Vue.js 为例，希望对大家有所启发。
你说，这像太阳吗？首先，我们来编写 Dockerfile，这里采用的是多阶段构建的做法，第一个阶段，即 build，主要是利用 node.js 基础镜像来实现前端项目的发布，所以，你可以看到 package.json、npm install 以及考虑到国情的 cnpm install 这些前端项目中喜闻乐见的东西，安装完依赖以后我们通过 npm run build 来完成打包，这取决于你项目中实际使用的脚本或者命令，如果你不喜欢 npm，你同样可以用 yarn 来编写这些指令，只要你喜欢就好。做人嘛，最重要的是开心！
# build FROM node:lts-alpine as build WORKDIR /app COPY package*.json ./ RUN npm install -g cnpm --registry=https://registry.npm.taobao.org RUN cnpm install COPY . . RUN npm run build # deploy FROM nginx:stable-alpine as deploy COPY --from=build /app/dist/ /usr/nginx/wwwroot COPY /nginx/nginx.conf /etc/nginx/nginx.conf EXPOSE 80 CMD [&amp;#34;nginx&amp;#34;, &amp;#34;-g&amp;#34;, &amp;#34;daemon off;&amp;#34;] OK，第二个阶段，即 deploy，前端发布出来的产物是无法直接在浏览器里打开的，这一点你平时用 Vue.</description></item><item><title>你不可不知的容器编排进阶技巧</title><link>http://example.org/posts/172025911/</link><pubDate>Sat, 14 Aug 2021 22:13:32 +0000</pubDate><guid>http://example.org/posts/172025911/</guid><description>在团队内推广Docker Compose有段时间啦，值得庆幸的是，最终落地效果还不错，因为说到底，大家都不大喜欢，那一长串复杂而枯燥的命令行参数。对我而言，最为重要的一点，团队内使用的技术变得更加透明化、标准化，因为每个微服务的配置信息都写在docker-compose.yml文件中，任何人都可以快速地构建出一套可用的服务，而不是每次都要去找具体的某一个人。我想说，这其实是一个信息流如何在团队内流动的问题。也许，我们有文档或者Wiki，可新人能不能快速融入其中，这才是检验信息流是否流动的唯一标准。就这样，团队从刀耕火种的Docker时代，进入到使用服务编排的Docker Compose时代。接下来，能否进入K8S甚至是云原生的时代，我终究不得而知。今天我想聊聊，在使用Docker Compose的过程中，我们遇到的诸如容器的启动顺序、网络模式、健康检查这类问题，我有一点Docker Compose的进阶使用技巧想和大家分享。
容器的启动顺序 使用服务编排以后，大家最关心的问题是，如果服务间存在依赖关系，那么如何保证容器的启动顺序？我承认，这是一个真实存在的问题，譬如，你的应用依赖某个数据库，理论上数据库要先启动，抑或者是像Redis、Kafka、Envoy这样的基础设施，总是要优先于应用服务本身启动。
假如章鱼的这些脚互相影响会怎么样？熟悉Docker Compose的同学，也许会想到depends_on这个选项，可如果大家亲自去尝试过就会知道，这终究只是我们的一厢情愿。为什么呢？因为这个depends_on主要是看目标容器是不是处于running的状态，所以，在大多数情况下，我们会注意到Docker Compose并不是按我们期望的顺序去启动的，因为目标容器在某一瞬间的确已经是running的状态了，那这样简直太尴尬了有木有啊！我们从一个简单的例子开始：
version: &amp;#34;3.8&amp;#34; services: redis_server: image: redis:latest command: &amp;gt; /bin/bash -c &amp;#39; sleep 5; echo &amp;#34;sleep over&amp;#34;;&amp;#39; networks: - backend city_service: build: CityService/ container_name: city_service ports: - &amp;#34;8081:80&amp;#34; networks: - backend depends_on: - redis_server networks: backend: 可以注意到，为了证明city_service服务不会等待redis_server服务，我故意让子弹飞了一会儿，结果如何呢？我们一起来看看：
Docker Compose 启动顺序：一厢情愿果然，我没有骗各位，city_service服务不会等待redis_server服务。我们知道，Redis提供的命令行接口中，有一个PING命令，当Redis可以正常连接的时候，它会返回一个PONG，也许，这就是乒乓球的魅力所在。基于这个想法，我们继续修改docker-compose.yml文件：
version: &amp;#34;3.8&amp;#34; services: redis_server: image: redis:latest networks: - backend city_service: build: CityService/ container_name: city_service ports: - &amp;#34;8081:80&amp;#34; networks: - backend depends_on: - redis_server command: &amp;gt; /bin/bash -c &amp;#39; while !</description></item></channel></rss>