<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>文本分类 on 元视角</title><link>http://example.org/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/</link><description>Recent content in 文本分类 on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sat, 17 Mar 2018 15:28:40 +0000</lastBuildDate><atom:link href="http://example.org/tags/%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB/index.xml" rel="self" type="application/rss+xml"/><item><title>基于新浪微博的男女性择偶观数据分析(下)</title><link>http://example.org/posts/3083474169/</link><pubDate>Sat, 17 Mar 2018 15:28:40 +0000</pubDate><guid>http://example.org/posts/3083474169/</guid><description>各位朋友，大家好，我是 Payne，欢迎大家关注我的博客。我的博客地址是：https://qinyuanpei.github.io。对于今天这篇文章的主题，相信经常关注我博客的朋友一定不会陌生。因为在 2017 年年底的时候，我曾以此为题写作了一篇文章：基于新浪微博的男女择偶观数据分析(上)。这篇文章记录了我当时脑海中闪烁着的细微想法，即当你发现一件事物背后是由哲学或者心理学这类玄奥的科学在驱动的时候，不妨考虑使用数学的思维来让一切因素数量化，我想这是最初数据分析让我感兴趣的一个原因。因为当时对文本的处理了解得非常粗浅，所以在第一次写作这篇文章的时候，实际的工作不过是在分词后绘制词云而已。等到我完成对微信好友信息的数据分析以后，我意识到微博这里其实可以继续发掘。关于微信好友信息的数据分析，可以参考这篇文章：基于 Python 实现的微信好友数据分析。在这样的想法促使下，便有了今天这篇文章，因为工作关系一直没有时间及时整理出来，希望这篇文章可以带给大家一点启示，尤其是在短文本分类方面，这样我就会非常开心啦！:slightly_smiling_face:
故事背景 关于故事背景，我在 基于新浪微博的男女择偶观数据分析(上) 这篇文章中说得非常清楚啦。起因就是我想知道，男性和女性在选择伴侣的时候，到底更为关注哪些因素？在对微信好友信息进行数据分析的时候，我们可以非常直接地确定，譬如性别、签名、头像、位置这四个不同的维度，这是因为我们处理的是结构化的数据。什么是结构化的数据呢？一个非常直观的认识是，这些数据可以按照二维表的方式组织起来。可对于微博这样一个无结构的文本数据类型，我们除了对词频、词性等因素做常规统计分析以外，好像完全找不到一个合理有效的方案，因为我们很容易就明白一件事情，即：在短短的 140 个字符中，人类语言的多样性被放大到淋漓尽致 。为了将种种离散的信息收敛在一个统一的结构里，我们必须为这些文本构建一种模型，并努力使这种模型可以量化和计算。我们通过词云对微博进行可视化分析，更多是针对词频的一种分析方法，这种方法虽然可以帮助我们找出关键字，可是因为最初写作这篇文章时，对数据分析领域相关知识知之甚少，而且在分析的过程中没有考虑停用词，所以我认为在文本分类或者是主题提取层面上，我们都需要一种更好的方法。
常见的技术方法 这篇文章涉及的领域称为文本分类或者主题提取，而针对微博、短信、评论等这类短文本的分类，则被称为短文本分类。为什么要进行文本分类呢？第一，提取出潜在主题以后可以帮助我们做进一步的分析。譬如博主这里想要从相亲类微博中分析男性和女性的择偶观，首先要解决的就是主题建模问题，因为在择偶过程中要考虑的因素会非常多，我们到底要选取哪些因素来分析呢？这些因素在特定领域中被称为特征，所以文本分类的过程伴随着特征提取。第二，**短文本数据通常只有一个主题，看起来这是在简化我们的分析过程，实则传统的基于文档的主题模型算法在这里难以适用。**因为这类主题模型算法都假定一篇文档中含有多个主题，而我们分析的是群体现象，这种个体上的差异必须设法将其统一于一体，比如美元和$属于同一个主题，我们需要一种策略来对其进行整合。
传统主题提取模型通常由文本预处理、文本向量化、主题挖掘和主题表示等多个流程组成，每个流程都会有多种处理方法，不同的组合方法会产生不同的建模结果。目前，人们在传统主题提取模型的基础上，发展起了以CNN和RNN为代表的深度学习方法，在这里我们依然关注传统主题提取模型，因为这个领域对博主而言是个陌生的领域，这里我们更多的是关注传统主题提取模型。按照传统主题提取模型，文本分类问题被拆分为特征工程和分类器两个部分，其中，特征工程的作用是将文本转化为计算机可以理解的格式，并提供强特征表达能力，即特征信息可以用以分类，而分类器基本上是统计学相关的内容，其作用是根据特征对数据进行分类。下面来简单介绍下常见的技术方法。
特征工程 特征工程覆盖了文本预处理、特征提取和文本表示三个流程。文本预处理通常指分词和去除停用词这两个过程，可以说分词是自然语言处理的基本前提。特征提取实际上囊括两个部分，即特征项的选择和特征项权重的计算。选择特征项的基本思路是：根据某个评价指标对原始数据进行排序，然后从中选择分数最高的评价指标，同时过滤掉其余的评价指标。通常可以选择的评价指标有文档频率、互信息、信息增益等，而特征权重的计算主要是经典的TF-IDF算法及其扩展算法。文本表示是指将文本预处理后转化为计算机可以理解的格式，是决定分类效果最重要的部分。传统做法是使用词袋模型(BOW)或者向量空间模型(VSM)，比如Word2Vec就是一个将词语转化为向量的相关项目。因为向量模型完全忽视文本的上下文，所以为了弥补这种技术上的不足，业界同时使用基于语义的文本表示方法，比如常见的LDA语义模型。
分类器 分类器主要是统计学里的分类方法，基本上大部分的机器学习方法都在文本分类领域有所应用，比如最常见的朴素贝叶斯算法(Naive Bayes)、KNN、支持向量机(SVM)、最大熵(MaxEnt)、决策树和神经网络等等。简单来说，假设我们所有的数据样本可以划分为训练集和测试集。首先，分类器可以在训练集上执行分类算法以生成分类模型；其次，分类器可以通过分类模型对测试集进行预测以生成预测结果；最后，分类器可以计算出相关的评价指标以评估分类的效果。这里最常用的两个评价指标是准确率和召回率，前者关注的是数据的准确性，后者关注的是数据的全面性。
TF-IDF 与朴素贝叶斯 TF-IDF(term frequency–inverse document frequency)是一种被用于信息检索与数据挖掘的统计学方法，常常被用来评估某个字词对于一个文件集或者是一个语料库中的一份文档的重要程度。在特征工程这里我们提到，特征工程中主要通过特征权重来对数据进行排序和分类，因此TF-IDF本质上是一种加权技术。TF-IDF的主要思想是：字词的重要性与它在文件中出现的次数成正比上升，与此同时与它在语料库中出现的频率成反比下降。这句话是什么意思呢？如果某个词或者短语在一篇文章中出现的频率(即TF)较高，并且在其它文章中出现的频率(即IDF)较低，那么就可以人为这个词或者短语可以作为一个特征，具备较好的类别区分能力，因此适合用来作为分类的标准。TF-IDF实际上是 TF * IDF，即 TF(term frequency，词频)与 IDF(inverse document frequency，逆文档频率)的乘积，具体我们通过下面的公式来理解： term frequency，词频显然，这里的 TF 表示某一词条在文档中出现的频率。再看 IDF: inverse document frequency，逆文档频率这里的 D 表示语料库中文档的数目，而分母表示的是含有指定词的文档的数目，这里两者求商后取对数即可得到 IDF。需要注意的是，当该词语不在语料库中时，理论上分母会变成 0，这将导致计算无法继续下去，因此为了修正这一错误，我们在分母上加 1，这样就可以得到 IDF 更为一般的计算公式。按照这样的思路，我们将两段文本分完词以后，分别计算每一个词的 tf-idf 并按照 tf-idf 对其进行排序，然后选取前 N 个元素作为其关键字，这样我们就获得了两个 N 维向量，按照向量理论的相关知识，两个向量间的夹角越小，其相关性越显著，这就是文本相似度判断的常规做法，在这个过程中，我们覆盖到了文本预处理、特征提取和文本表示三个过程，相信大家会对这个过程有更好的理解。
好了，那么什么是特征呢？这里计算出来的 tf-idf 实际上就是一组特征，这个特征是上下文无关、完全基于频率分析的结果，现在这些结果都是计算机可以处理的数值类型，所以特征工程要做的事情，就是从这些数值中分析出某一种规律出来。譬如，我们通过分析大量的气象资料，认为明天有 80%的概率会下雨，那么此时下雨的概率 0.8 就可以作为一个特征值，在排除干扰因素的影响以后，我们可以做一个简单的分类，如果下雨的概率超过 0.8 即认为明天会下雨，反之则不会下雨。这是一个接近理想的二值化模型，在数学中我们有一种概率分布模型称为 0-1 分布，即一件事情只有两个可能，如果该事件会发生的概率为 p，则该事件不会发生的概率为 1-p。如果所有的问题都可以简化到这种程度，我相信我们会觉得这个世界枯燥无比，因为一切非黑即白、非此即彼，这会是我们所希望的世界的样子吗？ 为什么在这里我要提到概率呢？因为这和我们下面要提到的朴素贝叶斯有关。事实上，朴素贝叶斯的理论基础，正是我们所熟悉的条件概率。根据概率的相关知识，我们有以下公式，即全概率公式：P(A|B) = P(AB)/P(B)。我们对 A 和 B 进行交换，同理可得：P(B|A) = P(A/B)/P(A)。由此我们即得到了贝叶斯公式： 贝叶斯公式所以，朴素贝叶斯本质上是一种基于概率理论的分类算法。我们知道条件概率成立的前提是各个事件都是独立的，因此在朴素贝叶斯算法中假设所有特征间都是独立的，可当我们逐渐地了解这个世界，就会明白这个世界并不是非黑即白、非此即彼的，甚至一件事情会受到来自方方面面的因素影响，就像我们从前学习物理的时候喜欢用控制变量法一样，总有一天你会明白当时的想法太天真。朴素贝叶斯算法中的“朴素”，通常被翻译为 Naive，而这个词就是表示天真的意思，这正是朴素贝叶斯的名称由来，它简单粗暴地认为各个特征间是相互独立的，有人认为这种假设是相当不严谨的，所以相当排斥这种分类的理论，所幸朴素贝叶斯在实际应用中分类效果良好，尤其是在解决垃圾邮件过滤这类问题上，所以到今天为止，朴素贝叶斯依然是一个相当经典的分类算法，它是一个根据给定特性/属性，基于条件概率为样本赋予某个类别标签的模型。</description></item></channel></rss>