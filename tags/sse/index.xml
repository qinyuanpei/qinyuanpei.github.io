<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>SSE on 元视角</title><link>http://example.org/tags/sse/</link><description>Recent content in SSE on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Thu, 06 Jun 2024 12:52:10 +0000</lastBuildDate><atom:link href="http://example.org/tags/sse/index.xml" rel="self" type="application/rss+xml"/><item><title>关于 ChatGPT 的流式传输，你需要知道的一切</title><link>http://example.org/posts/everything-you-need-to-know-about-streaming-with-chatgpt/</link><pubDate>Thu, 06 Jun 2024 12:52:10 +0000</pubDate><guid>http://example.org/posts/everything-you-need-to-know-about-streaming-with-chatgpt/</guid><description>当提及 ChatGPT 等生成式 AI 产品时，大家第一时间想到的是什么？对博主而言，印象最为深刻的是其流式输出效果，宛如打字机一般流畅。相信大家都注意到了，我给博客增加了 AI 摘要功能。虽然，这是一个非常“鸡肋”的功能，可是在光标闪烁的一刹那，我居然产生了一种“对方正在输入”的莫名期待。然而，此时此刻，理性会告诉我们：ChatGPT 的流式输出并不是为了让 AI 更“像”人类，它本质上是一种减少用户等待时长的优化策略。相比于人类的闪烁其词，心直口快或许更接近 AI 的真实想法。图灵测试，是一种用于判定机器是否具有智能的测试方法，其核心在于：如果程序表现出的行为与人类相似，我们便认为它具备了智能。当然，人机的不可区分性，同样带来了心理、伦理和法律上的问题。这便引出一个问题：人工智能，是否真的有必要像人类一样？有没有一种可能，让人工智能不那么地像人类，这反而是一种更加明智的做法？带着种种疑问，博主酝酿出了这篇文章，关于 ChatGPT 的流式传输，你需要知道的一切都在这里。从这一刻开始，“Attention Is All You Need”！
Server-Sent Events 目前，在众多生成式 AI 产品中，对话框依然是最普遍的产品形态。因此，当你准备开发一款 AI 应用时，实现“流式传输”功能是基本要求。正如矛盾先生所言，“模仿是创造的第一步”，所以，让我们先来看看 ChatGPT 是如何实现这个功能的。ChatGPT 早期使用的是 Server-Sent Events 技术来实现流式传输。然而，截止到博主写作这篇文章时，ChatGPT 中流式传输的实现已升级为 WebSocket。不过，这个话题还是值得探讨一下的，因为市面上依然有大量的项目在使用这个技术，我们姑且将其理解为，一笔由 OpenAI 引领而产生的技术债务。关于 Server-Sent Events 的基本概念，大家可以参考博主以前的博客 基于 Server-Sent Events 实现服务端消息推送：
Server-Sent Events 基本原理示意图下面，我们以 Kimi 为例来进行说明。通过观察浏览器的请求过程，足以一窥 Server-Sent Events 的个中奥妙。
Kimi 在浏览器中的请求过程 - A首先，Server-Sent Events 是基于 HTTP 协议的，其响应结果中的 Content-Type 取值为 text/event-stream。
Kimi 在浏览器中的请求过程 - B其次，Server-Sent Events 以事件流的形式向客户端返回数据，这些数据放在 Data 字段中。此时，客户端只需要从 Data 字段中提取内容，再将其显示到界面上即可，这样便可以快速地实现流式输出效果。按照这个思路，我们可以提供一个简单的实现，如下面的代码片段所示：</description></item><item><title>基于 Server-Sent Events 实现服务端消息推送</title><link>http://example.org/posts/3175881014/</link><pubDate>Fri, 18 Jan 2019 13:46:44 +0000</pubDate><guid>http://example.org/posts/3175881014/</guid><description>前段时间，为客户定制了一个类似看板的东西，用户可以通过看板了解任务的处理情况，通过 APP 扫面页面上的二维码就可以领取任务，而当任务被领取以后需要通知当前页面刷新。原本这是一个相对简单的需求，可是因为 APP 端和 PC 端是两个不同的 Team 在维护，换句话说，两个 Team 各自有一套自己的 API 接口，前端页面永远无法知道 APP 到底什么时候扫描了二维码，为此前端页面不得不通过轮询的方式去判断状态是否发生了变化。这种方式会发送大量无用的 HTTP 请求，因此在最初的版本里，无论是效率还是性能都不能满足业务要求，最终博主采用一种称为 服务器推送事件(Server-Sent Events) 的技术，所以，在今天这篇文章里，博主相和大家分享下关于 服务器推送事件(Server-Sent Events) 相关的内容。
什么是 Server-Sent Events 我们知道，严格地来讲，HTTP 协议是无法做到服务端主动推送消息的，因为 HTTP 协议是一种 “请求-响应” 模型，这意味着在服务器返回响应信息以后，本次请求就已经结束了。可是，我们有一种变通的做法，即首先是服务器端向客户端声明，然后接下来发送的是流信息。换句话说，此时发送的不是一个一次性的数据包，而是以数据流的形式不断地发送过来，在这种情况下，客户端不会关闭连接，会一直等着服务器端发送新的数据过来，一个非常相似而直观的例子是视频播放，它其实就是在利用流信息完成一次长时间的下载。那么，Server-Sent Events(以下简称SSE)，就是利用这种机制，使用流信息像客户端推送信息。
说到这里，可能大家会感到疑惑：WebSocket 不是同样可以实现服务端向客户端推送信息吗？那么这两种技术有什么不一样呢？首先，WebSocket 和 SSE 都是在建立一种浏览器与服务器间的通信通道，然后由服务器向浏览器推送信息。两者最为不同的地方在于，WebSocket 建立的是一个全双工通道，而 SSE 建立的是一个单工通道。所谓单工和双工，是指数据流动的方向上的不同，对 WebSocket 而言，客户端和服务端都可以发送信息，所以它是双向通信；而对于SSE而言，只有服务端可以发送消息，故而它是单向通信。从下面的图中我们可以看得更为直观，在 WebSocket 中数据&amp;quot;有来有往&amp;quot;，客户端既可以接受信息亦可发送信息，而在 SSE 中数据是单向的，客户端只能被动地接收来自服务器的信息。所以，这两者在通信机制上不同到这里已经非常清晰啦！
WebSocket与SSE对比SSE 服务端 下面我们来看看SSE是如何通信的，因为它是一个单工通道的协议，所以协议定义的都是在服务端完成的，我们就从服务端开始吧！协议规定，服务器向客户端发送的消息，必须是 UTF-8 编码的，并且提供如下的 HTTP 头部信息：
Content-Type: text/event-stream Cache-Control: no-cache Connection: keep-alive 这里出现了一个一种新的MIME类型，text/event-stream。协议规定，第一行的 Content-Type 必须是text/event-stream，这表示服务端的数据是以信息流的方式返回的，Cache-Control 和 Connection 两个字段和常规的HTTP 一致，这里就不再展开说啦！OK，现在客户端知道这是一个 SSE 信息流啦，那么客户端怎么知道服务端发送了什么消息呢？这就要说到 SSE 的消息格式，在 SSE 中消息的基本格式是：</description></item></channel></rss>