<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Docker on 元视角</title><link>http://example.org/tags/docker/</link><description>Recent content in Docker on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Thu, 01 Dec 2022 12:30:47 +0000</lastBuildDate><atom:link href="http://example.org/tags/docker/index.xml" rel="self" type="application/rss+xml"/><item><title>关于 Docker 容器配置信息的渐进式思考</title><link>http://example.org/posts/progressive-thinking-about-docker-container-configuration-information/</link><pubDate>Thu, 01 Dec 2022 12:30:47 +0000</pubDate><guid>http://example.org/posts/progressive-thinking-about-docker-container-configuration-information/</guid><description>作为一名软件工程师，不，或许应该叫做 YAML 工程师、Markdown 工程师、Dockerfile 工程师……等等，这绝非自谦，更多的是一种自嘲。毕竟，从入行的那一天开始，追求配置上的动态灵活，就如同思想一般刻进每个程序员的 DNA 里。可当你意识到，在这个世界上，提出主张的人和解决问题的人，并不是同一群人时，你或许会心头一紧，接着便是直呼上当，我甚至不能理解，为什么程序员提交完代码，还要像运维一样折腾各种配置文件。特别是在 DevOps 的理念流行开以后，程序员们简直就是在通过各种配置文件互相折磨对方。如果程序员不能通过程序变得懒惰，那是不是说明，我们早已忘记了当初学习编程时的初心？我们都以为代码可以不用修改，可有哪一次代码能逃过面目全非的结局？每当这个时候，我就特别想怼那些主张配置文件的人，要不您来？言归正传，今天我想聊聊容器、配置文件和环境变量，为什么称为渐进式思考呢？因为它更像是一种不同人生阶段的回顾。
从何说起 故老相传，鸿蒙初开，天地混沌。上帝说，要有光。于是，盘古抄起那把传说中的开天神斧，对着虚空世界就是一通输出。那一刻，这位创世神周围就像发生了奇点大爆炸一样迅速扩张。最终，它的身体化作了世间万物，推动这个世界从无到有的进化历程。屏幕前的你，无需纠结这段融合了东/西方神话、现代物理学的表述是否严谨，因为我想说的是，在一个事物发展的初期，一定是朴素而且原始的。相信大家开始写 Dockerfile 的时候，一定没少写过下面这样的脚本：
COPY /config/nginx.conf /etc/nginx/nginx.conf 如你所见，该命令会复制主机上的配置文件到容器的指定目录，而这其实是符合我们一开始对容器的预期的，即：我们只需要将程序打包到镜像里，就可以快速地完成程序的部署。可是，我们显然忽略了一个问题，当程序部署到不同的环境中时，它需要的配置文件自然是不同的。此时，你可能会采用下面的做法：
docker exec -it &amp;lt;容器Id&amp;gt; sh vim /etc/nginx/nginx.conf 环境变量 果然，大道至简，没有任何技巧，简直真诚到极致。常言道：智者不入爱河，这个做法辛不辛苦姑且不论，关键是容器一旦重启，你连慨叹镜花水月的时间都没有啦。所以，这个方案可谓是劳心劳力，为我所不取也！再后来，你发现容器里可以使用环境变量，于是你就灵机一动，为什么不能让这个配置文件支持动态配置呢？于是，你尝试使用下面的做法：
server { listen ${NGINX_PORT}; listen [::]:${NGINX_PORT}; server_name ${NGINX_HOST}; location / { root /usr/share/nginx/html; index index.html index.htm; } } 此时，我们只需要在 .env 文件或者 docker-compose.yml 文件里指定这些环境变量即可。对于这个思路，我们可以使用 envsubst 这个工具来实现：
export NGINX_PORT=80 export NGINX_HOST=xyz.com apt-get update &amp;amp;&amp;amp; apt-get install -y gettext-base envsubst &amp;lt; /config/nginx.conf &amp;gt; /etc/nginx/nginx.conf 此时，我们会发现，它可以实现环境变量的“注入”：
环境变量的“注入”当然，如果这段脚本是写在 RUN 指令后面，那么，这个改进是非常有限的。因为如果你希望更新配置，你必须要重新构建一个镜像，一个更好的做法是，将这段脚本放到 CMD 或者 ENTRYPOINT 指令里。这样，我们更新配置时只需要重启容器即可，这是不是就符合配置上的动态灵活了呢？事实上，这正是博主公司一直采用的做法。不过，运维同事大概率是没听说过 envsubst 这个工具，他使用的是更朴素的 sed 命令：</description></item><item><title>在 Docker 容器内集成 Crontab 定时任务</title><link>http://example.org/posts/integrate-crontab-scheduled-tasks-inside-docker-containers/</link><pubDate>Thu, 24 Nov 2022 12:30:47 +0000</pubDate><guid>http://example.org/posts/integrate-crontab-scheduled-tasks-inside-docker-containers/</guid><description>有时候，我们需要在容器内执行某种定时任务。譬如，Kerberos 客户端从 KDC 中获取到的 TGT 默认有效期为 10 个小时，一旦这个票据失效，我们将无法使用单点登录功能。此时，我们就需要一个定时任务来定时刷新票据。此前，博主为大家介绍过 Quartz 和 Hangfire 这样的定时任务系统，而对于 Linux 来说，其内置的 crontab 是比以上两种方案更加轻量级的一种方案，它可以定时地去执行 Linux 中的命令或者是脚本。对应到 Kerberos 的这个例子里面，从 KDC 申请一个新的票据，我们只需要使用 kinit 这个命令即可。因此，在今天这篇博客里，我想和大家分享一下，如何在 Docker 容器内集成 Crontab 定时任务，姑且算是在探索 Kerberos 过程中的无心插柳，Kerberos 认证这个话题博主还需要再消化一下，请大家拭目以待，哈哈！
Crontab 基础知识 众所周知，Linux 中的所有内容都是以文件的形式保存和管理的，即：一切皆为文件。那么，自然而然的地，Linux 中的定时任务同样遵循这套丛林法则，因此，当我们谈论到在 Linux 中执行定时任务这个话题的时候，本质上依然是在谈论某种特定格式的文件。事实上，这类文件通常被称为 crontab 文件，这是一个来源于希腊语 chronos 的词汇，其含义是时间。Linux 会定时(每分钟)读取 crontab 文件中的指令，检查是否有预定任务需要执行。下面是一个 crontab 文件的示例：
# 每分钟执行一次 ls 命令 * * * * * /bin/ls # 周一到周五的下午5点发邮件 0 17 * * 1-5 mail -s &amp;#34;hi&amp;#34; alex@162.com # 每月1号和15号执行脚本 0 0 1,15 * * /var/www/newbee/check.</description></item><item><title>你不可不知的容器编排进阶技巧</title><link>http://example.org/posts/172025911/</link><pubDate>Sat, 14 Aug 2021 22:13:32 +0000</pubDate><guid>http://example.org/posts/172025911/</guid><description>在团队内推广Docker Compose有段时间啦，值得庆幸的是，最终落地效果还不错，因为说到底，大家都不大喜欢，那一长串复杂而枯燥的命令行参数。对我而言，最为重要的一点，团队内使用的技术变得更加透明化、标准化，因为每个微服务的配置信息都写在docker-compose.yml文件中，任何人都可以快速地构建出一套可用的服务，而不是每次都要去找具体的某一个人。我想说，这其实是一个信息流如何在团队内流动的问题。也许，我们有文档或者Wiki，可新人能不能快速融入其中，这才是检验信息流是否流动的唯一标准。就这样，团队从刀耕火种的Docker时代，进入到使用服务编排的Docker Compose时代。接下来，能否进入K8S甚至是云原生的时代，我终究不得而知。今天我想聊聊，在使用Docker Compose的过程中，我们遇到的诸如容器的启动顺序、网络模式、健康检查这类问题，我有一点Docker Compose的进阶使用技巧想和大家分享。
容器的启动顺序 使用服务编排以后，大家最关心的问题是，如果服务间存在依赖关系，那么如何保证容器的启动顺序？我承认，这是一个真实存在的问题，譬如，你的应用依赖某个数据库，理论上数据库要先启动，抑或者是像Redis、Kafka、Envoy这样的基础设施，总是要优先于应用服务本身启动。
假如章鱼的这些脚互相影响会怎么样？熟悉Docker Compose的同学，也许会想到depends_on这个选项，可如果大家亲自去尝试过就会知道，这终究只是我们的一厢情愿。为什么呢？因为这个depends_on主要是看目标容器是不是处于running的状态，所以，在大多数情况下，我们会注意到Docker Compose并不是按我们期望的顺序去启动的，因为目标容器在某一瞬间的确已经是running的状态了，那这样简直太尴尬了有木有啊！我们从一个简单的例子开始：
version: &amp;#34;3.8&amp;#34; services: redis_server: image: redis:latest command: &amp;gt; /bin/bash -c &amp;#39; sleep 5; echo &amp;#34;sleep over&amp;#34;;&amp;#39; networks: - backend city_service: build: CityService/ container_name: city_service ports: - &amp;#34;8081:80&amp;#34; networks: - backend depends_on: - redis_server networks: backend: 可以注意到，为了证明city_service服务不会等待redis_server服务，我故意让子弹飞了一会儿，结果如何呢？我们一起来看看：
Docker Compose 启动顺序：一厢情愿果然，我没有骗各位，city_service服务不会等待redis_server服务。我们知道，Redis提供的命令行接口中，有一个PING命令，当Redis可以正常连接的时候，它会返回一个PONG，也许，这就是乒乓球的魅力所在。基于这个想法，我们继续修改docker-compose.yml文件：
version: &amp;#34;3.8&amp;#34; services: redis_server: image: redis:latest networks: - backend city_service: build: CityService/ container_name: city_service ports: - &amp;#34;8081:80&amp;#34; networks: - backend depends_on: - redis_server command: &amp;gt; /bin/bash -c &amp;#39; while !</description></item><item><title>WSL 下 Docker 使用踩坑小记</title><link>http://example.org/posts/4159187524/</link><pubDate>Mon, 22 Apr 2019 22:13:36 +0000</pubDate><guid>http://example.org/posts/4159187524/</guid><description>众所周知，Win10 中开始提供 Linux 子系统，即 Windows Subsystem for Linux，简称 WSL，它可以让我们在 Windows 系统使用 Linux 系统，自从有了这个新功能以后，博主果断地放弃双系统的方案，因为折腾起来实在花费时间。关于如何使用 WSL，网上有非常多的文章可以参考，这里不再赘述。今天想说的是，WSL 下使用 Docker 遇到的各种坑。
装完 WSL 以后，对各种编译环境的使用相当满意，最近在研究日志可视化平台 ELK，其中需要使用 Docker 来搭建环境，一顿 sudo 操作猛如虎，快速安装完 Docker 环境，结果发现熟悉的命令行居然无法正常工作，是可忍孰不可忍。
sudo apt-get update sudo apt-get install \ apt-transport-https \ ca-certificates \ curl \ gnupg-agent \ software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo apt-key fingerprint 0EBFCD88 sudo add-apt-repository \ &amp;#34;deb [arch=amd64] https://download.docker.com/linux/ubuntu \ $(lsb_release -cs) \ stable&amp;#34; sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.</description></item><item><title>基于 Docker 构建 .NET 持续集成环境</title><link>http://example.org/posts/3995512051/</link><pubDate>Tue, 12 Jun 2018 17:53:59 +0000</pubDate><guid>http://example.org/posts/3995512051/</guid><description>最近在考虑将整个项目组的产品，努力向着持续集成(CI)/持续部署(CD)的方向靠拢，因为目前我们仅仅实现了基于 Docker 的自动化部署，而部署包的构建依然依赖于人工打包，而每个版本的测试和部署，基本上都要给所有相关人员发一遍邮件，而写邮件无非是填写版本号和变更历史。身处在这样一个社会化分工逐渐加剧的『摩登时代』，我们唯一的希望就追求技能的多元化，你越是担心有一天会被 AI 所替代，就越是应该去追求灵动与美。这个世界何尝不是一个运行中的大型机器，可恰恰就是这种掺杂了情感的冰冷法则，让我们意识到需要更多的理解和宽容。管理者常常迷信敏捷开发的人月神话，希望人可以像零件一样按部就班，在这场噩梦到来以前，为何不去做一点更有用的事情，让云计算帮我们解放双手。
背景说明 我们的产品，从结构上来讲，分为后端、前端和客户端三个部分，其中，后端提供了从认证到上传、查询和下载等主要的 AP 接口；前端提供了基于后端 API 接口的页面，主要功能是监控和管理；客户端承担了主要的业务交互能力，主要功能是整合常用的硬件资源。从技术上来讲，后端是基于 Spring Cloud 的微服务架构，前端是基于 node.js 的典型前端工具链，而客户端是基于 .NET / Win32 的技术体系。所以，即使我们的客户端是运行在 Window 平台上，我们依然有大量的服务是运行在 Linux 环境下。负责部署的同事不愿意单独再构建一套持续集成(CI)环境，所以我们决定借助 Docker 完成整个持续集成(CI)环境的构建。
构建过程 完成整个项目的构建，需要覆盖到代码编译、单元测试、静态检查、版本发布这四个基本环节，我们整体上使用 Jenkins 作为内部持续集成的平台，这意味着我们只需要在提交代码或者合并代码的时候，触发一个构建指令即可。这里我们考虑通过 Docker 来完成这些工作，一个整体上的设计思路如下图所示：
构建思路MSBuild 首先是 MSBuild，它是我们整个构建流程中最重要的环节，我们平时通过 Visual. Studio 编译一个项目，背后其实就是由 MSBuild 这个构建工具来驱动，而通过 MSBuild 我们定义更多的构建流程，例如执行单元测试、实现 Zip 打包等等的流程。在 Window 平台下我们安装 Visual Studio 后就可以使用 MSBuild ，那么在 Linux 平台下呢？目前， MSBuild 已经被微软开源并托管在 Github 上，大家可以通过这个地址：https://github.com/Microsoft/msbuild来访问。通过阅读 MSBuild 的文档，我们了解到，目前 MSBuild 实际上有三个流向，分别是目前官方主推的 .Net Core 、传统的 .Net Framework以及由 Mono 托管的部分。
.Net Core 中 MSBuild 实际上被集成在 .</description></item><item><title>使用 Jexus 实现 ASP.NET 在 Linux 平台下的部署</title><link>http://example.org/posts/815861661/</link><pubDate>Sun, 20 May 2018 14:00:03 +0000</pubDate><guid>http://example.org/posts/815861661/</guid><description>Hello，大家好，我是 Payne，欢迎大家关注我的博客，我的博客地址是：https://qinyuanpei.github.io。今天想写一点关于 Linux 部署 ASP.NET 相关的话题，为什么突然想写这个话题呢？因为就在几天前，我被我所认识的一位前辈深深地鄙视了一番，原因是我依然在使用一个落后的 IoC 框架——Unity，在如今已然是公元 2018 年的今天。我突然想到，距离.NET Core 2.0 发布已经有一段时间，而.NET Core 3.0 的 roadmap 已经开始提上日程，可我好像还没来得及认真地去对待这个现状。我一直在关注跨平台和跨语言的技术，就像我在大学里的时候就开始接触 Linux 一样，未来我们要面对的是种类繁多的终端平台，从 PC 时代到移动互联网，再到 VR、AR、IoT 和 AI，有太多太多的事情在悄然发生着变化。偶尔我的内心会泛起焦虑和迷茫，可在时光蹉跎直至褪色以前，我或许只是变回了曾经的自己。既然要如同涅槃一般重新开始，为什么不首先重新拾起曾经关注的领域呢？所以，在这今天这篇文章里，你将看到：如何使用 Jexus 实现 ASP.NET 在 Linux 平台下的部署。
故事背景 我们项目组在开发这样一种服务，它可以通过收集招聘网站的简历来提取相关信息，而这些信息将作为训练集供 AI 算法使用。考虑到 Python 在 AI 领域的优势，我们决定采用 Python 来开发自然语言处理相关的业务，而简历的收集则是通过.NET 中的 Web Service 暴露给前端。整个开发相对顺利，可是在部署环节出现了问题。因为项目组以往的的项目都是部署在 Linux Server 上，所以在部署 Web Service 的问题上产生了分歧，负责运维的同事不愿意为这一个项目而单独配置一台 Windows Server。这里需要说明的是，采用.NET 来开发 Web Service 的一个重要原因是，这些简历中存在大量 Word 文档(.doc/.docx)，因此不得不采用 Office 提供的 COM 组件来支持文档的解析，虽然后来证明的确是这些 COM 组件拖了跨平台的后腿。所以，在这个时候，我们面临着两种选择，第一种方案是采用 Windows Server 来部署，我们的运维同事表示不开心；第二种方案是采用 Linux Server 来部署。我们知道.</description></item></channel></rss>