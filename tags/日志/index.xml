<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>日志 on 元视角</title><link>https://qinyuanpei.github.io/tags/%E6%97%A5%E5%BF%97/</link><description>Recent content in 日志 on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sun, 07 Aug 2022 16:01:13 +0000</lastBuildDate><atom:link href="https://qinyuanpei.github.io/tags/%E6%97%A5%E5%BF%97/index.xml" rel="self" type="application/rss+xml"/><item><title>.NET Core + ELK 搭建可视化日志分析平台(下)</title><link>https://qinyuanpei.github.io/posts/3687594959/</link><pubDate>Sun, 07 Aug 2022 16:01:13 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/3687594959/</guid><description>最近，我收到一位读者朋友的私信，问我 ELK 为什么没有下篇，道德感极强的我不得不坦诚相告，显然这一篇鸽了。这就是说，鸽子不单单会出现在吴宇森的电影里，只要你试图拖延或者逃避，你一样有鸽子可以放飞。话说回来，新冠疫情已然持续了三年，而这篇文章其实是我在新冠元年写下的。某年某月，彼时彼刻，立春过后紧接着是上元节，阳光已透过玻璃宣示着春天的到来，可在这一墙之隔的里里外外，仿佛是两个气候迥异的世界。记忆里那种每天都和消毒水、口罩打交道的日子，后来就变成了一种习以为常、甚至有一点唏嘘的常态化生活。在这过去的三年里，恍惚中已经发生太多的事情，譬如 ELK 早已变成了 EFK，譬如前女友有了新的男朋友，在一切的物是人非背后，在一切的断壁残垣下面，我想，我还是用这个旧题目来讲一个新的故事罢！
从 Logstash 到 Filebeat 当初准备写这个系列的时候，ELK 还是经典的 Elastaicsearch 、 Logstash 和 Kibana 组合，如下图所示，Logstash 从各种不同的数据源收集数据，通过内置的管道对输入的数据进行加工。最终，这些数据会被存储到 Elastaicsearch 中供 Kibana 完成数据可视化。 即使放到三年后的今天来看，这张图依然是非常经典的一幅图。为什么这么说呢？因为自此以后，可视化日志分析平台的搭建，基本都是围绕这三个方面展开，甚至 Logstash 的继任者 Filebeat、Fluentd、Fluent-Bit 等等无一不沿用了 Logstash 的这套管道设计，足可见其对后来者的影响之深远。不过，作为先驱出现的 Logstash，其本身是采用 Java 语言开发的，其插件则是采用 Ruby 语言开发的，特别是第一点，一直让 Logstash 在性能问题上遭人垢病。在实际使用中，你常常需要在每一台服务器上安装 Logstash ，这意味着它在 CPU 和内存上的占用会比较高。
经典的 ELK 全家桶组合为了解决这个问题，Elastic 官方推出了被称为 Beats 的下一代日志收集方案， 这是一种基于 Go 语言开发、更加轻量级的、资源占用更少的日志收集方案，可以认为是 Logstash 的替代品, 而 Filebeat 正好是其中一种实现。关于这两者的区别，我想，使用下面的比喻或许会更恰当一点， Logstash 就像一个轰鸣声不断的垃圾转运车，虽然可以让你直接把垃圾丢车上拉走，可你不得不忍受一整天的噪音；Filebeat 则像一个拎着扫帚和簸萁的环卫工人，那里有需要就去哪里清扫，不单单效率高而且不会让你感觉扰民，下面是一张来自 Elastic 官方文档 中的示意图：
Filebeat 日志收集示意图从这里我们可以看出， Filebeat 由两个主要的组件 Inputs 和 Harvester 组成。其中， Harvester 是一个负责读取单个文件内容的采集器，它可以打开和关闭一个文件，并将内容发送到指定的输出；Inputs 顾名思义就是输入，对于 Filebeat 而言，其实就是指各种不同类型的日志文件，譬如 Filebeat 可以支持 Kafka、Redis、MQTT、TCP、UDP、Stdin、Syslog 等等的输入。从某种意义上讲，你可以把 Filebeat 理解为一个文件扫描服务。例如，下面的配置表示 Filebeat 将会从一个指定的路径读取日志文件：</description></item><item><title>ASP.NET Core gRPC 拦截器的使用技巧分享</title><link>https://qinyuanpei.github.io/posts/1679688265/</link><pubDate>Wed, 26 May 2021 09:03:35 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/1679688265/</guid><description>gRPC是微软在.NET Core 及其后续版本中主推的 RPC 框架，它使用 Google 的 Protocol Buffers 作为序列化协议，使用 HTTP/2 作为通信协议，具有跨语言、高性能、双向流式调用等优点。考虑到，接下来要参与的是，一个以gRPC为核心而构建的微服务项目。因此，博主准备调研一下gRPC的相关内容，而首当其冲的，则是从 .NET Core 3.1 开始就有的拦截器，它类似于ASP.NET Core中的过滤器和中间件，体现了一种面向切面编程(AOP)的思想，非常适合在 RPC 服务调用的时候做某种统一处理，譬如参数校验、身份验证、日志记录等等。在今天这篇博客中，博主主要和大家分享的是，利用 .NET Core gRPC 中的拦截器实现日志记录的简单技巧，希望能给大家带来一点启发。
开源、多语言、高性能的 gRPC关于 Interceptor 类 Interceptor类是 gRPC 服务拦截器的基类，它本身是一个抽象类，其中定义了下面的虚方法：
public virtual AsyncClientStreamingCall&amp;lt;TRequest, TResponse&amp;gt; AsyncClientStreamingCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual AsyncDuplexStreamingCall&amp;lt;TRequest, TResponse&amp;gt; AsyncDuplexStreamingCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual AsyncUnaryCall&amp;lt;TResponse&amp;gt; AsyncUnaryCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual TResponse BlockingUnaryCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual Task&amp;lt;TResponse&amp;gt; ClientStreamingServerHandler&amp;lt;TRequest, TResponse&amp;gt;(); public virtual AsyncServerStreamingCall&amp;lt;TResponse&amp;gt; AsyncServerStreamingCall&amp;lt;TRequest, TResponse&amp;gt;(); public virtual Task DuplexStreamingServerHandler&amp;lt;TRequest, TResponse&amp;gt;(); public virtual Task ServerStreamingServerHandler&amp;lt;TRequest, TResponse&amp;gt;(); public virtual Task&amp;lt;TResponse&amp;gt; UnaryServerHandler&amp;lt;TRequest, TResponse&amp;gt;(); 整体而言，如果从通信方式上来划分，可以分为：流式调用 和 普通调用；而如果从使用方来划分，则可以分为：客户端 和 服务端。进一步讲的话，针对流式调用，它还分为：&amp;quot;单向流&amp;quot; 和 &amp;ldquo;双向流&amp;quot;。关于这些细节上的差异，大家可以通过 gRPC 的 官方文档 来了解，这里我们给出的是每一种方法对应的用途：</description></item><item><title>.NET Core + ELK 搭建可视化日志分析平台(上)</title><link>https://qinyuanpei.github.io/posts/3687594958/</link><pubDate>Sat, 15 Feb 2020 16:01:13 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/3687594958/</guid><description>Hi，各位朋友，大家好！欢迎大家关注我的博客，我的博客地址是: https://blog.yuanpei.me。今天是远程办公以来的第一个周末，虽然公司计划在远程两周后恢复正常办公，可面对着每天都有人离开的疫情，深知这一切都不会那么容易。窗外的阳光透过玻璃照射进屋子，这一切都昭示着春天的脚步渐渐近了。可春天来了，有的人却没有再回来。那些在 2019 年结束时许下的美好期待、豪言壮语，在这样一场灾难面前，终究是如此的无力而苍白。可不管怎么样，生活还是要继续，在这些无法出门的日子里，在这样一个印象深刻的春节长假里，除了做好勤洗手、多通风、戴口罩这些防疫保护措施以外，博主还是希望大家能够抽空学习，通过知识来充实这“枯燥&amp;quot;的生活。所以，从今天开始，我将为大家带来 .NET Core + ELK 搭建可视化日志分析平台 系列文章，希望大家喜欢。
什么是 ELK 当接触到一个新的事物的时候，我们最好是从它的概念开始入手。那么，什么是 ELK 呢？ELK，是 Elastaicsearch 、 Logstash 和 Kibana 三款软件的简称。其中，Elastaicsearch 是一个开源的全文搜索引擎。如果你没有听说过它，那至少应该听说过 Lucene 这个开源搜索引擎。事实上，Elastaicsearch 是 Lucene 的封装，它提供了 REST API 的操作接口 。而 Logstash 则是一个开源的数据收集引擎，具有实时的管道，它可以动态地将不同的数据源的数据统一起来。最后，Kibana 是一个日志可视化分析的平台，它提供了一系列日志分析的 Web 接口，可以使用它对日志进行高效地搜索、分析和可视化操作。至此，我们可以给 ELK 一个简单的定义：
ELK 是一个集日志收集、搜索、日志聚合和日志分析于一身的完整解决方案。
下面这张图，展示了 Elastaicsearch 、 Logstash 和 Kibana 三款软件间的协作关系。可以注意到，Logstash 负责从应用服务器收集日志。我们知道，现在的应用程序都是跨端应用，程序可能运行在 PC、移动端、H5、小程序等等各种各样的终端上，而 Logstash 则可以将这些不同的日志信息通过管道转换为统一的数据接口。这些日志将被存储到 Elasticsearch 中。我们提到 Elastaicsearch 是一个开源的全文搜索引擎，故而它在数据查询上相对传统的数据库有着更好的优势，并且 Elasticsearch 可以根据需要搭建单机或者集群。最终，Kibana 从 Elasticsearch 中查询数据并绘制可视化图表，并展示在浏览器中。在最新的 ELK 架构中，新增了FireBeat这个软件，它是它是一个轻量级的日志收集处理工具(Agent)，适合于在各个服务器上搜集日志后传输给 Logstash。
ELK-01.png总而言之，ELK 可以让我们以一种更优雅的方式来收集日志，传统的日志收集通常会把日志写到文件或者数据库中。前者，不利于日志的集中管理和查询；后者，则无法应对海量文本检索的需求。所以，使用 ELK 可以为我们带来下面这些便利：分布式日志数据集中式查询和管理；系统监控，譬如对系统硬件和应用各个组件的监控；故障排查；报表功能；日志查询，问题排查，上线检查； 服务器监控、应用监控、错误报警；性能分析、用户行为分析、时间管理等等。
如何安装 ELK 安装 ELK 的方式，首推以 Docker 方式安装。关于 Docker 的安装、使用请大家查阅官方文档：https://docs.</description></item><item><title>使用 Unity 框架简化应用程序异常处理及日志记录流程</title><link>https://qinyuanpei.github.io/posts/3291578070/</link><pubDate>Wed, 21 Mar 2018 19:35:40 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/3291578070/</guid><description>最近公司安排学习项目代码，前后花了一周左右的时间，基本熟悉了项目中的各个模块，感觉项目难度上整体偏中等。这是一个具备完整前端和后端流程的项目，在学习这个项目的过程中，我逐渐发现某些非常有趣的东西，比如在 Web API 的设计中采用严谨而完善的错误码、使用 OAuth 和 JWT 对 API 资源进行访问控制，在 JavaScript 中使用修饰器特性来实现日志记录等等，这些东西我会在后续的博客逐步去整理，今天想说的是如何通过 Unity 框架来简化应用程序异常处理和日志记录流程，而之所以关注这个问题，是因为我发现项目中接近滥用的异常处理，以及我不能忍受的大量重复代码。
背景描述 由于业务场景上的需要，我们在产品中集成了大量第三方硬件厂商的 SDK，这些 SDK 主要都是由 C/C++编写的动态链接库，因此在使用这些 SDK 的过程中，通常频繁地使用返回值来判断一个方法是否成功被调用，虽然项目上制定了严格的错误码规范，可当我看到大量的 Log()方法和业务逻辑混合在一起时，我内心依然是表示拒绝的，甚至我看到在捕获异常以后记录日志然后继续 throw 异常，这都是些什么鬼操作啊，考虑到我的语言描述得可能不太准确，大家可以从下面两段代码来感受下整体画风：
public short LoginTerminal(string uid,string pwd) { try { Log.BeginLog() return SDK.Login(uid,pwd) } catch(Exception ex) { log.LogError(ErrorCode.E2301,ex) throw new TerminalException(ex.Message); } finally { Log.EndLog() } } 这是一段相对完整的业务逻辑代码，当然这里都是伪代码实现，这里我比较反感的两个地方是：第一，从头出现到尾的 BeginLog()/EndLog()这对方法；第二，在 Catch 块中记录完日志然后将异常再次抛出。经过我对项目的一番了解，BeginLog()/EndLog()这对方法会在日志中记录某个方法开始执行和结束执行的位置。在方法执行前后插入代码片段，这不就是面向切面编程(AOP)的思想吗？这里记录完日志然后再抛出异常的做法，我个人是不大认同的，因为我觉得拦截异常应该有一个统一的入口，因为异常会继续向上传递，既然如此，为什么我们不能统一地去处理异常和记录日志呢？难道就一定要让 Log 这个静态类无处不在吗？同样地，我们注意到项目还会有下面这样的代码：
public void ProcessTerminal(object sender,ProcessEventArgs args) { try { Log.BeginLog(); var terminal = (Termainal)sender; var result = terminal.</description></item><item><title>基于 C# 中的 Trace 实现一个简单的日志系统</title><link>https://qinyuanpei.github.io/posts/1254783039/</link><pubDate>Tue, 25 Oct 2016 20:16:13 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/1254783039/</guid><description>&lt;p>最近在做的项目进入中期阶段，因为在基本框架结构确定以后，现阶段工作重心开始转变为具体业务逻辑的实现，在这个过程中我认为主要有两点，即保证逻辑代码的正确性和容错性、确定需求文档中隐性需求和逻辑缺陷。为什么我说的这两点都和用户需求这个层面息息相关呢？或许这和我这段时间的感受有些关系吧，我觉得当我们在面对用户提出的需求的时候，一个非常让我们不爽的一个地方是，我们总是需要花费大量的时间来和用户确定某些细节，而这些细节无论在 BRD 或者 PRD 中都无从体现。固然从用户层面上来讲，我们无法要求用户提供，详尽到每一个细节的需求文档。可我觉得这是一个修养的问题，我们习惯于宽以律己、严以待人，可是如果我们连自己都说服不了，我们该如何尝试去说服别人呢？我不认为我们就应该被用户限制自由，我们共同的目的都是想要好做一件事情，所以我们的关系应该是平等的伙伴的关系，这种上下级的、命令式的主仆关系让我感觉受到了侮辱。&lt;/p></description></item></channel></rss>