<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>事件订阅 on 元视角</title><link>https://qinyuanpei.github.io/tags/%E4%BA%8B%E4%BB%B6%E8%AE%A2%E9%98%85/</link><description>Recent content in 事件订阅 on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Wed, 15 Jul 2020 14:39:07 +0000</lastBuildDate><atom:link href="https://qinyuanpei.github.io/tags/%E4%BA%8B%E4%BB%B6%E8%AE%A2%E9%98%85/index.xml" rel="self" type="application/rss+xml"/><item><title>利用 MySQL 的 Binlog 实现数据同步与订阅(中)：RabbitMQ 篇</title><link>https://qinyuanpei.github.io/posts/580694660/</link><pubDate>Wed, 15 Jul 2020 14:39:07 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/580694660/</guid><description>紧接上一篇博客中的思路，这次我们来说说事件总线(EventBus)，回首向来，关于这个话题，我们可能会联想到发布-订阅模式、观察者模式、IObservable与 IObserver、消息队列等等一系列的概念。所以，当我们尝试着去解释这个概念的时候，它到底是什么呢？是一种设计模式？是一组 API 接口？还是一种新的技术？显而易见，发布-订阅模式和观察者模式都是设计模式，而 IObservable与 IObserver、消息队列则是具体的实现方式，就像你可以用委托或者事件去实现一个观察者模式，而 Redis 里同样内置了发布-订阅模型，换言之，这是抽象与具体的区别，消息队列可以用来实现 EventBus，而 EventBus 主要的用途则是系统间的解耦，说到解耦，你可能会对观察者模式和发布-订阅模式这两种模式感到困惑，因为它们实在是太像了，一个最本质的区别在于发布者(主题)是否与订阅者(观察者)存在强依赖关系，而发布-订阅引入了类似主题/Topic/Channel 的中介者，显然从解耦的角度要更彻底一些，所以，我们今天就来一起实现一个事件总线(EventBus)。
EventBus 整体设计 通过前面的探讨，我们可以知道，EventBus 其实是针对事件的发布-订阅模式的实现，所以，在设计 EventBus 的时候，我们可以结合发布-定阅模式来作为对照，而一个典型的发布-订阅模式至少需要三个角色，即发布者、订阅者和消息，所以，一般在设计 EventBus 的时候，基本都会从这三个方面入手，提供发布消息、订阅消息、退订消息的接口。由于 EventBus 本身并不负责消费消息，所以，还需要借助IEventHandler&amp;lt;T&amp;gt;来编写对应的事件处理器，这是 EventBus 可以实现业务解耦的重要原因。而为了维护事件和事件处理器的关系，通常需要借助 IoC 容器来注册这些 EventHandler，提供类似Castle或者Autofac从程序集中批量注册的机制，下面是博主借鉴 eShopOnContainers 设计的 EventBus，首先是 IEventBus 接口，其定义如下：
public interface IEventBus { void Publish&amp;lt;TEvent&amp;gt; (TEvent @event) where TEvent : EventBase; void Subscribe&amp;lt;T, TH&amp;gt; () where T : EventBase where TH : IEventHandler&amp;lt;T&amp;gt;; void Unsubscribe&amp;lt;T, TH&amp;gt; () where TH : IEventHandler&amp;lt;T&amp;gt; where T : EventBase; } 注意到，这里对事件(EventBase)和事件处理器(EventHandler)均有一定约束，这是为了整个 EventBus 的实现，在某些 EventBus 的实现中，可能会支持非泛型的EventHandler，以及Func这样的委托类型，这里不考虑这种情形，因为从 Binlog 中获取的数据，基本上都是格式固定的 JSON。关于这部分，下面给出对应的定义：</description></item><item><title>利用 MySQL 的 Binlog 实现数据同步与订阅(上)：基础篇</title><link>https://qinyuanpei.github.io/posts/1333693167/</link><pubDate>Tue, 07 Jul 2020 09:23:59 +0000</pubDate><guid>https://qinyuanpei.github.io/posts/1333693167/</guid><description>终于等到了周末，在经历了一周的忙碌后，终于可以利用空闲写篇博客。其实，博主有一点困惑，困惑于这个世界早已“堆积”起人类难以想象的“大”数据，而我们又好像执着于去“造”一个又一个“差不多”的“内容管理系统”，从前我们说互联网的精神是开放和分享，可不知从什么时候起，我们亲手打造了一个又一个的“信息孤岛”。而为了打通这些“关节”，就不得不去造一张巨大无比的蜘蛛网，你说这就是互联网的本质，对此我表示无法反驳。我更关心的是这其中最脆弱的部分，即：一条数据怎么从 A 系统流转到 B 系统。可能你会想到API或者ETL这样的关键词，而我今天想说的关键词则是Binlog。假如你经常需要让数据近乎实时地在两个系统间流转，那么你应该停下来听我——一个不甘心整天写CRUD换取996福报的程序员，讲讲如何通过Binlog实现数据同步和订阅的故事。
什么是 Binlog 首先，来回答第一个问题，什么是 Binlog？Binlog 即 Binary Log，是 MySQL 中的一种二进制日志文件。它可以记录MySQL内部对数据库的所有修改，故，设计 Binlog 最主要的目的是满足数据库主从复制和增量恢复的需要。对于主从复制，想必大家都耳熟能详呢，因为但凡提及数据库性能优化，大家首先想到的所谓的“读写分离”，而无论是物理层面的一主多从，还是架构层面的CQRS，这背后最大的功臣当属主从复制，而实现主从复制的更底层原因，则要从 Binlog 说起。而对于数据库恢复，身为互联网从业者，对于像“rm -f”和“删库”、“跑路”这些梗，更是喜闻乐见，比如像今年的绿盟删库事件，在数据被删除以后，工程师花了好几天时间去抢救数据，这其中就用到了 Binlog。
可能大家会好奇，为什么 Binlog 可以做到这些事情。其实，从 Binlog 的三种模式上，我们就可以窥其一二，它们分别是：Statement、Row、Mixed，其中Statement模式记录的是所有数据库操作对应的 SQL 语句，如 INSERT、UPDATE 、DELETE 等 DML 语句，CREATE 、DROP 、ALTER 等 DDL，所以，从理论上讲，只要按顺序执行这些 SQL 语句，就可以实现不同数据库间的数据复制。而Row模式更关心每一行的变更，这种在实际应用中会更普遍一点，因为有时候更关心数据的变化情况，例如一个订单被创建出来，司机通过 App 接收了某个运输任务等。而Mixed模式可以认为是Statement模式和Row模式的混合体，因为Statement模式和Row模式都有各自的不足，前者可能会导致数据不一致，而后者则会占用大量的存储空间。在实际使用中，我们往往会借助各种各样的工具，譬如官方自带的mysqlbinlog、支持 Binlog 解析的StreamSets等等。
好了，下面我们简单介绍下 Binlog 相关的知识点。在使用 Binlog 前，首先需要确认是否开启了 Binlog，此时，我们可以使用下面的命令：
SHOW VARIABLES LIKE &amp;#39;LOG_BIN&amp;#39; 如果可以看到下面的结果，则表示 Binlog 功能已开启。 Binlog已开启示意图如果 Binlog 没有开启怎么办呢？此时，就需要我们手动来开启，为此我们需要修改 MySQL 的my.conf文件，通常情况下，该文件位于/etc/my.cnf路径，在[mysqld]下写入如下内容：
# 设置Binlog存储目录 log_bin = /var/lib/mysql/bin-log # 设置Binlog索引存储目录 log_bin_index = /var/lib/mysql/mysql-bin.</description></item></channel></rss>