<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>独立博客 on 元视角</title><link>http://example.org/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/</link><description>Recent content in 独立博客 on 元视角</description><generator>Hugo</generator><language>zh-cn</language><lastBuildDate>Sat, 09 Jan 2021 20:37:47 +0000</lastBuildDate><atom:link href="http://example.org/categories/%E7%8B%AC%E7%AB%8B%E5%8D%9A%E5%AE%A2/index.xml" rel="self" type="application/rss+xml"/><item><title>实现网页长截图的常见思路总结</title><link>http://example.org/posts/3406626380/</link><pubDate>Sat, 09 Jan 2021 20:37:47 +0000</pubDate><guid>http://example.org/posts/3406626380/</guid><description>作为一个经常写博客的人，我有时会在微博上分享博客内容，可不知道从什么时候开始，国内互联网越来越丧失信仰，所有的厂商都在试图打造一个**“只进不出”的信息孤岛，进而达到增强“用户黏度”的目的。以微博为例，微博中的外链永远都会被转化为短地址，并且无法通过微博内置的浏览器进行跳转。即使你通过手动复制链接的方式打开链接，你依然需要至少两个步骤方能见到“庐山真面目”。借鉴/抄袭这一陋习的还有简书，花时间做了一个第三方链接跳转提示页面，唯独不愿意在上面加一个 a 标签，你还是要手动复制黏贴。坦白说，我觉得国内互联网正在丧失着信仰，看起来电商、物流、外卖、打车、支付……此起彼伏逐渐渗透到我们生活的方方面面，成为名副其实的“互联网+”，可在信息泛滥的今天，我们越来越难找到真正有价值的信息……既然外链注定要被屏蔽掉，那我就勉为其难地顺应潮流发“长截图”咯，所以，接下来我会为大家分享实现网页“长截图”**的常见思路，希望对有类似烦恼或者需求的小伙伴们有所帮助。
通过浏览器实现 要实现网页长截图，显然是和网页打交道，而和网页打交道最多的是谁呢？自然是我们每天都要用的浏览器啦！值得庆幸的是，不管是 Chrome 还是 Firefox ，我们都可以通过它们来是实现这个想法。
Chrome 对于 Chrome 来说，我们只需要“F12”打开开发者工具，并在其中找到“控制台”选项卡，在平时输入 JavaScript 脚本的地方(即 Console 选项卡)输入Ctrl + Shift + P命令，然后你会得到一个类似 VSCode 命令行体验的输入窗口，接下来，输入：Capture full size screenshot并回车。此时，我们就可以得到完整的页面截图。而如果你希望截取网页中的一部分，则可以在选中指定 DOM 元素后采用相同的方式输入命令：Capture node screenshot。此外，更常用的截取浏览器可见范围内的内容，可以使用：Capture screenshot。可能相对于一般可以进行拖拽截图的工具而言，这个方案显得有点笨拙且简陋，可它真的可以完美地实现我们的想法，而且不需要安装任何扩展或者插件。
使用 Chrome 的截图功能Firefox 对于 Firefox 而言，它本身自带截图功能，并且支持拖拽截图，对于我们这些需要长截图的人而言，唯一需要做的就是点击几下数据，确实要比敲命令行要简单一点、友好一点，我个人更喜欢用 Firefox 一点，因为 Chrome 正在从屠龙少年变成恶龙，为了让这个世界上不是只有 Chrome 一种浏览器内核，我决定支持一下 Firefox ，2020 年因为疫情的原因， Mozila 裁员 25%约 250 人，这家几乎靠着理想主义在维护 Gecko 内核的公司，之后可能再无法和 Google 的 Chrome 抗衡，而这个世界只有一种浏览器的时代我们都曾经经历过，它的名字叫做 IE6 ，不禁令人感慨，简直是开放 Web 的罗曼蒂克消亡史。
使用 Firefox 的截图功能通过 Selenium 实现 在我的认知中，有浏览器的地方就有爬虫，而有爬虫的地方就有 Selenium 。原本好端端的 UI 自动化测试框架，怎么就助纣为虐做起爬虫来了呢？其实，主要原因是它提供了一个可以和浏览器交互的环境，从某种意义上来讲，Selenium 、PhantomJS 以及 Playwright 都可以认为是类似的技术，这里我们以 Selenium 为例，而通过 Selenium 实现网页长截图则主要有两种方式：其一，是构造一个足够“大”的浏览器，然后调用save_screenshot()方法进行截图；其二，是通过“拖拽”滚动条来滚动截图，然后再通过PIL进行拼接，下面来看具体的代码实现：</description></item><item><title>原生 JavaScript 实现 Hexo 博客推荐功能</title><link>http://example.org/posts/478946932/</link><pubDate>Mon, 08 Jun 2020 12:30:54 +0000</pubDate><guid>http://example.org/posts/478946932/</guid><description>有时候，我不禁在想，我们到底处在一个什么样的时代呢？而之所以会有这样的疑问，则是因为我们的习惯在不断地被这个时代向前推进，就像我用了两年多的魅蓝 Note6 屏幕出现了问题，扫视了一圈新手机，居然再找不出一款带实体键的手机，刘海屏、水滴屏、破孔屏、异形屏、曲面屏等等简直令人眼花缭乱，唯独没有一款让我感到熟悉的非全面屏手机。做软件的时候，会不明白那些似是而非的定制需求的差异，可为什么偏偏到了硬件的时候，大家就能被迫适应这些越来越同质化的东西呢？也许有和我一样怀念非全面屏的人，可对于这个时代而言，一切都好像无足轻重，喜欢魅族对产品的设计，喜欢小而美的不妥协，可当大家都越来越相似的时候，也许，是因为我们终于都长大了吧，而怀念则是一种可有可无、甚至有一点多余的东西。在被告知一切向前看的路上，我们能拥有、用留住的东西本就不多，可偏偏我们就在给世间一切东西，努力刻上时间的温度，经历着花繁叶茂，经历着落叶归根。
写博客，曾经是件很有意思的事情，透过网页去读每条留言背后的人，常常令你产生神交已久的感觉，即便网络如此发达的今天，让一个人失散，无非是动动手指拉黑、删除。陈星汉先生有一款游戏作品叫做《风之旅人》，游戏里的玩家依靠某种微弱的信号相互联系，而一旦失散彼此，将永远迷失在浩瀚无际的沙海里，你说，这是不是有人生本身的意味在里面呢？再后来 140 个字符的微博开始流行，而这些沉迷在博客时代里的人们，或固执地继续在博客这一方天地里挥洒，或搭乘移动互联网的 “高铁” 通往新的彼岸。有人这样比喻朋友圈和微博，说朋友圈装饰别人梦境的月亮，而微博则是装饰自己梦境的镜子。其实呢，在隐私问题基本荡然无存的今天，我们都只是在装饰资本的 “窗户” 吧！
曾经运营过一段时间的微信公众号，最后发觉还是博客的载体更适合自己，虽然这些年没少为博客投入 “钱财”，在博客时代一去不复返的时间禁锢里，通过博客来盈利的想法堪堪聊以自慰，更不必说后来流行起来的 “在线教育” 和 Vlog。有人说，靠工资是没有办法挣到钱的，挣钱要靠这些 “睡后收入”，可当一件事物风头正盛的时候，彼时的你不足以追逐这一切的时候，这种感觉该如何言明呢？大概就像你在最落魄的时候，遇到一生中最想要保护的那个人一样，这听起来多少有点讽刺，人在不成熟的时候，总是后知后觉，可有一天真成熟了，再难有那时的运气或是豪气。所以呢，继续写下去吧，也许有一天，当你看着从前写的幼稚的文字，或哭或笑皆可入题，这不就是 “嬉笑怒骂，皆成文章” 了吗？
果然，一不小心又扯远了。虽然说博客平时没什么流量，可像搜索引擎优化(SEO)、前端构建(CI/CD)、PWA 等等这些东西倒是有所钻研，提高博客访问量的方式除了增加搜索引擎里的权重和曝光率以外，其实，还有一种方式就是减少跳出时间。换句话说，访客在你博客里停留的时间越长，这意味着你有更多的内容可以被对方访问到，所以，增加内链是一个不错的思路。最直接的方式，就是在每篇博客结束以后推荐相关的博客供访客继续阅读。之前曾经尝试过像 hexo-recommended-posts 这样的插件，坦白说效果不是特别好，因为有时候加载这些站外的内容，导致博客页面打开的时候异常卡顿，所以，我们今天将采用原生的 JavaScript 来为 Hexo 实现博客推理功能，希望对大家有所启发。
首先，我们来说说原理，推荐系统一般是需要一部分量化的指标来表征不同内容的相关性的。譬如通过 TF-IDF 来计算文本的相似度，通过公共词袋中的词频构造向量再配合余弦公式来计算，通过 TextRank 这类借鉴 PageRank 思想的方法来计算等等。这里呢，我们不采用这些方法来实现，主要是考虑到 200 篇左右的博客，两两计算相似度特别耗费时间，对于 Hexo 这种静态博客而言，我们还是应该节省生成静态页面的时间，虽然这部分时间都是 Travis CI 去跑的(逃……。我们采用的方案是基于标签和日期的推荐方式，即根据当前文章的标签筛选相同标签的文章，根据当前文章的日期筛选相同日期的文章。有了这两种策略，配合 Hexo 中提供的全局变量，我们可以很容易地编写出下面的代码：
&amp;lt;% function shuffle(a) { for (let i = a.length; i; i--) { let j = Math.floor(Math.random() * i); [a[i - 1], a[j]] = [a[j], a[i - 1]]; } return a; } function recommended_posts(page, site, limit = 5) { page.</description></item><item><title>使用 jsDelivr 为 Hexo 博客提供高效免费的CDN加速</title><link>http://example.org/posts/1417719502/</link><pubDate>Wed, 05 Feb 2020 19:01:00 +0000</pubDate><guid>http://example.org/posts/1417719502/</guid><description>最近给博客做了升级，从 3.x 升级到了 4.x，主要是在官网看到了关于静态页面生成效率提升的内容。众所周知，Hexo 在文章数目增加以后会越来越慢。博主大概是从 14 年年底开始使用 Hexo 这个静态博客的，截止到目前一共有 176 篇博客，其中的“慢”可想而知，中间甚至动过使用 Hugo 和 VuePress 的念头，所以，听说有性能方面的提升，还是决定第一时间来试试。整个升级过程挺顺利的，唯一遇到的问题是关于外部链接检测方面的，具体可以参考这里。今天，博主主要想和大家分享下关于如何使用jsDelivr来为博客提供免费、高效的 CDN 服务，希望对大家有所帮助。
jsDelivr是一个免费、快速和可信赖的 CDN 加速服务，官网上声称它每个月可以支撑680亿次的请求。博主是在去年年底的时候，偶然了解到这个服务的存在，这次趁着疫情肆虐的间隙，终于把这个服务集成到了博客中。更重要的是，这个服务在 Github 上是开源的。目前，它提供了针对npm、Github和WordPress的加速服务，只需要一行代码就可以获得加速效果，以常用的jQuery和Bootstrap为例：
// load jQuery v3.2.1 https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js // load bootstrap v4.4.1 https://cdn.jsdelivr.net/npm/bootstrap@4.4.1/dist/js/bootstrap.js 这意味着我们只需要发布一个 npm 的包，就可以使用它提供的加速服务。CDN 加速的好处我这里就不再多说了，只要我们的项目中用到了第三方的静态资源，譬如 JavaScript/CSS 等等都应该考虑接入到 CDN 中。有人常常担心 CDN 挂掉或者是私有化部署无法接入外网环境。我想说，我们目光应该长远一点，现在早已不是早年那种单打独斗式的开发模式了，我们不可能把所有资源都放到本地来。随着云计算的概念越发地深入人心，越来越多的基础服务都运行在一台又一台虚拟化的“云服务器”上，这种情况下，搞这种集中化配置的做法，是完全违背分布式的发展趋势的。
如果说，针对 npm 包的 CDN 加速服务离我们还有点遥远，因为我们大多数情况下都是在使用别人写好的库。那么，接下来，针对 Github 的 CDN 加速服务应该会让我们无比兴奋吧，毕竟 Github Pages 的“慢”大家是可以感受得到的。不然，为什么大家要用 Coding Pages 做国内/国外的双线部署呢？首先，我们在浏览器里输入下面这个地址：https://cdn.jsdelivr.net/gh/qinyuanpei/qinyuanpei.github.io@latest/
jsDelivr提供的CDN加速资源此时，可以注意到，jsDelivr可以把我们 Github 上的资源呈现出来，只要我们在 Github 上发布过相应的版本即可。这里的版本，可以理解为一次 Release，对应 Git 中 tag 的概念，虽然 Github 现在引入了包管理器的概念，试图统一像 npm、nuget、pip 等等这样的包管理器。它提供的 CDN 服务有一个基本的格式：</description></item><item><title>Valine 搭配 Server 酱实现博客评论推送</title><link>http://example.org/posts/369095810/</link><pubDate>Wed, 06 Nov 2019 18:15:14 +0000</pubDate><guid>http://example.org/posts/369095810/</guid><description>Valine是一个基于LeanCloud的评论系统，在很长的一段时间里，一直作为多说、Gitalk、Gitment等等的一个替代品，博主所使用的评论系统实际上就是 Valine，虽然独立博客的整体活跃度无法媲美专业博客，可还是想在这纷扰的世界里有自己的一方天地啊。多说评论的关闭，某种意义上来说，是很多 90 后站长们关于互联网的集体记忆，因为从博主搭建第一个 WordPress 博客的时候，多说就一直作为首选的评论系统而存在。那个时候通过多说就能接入主流的社交媒体，对于一个还不大会编写 Web 应用的博主来说，此刻想来实在是有种时过境迁的感觉。所以，Valine 作为一个相当优秀的评论系统，凭借着简洁大方的界面和开箱即用的优势，在这个时间点进入人们的视野，我们就不难理解，为什么它会成为博客作者们的“新宠”。
Valine 本身是利用 LeanCloud 的数据存储 SDK 来实现评论的读写的，所以，它相对于“多说”这种第三方的服务，在数据安全性上更有保障一点，虽然“多说”在关闭评论服务以前，提供了导出 JSON 格式评论信息的功能。可话说回来，以国内这种“敏感”的网络环境，其实没有一家云服务提供商敢打这样的包票，像阿里云、LeanCloud、七牛云存储这些服务，都曾经出现过宕机或者封杀域名的事情，所以，趁着数据还在自己手上，尽可能地做好备份工作吧！Valine 本身并没有提供评论推送的功能，我还是挺怀念过去“多说”推送评论到邮箱的功能。虽然Valine-Admin这个项目提供了类似的功能，但我感觉使用起来并不顺手，尤其是配置邮箱的时候，国内像 QQ、163 这些都非常麻烦，遇到一两个废弃的手机号，你就会发现短信验证码，是件多么尴尬而繁琐的事情，如同扫码使用的共享电话一般魔幻。
为了解决这个问题，我想到了 Valine 搭配 Server 酱实现评论推送的方案。首先，Valine 是基于 LeanCloud 而开发的，用户发表评论实际上就是向Comment表插入记录。因此，我们可以利用 LeanCloud 提供的Hooks来捕获写入评论的事件。所谓“Hooks”呢，通俗地说就是数据库里触发器的概念，我们可以在数据写入前后做点“小动作”。而Server 酱则是一个消息推送服务，它提供了一个基于 HTTP 的请求接口，通过这个接口，我们就能实现向微信推送消息，前提是关注“方糖”公众号。关于 Server 酱的原理大家可以进一步去看它的文档，我们这里只需要考虑怎么样把它们结合起来，这就是工程师和科学家的区别所在[doge]。
运行在Valine云引擎中代码LeanCloud 提供了一个称作“云引擎”的环境，它可以提供运行比如 Nodejs、Python 等等的环境，实际上，Valine-Admin这个项目就是用 Nodejs 编写的，你可以理解为，只要你的应用符合它的规范，就能在它的环境里运行，这就是所谓的“FAAS”(函数即软件)和“BAAS”(后端即软件)。所以，说白了我们就是想利用它这个“云引擎”来调用 Server 酱的接口，幸运的是，LeanCloud 提供的 Hooks 目前是支持 Nodejs 的，所以，到这里思路就非常清晰了，我们给Comment这张表加一个AfterSave类型的 Hooks，在保存完以后调用 Server 酱接口推送评论信息即可。创建 Hooks 是在部署-&amp;gt;云引擎选项下，我们来看下面的代码：
AV.Cloud.afterSave(&amp;#39;Comment&amp;#39;, async function(request) { var http = require(&amp;#34;request&amp;#34;); var obj = request.object; console.log(&amp;#39;收到一条新的评论：&amp;#39; + JSON.stringify(obj)); var title = &amp;#34;收到一条新的评论&amp;#34;; var url = request.</description></item><item><title>博客图片迁移折腾记</title><link>http://example.org/posts/3444626340/</link><pubDate>Fri, 18 Jan 2019 09:27:35 +0000</pubDate><guid>http://example.org/posts/3444626340/</guid><description>去年国庆的时候，七牛官方开始回收测试域名，这直接导致博客中大量图片出现无法访问的情况，虽然博主第一时间启用了新的域名：https://blog.yuanpei.me，可是因为七牛官方要求域名必须备案，所以，这件事情一直耽搁着没有往下进行。至于为什么会一直拖到 2019 年，我想大家都能猜到一二，没错，我就是懒得去弄域名备案这些事情:joy:。最近花了点时间，把博客里的图片从七牛和 CSDN 迁移了出来，所以，今天这篇博客，主要想和大家分享下这个折腾的过程，如果能帮助到和我一样，因为七牛官方回收了域名而无法导出图片的朋友，在下开心之至。虽然今天没有回望过去，没有给新的一年立 flag，就如此平淡地过渡到了 2019 年，可或许这才是生活本来的样子吧！
七牛的测试域名被官方回收了以后，我们有两种思路去导出这些图片，其一，是临时像官方提工单申请一个测试域名，这样在测试域名被回收前，我们可以直接使用官方提供的qrsctl或者qshell工具进行批量导出，因为此时我们可以直接在配置文件里配置测试域名，具体可以参考这篇文章：跑路之后七牛图片如何导出备份至本地，甚至你可以直接到七牛的管理控制台手动下载，可这样就一点都不极客了对吗？我们是一生追求做极客的人好伐。其二，同样是借助官方提供的qshell工具，因为没有域名，我们没有办法批量导出，可是工具中提供了两个非常有用的命令，它们分别是：qshell listbucket、qshell get。通过这两个命令，我们就可以列举出指定 bucket 中的文件以及下载指定文件，所以，这就是我们的第一步，首先把图片从七牛那里导出到本地。以博主的blogspace为例：
qshell account &amp;lt;ak&amp;gt; &amp;lt;sk&amp;gt; &amp;#39;qinyuanpei@163.com&amp;#39; /* 请使用你的ak/sk，谢谢 */ qshell listbucket blogspace 使用listbucket列举指定bucket内文件事实上，通过第一列的 Key，即文件名，我们就可以下载该资源到本地，因为七牛实际上是采用对象存储的方式来组织资源的，这里我们以第一张图片05549344-BF85-4e8c-BCBC-1F63DFE80E43.png为例：
qshell get blogspace 05549344-BF85-4e8c-BCBC-1F63DFE80E43.png 默认情况下，该图片会下载到当前目录下，本地文件和远程文件名保持一致。当然，我们还可以通过-o 参数来指定输出文件：
使用get命令下载指定文件好了，有了这个基础，我们就可以着手博客图片的迁移啦。博主最初的想法是，先获取到指定 bucket 下的全部文件，然后再对结果进行拆分，循环执行 qshell get 命令，可惜再 PowerShell 下并没有类似 grep 的命令，所以，这个想法放弃。其实，你仔细观察七牛图片外链的格式就会发现，除了域名部分以外，剩下的就是该文件在 bucket 里对应的 key 啦，所以，博主的想法开始从 Markdown 文件入手，最终我们的思路是，解析博客对应的 Markdown 文件，通过正则匹配所有的图片链接，截取出图片的文件名并通过 qshell 下载到本地。人生苦短，我用 Python。具体写出来，大概是下面这个样子：
def sync(root,ak,sk,account,bucket): files = [] children = os.listdir(root) for child in children: path = os.</description></item><item><title>基于 Travis CI 实现 Hexo 在 Github 和 Coding 的同步部署</title><link>http://example.org/posts/1113828794/</link><pubDate>Tue, 27 Feb 2018 10:45:04 +0000</pubDate><guid>http://example.org/posts/1113828794/</guid><description>各位朋友，大家好，我是 Payne，欢迎大家关注我的博客，我的博客地址是 https://qinyuanpei.github.io .在曾经的一篇博客：《持续集成在 Hexo 自动化部署上的实践》中，我为大家分享了在线持续集成服务 Travis CI 的相关内容，在这篇文章中我们通过 Travis CI 为 Hexo 提供了自动部署的支持。其原理是 Github 为 Travis CI 分配一个 token，当我们向 Github 推送新的代码以后，Travis 就会从代码仓库中拉取代码，并通过 npm 安装依赖生成静态页面，我们将这些静态页面推送到 master 分支，即可完成对 Hexo 的部署操作。这个流程从去年 10 月份建立以来，一直运行得非常稳定，对我个人而言，随着博客里得内容越来越多，在本地生成静态页面需要 20 多秒得时间，而有了持续集成服务以后，我可以用这个时间去做更多的事情，当持续集成流程发生异常的时候，微信上会收到 Travis 发送的邮件，整个过程简直令人心情愉悦。
今天想继续写点这个话题相关的内容，即如何通过 Travis CI 实现 Hexo 在 Github 和 Coding 的同步部署。显然，部署 Hexo 到 Github Pages 我们已经实现，今天我们着重来说 Coding Pages。为什么我们需要 Coding Pages 呢？主要从两个方面考虑，首先，因为 Github Pages 屏蔽了百度的爬虫，所以我们托管在 Github 上的博客，无法被搜索引擎正常收录；其次，由于 Github Pages 的服务器在国外，所以在国内博客的速度会受到影响，而且**&amp;ldquo;防火墙&amp;rdquo;**的国情决定了 Github 是一个不稳定的网站。曾经经历过短时间内无法使用 Github 的情形，故而，为了保证博客可以更加稳定地运行，我们必须为博客提供一个备份镜像，这就是我们今天要提到的 Coding Pages 服务啦。在正式使用这个服务前，我们首先简单介绍下这个服务。</description></item><item><title>使用 Python 生成博客目录并自动更新 README</title><link>http://example.org/posts/1329254441/</link><pubDate>Fri, 23 Feb 2018 09:32:45 +0000</pubDate><guid>http://example.org/posts/1329254441/</guid><description>各位朋友，大家好，我是 Payne，欢迎大家关注我的博客，我的博客地址是：https://qinyuanpei.github.io。首先在这里祝大家春节快乐，作为过完年以后的第一篇文章，博主想写点内容风格相对轻松的内容。自从博主的博客采用 TravisCI 提供的持续集成(CI)服务以以来，博客的更新部署变得越来越简单，所有的流程都被简化为 Git 工作流下的 提交(commit) 和 推送(push) 操作。考虑到博客是托管在 Github 上的，一直希望可以自动更新仓库主页的 README 文件，这样可以显示每次提交代码后的变更历史。基于这样一个构想，我想到了为博客生成目录并自动更新 README，其好处是可以为读者建立良好的文档导航，而且 Markdown 是一种简单友好的文档格式，Github 等代码托管平台天生就支持 Markdown 文档的渲染。关于博客采用 TravisCI 提供持续集成(CI)服务相关内容，可以参考 持续集成在 Hexo 自动化部署上的实践 这篇文章。
好了，现在考虑如何为博客生成目录，我们这里需要三个要素，即标题、链接和时间。标题和时间可以直接从 _posts 目录下的 Markdown 文档中读取出来，链接从何而来呢？我最初想到的办法是读取每个 Markdown 文档的文件名，因为我的使用习惯是采用英文命名，这样当博客的永久链接(permalink)采用默认的 :year/:month/:day/:title/ 形式时，每个 Markdown 文档的文件名等价于文章链接。事实证明这是一个愚蠢的想法，因为当你改变永久链接(permalink)的形式时，这种明显投机的策略就会彻底的失败。相信你在浏览器种打开这篇文章时，已然注意到链接形式发生了变化，当然这是我们在稍后的文章中讨论的话题啦。至此，我们不得不寻找新的思路，那么这个问题该如何解决呢？
我意识到我的博客配置了 hexo-generator-json-content 插件，这个插件最初的目的是为博客提供离线的搜索能力，该插件会在博客的根目录里生成一个 content.json 文件，而这个文件中含有我们想要的一切信息，因此我们的思路转变为解析这个文件，人生苦短啊，我果断选择了我最喜欢的 Python，这里我们会提取出所有的文章信息，按照日期由近到远排序后生成列表。Python 强大到让我觉得这篇文章无法下笔，所以这里直接给出代码啦：
# -*- coding: utf-8 -*- import os import re import sys import json import datetime # 文档实体结构定义 class Post: def __init__(self,date,link,title): self.date = date self.link = link self.</description></item><item><title>迁移 Hexo 博客到 Google 渐进式 Web 应用(PWA)</title><link>http://example.org/posts/450254281/</link><pubDate>Tue, 24 Oct 2017 23:13:41 +0000</pubDate><guid>http://example.org/posts/450254281/</guid><description>如果说通过 TravisCI 实现博客的自动化部署，是持续集成这个概念在工作以外的一种延伸，那么今天这篇文章想要和大家分享的，则是我自身寻求技术转型和突破的一种挣扎。前段时间 Paul 同我聊到 Web 技术的发展趋势，Paul 认为 Web 应用会逐渐取代原生应用成为主流，我对此不置可否。真正让我陷入思考的是，在这个充满变化的时代，知识的更新速度远远超过你我的学习速度，我们应该如何去追随这个时代的步伐。如同那些淹没在时间河流里的技术名词，当青春不再的时候，我们喜欢把这个过程称之为成长，当发现距离第一次使用 FontPage 制作网站已过去十年，当发现曾经的网页三剑客在岁月蹉跎里频频改换姓名，当发现那些淹没在历史里的技术来不及学习就成为过往&amp;hellip;&amp;hellip;或许，这个世界真正迷人的地方，就在于它每天都在不断变化。
新一代Web应用——PWA 接着 Paul 关于 Web 技术的这个话题，我认为 Web 技术在短期内会成为原生应用的一种补充。事实上，原生应用和 Web 应用哪一个会是未来，这个问题的争论由来已久，在业界我们可以看到 HTML5、PhoneGap、React/React Native、Electron/NW.js、小程序等方案百家争鸣，每一种方案都可以让我们去 Web 技术去打破平台间的差异。与此同时，我们注意到移动开发领域对原生技术的需求在缩减，虽然马克·扎克伯格曾表示，“选择 HTML5 是 Facebook 最大的错误“，可我们注意到，越来越多的 Web 技术被运用在原生应用中，Web 技术被认为是最佳的打造跨平台应用的技术，可以通过一套代码实现不同平台间体验的一致性。我们注意到知乎和天猫的客户端中都混合使用了一定的 Web 技术，因为纯粹使用原生技术去开发一个移动应用，其最大的弊端就在于我们要为 Android 和 iOS 维护两套不同的代码，从国内曾经疯狂火热的 iOS 培训就可以看出，单独使用原生技术去开发客户端，其成本实际上是一直居高不下的。
虽然我们有 Xamarin 这样的跨平台技术，试图用一种编程语言和代码共享的方式，去开发两种不同平台的应用程序，可是我们注意到，平台间的差异和抗阻是天然存在的，就像SQL和面向对象这样我们再熟悉不过的例子。同样的，Facebook 的 React Native 项目，试图用Web技术去弱化平台间的差异，React Native 存在的主要问题是，它依然依赖原生组件暴露出来的组件和方法，所以像 DatePickerIOS、TabBarIOS 等控件是 iOS Only的，这意味着在开发过程中开发者还是要考虑平台间的差异性，其次 React 本身的JSX(对应HTML)、CSS Layout(对应CSS)本身是具有一定的学习曲线的，虽然底层因为没有使用WebView的原因提高了部分性能，然而整体上是牺牲了扩展性的。总而言之，这是一个介于 Web 技术和原生技术之间的中间技术，在我看来地位着实蛮尴尬的，因为无论在Web层还是Native层都选择了部分妥协，完美实现跨平台真心不容易啊。
要掌握一门新技术，最好的方法就是去应用它。我的博客使用的是 Indigo主题，这是一个典型的 Material Design 风格的主题，所以我一直想尝试将其改造成原生应用，我曾经接触过移动端应用开发，如果通过 WebView 内嵌网页的方式来实现，我需要处理离线状态下页面的显示问题，以及所有混合应用开发都会遇到的一个问题，即原生应用层需要和Web应用层进行通信的问题。而如果采用 Hybrid App 的思路去开发一个混合应用，意味着我需要去学习 Cordova 这样的 Hybrid 开发框架，去了解 JavaScript 和 Native 交互的细节。那么有没有一种学习成本相对较低，同时可以提供原生应用体验的思路呢？答案是确定的，这就是我们下面要说的渐进式应用(PWA)。</description></item><item><title>在 Hexo 中为文章自动添加版权信息声明模块</title><link>http://example.org/posts/2950334112/</link><pubDate>Sun, 15 Nov 2015 13:12:22 +0000</pubDate><guid>http://example.org/posts/2950334112/</guid><description>&lt;p>各位朋友，大家好，欢迎大家关注我的博客，我是秦元培，我的博客地址是&lt;a href="http://qinyuanpei.com">http://qinyuanpei.com&lt;/a>。今天想和大家说说博客文章版权这件事情。每当提到版权的时候，我知道大家内心深处都是对此不以为然的，因为国内版权意识薄弱，所以版权在我们的眼中就变成了这样一件可有可无的东西，可是事实真的是这样的吗？首先我们必须承认一件事情，即你从互联网上获得的知识都是有价值的，即使这些知识的创造者并未因此而获得利益。&lt;/p></description></item><item><title>为 Hexo 开发一个网易云音乐的文章插件</title><link>http://example.org/posts/828223375/</link><pubDate>Tue, 24 Mar 2015 10:32:39 +0000</pubDate><guid>http://example.org/posts/828223375/</guid><description/></item><item><title>使用 Coding.NET 和 Hexo 实现网页游戏的发布</title><link>http://example.org/posts/1150071886/</link><pubDate>Tue, 24 Mar 2015 08:54:48 +0000</pubDate><guid>http://example.org/posts/1150071886/</guid><description>&lt;p>本文将尝试借助 Coding.NET 的项目演示功能，通过对 Hexo 中支持的发布类型进行扩充，实现可以在 Hexo 中发布网页游戏，从而方便博主展示游戏作品和帮助读者了解游戏效果。&lt;/p></description></item></channel></rss>